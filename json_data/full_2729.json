{
  "original_filename": "full_2729.md",
  "国内中文分词技术研究新进展": "",
  "冯书晓徐　新 杨春梅": {
    "context1": "(石河子大学药学院乌鲁木齐832002)",
    "context2": "摘要就开发中文搜索引擎在汉语语言方面的关键技术之一，即中文分词技术进行综述。关键词中文搜索引擎中文分词文献检索",
    "context3": "搜索引擎通常由信息收集和信息检索两部分组成。对于英文，由于英文中词与词之间是用空格隔开，检索起来很方便，故计算机采用了词处理的方式，大大减轻了用户与计算机的工作量；相对来讲，中文的情形就复杂得多。中文的词与词之间是没有分隔符的，因此若想建立基于词的索引，就需要专门的技术，这种技术被称之为\"汉语词语切分技术”。根据是否采用词语切分技术，中文搜索引擎又可分为基于字的搜索引擎和基于词的搜索引擎。由于中文信息处理的特殊性和复杂性，中文搜索引擎技术还很不成熟，开发中文搜索引擎决不像西文软件的汉化那样简单。在实现中文搜索引擎时，不能照搬国外现成的技术，需要对中文的信息处理技术作专门地研究。自然语言理解领域的应用已经越来越广，但是几乎任何一个基于汉语的系统，都必须经过分词这一步。自动分词系统是中文信息处理中的一个主要组成部分，是中文自然语言理解、文献检索、机器翻译即语音合成系统中最基本的一部分。在搜索引擎中，为了进行中文信息小型化，需要提取关键知识,也就是说首先要分隔出单个的中文词语，然后进行词频统计得到关键词。要开发中文搜索引擎，快速的汉语分词算法和可靠的汉化技术是至关重要的。本文将针对中文分词技术及近年来中文分词技术的发展作一综述。"
  },
  "1中文分词技术": {
    "context1": "1.1中文词的特点与英文不同,字是汉语的基本独立单位，但是具有一定语义的最小单位却是词。词由单个或多个字构成，一般用得最多的是二字词，其次是单字词,另外还有一些多字词(如成语、",
    "context2": "专有名词等)。",
    "context3": "1.1.1数量多。汉语中常用的词有几万条，《现代汉语词典》中收录的词就达6万个之多。而且，随着社会的发展，不断地有新词产生。",
    "context4": "1.1.2使用灵活、变化多样,容易产生歧义。例如同样的两个连续汉字，在有的句子中构成一个词，而在另外的句子环境中，却可能不构成词。这给计算机的词法分析工作带来了极大的困难。",
    "context5": "1.1.3书写习惯。在英文系统中，词与词之间在书写上用空格隔开，计算机处理时可以非常容易地从文档中识别出一个一个的词。而在汉语系统中，书写以句子为单位，句间有标点隔开，在句内，字和词则是连续排列的，它们之间没有任何分隔。这样，如果要对中文文档进行基于词的处理，必须先要进行词的切分处理，以正确地识别出每一个词。",
    "context6": "1.1.4其它特点。诸如汉字同音字、同音异形字等等。",
    "context7": "1.2一般分词方法目前采用的分词方法主要有以下几种：最大匹配法、反向最大匹配方法、逐词遍历法、设立切分标志法、最佳匹配法、有穷多层次列举法、二次扫描法、邻接约束方法、邻接知识约束方法、专家系统方法、最少分词词频选择方法、神经网络方法等等。除了这些，许多基于统计的方法也引入到分词过程中。例如分词与词性标注一体化方法，随机有限状态算法用于分词，模拟物理研究中结晶过程的统计方法也被尝试于分词过程。此外，还有大量的基于统计或规则的汉语未登录词识别的研究，这里不能一一列举。但归纳起来不外乎两类：一类是理解式切词法,即利用汉语的语法知识和语义知识以及心理学知识进行分词，需要建立分词数据库、知识库和推理机;另一类是机械式分词法，一般以分词词典为依据，通过文档中的汉字串和词表中的词逐一匹配来完成词的切分。下面笔者就以此对近年来中文分词技术的进展分类作一综述。"
  },
  "2中文分词技术的进展": {
    "context1": "目前的分词算法多种多样，基本上可分为两大类：机械性分词和理解性分词法。后者可谓理想的方法，但在语法分析、语义分析乃至篇章理解还没有得到解决之前，其分词实用系统主要采用机械分词法，但实际上纯机械性分词也无人在用，一般都使用介于二者之间的某种分词法。在此，本人称之为综合式分词法，收录了由作者本人明确指出同时采用了机械式分词法和理解式分词法的文章。",
    "context2": "2.1机械式分词法邹海山等在现有分词技术的基础上，提出了一种基于词典的正向最大匹配和逆向最大匹配相结合的中文分词方案，可以高效、准确地实现中文文档的主题词条的抽取和词频统计。应志伟等基于一个实际的文语转换系统，介绍了它的一些处理方法，采用了一种改进的最大匹配法，可以切分出所有的交集歧义,提出了一种基于统计模型的算法来处理其中的多交集歧义字段，并用穷举法和一些简单的规则相组合的方法从实用角度解决多音字的异读问题以及中文姓名的自动识别问题，达到实现文语转换的目的。陈桂林等首先介绍了一种高效的中文电子词表数据结构，它支持首字Hasb和标准的二分查找，且不限词条长度，然后提出了一种改进的快速分词算法。在快速查找两字词的基础上，利用近邻匹配方法来查找多字词，明显提高了分词效时问关异么。以派血、示顺于不用丕」日动建立词库的最佳匹配方法来进行中文分词,同时采用基于改造型马尔可夫N 元语言模型的统计处理方法来处理分词中出现的歧义问题,从而提高精度。三字长交集型分词歧义是分词歧义的主要类型之一,在真实文本中的出现频率相当高。孙茂松等提出了一种针对这种分词歧义的消解算法，回避了训练代价比较高昂的词性信息而仅仅利用了词的概率信息及某些具有特定性质的常用字集合。从一个60 万字的汉语语料库中抽取出全部不同的三字长交集型分词歧义共5367个作为测试样本。实验结果表明，该算法的消解正确率达到了 $9 2 . 0 7 \\%$ ,基本可以满足实用型中文信息处理系统的需要。郭祥昊、钟义信、杨丽提出了一种快速汉语自动分词算法。其主要思想是利用汉语中两字词占 $7 5 \\%$ 的统计规律,提出了两字词根和两字词簇的概念。算法把三音节以上的词用两字词簇来压缩处理,也就是把长词的扫描范围限定在词汇量很小的词簇内，从而不仅提高了分词速度，而且彻底解决了传统最大匹配分词算法中最大匹配词长的设定问题。另外，本文还提出了用两字词簇快速检测交叉歧义的算法。本文的分词算法简洁、速度快、易于实现。张翠英介绍一种在最大匹配法基础上，根据大量的真实语料中出现的歧义现象，把可能产生歧义切分的词进行特性分类，对每类确定一组规则进行处理。但不足之处是它不包含由于专用名词引起的歧义问题,由于专用名词(尤其是人名、地名)无法枚举,有限的词库规模无法满足这类问题的分词需要,它有待于自然语言理解各方面对这类问题的新的处理成果的应用。而李建华、王晓龙描述了一种有效的中文人名识别方法。它的基本原理是在大规模语料统计的基础上，利用知识源在文本上进行规则的施加与松弛，并引入概率分析器来提高识别的准确率和召回率。实验结果表明,在兼顾识别的准确率与召回率的情况下，系统取得了良好的效果。孙建军、陈肇雄等以语言文字的表达特征为基础，结合汉语词语在语言表达中的具体运用，从语言处理的可计算性角度出发,提出了一种基于多功能逻辑运算分析技术的汉语分词方法。这种汉语分词方法是在汉语电子词典系统支持下实现的，其特点主要表现在构成汉语词语字序列的计算机内部表示上采用了多功能逻辑运算分析技术，从而使汉语分词过程中以往采用的简单模式比较匹配手段转换为多模式逻辑运算下的功能操作，实现了数据表示与数据操作的一体化处理，这不仅在一定程度上提高了汉语自动分词效率，同时也对分词歧义问题的解决提供了有力支持,在具体的应用中表现出较好的实用性和通用性。基于词汇标注的特征项提取方法是中文信息处理的有效方法，但词汇的析取是基于词典的，词典的涵盖程度决定了词汇切分的准确率。因而不断地学习新词汇、动态地维护词典，使整个中文信息处理系统具有自适应性和动态性就成了一个关键问题。以搜索引擎系统为例,提出了一种基于词典动态变化的搜索引擎系统更新理论模型和实现模型。相关实验表明，该模型对缩短搜索引擎信息库的更新时间、提高查询准确率等方面十分有效。",
    "context3": "2.2理解式切词法韩客松等主要从知识的自动获取出发，介绍了研究中的汉语语言的无词典分词模型系统。通过算法的自然语言描述，阐述了模型的思想，分析了它与传统方法相比的优点。该模型尚在实验室中不断地完善，包括对模型的进一步细化、匹配算法的改进、特殊情况的考虑以及系统性能的实验验证等。邓伟等介绍一种针对特定领域的智能搜索引擎。它采用一种新型的概念背景网络来组织领域背景知识，然后在背景网上对领域概念进行概念扩展和相关性比较。与其他搜索引擎相比，该智能搜索引擎能对自然语言进行某种程度的语义理解，利用领域知识来提高搜索的查准率和查全率。",
    "context4": "2.3综合式分词法杨建林、张国梁利用词频统计的结果，优先处理两字词，不考虑最大词长，将传统的最短匹配法改进成在全局或者局部范围内均不依赖最大词长的最短匹配法，同时把匹配过程作了调整，使匹配次数成倍减少，从而显著地提高分词速度。利用上述改进的最短匹配法，找出可能存在歧义的词链，调用歧义词链的处理算法,给出词链的切分结果，从而提高切分的精度。本文定义的算法是一个综合了机械性分词法和理解性分词法的分词方法。"
  },
  "3结束语": {
    "context1": "自动分词是汉语自然语言处理的第一步。目前,汉语自然语言处理的应用系统处理对象越来越多的是大规模语料（如Internet信息搜索引擎，各种全文检索系统等),因此分词的速度和分词算法的易实现性变得相当关键。在多种分词算法中，正向最大匹配分词算法简洁、易于实现，在实际工程中应用最为广泛。但开发中文搜索引擎既要很好的解决汉语语言信息处理问题，又要与国外的其它各种搜索引擎看齐，向智能方向发展。从这方面来看，处理好中文信息处理，特别是中文分词技术是极其迫切、关键的，有待于进一步研究。"
  },
  "参考文献": {
    "context1": "1周涛.中文搜索引擎.图书馆理论与实践.2000  \n2邹海山,吴庸,吴月珠,陈阵.中文搜索引擎中的中文信息处理技术·计算机应用研究，2000  \n3王伟,钟义信等.一种基于EM非监督训练的自组织分词歧义解决方案.中文信息学报，2000;(15)  \n4应志伟,柴佩琪，陈其晖.文语转换系统中基于语料的汉语自动分词研究·计算机应用,2000  \n5欧振猛,余顺争·中文分词算法在搜索引擎应用中的研究·计算机工程与应用,2000  \n6严威,赵政·开发中文搜索引擎汉语处理的关键技术·计算机工程,1999;(25)  \n7陈红英，李卫华.智能信息Agent 的原理和实现方法·计算机系统应用,2001  \n8赵铁军,吕雅娟，于浩等.提高汉语自动分词精度的多步处理策略.中文信息学报.2001;(15)  \n9张翠英·三字歧义链自动分词方法·情报学报，1998;(17)  \n10陈桂林，王永成等.一种改进的快速分词算法·计算机研究与发展，2000  \n11孙茂松，左正平,黄昌宁·消解中文三字长交集型分词歧义的算法·清华大学学报（自然科学版),1999;(39)  \n12郭祥昊,钟义信,杨丽·基于两字词簇的汉语快速自动分词算法·情报学报,1998;(17)  \n13李建华,王晓龙·中文人名自动识别的一种有效方法·高技术通讯,2000;(2)  \n14孙建军,陈肇雄等·基于多功能逻辑运算分析技术的汉语分词·计算机研究与发展，1998;(35)  \n15雷鸣,刘建国,王建勇等．一种基于词典的搜索引擎系统动态更新模型·计算机研究与发展,2000;(37)  \n16韩客松,王永成,陈桂林·汉语语言的无词典分词模型系统.计算机应用研究.1999;(10)  \n17邓伟,张志伟,谭庆平,宁洪．一种新型的智能搜索引擎·计算机工程,2000;(26)  \n18杨建林，张国梁·基于词链的自动分词方法·情报理论与研究，2000",
    "context2": "(责编：钧王京)"
  }
}