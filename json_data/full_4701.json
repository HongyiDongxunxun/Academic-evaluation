{
  "original_filename": "full_4701.md",
  "综 述。": "",
  "基于网络知识资源的术语相似度计算方法综述": "",
  "徐健,肖卓,邓昭俊": {
    "context1": "(1.中山大学资讯管理学院,广东广州510006;2.中山大学图书馆,广东广州510275)",
    "context2": "摘要:在对当前基于网络知识资源的术语相似度计算相关文献进行分析研究的基础上,将其归纳为基于知识资源的术语相似度计算思路、基于搜索引擎的术语相似度计算思路以及术语相似度指标集成计算思路。对各类计算思路的特点和尚存在的不足进行了总结。最后对基于网络知识资源的术语相似度计算的未来研究发展进行展望，旨在为进一步构建高效的术语相似度计算系统提供良好借鉴。",
    "context3": "关键词：术语相似度;相似度计算;知识资源;搜索引擎中图分类号：G302 文献标识码：A 文章编号:1007-7634 (2012)11-1745-06"
  },
  "Research on Term Similarity Computational Methods Based on Network Knowledge Resources": {
    "context1": "XU Jian,XIAO Zhuo,DENG Zhao-jun (1.Information Management School,Zhongshan University,Guangzhou 510006,China;2.Library of Zhongshan University,Guangzhou 510275,China)",
    "context2": "Abstract:Based on the analysis of recent related literatures and projects,the paper concludes the term computational methods that based on network knowledge resources as follws: similarity computational methods based on knowledge resources,similarity computational methods based on search engine,and integration methods of multi-measure methods.It also concludes characters and shortcomings of those methods.Finally,the future development of research on term similarity measure based on network knowledge resources is discussed to help building more effcient term similarity calculation system in further step.",
    "context3": "Keywords:term similarity; similarity measure; knowledge resource; search engine"
  },
  "1引言": {
    "context1": "PhilipResnik认为,术语相似性可以通过它们之间共有的信息量来衡量。共有信息量越高，则相似性越高。本文采用维基百科对术语语义相似度的定义，即术语语义相似度是一个用来说明术语之间语义内容相似程度的度量。通过对术语之间相似程度的计算，能够为自然语言处理和知识挖掘的多项任务开展提供重要支持。术语规范化、识别同义/近义词、基于实例的机器翻译等任务都将术语相似度计算作为任务过程的核心模块。一些学者通过术语的语义相似度计算来发现同义、近义词关系，并基于这些相似关系进行聚类或其它处理任务。例如,PeterDTurney等人基于Web搜索引擎返回的检索命中数,提出了PMI-IR方法来识别同义词。Ping Chen等人使用Google Distance相似度算法自动生成检索词集合。此外,在本体构建和知识库构建任务中，通过计算术语语义相似度，能够发现术语之间存在的新关系，并在此基础上实现本体自动构建。",
    "context2": "当前主要术语语义相似度计算思路可归纳为两类，即基于领域文集本身所携带的语词、句法、语境等特征开展相似度计算，以及基于本体、搜索引擎等网络知识资源开展相似度计算。基于领域文集的相似度计算方法的计算结果受到术语在文集中出现实例数量的影响，因此这类算法的计算效果很大程度上取决于文集的大小和质量。而基于网络知识资源的相似度算法则充分利用网络知识资源的丰富性较好地解决了这一问题。许多学者在基于WordNet、Wiki等开放知识资源进行术语语义相似度计算方面进行了有益尝试。网络搜索引擎也可以被看作一种特殊的知识资源，通过检索获得的命中数和摘要信息可以用来进行术语语义相似度计算。本文重点对近年来发展较快的基于网络知识资源的相似度计算理论及方法进行梳理和探讨。"
  },
  "1基于知识资源的术语相似度计算思路": {
    "context1": "随着各种本体、知识库等网络知识资源相关研究和实践的开展，近年来因特网中能够被访问的知识资源呈现出快速增长的势头。这些知识资源的知识组织以网状或树状结构为主,知识点之间的关联结构清晰，语义信息丰富，这就为术语之间以关联结构为计算依据的相似度计算提供了良好素材。此外,在资源质量方面，网络知识资源组织规模通常较为庞大，能够提供更为客观的计算基础。目前已经有一些学者在基于WordNet、Wiki等开放知识资源进行术语相似度计算方面进行了有益尝试。"
  },
  "1.1基于概念节点间距离的相似度计算思路": {
    "context1": "在知识分类体系中，两个概念对应节点之间的距离反映了它们之间的语义关联程度。节点之间距离越近，则节点对应概念之间的相似程度越高。利用这一规律可以开展术语语义相似度计算。RoyRada等人b-在解决检索式和文档匹配问题时，提出相似性测度可以通过分类体系或词表中语词对应节点之间的距离来确定。如果两个语词对应节点之间的路径越短，它们越相似。如果有多条路径，则选择最短的路径作为计算依据。Resnik基于信息内容概念,在IS-A分类体系中提出了一个新的语义相关性测度。Resnik认为,两个概念之间的相似性本质是它们具有共同信息的程度，这在一个IS-A分类体系中可以通过两个概念共有的最直接的上位类体现出来。通过路径边数统计的方法来判断概念之间的相似度在一定程度上也体现出了两个概念之间共有信息量这个指标，因为如果两个节点的IS-A链接的最小路径很长，那意味着它们共有的最临近上位类处在更高的层次。Resnik使用分类体系中某个概念的实例出现的概率作为衡量该概念信息量的指标，而两个概念的共同信息量可以通过这两个概念的最临近共同上位类的概率来衡量。",
    "context2": "除了术语之间的路径长度特征能够反映相似程度，术语对应节点所处的层次树深度以及区域密度等因素同样会影响到相似度计算的结果。这是因为,路径长度相同的两个结点,如果位于概念层次的越底层，一般来说其语义距离就越大如：动物”和植物\"“哺乳动物'和‘爬行动物”这两对概念间的路径长度在WordNet中都是2,但前一对词处于语义树的较高层，语义相似度较小，后一对词处于语义树的较低层，语义相似度较大。另外，路径长度相同的两个结点，如果位于概念层次树中结点较密集的区域，其语义相似度一般会小于位于低密度区域的情况。EnekoAgirre等人在利用WordNet计算词语的语义相似度时，就将概念结点间的路径长度因素和概念结点所处的层次树的深度以及区域密度因素结合在一起完成相似度计算，取得了良好的效果。类似的计算思路在LipingJing等人进行的文本聚类任务中,也有明确体现。"
  },
  "1.2利用知识资源语义信息进行相似度计算的思路": {
    "context1": "知识资源本身所体现的语义信息也能够被用于相似度计算。一种普遍被认可的典型计算思路是：在相同句法角色中的语词，如果与相似名词或动词搭配,则这些语词之间很可能是语义相似的。可以使用WordNet等知识资源来自动判断动词之间的相似性，并根据名词和这些动词的搭配情况，间接判断这些名词之间的相似性。具有代表性的研究为MahmoodNeshati等人开展的基于WordNet的语词相似度计算研究。此外,Andrzej Sieminski在进行网页链接文字相似度计算时，还提出了借助WordNet识别待计算语词的共同概念下位词，然后通过计算共同概念下位词的信息内容(InformationConteni)来反映两词之间相似度的计算方法。",
    "context2": "随着研究的进一步深入，除本体以外的一些网络密集知识资源也逐渐被作为相似度计算的数据基础。MandarA.Rahurkar等人[在识别特定语词具体有几个意义的任务中,使用Wiki来计算语词之间的相似度。他们认为,如果两个概念共享一个出站和入站链接的子集，那么这两个概念很有可能是相似的,并据此提出了基于Wiki的语词相似度计算方法。",
    "context3": "基于知识资源的术语相似度算法的特点是利用语词概念在开放的语词知识体系中对应节点之间的距离来衡量语词之间的相似程度。这类算法充分利用了现有语词知识体系的结构或语义信息，具有计算实现简单、计算准确率较高的特点。虽然以WordNet、Wiki等开放知识资源为代表的语词知识体系具有的丰富语义信息可以作为判断术语语义相似度的依据，但是在利用过程中也存在一些局限性。以WordNet为例,它所收录的语词多为常见语词，如果直接将其应用于语义较为专指的特定领域科研术语的相似度计算，则会因为大量的专业术语未在WordNet中收录而影响到计算效果。为了克服以上弊端，可以将多个具有互补性的知识资源共同作为计算术语相似度的数据基础，通过知识资源的联合来提升术语出现频率以及术语语义信息量，从而提升计算效果。"
  },
  "2 基于搜索引擎的术语相似度计算思路": {
    "context1": "与传统文集中术语共现能够体现术语间相似度的原理类似，在Web网络庞大的文档集合中的术语共现特征也能够被直接用来作为衡量术语间相似程度的指标。应用 $\\mathrm { { W e b } }$ 网络文献进行术语相似度计算的关键是如何获得术语在 $\\mathrm { { W e b } }$ 文集中的单独出现指标、共现指标以及出现语境等信息，而商业搜索引擎提供了方便的 $\\mathrm { { W e b } }$ 网络文集访问途径，能够快捷地获取上述用于计算的指标。",
    "context2": "总体来讲，借助搜索引擎进行术语相似度计算的方法主要以搜索引擎返回的检索结果命中数以及检索结果摘要这两条线索展开。"
  },
  "2.1基于检索结果命中数的相似度计算思路": {
    "context1": "借助搜索引擎对术语对进行联合检索和分别检索，可获得相应网页命中数指标，作为计算术语间相似程度的有效度量。目前已经有一些基于命中数的",
    "context2": "术语相似度算法被提出来，典型的有 $\\mathbb { W } \\mathrm { e b - P M I }$ 算法、LC-IR算法以及Google Distance算法。",
    "context3": "Web-PMI (Web Pointwise Mutual Informa-tion)方法的计算公式如下：",
    "context4": "$$\nW e b P M I ( P , Q )\n$$",
    "context5": "$$\n= \\left\\{ \\begin{array} { l l } { \\displaystyle { 0 } } & { \\displaystyle { i f H ( P \\cap Q ) \\leqslant c } } \\\\ { \\displaystyle { \\log _ { 2 } ( \\frac { H ( P \\cap Q ) } { N } } } & { \\displaystyle { \\begin{array} { l } { \\displaystyle } \\\\ { \\displaystyle { \\frac { H ( P ) } { N } \\frac { H ( Q ) } { N } } } \\end{array} } } & { \\displaystyle { o \\ t h e r w i s e } } \\end{array} \\right.\n$$",
    "context6": "在公式1中,表示两术语联合检索， $\\mathrm { H } ( P \\cap Q$ 表示联合检索命中数， $\\mathrm { H } ( \\mathrm { P } )$ 和 $\\mathrm { H } ( \\mathrm { Q } )$ 表示术语P和Q分别进行检索时的命中数。在 $\\mathrm { { W e b } }$ 网页规模和噪音既定的情况下，很可能两个术语在一些网页中的共现仅仅是出于偶然。为了减少由于随机情况带来的不利的影响，在公式中附加了这样的条件如果检索得到的网页命中数小于阈值c,则令相似度得分为$0 _ { \\circ }$ Web-PMI算法是PMI算法使用网页数量进行计算的版本。在公式中，N是搜索引擎索引的文档数量。为了准确计算Web-PMI,需要预先知道N的取值。N的取值一般根据商业搜索引擎的相关新闻报道数量来设定。PeterTurney等人提出了原理基本一致的PMI-IR (Pointwise Mutual InformationusingInformationRetrieval算法,并且更加深入地探讨了使用不同的检索式构造策略进行PMI-IR计算的效果。",
    "context7": "受到PMI-IR算法的后发,Derrik Higgins提出了LC-IR (local context-information retrieval)算法。和PMI-IR算法类似,LC-IR算法也是基于目标语词对在Web文档中临近出现次数来计算相似度的，不同之处在于它限定了更小的语词共现窗口 (要求语词在文档中直接相邻),因而在一定程度上减少了Web-PMI算法在应用时遇到的术语偶然共现对计算结果的干扰。LC-IR的计算公式为：",
    "context8": "$$\n\\mathrm { S i m i l a r i t y _ { L c - I R } } \\big ( \\mathbf { W } 1 , \\mathbf { W } 2 \\big )\n$$",
    "context9": "$$\n= \\frac { H i t s ( w _ { 1 } N E X T - T O w _ { 2 } ) } { H i t s ( w _ { 1 } ) \\times H i t s ( w _ { 2 } ) }\n$$",
    "context10": "在公式2中， $\\mathbf { W } _ { 1 }$ 和 $\\mathbf { W } _ { 2 }$ 为需要计算相似度的语词。\" $\\mathbf { W } _ { 1 }$ NEXT-TO $\\mathbf { W } _ { 2 }$ 表示语词 $\\mathbf { W } _ { 1 }$ 和 $\\mathbf { W } _ { 2 }$ 临近出现的检索命中数。该算法的主要缺点是需要所使用的搜索引擎支持邻接检索功能，而目前大多数主流搜索引擎并不支持此功能。",
    "context11": "与上述方法类似,Rudi Cilibrasi等人[4提出了Google Similarity Distance算法。该算法利用Google检索获得的命中记录数来计算概念间的语义距离。这些本体中的概念以标签的形式表现出来，然后被Google搜索引擎当作检索语词进行检索。比如两个概念X和Y,X与Y之间的相似度可表示为：",
    "context12": "$$\n\\begin{array} { l l } { \\displaystyle \\operatorname { N G D } ( \\mathrm { x } , \\mathrm { y } ) } \\\\ { \\displaystyle = \\frac { \\operatorname* { m a x } \\{ \\log f ( x ) , \\log f ( y ) - \\log f ( x , y ) } } { \\log M - \\operatorname* { m i n } \\{ \\log f ( x ) , \\log f ( y ) \\} }  \\end{array}\n$$",
    "context13": "在公式3中， $\\operatorname { f } ( \\mathbf { x } )$ 是检索语词 $\\mathbf { X }$ 的Google命中数， $\\operatorname { f } ( \\mathbf { y } )$ 是检索语词y的Google命中数， $\\mathrm { f } ( { \\bf x } , { \\bf y } )$ 是将 $\\mathbf { X }$ ，y作为一组检索语词同时进行检索的Google命中数， $\\mathbf { M }$ 是被Google所标引的网页数。Risto Gligorov等人 $\\left[ 1 5 \\right]$ 将GoogleDistance方法用于音乐本体的映射任务中，获得了良好效果。",
    "context14": "一些学者对上述方法的应用效果进行了对比测试[.14,16-19],认为就普遍适用性和计算效果两方面综合而言， $\\mathbb { W } \\mathrm { e b - P M I }$ 算法表现较为出众。",
    "context15": "使用页面数量作为相似度测度具有简单快捷的优点,也存在几个方面的缺陷。首先,网页数量分析忽略了术语在网页中的位置。即使两个词出现在一个网页中，它们也可能并不相关。其次，多义术语(一个术语具有多种意思)的网页数量可能是它的各种意思对应页面的一个合集。例如，apple'对应的网页数量包含了那些将apple作为水果意思的网页和将apple作为‘company'意义的网页。最后，Web网络中的网页规模虽然庞大，但质量参差不齐,存在较多噪音,部分术语可能随机出现在一些页面上。出于上述原因,这类方法与其它基于知识资源或领域特定文集的方法互相配合会收到更好的效果。"
  },
  "2.2基于检索结果摘要的相似度计算思路": {
    "context1": "检索结果摘要是搜索引擎抽取的对命中文档进行精简描述的文本片段，它提供了检索语词出现的上下文局部语境。对摘要进行计算的优势在于计算的高效性,因为它避免了下载Web页面这样非常耗时的处理。已经有一些基于检索结果摘要的术语相似度算法被提出来。",
    "context2": "Hsin-HsiChen等人[在其基于搜索引擎的综合语词相似度计算方法中,提出了CODC(Cooccur-rence Double Checking)方法。",
    "context3": "$$\n\\mathrm { P , Q ) } \\left\\{ { \\begin{array} { l l } { \\displaystyle 0 \\ } & { { i f _ { f ( P @ Q ) = 0 } } } \\\\ { \\displaystyle { \\log [ \\frac { f ( P @ Q ) } { H ( P ) } \\times \\frac { Q ( P @ P ) } { H ( Q ) } ] o \\ t h e r w i s e } } \\ } \\end{array}  \\right.\n$$",
    "context4": "在公式4中， $\\operatorname { f } ( \\operatorname { P }  @ \\operatorname { Q } )$ 表示在Goolge中的术语Q的高排名查询片段中术语P的出现次数。H(P)是P的网页数。a是CODC模型中的一个常数，一般设置a为 $0 . 0 1 5 _ { \\circ }$ CODC的输出结果在区间 $[ 0 , 1 ] _ { \\circ }$ 在极端的情况下，当 $\\operatorname { f } ( \\mathrm { Y } @ \\mathrm { X } ) = 0$ 或 $\\operatorname { f } ( \\mathrm { X } @ \\mathrm { Y } ) = 0$ ，则$\\mathrm { C O D C } ( \\mathrm { X } , \\mathrm { Y } ) { = } 0$ 当 $\\operatorname { f } ( \\operatorname { Y } @ \\operatorname { X } ) { = } \\operatorname { f } ( \\operatorname { X } )$ 并且 $\\operatorname { f } ( \\mathbf { X } @ \\mathbf { Y } ) { = } \\operatorname { f } ( \\mathbf { Y } )$ ，则 $\\mathrm { C O D C } ( \\mathrm { X } , \\mathrm { Y } ) { = } 1 \\mathfrak { c }$ ，Danushka Bollegala等人 $_ { [ 1 2 ] }$ 对CODC等算法进行了对比测试，并总结了造成CODC计算结果为零的深层原因在于,即使语词对(P,Q)在语义上相似,也不一定能在P对应的较高排名命中结果中找到Q,反之亦然。而这种情况必然造成依公式计算得到的相似度得分为0。搜索引擎在对检索结果排序时，通常会综合考虑检索结果的新颖性、权威性、链接结构、用户偏好排名等因素。因此,CODC方法也受到这些因素的影响。",
    "context5": "检索结果摘要中的语词、句法特征也能被直接作为术语相似度计算的特征。DanushkaBollegala等人提出了一个通过自动抽取Web检索结果中的语词-句法模式来计算语义相似度的方法。考虑到所需处理的检索摘要在语句完整性方面表现不佳，该方法使用了浅模式抽取方法(Shallow Pat-ternExtraction Method)来获取摘要中语词共现的句法模式。给定一对检索词A和B,首先获取同时出现检索词A和B的摘要集合S,然后采用N-Gram$\\mathrm { ( n } = 2 , 3 , 4 , 5 )$ 方法抽取包含语词A和B的语句片段。例如对于语句‘ Toyota and Nissan are two ma-jorJapanesecarmanufacturers\",通过抽取产生了模式X and Y,Xand Y are,X and Y are two。最后，统计被抽取的每个模式的次数。这些模式在语词相似度方面的贡献值 (也就是各个模式的权重)通过预先借助WordNet获得的相似语词集合和非相似语词集合进行训练获得。",
    "context6": "除了对检索结果摘要中直接出现的检索词进行相似度计算的地方法以外,还可以通过对检索词各自的检索结果之间的相似度进行计算，以间接反映检索词之间的相似度。MehranSahami等人在检索式扩展任务以及自动问答系统中应用了基于TFIDF关键词向量的相似度计算方法，并取得了较好的效果。该方法的主要思路为通过搜索引擎检索获得相关文摘，再通过TFIDF计算获得每篇文摘的关键词向量。在对这些文摘对应向量进行L2质心向量计算 (向量合并)后，使用两个检索词对应的质心向量内积表示它们之间的相似度。其中，L2质心向量计算实质上就是求检索词对应各摘要的向量的几何平均数。",
    "context7": "对于以摘要为处理对象的相似度算法而言，被普遍承认的缺陷表现在油于 $\\mathrm { { W e b } }$ 规模巨大，搜索引擎命中结果集通常也很大，只有被搜索引擎排列在最前面的那些摘要能够得到有效处理，因此搜索引擎的排序策略对基于摘要的术语语义相似度计算可能具有较大影响。"
  },
  "3基于多指标集成的相似度计算思路": {
    "context1": "基于网络知识资源的术语相似度计算所涉及的各种算法可以通过集成计算形成互补优势,也可以与基于特定领域文集的其它相似度算法进行集成，以达到更加客观地反映术语相似程度和打破相似度计算条件限制的目的。当前在术语相似度指标集成计算方面，具有代表性的研究思路主要有基于线性加权的指标集成方法，基于神经网络的指标集成方法,以及基于SVM的机器学习方法。",
    "context2": "为了综合术语的语词相似度、句法相似度和语境相似度,Goran Nenadic等人使用了线性加权的多指标集成方法,计算思路可以表达为公式 $5 ^ { [ [ 1 ] }$ ：",
    "context3": "$\\mathrm { C L S ( t _ { 1 } , t _ { 2 } ) } { = } \\alpha \\mathrm { C S ( t _ { 1 } , t _ { 2 } ) } { + } \\beta \\mathrm { L S ( t _ { 1 } , t _ { 2 } ) } { + } \\gamma \\mathrm { S S ( t _ { 1 } , t _ { 2 } ) }$",
    "context4": "在公式5中,t1,t2为需要进行相似度计算的术语对,CS(t1,t2)为术语 $_ \\mathrm { t l }$ 和 $_ { \\mathrm { t } 2 }$ 的语境相似度指标，$\\mathrm { L S } ( \\mathrm { t } 1 , \\mathrm { t } 2 )$ 为语词相似度指标,SS(t1,t2)为句法相似度指标， $\\mathrm { C L S } ( \\mathrm { t } 1 , \\mathrm { t } 2 )$ 为经过集成计算后得到的术语相似度值。上式中,参数 $\\alpha + \\beta + \\gamma = 1$ ,它们分别是各项相似度指标的权重。AshwinIttoo等人采用了类似的线性加权方法来实现语境相似度和语义相似度的集成。HaiDong等人在使用本体进行术语相似度计算时，采用了基于概念描述的相似度算法和基于概念在本体中对应节点位置的相似度算法,并通过线性加权的方法集成这两种计算指标，得到最终的术语相似度判断结果。尽管在上述文献中并未将特定基于网络知识资源的术语相似度计算作为集成计算的参与算法，笔者认为该集成计算思路对于多种基于网络知识资源的术语相似度集成计算也是适用的。",
    "context5": "基于线性加权的方法存在各项加权系数难于确定的问题,因此MahmoodNeshati等人提出了基于神经网络的相似度集成计算方法。Mahmood Ne-shati等人采用基于WordNet的相似度算法、基于窗□共现的相似度算法以及基于句法共现的相似度算法分别进行相似度计算，并使用神经网络算法来确定这些相似度指标的权重。MahmoodNeshati等人首先将相似性测度表达为4维向量,然后使用一个旅游分类系统作为参照，通过基于路径长度的相似算法计算分类系统中术语对之间的相似性，并将其作为神经网络模型学习各种相似性计算指标集成权重的依据。在测试阶段，每一对待计算术语被表示为相应的向量，使用神经网络学习阶段产生的权重进行集成，得到最终的相似度计算结果。",
    "context6": "随着SVM相关研究的兴起，也有一些学者开始尝试使用SVM技术实现相似度集成计算，以获得更好的计算效果。Danushka Bollegala等人[认为，术语相似度计算可以看作一个分类问题，而多种相似度计算指标的集成则可以通过基于SVM (Sup-port VectorMachine的机器学习方法来实现。Bollegala等人首先分别计算基于命中数的Jacca-rd、Overlap (Simpson)、Dice、PMI四个相似度指标,其次使用N-Gram方法从检索结果摘要中截取术语出现模板，从中选择术语对共现频率最高的200个模板,加上上述4个基于命中数的指标，构成描述术语对的204维向量，并将其作为SVM分类器的输入，最终通过自动分类得到术语之间相似性的判断结果。这种集成方法避免了使用线性加权方法集成相似度指标时权重设置易受主观因素影响的问题，能够获得较好的集成效果。"
  },
  "4结语": {
    "context1": "本文对近年来发展较快的基于网络知识资源的术语相似度计算主要计算思路进行了梳理，对重要相关研究文献进行了综述，并对各类计算思路的特点和尚存在的不足进行了总结。随着该领域研究的不断发展，能够体现术语相似度的指标被逐渐挖掘和探索，各种指标的集成效率得到不断提高。术语语义相似度计算的性能提升也势必会为其在各种相关任务中的应用提供推动力。",
    "context2": "目前在基于网络知识资源的术语相似度计算方面仍存在计算效率低、计算准确率有待进一步提高等问题，这影响了相似度计算在更广阔领域开展应用。笔者认为,术语语义相似度计算的研究正在向着多指标集成、高速计算方向发展。当前重点应解决的主要矛盾是如何高效地集成多种相似度指标，以及如何解决术语相似度海量计算处理的高效率与高准确率之间的矛盾。下一步的研究重点应放在提升基于网络知识资源的术语相似度计算准确率和大规模处理效率方面，以便为各种自然语言处理任务"
  },
  "和知识挖掘任务的开展提供良好支持。": "",
  "参考文献": {
    "context1": "1 Philip Resnik.Using information content to evaluate semantic similarity in a taxonomy[EB/OL]. http:/lsdis. cs.uga.edu/\\~ravi/academic/ATIS/SemanticSimilarity. pdf,2010-05-15.   \n2 Semantic similarity[EB/OL].http://en.wikipedia.org/wiki/Semantic_similarity,2010-05-15.   \n3Peter D Turney.Mining the web for synonyms:PMI-IR versus LSA on TOEFL[C]. Proceedings of the Twelfth European Conference on Machine Learning. Berlin: Springer-Verlag,2001.   \n4 Ping I Chen,Shi Jen Lin.Automatic keyword prediction using Google similarity distance[J]. Expert Systems with Applications,2010,37(3):1928-1938.   \n5Roy Rada, Ellen Bicknell. Ranking documents with a thesaurus[J]. Journal of the American Society for Information Science,1989,40(5):304-310.   \n6 Roy Rada, Hafedh Mili, Elen Bicknell,etal. Development and application of a metric on semantic nets[J]. IEEE Transactions on Systems,Man,and Cybernetics, 1989,19(1):17-30.   \n7Eneko Agirre,German Rigau. A proposal for word sense disambiguation using conceptual distance[J]. Amsterdam studies in the theory and history of linguistic science,1997,4:161-172.   \n8Liping Jing,Michael K Ng, Joshua Z Huang. Knowledge-based vector space model for text clustering[J/ OL]. Knowledge and information systems,http://www. springerlink.com/content/m178072619111181/,2010- 05-26.   \n9 Mahmood Neshati,Leila Sharif Hassanabadi. Taxonomy construction using compound similarity measure [EB/OL].http://www.springerlink.com/index/t2244258 v8k47705.pdf,2010-05-15.   \n10 Andrzej Sieminski. Using WordNet to Measure the Similarity of Link Texts[EB/OL]. Computational Collective Intelligence.Semantic Web,Social Networks and Multiagent Systems,2009,5796(10):720-731.   \n11 Mandar A Rahurkar,Dan Roth,Thomas S Huang. Which“Apple”are you talking about ?[C].Proceeding of the 17th international conference on World Wide Web.Beijing, China: ACM, 2008.   \n12 Danushka Bollegala, Yutaka Matsuo,Mitsuru Ishizuka.Measuring semantic similarity between words usingwebsearchengines[C].Proceedingsof WWW2007．Banff,Alberta,Canada:International World Wide Web Conference Committee,2007.   \n13 Derrik Higgins.Which statistics re?ect semantics? rethinking synonymy and word similarity[C].In international conference on linguistic evidence.Tubingen, Germany,2004.   \n14Rudi Cilibrasi,Paul Vitanyi. The google similarity distance[J]. IEEE transactions on knowledge and data engineering,2007,10(3):370-383.   \n15 Risto Gligorov, Zharko Aleksovski,Warner ten Kate. Using google distance to weight approximate ontology matches[C]. Proceedings of the seventeenth World Wide Web conference. Korea: ACM, 2007.   \n16 Sean M Falconer, Dmitri Maslov,Margaret Anne Storey. Combining web-based searching with latent semantic analysis to discover similarity between phrases [C].On the Move to Meaningful Internet Systems 2006: CoopIS,DOA,GADA,and ODBASE. Montpellier, France: Springer, 2006.   \n17Wen-tau Yih,Christopher Meek.Improving similarity measures for short segments of text[C]. Proceedings of the Natural Conference on Artificial Intelligence.London: AAAI Press,2007.   \n18 Roberto JBayardo,Yiming Ma,Ramakrishnan Srikant.Scaling up all pairs similarity search[C]. Proceedings of the seventeenth World Wide Web conference.Korea: ACM,2007.   \n19Hsin-Hsi Chen,Ming-Shun Lin,Yu-Chuan Wei. Novel association measures using web search with double checking[C]. Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL. Sydney: Association for Computational Linguistics,2006.   \n20Mehran Sahami, Timothy D Heilman.A web-based kernel function for measuring the similarity of short text snippets[C]. Proceedings of the 15th international conference on World Wide Web.Edinburgh,Scotland:ACM,2006.   \n21 Goran Nenadic,Irena Spasic, Sophia Ananiadou. Automatic discovery of term similarities using pattern mining[EB/OL].http://portal.acm.org/citation.cfm?id= 1118771.1118779,2010-05-15.   \n22 Ashwin Ittoo,Laura Maruster. Ensemble Similarity Measures for Clustering Terms[J]. CSIE,2009,(4): 315-319.   \n23 Hai Dong，Farookh Khadeer Hussain,Elizabeth Chang.A Hybrid Concept Similarity Measure Model for Ontology Environment[EB/OL]. On the Move to Meaningful Internet Systems: OTM 2009 Workshops, 2009,5872(11):848-857."
  }
}