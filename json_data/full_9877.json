{
  "original_filename": "full_9877.md",
  "近年来Hadoop 国内研究进展": "",
  "王彦明": {
    "context1": "(河南中医学院思想政治理论教研部，河南郑州450046)",
    "context2": "(摘要）Hadop作为著名开源云计算技术近年来得到广泛应用，研究成果快速增长。理论研究主要集中在任务调度、小文件优化、中间数据管理、功能扩展和安全性优化；应用研究主要涉及数据存储、数据分析、数据挖掘、搜索引擎以及信息安全领域。通过分析相关研究成果明确Hadoop近年来国内研究现状。",
    "context3": "（关键词）云计算；Hadoop；MapReduce；HDFS；编程模型；大数据DOI:10.3969/j.issn.1008 -0821.2014.08.003",
    "context4": "（中图分类号）TP393（文献标识码）A（文章编号）1008-0821（2014）08-0014-06"
  },
  "Domestic Hadoop Research Progress in Recent Years": {
    "context1": "Wang Yanming (Henan Traditional Chinese Medicine College，Zhengzhou 45O046，China)",
    "context2": "(Abstract）As a well-known open source cloud computing technology Hadoop was widely used in recent years. It's research results rapid growth.The theory research mainly concentrated in task scheduling，smallfle optimization，middle data management，function expansion and security optimization.The aplication researches were mostlyabout data storage, dataanalysis，data mining，search engineand informationsecurity.Through theanalysisof the related research results, we define the domestic Hadoop research current situation in recent years.",
    "context3": "(Key words）cloud computing；Hadoop；MapReduce;HDFS；programming model； big data",
    "context4": "随着社会信息化程度的提高，许多行业面临海量数据处理任务。传统单机处理成本高灵活性差，难以应对大数据挑战。云计算作为IT领域的一场革命，通过分布式计算提高效率。Hadoop开源系统可以部署在廉价硬件上，特别适合大数据存储和分析，目前在国内外已经得到广泛应用。本文检索统计近年来相关研究成果，理顺主要内容，以资借鉴。"
  },
  "1文献计量分析": "",
  "1.1检索": {
    "context1": "本文选择CNKI数据库，检索时间2014年4月22日，主题选择Hadoop或MapReduce，发表时间2007年1月1日到2014年4月22日，获得文献2158篇。其中期刊论文1123篇，占 $4 9 . 2 8 \\%$ 。学位论文862篇，占 $3 8 . 2 6 \\%$ 。会议论文135篇，占 $5 . 4 8 \\%$ 。报纸文章38篇，占 $1 . 7 \\%$ 。期刊论文分布在计算机科学、计算机工程、计算机应用等计算机专业核心期刊。学文论文分布在北京邮电大学、电子科技大学、华南理工大学、哈尔滨工业大学等高校。",
    "context2": "表1排名前10位的期刊论文和学位论文来源",
    "context3": "<table><tr><td>排序</td><td>期</td><td>刊</td><td>数量</td><td>排序</td><td>高 校</td><td>数量</td></tr><tr><td>1</td><td>计算机科学</td><td></td><td>36</td><td>1</td><td>北京邮电大学</td><td>83</td></tr><tr><td>2</td><td>计算机工程</td><td></td><td>33</td><td>2</td><td>电子科技大学</td><td>60</td></tr><tr><td>3</td><td>计算机应用</td><td></td><td>29</td><td>3</td><td>华南理工大学</td><td>42</td></tr><tr><td>4</td><td>计算机系统应用</td><td></td><td>27</td><td>4</td><td>哈尔滨工业大学</td><td>36</td></tr><tr><td>5</td><td>计算机研究与发展</td><td></td><td>25</td><td>5</td><td>浙江大学</td><td>30</td></tr><tr><td>6</td><td>计算机应用研究</td><td></td><td>25</td><td>6</td><td>华中科技大学</td><td>29</td></tr><tr><td>7</td><td>计算机工程与应用</td><td></td><td>25</td><td>7</td><td>上海交通大学</td><td>29</td></tr><tr><td>8</td><td>计算机技术与发展</td><td></td><td>22</td><td>8</td><td>吉林大学</td><td>23</td></tr><tr><td>9</td><td>计算机工程与科学</td><td></td><td>19</td><td>9</td><td>复旦大学</td><td>21</td></tr><tr><td>10</td><td>小型微型计算机系统</td><td></td><td>19</td><td>10</td><td>北京交通大学</td><td>18</td></tr></table>"
  },
  "1.2年份统计": {
    "context1": "统计表明，文献发表年份分布在2007－2014年。相比国外研究，国内虽然起步较晚但发展势头强劲。随着大数据时代的来临，Hadoop作为重要开源云计算技术得到广泛应用和深入研究。",
    "context2": "表2文献年代分布",
    "context3": "<table><tr><td>年份</td><td>数量</td><td>年份</td><td>数量</td></tr><tr><td>2007</td><td>8</td><td>2012</td><td>595</td></tr><tr><td>2008</td><td>11</td><td>2013</td><td>917</td></tr><tr><td>2009</td><td>45</td><td>2014</td><td>69</td></tr><tr><td>2010</td><td>153</td><td>合计</td><td>2 158</td></tr><tr><td>2011</td><td>360</td><td></td><td></td></tr></table>"
  },
  "1.3内容分类": {
    "context1": "选择主要核心期刊论文和学位论文648篇进行内容分类，见表3。",
    "context2": "表3文献内容分类",
    "context3": "<table><tr><td>大类</td><td>研究内容</td><td>篇数</td><td>大类</td><td>研究内容</td><td>篇数</td></tr><tr><td rowspan=\"6\">1R</td><td>任务调度</td><td>114</td><td rowspan=\"6\">西</td><td>数据存储</td><td>60</td></tr><tr><td>小文件优化</td><td>48</td><td>数据分析</td><td>78</td></tr><tr><td>中间数据管理</td><td>39</td><td>数据挖掘</td><td>174</td></tr><tr><td>功能扩展</td><td>36</td><td>搜索引擎</td><td>75</td></tr><tr><td>安全优化</td><td>24</td><td>信息安全</td><td>15</td></tr><tr><td></td><td></td><td></td><td></td></tr></table>"
  },
  "2Hadoop 理论研究": "",
  "2.1任务调度": {
    "context1": "Hadoop 默认调度算法FIFO、计算能力调度算法以及公平调度算法遵守严格队列规律，缺乏动态性和灵活性，在很多情况下无法实现最优调度效果。目前的改进主要有三类。"
  },
  "2.1.1基于优先级调度改进": {
    "context1": "基于优先级自适应调度算法根据历史信息调整JobT-tacker可执行队列动态进行负载均衡，利用优先权为不同的作业分配系统资源。基于优先级加权的滑动窗口调度算法通过滑动窗口技术动态监控作业数量，自适应管理负载平衡。结合种群重优化机制的离散PSO算法通过自定义速度和位置更新加入用户优先级参数和重优化的判断规则，既保留了PSO算法的优点又可以应用于离散空间求解。"
  },
  "2.1.2反馈调整自适应改进": {
    "context1": "反馈调度自适应算法思想是当前调度决策会影响下一次调度决策，通过以前决策的经验和教训修改集群配置，通过历史信息动态调整Map和Reduce各阶段时间比例，找出需要后动备份的任务。采用k-means聚类算法动态调整阶段进度值，估计任务的执行时间，查找慢任务。通过节点分类在快速节点上后动落后任务的备份减小响应时间，",
    "context2": "避免空载，减少资源浪费。"
  },
  "2.1.3数据局部性改进": {
    "context1": "数据局部性问题源于将计算发送到数据的方式。节点物理机故障、网络传输或数据集划分不合理都会造成个别节点计算时间变长，运行时负载均衡机制与迭代HaLoop 局部增强机制能均衡计算量。在公平调度算法基础上结合槽分配延迟和优先级技术提出的改进算法能改善吞吐率和响应时间。在LATE基础上提出的局部性改进算法能解决慢任务读数据时间过长影响处理速度问题。基于时间的等待调度方法优先将任务调度到数据所在节点，实现更好的数据本地性，减少IO开销减少单个作业响应时间-4"
  },
  "2.2小文件优化": {
    "context1": "HDFS设计仿照GFS，处理对象主要是搜索引擎中的大数据集。在很多应用中小文件普遍存在，元数据对主节点内存的大量消耗造成效率低下。解决方法有有文件合并、HBase、调整索引策略以及元数据缓存策略。"
  },
  "2.2.1文件合并": {
    "context1": "通过转化工具将大量小文件转化为 Sequencefile格式大文件，减少名字节点元数据数量，提高检索和查询效率。"
  },
  "2.2.2结合HBase": {
    "context1": "首先通过测试确定小文件标准，默认字符串方式可以直接存储结构化文本。图片和视频以文件形式存储在HDFS中，在HBase中建立描述和地址信息表。HTML转换为XML数据存储-。"
  },
  "2.2.3索引策略": {
    "context1": "建立小文件索引并分片放置能提高检索效率。根据小文件相关性和数据目录结构合并，生成分层索引，采用集中存储和分布式存储相结合的方式管理并进行预加载以提高访问效率。"
  },
  "2.2.4元数据缓存": {
    "context1": "通过Datanode缓存部分小文件元数据，对热点数据以动态方式增加副本数。只有向数据节点请求不到数据时才向名字节点请求，大幅减少了名字节点的负担。"
  },
  "2.3中间数据管理": {
    "context1": "MapReduce对Map输出的中间数据处理机制不灵活，数据规模大、分布不均衡，容易成为性能瓶颈。在map 函数中引入关联数组可以使中间结果在Map函数中自动进行合并，减少中间结果数量，降低网络负担。通过切分函数对中间结果进行切割、启动新规约任务和相应调度机制能较大提高执行效率。对于一些复杂度高的应用，通过延迟读技术在Lustre开始阶段通过硬链接功能替代原来的HTTP传输，实际I/O操作通过Lustre客户端读取从而减少Reduce任务开始阶段网络风暴。针对Reduce任务节点存在数据倾斜导致多个Reduce完成时间差别较大，有研究提出改进型MBR（Map-Balance-Reduce）模型，通过添加",
    "context2": "Balance任务对Map中间数据进行均衡操作，使得分配到Reduce任务节点的数据比较均衡，从而确保Reduce任务完成时间基本一致。"
  },
  "2.4功能扩展": "",
  "2.4.1海量数据高性能计算": {
    "context1": "海量数据高性能计算同时具有数据密集和计算密集两方面特点，融合GPU计算的MapReduce框架在Hadoop 基础上采用注释码的形式对MapReduce函数中需要并行的部分进行标记，通过定制GPU类加载器，将被标记代码转换为CUDA代码并动态执行，从而将GPU的计算能力融合到MapReduce框架中[id"
  },
  "2.4.2多数据源处理": {
    "context1": "MapReduce不支持多数据源的数据处理，不能直接应用于具有多个处理操作、多个数据流分支的数据处理流程。面向MapReduce的模型驱动数据处理方法使用模型转换算法和代码生成算法将逻辑模型转化为物理模型，再转换为能在Hadoop上运行的MapReduce程序。基于该方法实现的CloudDataFlow开发工具可以有效提高处理效率[。"
  },
  "2.4.3强关联性数据": {
    "context1": "针对MapReduce不能处理树形结构等关联性强的数据，有研究提出基于树结构的MapReduce模型，基于一种聚类聚合反复轮询过程，聚合时用 $\\langle \\mathrm { k } 1 , \\mathrm { k } 2 , \\cdots , \\mathrm { k n } , \\mathrm { v a l u e } \\rangle$ 代替传统的 $\\langle \\mathbf { k } , \\mathrm { v a l u e } \\rangle$ ，使模型更具有一般性。XML海量数据处理实验表明其执行速度明显优于传统模型[。"
  },
  "2.5安全性优化": {
    "context1": "Hadoop的广泛应用带来了日益突出的安全性问题。在Kerberos和RBAC基础上提出的基于令牌的认证机制、基于令牌的访问控制机制以及基于域和角色的访问控制模型能解决HDFS的认证与授权问题。结合心跳监测机制的节点DDoS检测与自修复模型通过引入双曲正切函数设计保护阀值函数，作为核心算法结合实时数据对攻击IP地址彻底清理。实验表明具有较好的检测效果[。为了防止数据传输和存储过程中的泄露，对上传的文件进行AES加密，用RSA算法保障AES密钥的安全。用户可以以密文或明文方式对文件进行存储从而选择是否加密。基于属性和固定密文长度的算法将密文长度和加解密计算量维持在固定值，从而减轻通信量提高系统效率。层次化授权模型能够减少中心授权的负担和风险，同时解决存储空间有限的问题[14-15] 。"
  },
  "3Hadoop应用研究": "",
  "3.1数据存储": "",
  "3.1.1电子商务数据": {
    "context1": "电子商务数据包括产品描述数据、订单数据、用户评价数据等。索引文件、日志和备份数据属于大文件，文本、图片、网页数据等属于小文件。对于海量数据采用关系型数据库分库、分表方法。对大文件和小文件采用Hadoop系统存储。Hadoop电子商务数据存储模型包含前端页面缓存、多个Apache 服务器、页面片段缓存ESI、包含HBase和 HDFS的Hadoop系统、用于划分不同数据库功能的数据库接口层DAL、Memcache分布式缓存和主从式关系型数据库 。"
  },
  "3.1.2RDF数据": {
    "context1": "RDF（资源描述框架）是W3C推荐使用的用来描述资源及其关系的语言规范。由于实际应用中RDF数据文件属性众多，采用关系型数据库占用空间巨大。由于HBase采用列导向方式存储数据，Null值不占用任何空间，比较适合RDF三元组数据存储。SPARQL是W3C提出的RDF标准查询语言，其查询建立在模式匹配上。采用MapReduce框架处理 SPARQL 查询语言中的 BGP（Basic Graph Pat-tern）。在已有的MapReduce多路连接之上提出一个贪心多路连接策略，优先处理高选择性TriplePattern子句，在Map 阶段提前过滤冗余数据，从而减少整个过程的I/O开销。实验表明该查询策略适用于大规模数据集[。"
  },
  "3.1.3电网数据": {
    "context1": "电网状态监测数据涵盖一次系统设备、二次系统设备。绝缘子泄露电流检测 $1 0 \\mathrm { m s }$ 采集一次数据。智能电网环境下如何有效的存储和分析这些状态监测数据成为关键问题。目前国家电网公司的SG186、SGERP、南方电网公司基于SOA的企业级信息系统仍采用大型服务器、磁盘阵列和关系型数据库，成本高，扩展性差。基于MapReduce的电网数据管理系统由算法调用和任务管理两部分组成。算法调用采用插件形式调用第三方实现的模糊诊断、灰色系统诊断、小波分析、神经网络以及阈值诊断等各种算法。任务管理实现基于MapReduce并行模型的任务管理、调度和监控系统。"
  },
  "3.1.4医学影像": {
    "context1": "构建区域性医学影像分布式存储系统有利于均衡医疗资源、提高基层医院诊疗水平、降低患者医疗花费。数字医学影像技术遵循DICOM3.0标准。依照这种标准建立的系统数据量大，对存储空间、网络传输带宽以及可用性提出了挑战。为了对众多医疗机构的影像数据进行高效整合，有研究提出采用Hadoop分布式存储与FC－SAN集中式存储相结合的存储架构。医学影像资料中常见的CT、MRI图像大小一般在512KB左右，一次拍摄产生 $1 0 0 \\sim 2 0 0$ 幅图片。相对HDFS默认的块大小属于小数据。以病人为单位将各种检查数据进行合并，通过Hadoop的 SequenceFile文件格式转化成键值对形式合并成一个文件进行存储。测试表明，随着Hadoop节点的增多，聚合形成的传输带宽远远超过FC -SAN。"
  },
  "3.1.5遥感影像": {
    "context1": "高分辨率遥感影像在土地、植被、水体、海洋、农业以及大气环境、地质灾害等方面应用广泛，通常以栅格格式存储。栅格格式模型简单，但数据量大，一副影像达到几百MB到数GB。影像金字塔通过分层、分块方式管理，分层通过采样得到低分辨率影像，以进行快速显示；分块将分层后的数据按照影像块进行分割，便于加载浏览。当前商业性系统如ArcSDE、GeoRaster等基于关系数据库设计。采用Hadoop存储遥感影像通常将影像文件存储在HDFS，元数据存入HBase。基于MapReduce编程模型构建影像金字塔，将海量数据处理任务以分布式方式分配到各节点执行，能显著加快处理速度。对于HBase中每个记录的相同属性数据如果主键相邻，相应数据在物理存储上也是相邻的。利用Hilbert曲线良好的空间聚类特性和影像金字塔快速响应能力可以提高空间查询命中率，提高响应速度20-21。"
  },
  "3.2数据分析": "",
  "3.2.1网站日志分析": {
    "context1": "网站日志分析从用户访问历史中发现访问规律。目前用于Web日志分析的算法主要有最大向前序列法、参考长度法、树形拓扑结构法以及基于支持——偏爱度概念的访问矩阵浏览偏爱路径挖掘算法等。由于实际中大型网站访问矩阵过大，传统处理方式难以应对。基于MapReduce的AprioriTid算法先将数据集划分为适当子块，在各子块上用传统算法处理，然后再将结果合并。"
  },
  "3.2.2社交网络分析": {
    "context1": "社会网络分析（SNA）从社交网站用户数据中发现具有商业价值的信息。个体之间关系的日益复杂给传统分析带来了挑战。在HDFS和 MapReduee基础上设计的X-RIME包含十几种MapReduce化的分布式社会网络分析算法，可以部署在成百上千台普通 PC机上。其中分布式MST最小生成树算法在计算最优传递问题方面有着广泛应用，具有良好的扩展性和通用性。"
  },
  "3.2.3安全日志分析": {
    "context1": "随着网络技术的迅猛发展，网络攻击呈多样化趋势。在网络入口提取安全事件特征转换成日志分析有利于发现网络安全问题。传统数据库因扩展性、容错性和可靠性不足面临挑战。基于Hadoop的网络安全日志分析系统由捕获存储、读取和分片分析三部分组成。通过快速提炼访问日志中每个IP地址的请求次数，获取其中请求频率较大的异常以有效甄别攻击源，为解决问题提供重要依据。实验表明分布式模式较单机模式具有明显的时效性优势24"
  },
  "3.3数据挖掘": "",
  "3.3.1分类": {
    "context1": "分类是基本的数据挖掘技术，大规模数据集对单点计算能力提出了挑战。并行化是一种有效的解决方法。目前研究中采用MapReduce实现的分类技术有贝叶斯文本分类、TF-IDF、SPRINT以及增量分类。",
    "context2": "$\\textcircled{1}$ 贝叶斯文本分类。贝叶斯文本分类需要3个MapRe-duce实现。首个阶段主要任务是接收训练文档数据块计算词频文档数量，全局统计并存储为中间结果；第二阶段每个mapper接收第一步的中间数据，用词频法对文档进行特征抽取，并存储抽取后的中间数据；第三阶段每个mapper接收第二步生成的中间数据，计算得到各类别先验概率和各词的特征权值得到贝叶斯分类模型。实验表明算法能获得接近线性的加速比。",
    "context3": "$\\textcircled{2}$ TF-IDF。TF-IDF用来评估单词对文件集或语料库中一份文件的重要程度。通过分割数据并行统计TF能加快计算速度。因为文档总数是一个常量，得到TF后TF-IDF取决于包含此单词的文档个数，只要能确定文档个数，即能以MapReduce方式求解。实验表明并行算法效率明显高于传统算法。",
    "context4": "$\\textcircled{3}$ SPRINT。SPRINT算法是一种用于分类的决策树算法。并行构造决策树重点是寻找可行的策略进行数据集划分。研究发现可以采用节点并行、属性并行和排序并行3种策略。通过并行策略设计用于表示属性表的(key,value>结构算法第一阶段主要产生已排序的属性表，产生根节点的分裂，第二阶段主要执行循环的分裂过程，完成属性表的完全分裂，生成一颗完整的决策树，第三阶段主要用来提取树结构，并生成相应的模式规则。",
    "context5": "$\\textcircled{4}$ 增量分类。基于MapReduce的增量分类通过Map 函数对训练数据进行训练，得到不同时刻增量块的分类器，Reduce函数利用Map训练好的分类器对测试样本进行预测，将不同时刻训练得到的分类器进行集成，得到最终的分类结果。实验表明基于Hadoop的增量学习模型简单，易于实现。通过设置Map任务的个数可以自动对训练样本进行划分，划分后的各个任务相互独立，通过并行训练提高了海量数据的处理速度，实现了实时增量分类。"
  },
  "3.3.2聚类": {
    "context1": "目前研究中基于MapReduce实现的分布式聚类算法有K-means聚类、分布式谱聚类、并行化AP聚类、朴素贝叶斯算法、FP-Growth算法等。MapReduce实现的k-means聚类中Map函数完成每个记录到聚类中心距离计算并重新标记其属于的新聚类类别，Reduce函数根据Map函数得到的中间结果计算出新的聚类中心供下一轮MapRe-duce 使用。采用canopy算法对k-means进行优化，并用MapReduce实现并行化，具有较好的加速比和可扩展性。分布式谱聚类策略是计算相似矩阵，稀疏化时按数据点标识切分，计算特征向量时把拉普拉斯矩阵存储于HDFS,采用分布式Lanczos运算，并行计算得到特征向量，对特征向量的转置矩阵采用并行K-means聚类得到聚类结果。并行化AP聚类的策略是先把吸引度矩阵和归属度矩阵分布式存储在HBase上，每次迭代中按行分割，使其矩阵值按行分布在多台机器上运算29"
  },
  "3.3.3关联规则挖掘": {
    "context1": "关联规则是数据挖掘的重要内容，它反映了一个事物和其他事物之间的依赖或关联。关于关联规则发现的算法很多，但大部分是经典算法Apriori算法的改进。Hadoop 平台下实现Apriori算法 $\\mathrm { M a p }$ 阶段读取HDFS中的文件集，以<key,value>形式输入每项数据，Combiner阶段 key,value>经过处理后得到整个数据集中所有的频繁 $\\left( \\textbf { k } - 1 \\right)$ 项集，Reduce阶段由频繁（k-1）项集生成候选k-1项集并进行修剪，通过最小支持度得到所有频繁项集。通过把数据库划分成规模相当的数据集，采用压缩原始事务集的方式进一步提高在Hadoop 框架下的性能b。将FUP算法与MapReduce相结合提出的基于MapReduce的关联规则增量更新算法只需扫描原数据集一次可以取得更好的性能。"
  },
  "3.3.4Web结构挖掘": {
    "context1": "Web结构挖掘通过网页之间的链接结构发现网络中隐藏的知识。用于网站排名的Web链接结构分析算法主要是PageRank和HITS。针对PageRank迭代次数多，时空消耗大，执行速度和收敛速度慢的缺点通过对PageRank算法重新设计，考虑了结点存在的各种情况，有针对性的对Key和Value进行设计，使算法并行化。基于MapReduce的PageRank算法利用矩阵分块思想将邻接矩阵分块处理以减少每次迭代混合排序时间，在增加计算跨度基础上成倍减少迭代次数、网络通信和IO消耗。K步跨度算法K－span在PageRank并行迭代时减少Hadoop集群节点之间的通信次数，使得总的迭代时间减少。在Hadoop上实现的基于中文词网络的HITS 算法打破Hub 值和Authority值的共引用共耦合复杂关系，通过改变信息结点的存储结构实现了分布式矩阵和向量运算。"
  },
  "3.4搜索引擎": "",
  "3.4.1分布式爬虫": {
    "context1": "网络爬虫是搜索引擎的重要模块。Nutch核心模块采用MapReduce方式，主要由爬行、索引和查询3个组件构成。研究发现Nutch 网络爬虫存在等待时间僵化、对抓取失败的链接缺乏管理的问题。改进措施在Nutch-defau.xml增加参数、设定链接的路径和级别、在Hbase上建立过滤列表，对失效链接的本地路径进行记录、在Fetchlist中增加键值进行过滤等方法。持续优化通过对Nutch当前爬行的job进行检测，搜索运行时数据进行暂存，然后使用暂存的jobprofile数据生成优化后参数，替换新一轮的相同类型job的默认配置参数。实验表明改进方案能够更高效的抓取网络资源。"
  },
  "3.4.2分布式索引": {
    "context1": "倒排索引是搜索引擎最为常用的索引结构，是搜索引擎核心技术之一。利用MapReduce构建倒排索引能够解决集中式系统性能瓶颈。Map函数分析抓取到的正排索引文档，Reduce函数对相同word所有序列组进行合并排序。通过把大规模数据集分割成小块分发给网络中其他节点运算，每个节点周期性地把运算结果返回。Spitter把大规模正排索引文档数据集进行分块，分发到不同机器上进行Map 处理，产生各自的倒排索引文档，然后Reduce再把这些索引文档进行合并处理产生统一的倒排索引文档。使用MapRe-duce构建列存储数据索引在Map阶段完成数据划分，在Reduce阶段完成数据的排序，在此基础上创建的 $\\mathrm { R B } +$ 树索引，减少因为 $\\mathrm { R B } +$ 树内部节点递归分裂而产生的昂贵代价和树高度，提高了查询性能。"
  },
  "3.5信息安全": "",
  "3.5.1网络安全": {
    "context1": "基于Hadoop的分布式入侵检测系统采用检测代理、数据收集器和集群监控中心三层结构。基于MapReduce的FP-Growth算法将无法基于内存构建的FP－树分解为多棵FP-子树，通过对子树的挖掘得到全局频度模式，解决了传统关联规则算法无法处理海量入侵记录的问题。对于僵尸网络的检测MapReduce 算法包含4个串行工作的Job。Job1、Job2、和Job3提取二级关联关系，Job4计算云客户端的分数。由于贝叶斯算法检测僵尸网络具有较高准确性，基于MapReduce实现的贝叶斯算法并行化部分包括训练阶段先验概率、条件概率和检测阶段的后验概率。MapRe-duce并行化还用于解决大型网络防火墙中规则冲突问题。通过对基于规则的分段技术得到的片段进行自定义排序，片段间不相交且匹配的包只执行一种动作，从而消除了冲突6-37 。"
  },
  "3.5.2密码恢复": {
    "context1": "目前哈希函数在操作系统、通信协议中应用广泛，SHA、MD5、NTLM等哈希算法密码恢复耗费大量时间。研究者在Hadoop集群中以MapReduce方式进行哈希算法设计。Map过程一般包含计算哈希值的函数，Reduce过程用来收集和汇总结果，将一个任务分配到多个节点计算最后统一输出结果。在对哈希算法的原像攻击方面，除了暴力攻击外，Oechslin提出的彩虹表是重要手段。彩虹表的基础是Hellman提出的时间与空间折中方法，经Oechslin等人改进通过使用不同的Reduction函数解决了经典表中链重合概率高的问题，在短时间内提供极高的破解率。使用MapReduce进行彩虹表生成和破解能够解决有限硬件环境下较大明文空间彩虹表生成时间过长问题。"
  },
  "4总结与展望": {
    "context1": "Hadoop作为最著名的开源云计算技术近年来得到广泛应用，研究者对其进行了多方面的改进，使其更适合于大规模数据处理。随着社会信息化水平提高，海量数据处理需求更加广泛。利用MapReduce实现的并行化算法能够运行在廉价硬件上，提高了系统性能，节省了建设成本。但是Hadoop改进和应用需要较高的并行化开发能力，对企业技术水平提出了挑战。在具体产业应用中需要根据特定场景进行个性化开发。借鉴已有研究成果能够节约时间和成本，实现Hadoop 技术的高效利用。"
  },
  "参考文献": {
    "context1": "[1］蒲汛，杜嘉，卢显良．基于用户优先级的云计算任务调度策略［J]．计算机工程，2013，39（8)：64-68.  \n[2]杨立身，余丽萍．异构环境下增强的自适应MapReduce 调度[J]．计算机工程与应用，2013，49（19)：39-43，140.  \n[3］王凯，吴泉源，杨树强．一种多用户 MapReduce 集群的作业调度算法的设计与实现[J]．计算机与现代化，2010，（10)：23-28.  \n[4］李丽英，唐卓，李仁发．基于LATE的 Hadoop 数据局部性改进调度算法[J]．计算机科学，2011，38（11)：67-70.  \n[5］余思，桂小林，黄汝伟．一种提高云存储中小文件存储效率的方案[J]．西安交通大学学报，2011，45（6)：59-63.  \n[6］张烨，沈奇威．Jackrabbit封装 Hadoop的设计与实现［J]．四川兵工学报，2010，31（11)：84-87.  \n[7］李克然，刘东苏，邓媛．电子商务环境下海量数据存储模型[J]．情报杂志，2010，29（12)：133-134，138.  \n[8]栾亚建，黄民，龚高晟．Hadoop平台的性能优化研究[J]．计算机工程，2010，36（14)：262－263，266.  \n[9］李玉林，董晶．基于Hadoop 的MapReduce 模型的研究与改进[J]．计算机工程与设计，2012，33（8)：3110-3116.  \n[10］翟岩龙，罗壮，杨凯．基于Hadoop的高性能海量数据处理平台研究[J]．计算机科学，2013，40（3)：100-103.  \n[11］易小华，刘杰，叶丹．面向MapReduce 的数据处理流程开发方法[J]．计算机科学与探索，2011，5（2)：161-169.  \n[12］李远方，贾时银，邓世昆．基于树结构的MapReduce 模型[J]．计算机技术与发展，2011，21（8)：149－152.  \n[13］韩伟．基于Hadoop 云计算平台下DDoS攻击防御研究[D].太原：太原科技大学，2011.  \n[14］张欣晨，杨庚．Hadoop 环境中基于属性和定长密文的访问控制方法［J/OL]．计算机工程与应用．http://www.cnki.net/kcms/doi/10.3778/j.issn.1002-8331.1311-0372.html，2014-04-03.  \n[15]沈晴霓，杨雅辉，禹熹．一种面向多租户云存储平台的访问控制策略[J]．小型微型计算机系统，2011，32（11)：2223-2229.  \n[16]李克然．基于云计算的电子商务数据管理模式研究［D].西安：西安电子科技大学，2011.  \n[17］郭亨亨，赵文静．海量RDF 数据的分布式存储研究［J].现代计算机，2010，（4)：61-64.  \n[18］王德文，宋亚奇，朱永利．基于云计算的智能电网信息平台[J]．电力系统自动化，2010，34（22)：7-12.式存储框架设计[J]．南方医科大学学报，2011，31（3)：495-498.  \n[20］康俊锋．云计算环境下高分辨率遥感影像存储与高效管理技术研究［D]．杭州：浙江大学，2011.  \n[21］霍树民．基于 Hadoop 的海量影像数据管理关键技术研究[D]．长沙：国防科学技术大学，2010.  \n[22］程苗，陈华平．基于Hadoop的Web 日志挖掘［J]．计算机工程，2011，37（11)：37-39.  \n[23］杨寅．社会网络分析工具中的分布式最小生成树算法[D].北京：北京邮电大学，2011.  \n[24］金松昌，方滨兴，杨树强．基于Hadoop 的网络安全日志分析系统［A]．第25次全国计算机安全学术交流会论文集·第 25卷[C]．2010.  \n[25］朱杰．云计算在基于贝叶斯分类的垃圾短信过滤中的研究与应用［D]．成都：电子科技大学，2010.  \n[26］向小军，高阳，商琳．基于Hadoop平台的海量文本分类的并行化[J]．计算机科学，2011，38（10)：184-188.  \n[27］王鄂，李铭．云计算下的海量数据挖掘研究［J]．现代计算机，2009，（11)：22-25，50.  \n[28］李曼．云计算平台上的增量学习研究［D]．南京：南京邮电大学，2012.  \n[29］牛新征，余堃．面向大规模数据的快速并行聚类划分算法研究[J]．计算机科学，2012，39（1)：134-137，151.  \n[30］丁振，项颖．基于Hadoop的关联规则算法在电子商务中的应用[J]．计算机与现代化，2012，（8)：122－125.  \n[31］李玲娟，张敏．云计算环境下关联规则挖掘算法的研究[J]．计算机技术与发展，2011，21（2)：43-46，50.  \n[32］朱晓峰，李玲娟，徐小龙．基于MapReduce的关联规则增量更新算法[J]．计算机技术与发展，2012，22（4)：115-118，122.  \n[33］李远方，邓世坤，闻玉彪．Hadoop MapReduce下的 PageRank矩阵分块算法[J]．计算机技术与发展，2011，21（8)：6-9，13.  \n[34］周世龙．Hadoop 视角下的 Nutch 爬行性能优化［J]．计算机应用，2013，33（10)：2792-2795.  \n[35］丁祥武，李清炳，乐嘉锦．使用MapReduce 构建列存储数据的索引[J]．计算机应用与软件，2014，31（2)：24-28.  \n[36］邵秀丽，耿梅洁，蒋鸿玲．基于MapReduce 检测僵尸网络的贝叶斯算法的实现[J]．计算机科学，2014，41（3)：153-158.  \n[37］肖淇，秦云川，阳王东．一种基于MapReduce 的防火墙策略冲突并行化检测及消解模型［J]．计算机科学，2013，40(3):50-54.  \n[38］仇李寅，邱卫东，苏芊．基于Hadoop 的分布式哈希算法实现[J]．信息安全与通信保密，2011（11)：54-56.",
    "context2": "(本文责任编辑：孙国雷)"
  }
}