{
  "original_filename": "full_4469.md",
  "基于图神经网络的知识图谱补全研究综述": "",
  "吴越」孙海春1,2": {
    "context1": "1（中国人民公安大学信息网络安全学院北京100038)  \n2(安全防范技术与风险评估公安部重点实验室北京 100026)",
    "context2": "摘要：【目的】通过调研和梳理文献,总结基于图神经网络的知识图谱补全方法。【文献范围】以“KnowledgeGraph Completion”、“知识图谱补全\"作为检索词在Web of Science、DBLP和CNKI数据库中进行检索,共筛选出79篇文献。【方法】分别归纳总结图卷积神经网络、图注意力网络、图自动编码网络三种基于图神经网络的知识图谱补全方法类别,并对每种类别的技术脉络、典型方法、模型框架优缺点等进行对比论述。【结果】运用知识图谱补全任务的常用数据集和评价指标,从MRR、MR、Hit@k等性能评价角度对各类模型的效果进行对比分析,并对未来研究提出展望。【局限】在实验结果对比中,只讨论了FB15K-237和WN18RR数据集上部分应用较广的模型的评估结果,缺乏全部模型在同一数据集上的对比。【结论】相比基于表示学习模型和基于神经网络模型,基于图神经网络模型具有更好的图谱补全性能,但模型关系复杂性高、过平滑、可扩展性通用性差，这也是未来研究要解决的问题。",
    "context3": "关键词：知识图谱补全图神经网络图卷积神经网络图注意力网络图自动编码网络  \n分类号：TP391  \nDOI: 10.11925/infotech.2096-3467.2023.0753",
    "context4": "引用本文：吴越，孙海春.基于图神经网络的知识图谱补全研究综述[J].数据分析与知识发现，2024，8(3): 10-28.(Wu Yue, Sun Haichun. An Overview of Research on Knowledge Graph Completion Based on GraphNeural Network[J]. Data Analysis and Knowledge Discovery, 2024,8(3): 10-28.)"
  },
  "1引言": {
    "context1": "知识图谱是一种知识表示方法，其擅长描述真实世界中存在的各种实体和概念，以及它们之间的关系。2012年,谷歌首次发布知识图谱(KnowledgeGraph,KG)的概念[1],引起了学界和工业界极大的研究兴趣。随着研究的深人，越来越多的开放领域知识图谱被构建出来，其中具有代表性的图谱有",
    "context2": "DBpedia[2]、Freebase(FB15K)[3]、WordNet(WN18)[4]Facebook知识图谱[5]、微软知识图谱（MicrosoftConceptGraph)[6等。知识图谱是一个包含实体、属性和关系的图数据库,其基本构成形式为三元组（头实体，关系，尾实体),记为 $( h , r , t )$ 。实体可以是现实世界中具体的对象或抽象的概念，如人、地点、物体、事件等。关系用于表示实体之间的关联或实体的属性，也可以描述实体之间的联系和相互作用，通过三元组可以帮助人们组织和理解大量的结构化和半结构化数据。",
    "context3": "知识图谱将人类语言和文本中的信息进行提炼,转换为结构化的关联性知识,从而支持各种需要知识辅助的下游任务。知识图谱在问答系统[、推荐系统[8]、机器翻译[9]、情报分析[10]、智能决策[]等领域发挥重要作用，在医学诊断[12]、金融安全[13]、军事应用[14]、公安情报[15]等领域也展示出良好的应用前景。",
    "context4": "不完备性(Incompleteness)是知识图谱的特性之一。大规模知识图谱一般从文本中自动提取知识构建,知识具有不完备性,而这种不完备性会对下游任务的性能产生负面影响。建立一个数据丰富且准确的知识图谱,需要大量的技术和人力。多数知识图谱在建立后仍存在内容不完善的问题，因此，如何自动向知识图谱添加新的事实，即知识图谱补全（Knowledge Graph Completion,KGC）,已成为当前知识图谱领域的一个研究热点。",
    "context5": "深度学习和预训练语言模型的发展为知识图谱补全提供良好支撑。目前主流的知识图谱补全方法包括基于Trans 结构、基于张量分解、基于神经网络和基于图神经网络等多种技术。其中,基于图神经网络(Graph Neural Network,GNN)的知识图谱补全方法能够处理非欧几里得的图结构,不依赖于图的具体形状或拓扑结构,突破了传统神经网络方法在处理图结构数据上的局限性。图神经网络通过聚合图结构的数据,利用节点之间的连接关系和节点属性的特征进行信息传递和图结构学习，能够捕捉知识图谱中的局部和全局信息，从而实现知识图谱的补全。因其具备更高的计算效率和更好的可解释性,近年来受到广泛关注。",
    "context6": "深度学习和自然语言处理技术的不断成熟推动着知识图谱补全技术的不断演变和创新。随着知识图谱补全研究的深入,产生了大量的研究成果,也有较多关于知识图谱补全的综述文献发表。文献[16-19]这4篇关于知识图谱补全技术的综述文章,概述了知识图谱表示、获取和各类应用,并对知识图谱获取的不同方法进行了深入分析。Shen等[20]根据知识图谱补全方法中使用的信息源,将现有的知识图谱补全方法分为两大类：依赖结构信息的知识图谱补全方法和使用其他附加信息的知识图谱补全方法，每个类别被细分为不同的粒度以便于总结和比较。以上综述中,关于\"基于图神经网络的知识图谱补全方法\"缺少系统、全面与深入的论述。Arora[2总结了图神经网络在知识图谱补全任务中的最新应用。2022年，Li等[22]和Dai等[23]关于图注意力的研究为知识图谱补全提供了新的思路。此外,2023年GS-InGAT模型[24]和MA-GNN模型[25]在多个评价指标上获得最优评价，大大提升了知识图谱补全任务性能。综上所述,对基于图神经网络的知识图谱补全研究进行更全面的综述非常必要。",
    "context7": "本文将基于图神经网络的知识图谱补全(KGC)方法作为研究对象，整理归纳最新研究成果，并对未来的研究趋势进行展望。本文的主要贡献如下。",
    "context8": "(1)梳理归纳了基于图神经网络的方法类别。按照基于图卷积神经网络（GraphConvolutionalNetwork，GCN）、基于图注意力网络（GraphAttentionNetwork,GAT)以及基于图自动编码网络(GraphAuto EncoderNetwork,GAE)三个类别,对知识图谱补全方法进行综述，探讨了不同知识图谱补全模型的框架特点、技术发展脉络、典型工作、优势与不足等。",
    "context9": "(2)对比分析了常见模型的性能；列出了FB15K-237、WN18RR等常用的知识图谱补全数据集;并以知识图谱补全任务中常用的MR、Hits@k、MRR等评价指标为参考,给出典型模型的性能对比分析。",
    "context10": "(3)探究未来的趋势方向。结合已有工作及当前人工智能热点技术，展望了知识图谱补全研究未来值得关注的方向。"
  },
  "2知识图谱补全任务": "",
  "2.1知识图谱补全": {
    "context1": "知识图谱补全的任务在于填充知识图谱的缺失边(又称为缺失链接),即被认为正确但既没有给出也没有包含在知识图谱中[26],典型的子任务包括链接预测、关系预测以及实体分类等。链接预测(LinkPrediction）是确定给定三元组 $( ? , r , t )$ 或 $\\left( \\boldsymbol { h } , \\boldsymbol { r } , ? \\right)$ 的头实体或尾实体;关系预测(RelationPrediction）是预测给定三元组 $( \\pmb { h } , ? , \\pmb { t } )$ 的头实体和尾实体之间的关系；实体分类(Entity Classification)是一个多标签分类任务，旨在预测实体类型[27]。如图1所示，在R-GCN（Relational Graph Convolutional Network）模型[28]中,节点是实体,边是标有类型的关系,节点用实体类型标记。例如，U.S.A.的实体类型为国家，VaganovaAcademy是俄罗斯圣彼得堡一所著名的舞蹈学院,实体类型为大学。推断红色边的缺失信息即是链接预测任务，推断红色节点标签是实体分类任务。",
    "context2": "![](images/c8687885c9e27e6dd3a55e1a067d7a0389f3d51f95ba3c78c139fd06ed645dd6.jpg)  \n图1知识图谱片段  \nFig.1A Knowledge Graph Fragment"
  },
  "2.2知识图谱补全技术发展脉络": {
    "context1": "当处理大规模知识图谱时,通常会面临两个主要挑战：数据稀疏和计算低效。数据稀疏使得计算实体之间的语义或推理关系变得困难。在使用知识图谱进行实体之间的语义关系计算或多关系数据建模时，通常需要设计更加通用的算法实现这些复杂任务。为了克服这些挑战,知识图谱嵌入技术被提出[29]。为了表示实体之间的关系并有效地计算低维空间中的语义关系，通常可以将实体嵌入稠密的低维特征空间中。通过将实体映射到低维空间中的向量表示，可以捕获实体之间的语义关系，包含的参数数量减少，以简化操作并同时保留知识图谱的固有结构[30]。",
    "context2": "因此，最初研究人员使用嵌入技术解决知识图谱补全任务，典型的成果包括TransE模型[29]等,通过三元组向量化,头实体 $\\pmb { h }$ 加上关系 $r$ 即可得到尾实体$\\pmb { t }$ ，如公式(1)所示。",
    "context3": "$$\n\\pmb { h } + \\pmb { r } \\approx \\pmb { t }\n$$",
    "context4": "这样可以通过一个实体和关系来预测另一个实体。考虑到TransE模型较为简单，只是三元组内的向量叠加，难以解决知识图谱中节点间多种多样的关系，因此引入具备更强的泛化能力和学习能力的神经网络，典型成果包括卷积神经网络、循环神经网络等。随着大语言模型(Large Language Models,LLMs)浪潮的到来,LLMs[31以其从大规模语料库中学习知识的能力而闻名，可对文本进行编码生成事实，以提高知识图谱补全任务的性能。Lovelace等[32]研究表明,可以从预先训练好的大语言模型中提取实体表征，进而将这些表征应用于知识图谱补全任务。",
    "context5": "从Trans模型开始至今，知识图谱补全相关研究从初步侧重于学习低维嵌入以进行三重预测[16到运用图神经网络方法。本文将已有知识图谱补全技术的相关研究分为三种类型：基于表示学习、基于神经网络和基于图神经网络，如表1所示。每种类型都涵盖了不同的方法和技术，用于解决知识图谱补全的问题，这样的分类有助于整理和理解现有的研究成果。",
    "context6": "本文按照时间进展列举具有代表性的主要模型，以展示知识图谱补全主要模型的发展脉络，如图2所示。",
    "context7": "（1）基于表示学习的知识图谱补全",
    "context8": "知识图谱嵌入技术通常使用以下两类模型：基于平移距离的模型，如 TransE、TransH、TransR、RotatE;基于张量分解的模型,如RESCAL、DisMult、ComplEx、TuckER。",
    "context9": "TransE模型[29]于2013年提出,利用知识图谱嵌入技术,是经典的知识图谱表示学习模型之一。基于表示学习模型的基本思想是将知识图谱中的关系表示为从头实体到尾实体的向量差，即通过对三元组(头实体,关系,尾实体)中的头实体和关系进行加法运算得到尾实体的向量表示。具体来说,基于表示学习的方法将语义网络中的实体、关系和属性转换为低维向量，以获取分布式表示并捕获实体和关系之间的隐含关联。TransH模型[33]和TransR模型[34]都是基于TransE的改进模型,TransH模型假设每种关系都有一个关系特定的超平面，实体在该超平面上进行投影。TransR模型的关系嵌入矩阵 $\\pmb R$ 是一个可学习的矩阵，而不是直接对关系向量进行映射。"
  },
  "12 数据分析与知识发现": "",
  "表1知识图谱补全方法分类": {
    "context1": "Table 1 Classification of Knowledge Graph Completion Methods",
    "context2": "<table><tr><td>分类</td><td>子类</td><td>经典模型</td></tr><tr><td rowspan=\"2\">基于表示学习</td><td>平移距离结构</td><td>TransE[29]、TransH[33]、TransR[34]、RotatE[35]</td></tr><tr><td>张量分解</td><td>RESCAL[36]、DisMult[37]、ComplEx[38]、TuckER[39]</td></tr><tr><td rowspan=\"4\">基于神经网络</td><td>基于卷积神经网络</td><td>ConvE[40]、InteractE[41]、ConvKB[42] RSN[43]</td></tr><tr><td>基于循环神经网络</td><td></td></tr><tr><td>基于强化学习</td><td>DeepPath[44]</td></tr><tr><td>基于BERT</td><td>KG-BERT[45]</td></tr><tr><td rowspan=\"4\">基于图神经网络</td><td>基于图卷积神经网络</td><td>R-GCN[28]、RA-GCN[46]、SACN[47]、PGE-WGCN[48]、TransGCN[49]、VR-GCN[50]、COMPGCN[51] KE-GCN[52]、GGSHCN[53]</td></tr><tr><td>基于图注意力网络</td><td>KBGAT[54]、ICGAT[5]、GS-InGAT[24]、RGHAT[56]、LSA-GAT[57]、GAFM[58]、DisenKGAT[59]、RR- GA[60]、GCAT[61]、MRGAT(1)[2]、MRGAT(2)[23]、HRGAT[62]、MA-GNN[25]</td></tr><tr><td>基于图自动编码网络</td><td></td></tr><tr><td></td><td>VGAE[63]、GAEAT[64]、R-GAE[65]、M2GNN[6]、GATE[67]</td></tr></table>",
    "context3": "![](images/88d2c66b2fd9e18381248a17845d3448d38fd2a7264a2b9590d779575d112d30.jpg)  \n图2知识图谱补全主要模型发展脉络  \nFig.2Development of the Main Models for Knowledge Graph Completion",
    "context4": "基于表示学习的方法将实体或关系映射到低维向量空间中进行判断。相比于传统的One-Hot表示，其优点主要体现在维度较少且计算复杂度较低。同时,通过低维向量间的距离计算可以精准地展示实体间的相似性，有效地解决了数据稀疏性问题。然而,该方法存在一些局限性,如可解释性差，且未考虑更深层次的成分信息等。此外,这类模型对于数据中存在的错误和噪声比较敏感，而且对于长尾数据的处理能力相对较弱。",
    "context5": "(2）基于神经网络的知识图谱补全基于神经网络的知识图谱补全模型分为基于卷积神经网络、基于循环神经网络、基于强化学习以及基于 BERT（Bidirectional Encoder Representationsfrom Transformers)等主流框架模型。",
    "context6": "ConvE模型[40]于2018年提出，是知识图谱补全领域的一种创新性模型,模型首次将卷积神经网络应用到知识图谱补全任务中。卷积神经网络（Convolutional Neural Network，CNN）中 卷积核(Kernel)是模型的关键部分之一,用于从输入的图像中提取特征。卷积核的参数在不同位置是共享的,这意味着不同位置的卷积操作使用相同的参数。这种共享参数的设计可以大大减少模型需要学习的参数数量，从而降低模型的复杂度，并加速模型的训练过程[68]。循环神经网络（RecurrentNeuralNetwork,RNN)主要目的是学习序列数据的表示，通过递归地应用相同的转移函数处理输入序列,每一步都会根据前一时刻的状态和当前的输入计算出一个新的状态,并输出一个结果,每个时刻的状态都包含前面所有时刻的信息。循环跳跃网络(RecurrentSkippingNetwork,RSN)[43]将循环神经网络与残差学习相结合,有效地捕获知识图谱内部和之间的长期关系依赖关系。",
    "context7": "基于神经网络方法的本质是提取知识图谱的深度特征进行表示。将实体和关系作为神经网络中的节点和边进行建模，可以学习实体和关系之间更复杂的关系，便于对知识图谱中的隐式信息进行建模和预测。神经网络方法通过并行计算，能够快速处理大规模知识图谱,提高补全效率;同时，缓解了大规模知识图谱带来的数据爆炸问题,降低了计算难度。然而,神经网络模型通常需要大量的数据进行训练,尤其是在自然语言处理任务中,需要大量文本数据学习语义表示。模型的性能还会严重依赖于训练数据的质量，低质量的数据可能导致模型表现不佳。此外,神经网络模型通常是黑盒模型,很难解释模型如何得出预测结果。"
  },
  "（3）基于图神经网络的知识图谱补全": {
    "context1": "结构规则的图片或语言属于欧几里得结构数据。但在现实生活中，很多数据都具有不规则的结构,其中典型的就是图结构，或称为拓扑结构。知识图谱就是一种图结构。图结构的数据往往是非欧几里得的,因为它们没有固定的规则和网格,而是由实体和关系的交互形成,每个节点的邻居数量和邻居之间的连接方式都是独一无二的。",
    "context2": "对于这些不规则的数据结构，传统的欧几里得结构数据处理方法无法适用，图的非欧几里得特征使得图上的卷积和过滤失去意义，导致无法捕捉到复杂的关系和依赖。为了处理图结构数据，研究人员借鉴了卷积神经网络(CNN)和循环神经网络(RNN)等经典神经网络的思想,提出一类特殊的神经网络结构一一图神经网络，用于处理和分析图数据。",
    "context3": "基于图神经网络的知识图谱补全方法本质是将知识图谱看作一个图结构进行处理。实体被看作节点，关系被看作边,利用图神经网络学习实体、关系和属性之间的关系，从而进行知识图谱补全。与深度学习方法不同,图神经网络的输入数据是图结构。每个节点和边都具有一个向量表示,通过学习它们之间的拓扑结构表示，获得整个图的特征表示。例如,R-GCN模型[28]对不同关系中的节点都有对应的信息聚合方法，设定独立的权重矩阵。这使得聚合邻域节点时，节点信息会被权重矩阵记录。",
    "context4": "基于图神经网络的知识图谱补全方法优势在于能够通过学习实体和关系之间的复杂交互关系，进一步提高知识图谱的表示能力和预测准确性。同时，图神经网络具有良好的可扩展性和灵活性，不依赖于图的特定形状或拓扑结构，可以处理各种类型的图结构，如有向图、无向图、加权图等,适应各种不同类型的知识图谱补全任务。"
  },
  "3基于图神经网络的知识图谱补全方法": "",
  "3.1Encoder-Decoder框架": {
    "context1": "R-GCN[28]于2018年提出,是第一批将GCN成功应用于知识图谱补全任务的模型之一,是将GCN引入知识图谱补全任务中的开拓者。R-GCN模型构建了一个Encoder-Decoder框架，如图3所示，这种框架将基础的图神经网络模型广泛应用于链接预测和实体分类任务中。",
    "context2": "![](images/a2bb00b7df54a72d087734e8b506ce9dca938bb514a21600553ff657fccb8e09.jpg)  \n图3Encoder-Decoder框架  \nFig.3Encoder-Decoder Framework",
    "context3": "在该框架中，R-GCN作为Encoder,用于学习实体的特征表示;DisMult模型[37]作为Decoder,用于为图中的每个(潜在)边生成一个分数,计算三元组的得分。此后，许多基于图神经网络的知识图谱模型都采用Encoder-Decoder框架作为模型的基础框架。例如 SACN模型[47],对于Encoder部分，其采用多个加权图卷积网络（Weighted GraphConvolutionalNetwork,WGCN)层的堆栈，构建了一个实体/节点嵌入矩阵;对于Decoder部分，设计了一个基于"
  },
  "14 数据分析与知识发现": {
    "context1": "ConvE但具有TransE平移特性的解码器Conv-TransE,将三元组中的实体嵌入输入解码器中。输出嵌入经过向量化和投影，并与所有候选嵌入进行内积匹配,使用Sigmoid函数计算得分。TransGCN模型[49]能够同时对实体嵌入和关系嵌入进行编码，并通过Decoder部分生成预测结果。MA-GNN[25]使用编码器捕获局部和全局信息，使用GAT和Snowball局部注意方法学习局部图结构信息,基于Transformer的自注意力学习全局、远程关系。",
    "context2": "图注意力网络知识图谱补全模型也广泛使用了Encoder-Decoder框架。KBGAT模型[54]以ConvKB[42]作为解码器,采用卷积操作处理三元组数据。该模型的卷积层的目的是分析三元组在每个维度上的全局嵌入属性，并综合模型中的过渡特征。GAEAT模型[64]编码器利用扩展的图注意力机制,在对节点和其邻居之间的关系进行注意力加权的基础上，进一步考虑多跳邻居的信息，这使得编码器可以在给定实体的多跳邻居中同时生成实体和关系的特征表示,解码器使用DisMult提取三元组的内部潜在特征。R-GAE模型[则通过图自动编码器学习实体的嵌入表示。编码器将知识图谱中的实体和关系转换为低维向量表示,并捕捉它们之间的相互作用;解码器则用于重构原始的知识图谱，即通过嵌人向量还原实体和关系。",
    "context3": "由以上分析可知,Encoder-Decoder框架在图神经网络中应用广泛，设计和选择与具体任务密切相关。在图神经网络中,Encoder部分通常用于将图数据中的节点和边转化为低维向量表示，捕捉节点之间的拓扑结构和关系信息。Encoder可以是基于图卷积网络、图注意力网络、图自编码网络等各种模型。Decoder部分用于从学习到的低维向量表示中还原出原始的图数据或生成新的图数据。根据任务的不同，Decoder可以是用于节点分类、图分类、链接预测等任务的分类器;也可以是用于图生成、图重建等任务的生成器。",
    "context4": "Encoder-Decoder框架适用于大多数图神经网络模型，是知识图谱补全的一个高效的解决方案。但是，目前存在的图神经网络模型通常是基于公开可用的通用数据集,这限制了对特定任务和应用场景的设计与优化。因此,如何设计通用的图神经网络模型,适用于不同类型和规模的知识图谱,是一个具有挑战性的任务。"
  },
  "3.2典型类别技术脉络研究": {
    "context1": "按照核心模型框架,将基于图神经网络的知识图谱补全方法分为基于图卷积神经网络、图注意力神经网络和图自编码网络三类，总结分析了基于图神经网络的知识图谱补全方法最新进展。"
  },
  "（1）基于图卷积神经网络的方法": {
    "context1": "图卷积神经网络(GCN)是一种用于在图结构数据上进行半监督学习的方法。表示学习在许多领域都取得了很大的成功,学习图在低维欧氏空间中的表示，图的属性就可以被保留。通过引入在图上操作的卷积神经网络变体，克服了传统卷积神经网络在处理图数据时的限制。本文按照时间脉络梳理GCN模型的演进,如图4所示。",
    "context2": "![](images/720ed47dfaf2e4989dffaabf3e2a1222d8695216bc5017805a6272fa9ddf40cb.jpg)  \n图4GCN模型演进示意图  \nFig.4Evolution of GCN Model",
    "context3": "GCN模型[9]于2017年提出,将图中的数据通过映射函数聚合自身节点和邻居节点的特征信息，从而实现对图数据的特征提取。与传统卷积神经网络(CNN)相似,GCN也可以看作一个特征提取器，但它的对象是图数据而不是图像数据。GCN精妙地设计了一种从图数据中提取特征的方法，借鉴卷积神经网络在图像处理领域的成功经验，将卷积操作从欧几里得空间推广到非欧几里得空间,实现了图数据的特征提取。如公式(2)所示，输入包括邻接信息矩阵 $\\pmb { A }$ 、输入特征矩阵 $X$ （或者称为特征矩阵Feature)以及权重矩阵 $W$ 。",
    "context4": "$$\n\\begin{array} { r } { \\pmb { Z } = f ( \\pmb { X } , \\pmb { A } ) = \\mathrm { S o f t m a x } \\left( \\pmb { A } \\mathrm { R e L U } \\left( \\pmb { A } \\pmb { X } \\pmb { W } ^ { ( 0 ) } \\right) \\pmb { W } ^ { ( 1 ) } \\right) ( 2 \\pmb { A } \\pmb { W } ^ { ( 0 ) } \\pmb { W } ^ { ( 0 ) } ) } \\end{array}\n$$",
    "context5": "在GCN的基础上，R-GCN模型[28考虑了关系的远近对消息传播的不同影响。因此,在处理邻居时，考量关系的因素对邻居进行分类操作。对于每一种关系的邻居引入不同的权重参数,分别对属于同一关系类型的邻居聚合之后，再进行一次总聚合。R-GCN和RA-GCN模型中单个图节点更新示意图如图5所示。",
    "context6": "![](images/73596b72be81eee0ca1a27c7b74d9327ade708c4e1203a53022662ec46044fc7.jpg)  \n图5R-GCN和RA-GCN模型中单个图节点更新示意图[28,46] Fig.5Updating a Single Graph Node in R-GCN and RA-GCN Models",
    "context7": "对于相邻节点,计算单个图节点/实体(红色)时考虑了图中的方向。关系类型分为入边和出边，同时考虑自身节点的自环。结果(绿色)经过归一后的总和通过激活函数(ReLU函数)传递,保证每个节点的更新可以与整个图中的共享参数并行计算。其特征更新函数如公式(3)所示。其中 $\\pmb { h } _ { i } ^ { ( l + 1 ) }$ 是指更新后各个节点的特征， $N _ { i } ^ { r }$ 表示在满足 $r { \\in } R$ 关系下，节点 $j$ 的邻居节点集合， $\\frac { 1 } { c _ { i , r } }$ 为常数项(正则化常量)。",
    "context8": "$$\n\\pmb { h } _ { i } ^ { ( l + 1 ) } = \\sigma ( \\sum _ { r \\in R } \\sum _ { j \\in N _ { i } ^ { r } } \\frac { 1 } { c _ { i , r } } \\pmb { W } _ { r } ^ { ( l ) } \\pmb { h } _ { j } ^ { ( l ) } + \\pmb { W } _ { 0 } ^ { ( l ) } \\pmb { h } _ { i } ^ { ( l ) } )\n$$",
    "context9": "在R-GCN模型的基础上,RA-GCN(RelationalAggregation Graph Convolutional Network)模型[46]对实体分类和链接预测进一步优化。通过寻找具有相同属性的实体并抽象为虚拟实体，收集与要更新的实体相关的关系向量，从而聚合此子集中具有部分相同属性的实体，如图5所示。其特征更新函数如公式(4)所示。其中， $\\sum _ { a \\in A } \\frac { 1 } { c _ { a } } \\pmb { h } _ { a } ^ { ( l ) } \\pmb { W } _ { a } ^ { ( l ) }$ 为关系聚合项; $\\frac { 1 } { c _ { a } }$ 为常数项，可以预先设定,也可以通过训练模型获得。",
    "context10": "$$\n{ \\pmb h } _ { i } ^ { ( l + 1 ) } = \\sigma \\big ( { \\pmb h } _ { i } ^ { ( l ) } { \\pmb W } _ { 0 } ^ { ( l ) } + \\sum _ { j \\in N _ { i } ^ { r } } \\sum _ { r \\in R } { \\pmb h } _ { j } ^ { ( l ) } { \\pmb W } _ { r } ^ { ( l ) } + \\sum _ { a \\in { \\pmb A } } \\frac { 1 } { c _ { a } } { \\pmb h } _ { a } ^ { ( l ) } { \\pmb W } _ { a } ^ { ( l ) } \\big )\n$$",
    "context11": "R-GCN模型聚合的目标是邻居，对关系本身的信息没有进行捕捉。由于没有考虑节点邻域的差异权重，每个邻居节点都被认为是同等重要的。然而，在实际场景中，节点之间的边的权重可能是不同的,节点的邻域结构也可能是不规则的，这导致R-GCN模型在一些复杂场景下表现不佳。R-GCN是一个逐层聚合节点特征的过程，模型也需要使用解码器"
  },
  "16 数据分析与知识发现": {
    "context1": "计算实体之间的相似度，这增大了模型的复杂度和计算量,模型训练速度会比较慢。在具体场景中,网络中的关系也携带丰富的语义信息作为节点,如何考虑将关系嵌入提高具体应用的有效性成为研究人员考虑的重点。基于上述方向，SACN模型[47]和TransGCN模型[49]给出了解决办法。",
    "context2": "2019年,Shang等提出 SACN模型[47],结合GCN和ConvE模型构建了端到端的卷积网络。该网络由加权图卷积网络(WGCN)和Conv-TransE的卷积网络解码器组成。该模型利用节点结构、节点属性和边缘关系类型，具有可学习的权重，可以适应局部聚合中使用邻居信息的数量。聚合时，对不同类型的关系分配不同的权重，并且在网络的训练过程中自适应学习权重。2022年提出的PGE-WGCN模型[48]是SACN模型的具体应用,构建了一种解析图嵌入和加权图卷积网络(WGCN)结合的模型框架。通过聚合邻域特征、更新当前节点两个步骤对语义依存解析图生成语义依存解析图嵌入。该模型在如何提取网络中丰富的语义信息的方向上进行了优化,通过非结构化文本等辅助信息中提取深层次语义特征的原理对实体建模。",
    "context3": "TransGCN模型[49]同样注意到R-GCN模型不学习关系嵌入的问题，这导致在没有解码器的情况下不能直接用于链接预测。之后，研究人员还注意到R-GCN模型同时在编码器端和解码器端重复引入关系特定参数，导致参数数量增加的问题。TransGCN模型将具有关联关系的邻近节点聚合成消息传播到中心节点，以学习实体嵌入和关系嵌入，同时模型将头部实体转换为尾部实体以便知识图谱中的异质邻域转换为同质邻域。可见,TransGCN模型的改进将用于知识图谱补全任务的编码器同时编码实体和关系嵌人，以减少参数的数量，从而提高训练效率。",
    "context4": "虽然 SACN和TransGCN模型考虑了关系嵌入问题,提高了补全效率,但是仍存在多关系信息不能充分利用、多关系网络对齐任务应用效果差的问题。例如，在GCN层之间传输的多关系信息遭受了很多损失，这会导致实体间的节点结构特征和语义特征关联挖掘不足,降低图谱知识补全的效率。因此，一种矢量化关系图卷积网络模型VR-GCN[50]被提出。",
    "context5": "VR-GCN模型通过累积其相邻实体和关系的嵌入更新实体的嵌入，并通过集成其头部和尾部实体的嵌入更新关系的嵌入。同时，考虑角色区分,针对实体角色不同以及关系的类别信息和方向信息，进行不同的卷积操作。分析发现,和以往的GCN模型进行比较,VR-GCN模型不仅可以对节点进行嵌入学习，而且对关系也能很好地进行嵌入学习，其整合了GCN和翻译模型的优点。",
    "context6": "如果图中节点的顺序是重要的,则为有向图;反之则为无向图。知识图谱是一个异构有向图,这意味着两个节点之间的关系是有向的，并且两个节点之间可以存在多条边[18]。沿着VR-GCN模型的研究思路，COMPGCN模型[5]是一种针对多关系有向图的图神经网络模型,将图的关系加入表示学习中，同时联合学习实体嵌人和关系嵌人。该模型丰富了边的类型,包括反向关系类型和自循环关系类型，以对多关系图进行表征学习，并且解决了多关系图表示中参数过载的问题。",
    "context7": "上述知识图谱补全任务的图卷积模型虽然同时学习了节点和边的嵌人，但主要精力还是在根据关系嵌入优化实体嵌人，没有对称的过程。例如，在COMPGCN模型中，关系嵌入仅通过线性变换进行更新，因此KE-GCN模型[52]在关系表示更新过程中引入了相邻实体表示的聚合，同时实体嵌入和关系嵌入进行相互更新。在计算关系嵌入时，还考虑了关联的实体信息，并且关系嵌入也被相邻上下文增强,是对COMPGCN模型的一种改进。设 $\\pmb { h } _ { i } ^ { l + 1 }$ 表示 $k$ 层后得到的节点 $\\nu$ 的特征更新函数，如公式(5)所示。其中， $\\pmb { h } _ { u } ^ { ( l ) }$ 和 $\\pmb { h } _ { r } ^ { ( l ) }$ 分别表示节点和关系的初始特征， $\\pmb { h } _ { i } ^ { ( l + 1 ) }$ 表示节点 $\\nu$ 的更新表示。",
    "context8": "$$\n{ \\pmb h } _ { i } ^ { ( l + 1 ) } = \\sum _ { ( u , r ) \\in N ( i ) } { \\pmb W } _ { r } ^ { ( l ) } \\phi _ { i n } \\big ( { \\pmb h } _ { u } ^ { ( l ) } , { \\pmb h } _ { r } ^ { ( l ) } \\big )\n$$",
    "context9": "知识图谱中大量节点的直接邻居很少，导致节点特征无法充分表达。因此,多跳结构特征对于节点的表示学习至关重要，多跳结构表示需要多跳关系。He等[53]构建了GGSHCN模型,该模型是一种基于矩阵的图子跳卷积网络模型(Graph Sub-HopConvolutionalNetwork）,基于TransE理论表示了多跳关系的特征表示，将多跳特征信息直接融合到节点嵌入中。该模型通过学习实体的结构特征寻找隐式三元组，运用多跳关系表示方法划分和表示关系嵌入，填补了多跳关系问题的空白。",
    "context10": "通过分析图卷积神经网络知识图谱补全的技术发展脉络可知,基于图卷积神经网络模型通过将图结构信息由拉普拉斯矩阵特征向量表示聚合相邻节点的信息，且大多模型同时考虑了知识图谱的语义信息和结构信息。但是,这类模型复杂度高，图神经网络对一个三元组往往会有多层的信息传递和计算,这虽然增强了对关键信息捕捉的能力,但一定程度上加重了模型训练负担,使得模型训练代价高。",
    "context11": "基于图卷积神经网络的知识图谱补全任务虽然已经取得了一些成果,但是依然面临着一些难点。大部分知识图谱补全模型(如Trans模型和张量分解模型)都是对同一时间点的图谱内容进行补全，模型在训练时也只是针对训练集中已有的三元组,无法推测出数据中未知的三元组数据，这种静态的补全方式难以适应外界环境的变化,模型的可扩展性差。"
  },
  "(2）基于图注意力网络的方法": {
    "context1": "2018年，Velickovic等[70]提出图注意力网络（GraphAttentionNetwork,GAT）。GAT是一种基于图结构数据的新型神经网络架构，借鉴人类的视觉注意力机制,聚焦于感兴趣的区域,将重点放在特定的目标上，利用隐藏的自注意力层扫描全局图像，并获取需要重点关注的目标区域,进而为这些区域分配更多的注意力资源,以获取与目标相关的详细信息。GAT模型的演进示意图如图6所示。",
    "context2": "![](images/e2ce0476c6dddcf197f7071ee983c9031632974b020ff804f4ffa538e80f248c.jpg)  \n图6GAT模型演进示意图  \nFig.6Schematic Diagram of GAT Model Evolution",
    "context3": "在参考GAT思想的基础上，Nathani等[54]提出KBGAT模型，是第一个基于图注意力的知识图谱补全模型。KBGAT模型为GAT加入边的关系，可以让实体多次迭代，能够捕捉任意给定实体的多跳邻居中的实体和关系特征。将特征向量进行拼接之后再通过一层全连接层，然后经由卷积层和ReLU层进行激活,之后使用 Softmax函数归一化,得到节点对节点的注意力系数，在模型最后一层取平均后得到特征更新函数，如公式(6)所示。即GAT更新节点的方式是使用注意力系数乘以邻居节点的表示后求和;而KBGAT模型计算方式是使用注意力系数乘以该节点所在三元组的表示后求和。其中, $\\boldsymbol { \\mathcal { \\alpha } } _ { i j k }$ 为每条边的注意力值,通过对该节点所在三元组 $\\pmb { t } _ { i j } ^ { k } =$ $( \\boldsymbol { e } _ { i } , \\boldsymbol { r } _ { k } , \\boldsymbol { e } _ { j } )$ 中实体 $e _ { i }$ 和 $e _ { j }$ 以及关系 $\\boldsymbol { r } _ { k }$ 特征向量的串联执行线性变换,得到三元组的向量表示 $c _ { i j k }$ 。使用这种计算方式,可以学习与 $e _ { i }$ 关联的每个三元组。",
    "context4": "$$\n\\pmb { h } _ { i } ^ { ( l + 1 ) } = \\sigma ( \\frac { 1 } { M } \\sum _ { m = 1 } ^ { M } \\sum _ { j \\in N _ { i } } \\sum _ { k \\in R _ { i j } } \\alpha _ { i j k } ^ { m } \\pmb { c } _ { i j k } ^ { m } )\n$$",
    "context5": "KBGAT模型为不同的三元组分配不同的权重，突破了基于图卷积神经网络的模型无法分配不同权重的局限性。然而，KBGAT模型只是在GAT模型的基础上加入关系调整,简单地将关系向量拼接在两个节点信息后面,忽略了关系特征对三元组头、尾节点作用程度的差异，实体和关系没有充分交互。同时,KBGAT模型使用Encoder-Decoder框架,编码器和解码器分开训练，导致两者不能有效联动，影响链接预测任务的准确性。",
    "context6": "在KBGAT模型的基础上，Lu等[55]构建了ICGAT模型,一种基于交互式连接的图注意力网络。Yin等也同样构建一种基于交互图注意网络的GS-"
  },
  "18 数据分析与知识发现": {
    "context1": "InGAT模型[24]。在KBGAT模型的基础上,ICGAT模型增强了关系特征的捕获,获得实体邻居之间的指示性交互信息，但是还存在将文本信息视为单个实例增强相应实体的结构信息，而忽略其在知识图谱中的全局语义信息的问题。GS-InGAT模型利用图结构学习方法学习最优语义图，能够有效地学习实体的全局语义特征和交互特征，进一步解决了KBGAT模型和ICGAT模型存在的问题。然而，现有的关于图结构学习模型的研究都假设给出了初始节点特征,生成的初始节点特征有可能不准确,如何获得真实的特征也是下一步研究需要解决的难点。此外,GS-InGAT模型存在无法处理训练集中没有出现的实体的问题。",
    "context2": "RGHAT模型[56]是一种层级注意力的图神经网络模型。通过将实体之间的关系作为边来构建图，并利用注意力机制对实体之间的关系进行加权，相同关系的领域权重能够以共同的方式进行训练。GAFM模型[58]基于图注意力衰减机制,根据路径长度的变化调整邻居节点的注意力值，给予目标实体的邻居节点不同的权重。注意力衰减系数通过减小邻居节点与目标实体之间的距离调整注意力值。以上两种模型都通过各自不同的思想,实现实体嵌入与关系嵌入的良好交互，提高补全效率。",
    "context3": "在解决图卷积神经网络模型无法分配不同权重的问题上，如何使用多阶关系进一步丰富邻域信息也是研究的重点。图卷积神经网络模型被认为忽略了丰富的局部结构，这些结构的不同语义信息没有被捕捉，Ji等[57]构建LSA-GAT模型，提出了局部结构感知图注意网络,应用实体周围的局部结构并聚合局部结构信息更新实体和关系的嵌入，同时引入基于局部结构感知的词向量嵌入方法,增强对文本信息的理解能力。模型证明了不同的局部结构对链接预测性能的贡献不同,整体性能与应用的实体局部结构数量成正比,这验证了局部结构信息对于知识图谱补全是有意义的。",
    "context4": "知识图谱中存在复杂的关系，如国籍就是一种典型的多对一关系,以(科比,职业,？)和(比尔·盖茨，职业，？)为例，由于两人国籍均为美国,科比和比尔·盖茨两个实体将会被拉近以共享国籍为美国这一信息。而针对职业这一关系,两者差异巨大,直觉是应该疏远两者，并无明显相关性，显然静态且唯一的表征会显著影响图谱补全的效果。现有的方法只将图谱中的实体表征成单独的静态的一个向量，难以捕捉图谱中复杂的关系。基于此,DisenKGAT模型[59]采用知识图谱解耦表征方法,将每个实体表征为多个独立的向量，从而提升模型的表达能力。因此,该模型一方面实现了“微观解耦”,在知识图谱卷积中引入关系感知信息聚合机制，促使表征的每个成分聚合到不同的信息；另一方面实现了“宏观解耦”,通过添加互信息正则项增强表征中每个成分之间的独立性。通过将实体不同主题语义表示进行拆分解耦，实现不同场景下动态化表示，从而有效解决复杂多语义知识图谱表示补全。",
    "context5": "当前基于GNN的模型中，实体嵌入的更新利用网络的拓扑信息，而关系的更新通常采用线性变换，忽略同一关系在不同局部网络结构中具有语义差异的事实。同时，不同类型的相邻实体被简单地聚合在一起,失去了实体的类型和全局重要性等实体的全局属性,易造成过平滑问题。Zhang等[0]构建DRR-GAT模型,提出一种具有动态表示关系和全局信息的图注意力网络。关注关系的动态表示的任务是学习同一关系在不同三元组中的独特表示,通过路径转换器将路径信息作为其输入，其中只考虑那些从目标实体到与目标关系类型相同的邻接关系的路径。随后，全局嵌入的机制被纳入图注意力网络，以捕捉实体和关系的全局信息。",
    "context6": "除了上述在KBGAT模型的基础上进行改进的模型外，还有一些借助外部知识的知识图谱补全模型：GCAT模型]将对比学习融入补全任务；MRGAT(1)[22]和MRGAT(2)[23]考虑异构多关系连接；HRGAT模型[62]研究多模态KGC任务;MA-GNN模型[25]采用基于Transformer的自注意力机制。",
    "context7": "GCAT模型另辟蹊径，将对比学习运用在知识图谱补全中，关键之处在于利用对比学习增强实体表示的能力。对比学习是一种无监督学习方法，通过比较正样本和负样本学习更具有判别性的表示。在GCAT模型中，中心实体和其上下文关系子图可以看作正样本，而其他不相关的实体和子图则可以作为负样本。通过将正样本和负样本进行对比学习,GCAT模型可以学习到更具有区分性的实体嵌"
  }
}