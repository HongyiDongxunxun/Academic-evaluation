{
  "original_filename": "full_2530.md",
  "可解释信息推荐研究综述": {
    "context1": "李伟卿1.3，王伟军²，黄炜1,3，田萌¹，张瑞}（1．湖北工业大学经济与管理学院，武汉430068；2.华中师范大学青少年网络心理与行为教育部重点实验室，武汉430079；3．湖北循环经济发展研究中心，武汉430068)",
    "context2": "摘要可解释信息推荐能有效提高推荐结果的可靠性，提升用户信任度和满意度，是未来研究的重要方向之一。了解可解释信息推荐的研究进展，能为可解释推荐研究提供新的思路与借鉴，促进可解释推荐研究的发展。通过对国内外可解释信息推荐相关文献的梳理与分析，深人剖析可解释信息推荐算法与解释机理、推荐解释的媒介与呈现，以及推荐解释评价3个方面的研究现状与不足，尝试对可解释智能推荐系统所关注的“三个W（who，what，why）问题”进行回答，并提出了可解释信息推荐未来的研究方向与课题。",
    "context3": "关键词可解释信息推荐；研究综述；可解释性；因果推断"
  },
  "A Review of Explainable Information Recommendation": {
    "context1": "Li Weiqing13, Wang Weijun², Huang Wei1,3, Tian Meng' and Zhang Rui' (1.School ofEconomics and Management,Hubei University of Technology,Wuhan 430068; 2. Key Laboratory of Adolescent Cyberpsychology and Behavior(CCNU),Ministry of Education, Wuhan430079; 3.Hubei Circular Economy Development Research Center, Wuhan 430068)",
    "context2": "Abstract:Explainable informationrecommendation can efectively improvethereliabilityofrecommendationresults and user'strust and satisfaction,which willbe an important directionoffutureresearch.Reviewing thesituationand progress of esearch inthis areacan provide ideas andreferenceforfurther investigation,and promote thedevelopmentof explainablerecommender.By searching and investigating the literaturerelated to explainable information recommendationat homeand abroad,we deeply analyzed the statusand shortcomingsofresearch in three aspects: interpretation mechanism of explainable recommendation model,mediaand presentationofrecommendation interpretation,andrecommendation interpretation evaluation.Furthermore,werespondedtothe“threeW(who,what,why)questions”inexplainable intellient recommender system, proposed future research directions and topics of explainable information recommendation.",
    "context3": "Keywords: explainable information recommendation; review; explainability; causal inference"
  },
  "0引言": {
    "context1": "者展示推荐结果，而且提供相应解释以阐明推荐理由的个性化推荐算法。它能够描述智能推荐系统的推荐原理和过程，是未来研究的重要方向之一[1-2]。",
    "context2": "可解释信息推荐，是指不仅向用户或系统设计推荐准确度只能部分评估推荐系统的性能，而推荐系统的可解释性，即解释一个项目为何被推荐的能力，是同等重要的。适当的解释可以增加用户信任度，改善用户体验，帮助用户做出更好的决策[3-4]。自其出现以来，信息推荐技术一直是学术界和产业界关注的焦点，已被广泛应用于人们网络生活的方方面面[5]。目前的信息推荐算法普遍缺乏有效的解释机制，用户的使用体验较差，会感觉推荐系统是一个黑箱子，无法理解其推荐的理由，造成用户对于推荐结果的满意度和感知价值有限。人们通常对人工智能推荐系统为什么做出如此决策、形成这样的推荐知之甚少。对于用户而言，很多推荐算法是难以理解的，特别是矩阵分解、深度学习等复杂的算法模型，这种不可理解性和不可预知性会降低用户对于推荐系统的信任，尤其在决策错误会面临重大后果的情况下[6-7]。国家互联网信息办公室、工业和信息化部、公安部、国家市场监督管理总局颁布的《互联网信息服务算法推荐管理规定》中明确提出，算法推荐服务提供者应当“综合运用内容去重、打散干预等策略，并优化检索、排序、选择、推送、展示等规则的透明度和可解释性，避免对用户产生不良影响，预防和减少争议纠纷”[8]。因此，对信息推荐技术的透明性和可解释性进行研究具有紧迫性与重要意义。本文对可解释信息推荐相关研究成果进行了系统梳理与总结，尝试回答可解释智能推荐系统所关注的3个W（who,what,why）问题[9]，最后结合现有研究的不足和网络发展的趋势探讨可解释信息推荐的研究方向，为未来可解释信息推荐的研究提供参考和借鉴。"
  },
  "1可解释信息推荐研究概况": {
    "context1": "本文通过WebofScience（WoS）中的高级检索工具，以“explainable”“explainability”“recom-mendation”“recommender system”作为检索词，检索式为 $\\mathrm { T I } =$ “explainable and recommender system”or“explainable and recommendation”or“explain-ability and recommender system”or“explainabilityand recommendation”，共命中文献 521篇，去除本领域无关文献93篇，最终得到文献438篇，具体如图1所示。就整体而言，学术界对可解释推荐研究的关注度从2017年开始持续上升，越来越多的研究者认识到可解释性对于推荐系统发展的重要性。早期，基于内容的推荐，利用用户和项目的相关特征进行建模，其推荐解释一般是让用户了解其感兴趣的特征[10]；基于项目的协同过滤（item based collab-orativefiltering，ItemCF）推荐，一般通过用户熟悉的其他项目来解释推荐结果，如“这个产品与你喜欢的其他产品相似”[；而基于用户的协同过滤，其解释为“与你品味相似的用户也喜欢”[12-13]。2002年，Sinha等[14]指出了透明性对于推荐算法的重要性，推荐解释提供了一种建立用户信任的解决方案，可通过解释提升其透明度、用户的信任度、用户的满意度及购买意愿[15]。2007年，Tintarev等[提出了可解释推荐的7个目标与标准，为推荐解释的评价提供了依据。2014年，Zhang等[17]针对隐因子模型的不可解释性，提出了一种显式因子模型，将显式的项目特征与模型潜在维度进行对应，以获取推荐结果的可解释性。近年来，研究者探索深度学习推荐模型和基于知识图谱推荐的可解释性，如Lu等[8]提出了一个多任务深度学习模型用于生成推荐和解释，该模型联合因子分解模型用于评分预测和基于注意力的GRU（gatedrecurrentunit）网络提取评论文本特征并学习为推荐结果生成推荐解释；He等[19]提出一种三元组（用户-项目-特征）图网络结构，通过三元组的相似度对用户形成Top $. N$ 推荐，解释则归因于用户和推荐项目之间匹配的特征。随着因果推断的兴起，很多学者开始探索将因果推断模型应用于推荐算法的研究中，构建可解释信息推荐模型[20-22]。",
    "context2": "![](images/b674ca1c8bbbbcb4bdd9e84440409a5a3be824df588fb4bdcef325d97d632a42.jpg)  \n图1国际期刊关于可解释推荐系统研究的发文现状",
    "context3": "通过中国知网的高级检索功能，以“解释”且“推荐”作为检索式，检索结果如图2所示。可以看出，国内期刊上关于推荐系统的可解释性研究的发文量明显偏少，从2016年才开始出现相关研究成果，至今共发表相关论文17篇，其研究主要包括两个方面。一方面，是提出一种可解释推荐算法。如余以胜等[23]通过在基于项目的协同过滤算法中引入偏置，提出一种可解释的实时图书推荐模型；高嘉良等[24]引入基于知识图谱的景点推荐框架，将推荐过程与知识图谱嵌入相结合，推断用户兴趣在知识图谱上的传播路径，以此作为推荐依据与解释；李伟卿等[25]从用户近期产品需求及其长期生活方式两个维度构建用户长短偏好模型，将用户长短偏好与其评分相结合进行推荐预测，形成相应的推荐和解释。另一方面，是采用用户研究的方法分析推荐信息呈现、推荐解释的偏好对于消费者购买意愿的影响。如李芳等[2基于解释水平理论，分析了信息呈现对于推荐效果的影响；李治等[27基于传播说服理论，研究了动/静态推荐解释对用户购买意愿的影响。",
    "context4": "![](images/830a94b7c8b084e8962ec5967c293e69b1588c71c673adfb563af05f71912a90.jpg)  \n图2国内期刊关于可解释推荐系统研究的发文现状",
    "context5": "Zhang等[28]指出，机器学习算法的可解释程度通常与相应模型的两个属性相关联：一是模型的响应函数 $f ( x )$ ；二是模型的输入特征 $x$ 和输出 $y$ 之间的关系。因此，信息推荐技术的可解释性可以从模型和输入数据两个方面进行分析，一方面，是解释的信息来源及呈现方式，代表了可解释推荐研究的人机交互视角；另一方面，是生成解释的模型，代表了可解释推荐研究中的机器学习视角。从这两个角度对可解释信息推荐研究进行了系统性的介绍，但缺乏对可解释推荐模型的内在机理与推荐解释如何影响用户的分析。综上，本文尝试从可解释信息推荐算法与解释机理、推荐解释的媒介与呈现，以及推荐解释的评价3个方面对现有研究进行梳理与总结，以揭示可解释信息推荐技术关注的3个重要问题—一向谁解释、解释什么和解释的目的，并从这3个方面提出可解释推荐技术的研究方向。"
  },
  "2可解释信息推荐算法及解释机理": {
    "context1": "每一种推荐算法本质上都是基于一定的数学、营销学、心理学等原理计算形成推荐结果，可解释信息推荐的关键是在推荐结果的同时呈现这个原理。从推荐方法而言，推荐系统被划分为基于内容的推荐、基于协同过滤的推荐和混合推荐3种。具体如图 $3 ^ { [ 4 ] }$ 所示。",
    "context2": "![](images/4a782eb30aafbbecb3fff248dd3a2cd10dff3dc538bdd32793cad4bf5a66601c.jpg)  \n图3推荐算法[4]",
    "context3": "其中，基于协同过滤的推荐又分为基于内存的协同过滤和基于模型的协同过滤。基于内存的协同过滤包括基于用户的协同过滤和基于项目的协同过滤；基于模型的协同过滤即通过机器学习或者数据挖掘模型构建一个评分预测算法，以此提升协同过滤推荐技术的性能，这些模型主要包括聚类、矩阵分解、关联规则、神经网络等。在实践中，为了弥补单一推荐方法的局限，通常会采用混合推荐（综合使用以上两种推荐方法）的方法，以便能够获得更好的推荐效果。因此，根据以上划分，这里针对基于内容的推荐和基于协同过滤的推荐这两种经典推荐，剖析其推荐机制及解释机理。同时，从推荐算法的实现模型来看，由于有些算法模型可能存在于以上两种推荐中，彼此之间存在着交集，而且近年来又新出现了如基于因果推断模型的推荐等，本节最后做了说明，并最终形成可解释信息推荐算法及其解释机理体系图（详见2.2节图6）。"
  },
  "2.1基于内容推荐的解释机理": {
    "context1": "基于内容的推荐强调分析项目的特征形成推荐，从用户的交互数据中提取项目特征，形成用户的偏好配置文档，然后通过计算模型寻找项目文档和用户配置文档之间的相似性以产生推荐。常用的计算模型包括词频逆文档频率（term frequency-inverse document frequency，TF-IDF）、决策树、聚类分析、余弦相似度等[29]。基于内容的推荐不需要知道其他用户的偏好即可形成推荐。其解释性通常体现在推荐结果与用户喜欢的项目之间的相似性以及特征出现的频率所代表的用户偏好权重[30]。例如，NewsDude新闻推荐系统采用TF-IDF模型表征新闻信息，计算用户偏好与新闻特征向量之间的余弦相似度，从而形成推荐[4]。王微微等[31通过对不同时间周期内用户所浏览、购买的项目频率进行计算，表示用户的长短周期偏好与兴趣变化，以提升推荐效果。另外，基于知识的推荐，即满足用户明确需求的推荐，通常基于领域本体的构建或者明确的规则进行推荐，也是一种基于内容推荐。其推荐产生的原因较为明确，解释性体现在满足用户需求的同类产品之间的相关性或者明确的推荐规则。例如，李明等[32]提出基于模糊文本分类的多知识领域专家推荐方法，建立模糊文本分类器，通过分析用户浏览日志识别其知识需求，根据专家的知识模型与用户知识需求的匹配度进行专家推荐。陈明[33]基于领域知识与顾客购买偏好的关联事实，从相关领域知识表示、知识获取和系统实现3个方面提出个性化协同商务推荐。"
  },
  "2.2基于协同过滤推荐的解释机理": {
    "context1": "基于协同过滤的推荐主要思想是通过用户的显式反馈或隐式反馈建立用户项目偏好（user-item）矩阵，进而计算用户或者项目的相似度以形成推荐。其中，基于用户的协同过滤推荐（user basedcollaborative filtering，UserCF）是以用户为核心,通过比较用户对同一项目的评分计算用户之间的相似度，寻找其“近邻用户”，通过“近邻用户”对项目的偏好预测目标用户对未知项目的偏好得分以形成推荐[34]，如图4所示，其解释性就是通过相似用户的偏好体现的。",
    "context2": "基于项目的协同过滤（ItemCF）是以项目为核心，根据user-item矩阵计算项目之间的相似性进行推荐预测。从user-item矩阵中检索目标用户的所有评分项目，通过其他用户的评分计算项目与目标用户喜欢的项目之间的相似度，并进行排序，把排名较高的结果反馈给用户形成推荐[35]。基于项目的协同过滤推荐算法如图5所示。",
    "context3": "![](images/1e111beeb9da062509cf6f46caaf8e690ddad1c647f61d3bc6a68f7541cae4fc.jpg)  \n图4基于用户的协同过滤推荐算法",
    "context4": "![](images/b1806771a02534276540b8ce2f2967f4df79f326567f70e6c10185f0a394582e.jpg)  \n图5基于项目的协同过滤推荐算法",
    "context5": "其解释性可描述为“喜欢项目A的用户大多也喜欢项目B”。因此，基于内存的协同过滤推荐的解释性通常是“兴趣偏好相似的用户，其对某个新项目的偏好可能也相似”。如亚马逊电商网站通过近邻用户形成推荐并给出解释，“购买此商品的用户也购买了.”[23]。Heckel等[3]基于 user-item 矩阵的重叠聚类提供可解释推荐，在每个共同集群中，用户具有相似的兴趣，项目具有相似的特征。",
    "context6": "基于模型的协同过滤算法需要一个独立的模型训练阶段，利用全体或部分数据训练一个模型。这一步一般是离线完成的，在线推荐时则利用训练好的模型实时做出相应推荐。下文将从模型层面探讨可解释推荐模型的解释机理。",
    "context7": "（1）基于关联规则挖掘的推荐算法。也称之为购物篮分析，通过从大数据中挖掘频繁项集，即同时出现频率较高的项目组合形成推荐。其解释性体现在被推荐的项目与用户已购买或者喜欢的项目同时出现的频率较高。例如，买鞋的用户中有 $10 \\%$ 也会买袜子， $60 \\%$ 买面包的用户也会买牛奶，其中最有名的就是“尿布和啤酒”的例子[37]。Lin等[38]提出了一种“个性化”关联规则挖掘算法，提取用户和项目之间的关联以形成推荐，推荐结果通常可以通过产生关联规则来自我解释，如“用户A和用户B所喜欢的文章中有 $90 \\%$ 也被用户C所喜欢”。",
    "context8": "（2）基于显式因子模型的推荐算法。这种可解释的推荐模型主要基于矩阵分解（matrix factoriza-tion，MF）算法（又称为隐语义模型，latent factormodel，LFM）设计实现。基于矩阵分解的推荐算法会将用户与项目的特征向量嵌入低维空间中，每个维度代表可能影响用户决策的特定因素，然而用户甚至算法设计人员也不清楚每个维度因素的确切含义，故推荐结果难以解释。为了应对此问题，Zhang等[7]提出显式因子模型（explicit factor model,EFM)，基本思想是推荐在用户喜欢的功能上表现良好的产品。首先，从用户评论中提取明确的产品特征（如屏幕、听筒）及用户对这些特征的偏好（正、负），构建用户特征-情感对；其次，基于LFM的思想构建3个矩阵：用户打分矩阵A、用户-特征偏好矩阵 $X$ 、项目-特征质量矩阵Y；最后，采用最优化损失函数的方法估计3个矩阵 $X$ 、Y、A的缺失值，形成评分预测与推荐。其矩阵分解的每个潜在维度与一个显式特征对齐，使矩阵分解和评分预测过程在算法和特征层面都是可跟踪的，从而提供明确的解释。Chen等[39]基于此将EFM模型扩展到张量分解模型，从文本评论中提取了产品功能，并构建了用户-特征多维数据集，然后就用户对功能和项目的偏好进行成对预测，实现功能特征层面的可解释推荐。",
    "context9": "（3）基于图模型的推荐算法。对于图模型，存在节点和边的结构，可通过图嵌入的方法对实体和实体之间的关系进行表征，扩充原有用户和项目表征的语义信息，通过计算节点之间的相似性，或者节点到节点之间的路径形成推荐以及推荐解释[40]。其解释性通常体现在节点之间的相似度，或者用户节点到项目节点之间的路径或者距离。例如，Park等[41通过图嵌入的方法将复杂的实体关系映射到连续的向量空间中，然后根据用户偏好的相似性或者用户与项目之间的连通相似性进行推荐预测。Zhang等[42]在构建了用户-项目及实体关系的信息网络图后，通过计算“用户节点 $U _ { i }$ ”和“项目节点L”在关系“购买 $R _ { b }$ ”上的“距离 $d \\left( U _ { i } + R _ { b } , I _ { j } \\right) ^ { \\ast }$ ，对所有项目进行排序，以得到推荐列表。Ai等[43]构建一个用户-项目的知识图谱，包含用户-项目与实体之间的关系，通过图模型找到相似的项目以形成推荐，推荐解释则表示为用户到推荐项目的最短路径。对于路径层面的推荐解释，具体可参考文献[40]中描述的一个基于可解释性知识图谱的推荐示例：（用户A,喜欢，《成事在人》)（《成事在人》，主演是,摩根弗里曼)(摩根弗里曼,主演，《肖申克的救赎》） $\\Rightarrow$ （用户A,喜欢，《肖申克的救赎》），基于以上路径可将《肖申克的救赎》推荐给用户A，并得到推荐解释。",
    "context10": "（4）基于神经网络模型的推荐算法。这类推荐模型具有复杂的层次结构，将用户及项目相关特征信息进行嵌入化处理后，通常会进行如卷积、池化、舍弃、全连接等变换，但对所得到的向量空间很难进行直观的解释。因此，在基于深度学习的推荐算法中，主要基于注意力模型对产生推荐的特征生成注意力权重，以形成解释，告知哪些特征对推荐结果的贡献更大[44]。注意力模型的核心设计思想源于人类的视觉注意力机制。人类视觉总是快速扫描全局，并马上聚焦于需要重点关注的目标区域，以获取更多所需要关注的细节信息，并抑制无用信息。人类视觉注意力机制极大地提高了视觉信息处理的效率与准确性。深度学习注意力机制与之类似，核心目标也是从众多信息中选择出对当前任务目标更关键的信息[45]。注意力模型被广泛用于自然语言处理、图像识别及语音识别、个性化推荐等各种不同类型的深度学习任务中。其解释主要体现在对于用户关注重点的自动提取。例如，Seo等[46]提出的可解释卷积神经网络评分预测模型，在预测用户-项目评分时，该模型可以告知评论中的哪个部分对输出更重要，并突出评论中的重要词汇作为推荐解释；Gao等[47]开发了一个多视角注意力学习的可解释推荐模型（deep explicit attentive multi-viewlearningmodel，DEAML），旨在通过开发可解释的深度学习模型以权衡推荐的准确性和可解释性。",
    "context11": "上文从基于内容的推荐和基于协同过滤的推荐两个方面介绍了最为常见的、典型的可解释推荐算法的解释机理，其间还存在着交集，如聚类模型、图模型、神经网络模型，均可适用于基于内容的推荐及基于协同过滤的推荐方法中，区别仅体现在是否采用其他用户的偏好信息对目标用户形成推荐。另外，以上算法的划分并不全面，如近年来提出的基于因果推断模型的推荐，将因果推断中的干预模型、反事实学习模型等引入传统的推荐算法，为推荐结果构建具有因果关系的推荐解释。因果推断是近年来的研究热点，因其能够更直观地从观察性数据中估计因果关系，已在统计学、计算机学、经济学等领域获得了广泛的研究与应用。对于可解释信息推荐，因果推断模型可以捕捉推荐项目特征对用户的影响，得到可靠的推荐解释。例如，Zhang等[20]采用潜在结果框架，提出基于因果推理的增强注意力机制推荐模型，可以捕捉到特征与行为之间的因果效应，纠正特征的重要性； $\\mathrm { X u }$ 等[21]提出的事后推荐解释模型，通过扰动模型获取反事实用户的行为和反事实推荐项目，然后基因果规则挖掘算法提取推荐模型中的因果关系；Tan等[22]提出了反事实解释性推荐模型，通过在项目中产生最小的变化，创建一个反事实项目，当推荐决策逆转时，这些改变构成原始推荐项目的解释。",
    "context12": "综上，可解释信息推荐算法及其解释机理可归结为图6。可以看出，基于相似度的解释是多种推荐算法的解释依据，其中基于特定模型的推荐算法也可以根据自身的计算模型产生相应推荐解释。信息推荐技术的重点在于通过分析用户属性并挖掘其偏好特征，进而提供与其需求或偏好相匹配的项目。而可解释信息推荐需要兼顾推荐结果和推荐解释两个方面的内容呈现，其中需要保证推荐模型的每一次计算都是有理可寻、经得起推敲的。可解释推荐算法的解释机理即推荐算法原理的透明和可理解性，保证了推荐结果的可靠与可控。本文对现有可解释推荐算法形成推荐与解释的原理进行了介绍、归纳与总结，有助于推荐领域的研究者和系统设计开发人员进行可解释推荐相关研究的算法理解、选择、调试与改进。",
    "context13": "![](images/25fd035482bc2e8efa93427bb72370ba5b08a8dac6f5d5683f75d48b15e87f8c.jpg)  \n图6可解释信息推荐算法及其解释机理"
  },
  "3推荐解释的媒介与呈现": {
    "context1": "推荐解释是向用户呈现的一段信息，用于解释推荐某个特定项目的原因。推荐解释可从不同的数据来源生成，并以不同的方式呈现，主要有文本和图片两种[48]。另外，同一推荐项目可能存在多种解释。从推荐系统的输入数据上划分，推荐解释可分为以用户为媒介的解释、以项目为媒介的解释和以特征为媒介的解释3种，如图7[49]所示。",
    "context2": "![](images/b97f7586a02880e32c7e3f89043cea376a9e58881075b56bcd33f2e328c19a16.jpg)  \n图7推荐系统数据层面的解释性[49]"
  },
  "3.1以用户为媒介的推荐解释": {
    "context1": "以用户为媒介的推荐解释主要是基于用户的人口统计学信息、打分（rating）和社交信息等形成推荐和解释。",
    "context2": "（1）基于人口统计学的推荐是最早的推荐方法之一，主要根据用户的年龄、性别、职业、受教育程度和居住地等信息进行推荐[50-51]，这种推荐算法可使用触发推荐的人口统计学特征进行解释，如告诉消费者这个职业需要这个产品、秋季临近需要冬装、向女士推荐化妆品等。",
    "context3": "（2）用户的打分和社交信息也经常被用于项目推荐和解释中，如最基本的高分项目推荐，其推荐理由是大多数用户对此项目给出了高分评价。另外，在进行高分项目推荐时，用户不了解具有“相似兴趣”的陌生用户，可能会产生信任问题；而如果告诉用户，其好友对推荐项目感兴趣或做出正向评价，那么该项目往往会更容易被用户接受。例如，Sharma等[52通过向目标用户推荐朋友感兴趣的音乐，提升了音乐推荐的效果；Park等[4提出了利用评分和社交信息来生成可解释的产品推荐，根据与目标用户具有相似首选项的朋友来解释推荐结果；Quijano-Sanchez等[53]对4种基于社交信息的推荐解释进行了实验，即 $\\textcircled{1}$ 整体热度：2612211位Facebook用户喜欢它； $\\textcircled{2}$ 朋友热度：您的朋友中有7人喜欢它； $\\textcircled{3}$ 好朋友：张三喜欢它； $\\textcircled{4}$ 好朋友及人数：张三和其他5位您的朋友喜欢它。该研究发现第 $\\textcircled{3}$ 和第 $\\textcircled{4}$ 两种推荐解释对用户的说服力最高，且在使用这两种推荐解释时，选择一个正确的朋友非常重要。以用户为媒介的推荐解释，通常通过以上描述性理由作为推荐解释提供给用户，也有研究者采用近邻用户评分的聚合直方图来提供解释[13],这种形式可以帮助用户从整体上了解其他用户对此产品或服务的评分分布，仅从用户评价方面提供更为详细的解释。"
  },
  "3.2以项目为媒介的推荐解释": {
    "context1": "以项目为媒介的推荐解释通常表述为“这个项目和您喜欢的其他项目相似”，这类解释以用户关注过的项目作为中介，将用户与推荐项目联系起来，其呈现方式常常是一个曾经购买、评论或者浏览过的项目列表，此列表中的项目和推荐列表中的项目在名称、功能、效用、品牌等方面相同或相似。例如，Netflix上的“为什么推荐这部电影”功能向用户展示了其过去对相关电影的打分。类似地，亚马逊在向用户推荐新商品时会展示了其过去购买的商品[49]。这类方法简单、直接，能够增加推荐项目的点击率和接收率，但是这类推荐解释的问题是用户难以找到项目之间的异同，帮助用户进行比较与分析。另外，其产生的推荐列表存在单一与过度特化的问题，用户有时可能希望看到一些自己没有购买过的、不一样的项目，即推荐列表的新颖性和多样性[54]。",
    "context2": "很多学者指出过于强调推荐的准确性可能导致信息的单一，并导致推荐结果变得可预测而吸引力降低，新颖性和多样性是解决以上问题的有效方法。例如，Berbague 等[55]提出一种基于遗传算法的重叠聚类推荐模型，通过为用户划分聚类簇的方法提升推荐结果的多样性和新颖性；Cai等[5提出一种基于知识图谱的多目标优化可解释推荐模型，通过多目标优化算法寻求兼具准确性、多样性、新颖性的推荐结果，基于用户和推荐项目之间的路径形成解释。文献[25]中构建用户长短期偏好模型后，通过对长短期偏好系数的改变，实现对推荐结果多样性与准确性的调节，并形成相应推荐和解释：当短期偏好权重更高时，其解释性表现为“您近期较为关注此类产品，可能会喜欢产品X”；当长期偏好权重更高时，其解释性表现为“根据您的生活方式（品牌或价格偏好）向您推荐了产品X”。现有研究成果中，已有不少学者针对推荐结果新颖性和多样性的提升进行了一定的研究和探索，但少有研究探讨如何针对推荐结果的新颖性和多样性进行解释。随着推荐算法对这两项指标越加重视，关于推荐项目新颖性或者多样性的推荐解释也是未来研究的重要方向之一。"
  },
  "3.3以特征为媒介的推荐解释": {
    "context1": "以特征为媒介的推荐解释可表述为“您可能喜欢推荐项目的这些特征，或者是推荐项目的某些特征满足您的需求”。这类推荐解释常见的形式是将推荐项目中用户感兴趣的主要特征进行列举。研究表明，这类推荐解释有助于用户更加准确地判断是否喜欢推荐项目，与前两类推荐解释相比，用户对此类推荐的结果和解释满意度更高[57]。这类推荐解释需要判断用户对不同特征的感兴趣程度，从而找到最适合用于解释的特征，建模粒度更细。根据应用场景的不同，以项目特征形成为媒介的推荐解释，其呈现方式更加多样。例如，Vig等[49]采用电影类型、演员或导演等标签信息生成推荐和解释，推荐系统呈现所推荐电影的特征，并提供用户对这些特征的偏好程度以形成解释；Hou等[58]使用雷达图表示所推荐的项目在多大程度上满足用户，以此解释为什么一个项目会被推荐。",
    "context2": "另外，项目特征也可来源于用户评论等UGC（usergeneratedcontent）数据，对评论信息的挖掘有助于了解用户偏好，并生成推荐结果与解释[59]。基于对用户评论的观点挖掘形成的推荐解释可划分为特征层面的解释和句子层面的解释。项目特征可作为标签放置于配置文件中，也可从UGC中即时提取、筛选与学习，一般需要从大规模的文本评论中提取产品特征与用户情感的观点对。例如，Zhang 等[6]开发了一个Sentires的短语情感分析工具，从文本评论中提取aspect-opinion-sentiment 三元组，并据此提出了基于显式因子的推荐解释，突出了推荐项目在特征层面的表现。另有学者采用主题建模的方法，生成关于用户偏好特征的词云形成推荐解释[61]。句子层面的解释即将推荐理由以完整的句子呈现给用户。一种是基于模版的推荐解释语句生成方法，首先定义一些解释语句模版，然后根据产品的特征及不同用户的偏好在模版中填充不同的特征词。在此模版中，推荐算法根据用户偏好选择相应特征形成个性化解释，另外，此模型还可以提供“不推荐”的建议，通过告知用户此产品的某项性能较差，让用户知道为什么不合适，且研究表明同时提供推荐和不推荐的项目以及对应的解释可以提升推荐结果的说服力、转化率和可信度[62]。另一种是基于自然语言处理技术生成解释性语句的方法。如Costa等[63基于长短记忆神经网络，对大规模用户评论进行训练生成解释性语句；Lu等[18]提出了一种多任务推荐模型，该模型采用联合训练的方法同时进行评分预测和生成推荐解释，解释模块采用一种对抗性生成网络对评论序列进行编码、训练学习以生成解释性语句。",
    "context3": "推荐解释的呈现，即通过向用户展示合理推荐理由的方式以达到增加推荐信息的感知价值的目的，从而提升用户的信任度和使用体验感。目前使用最广泛的是以项目为媒介的推荐解释，这是因为其易理解、易实施，且能带来不错的推荐转换率。然而，这个高的推荐转换率中有多大比例是由推荐解释带来的还有待验证；由于其解释简单，说服力和用户满意度并不高。用户对以特征为媒介的推荐解释满意度和信任度较高，这类推荐解释可将推荐项目的特征优劣进行有效的展示，有助于用户更加准确地判断是否喜欢推荐项目。相较于以项目和以特征为媒介的推荐解释，以用户为媒介的推荐解释通常最能说服用户对推荐项目进行评估、尝试与购买，但是对用户实际使用项目后的喜爱程度影响较小。如果推荐的项目用户不够喜欢，反而会降低用户的信任和满意度。在实际的可解释推荐应用中，可结合推荐模型和具体项目综合使用以上3种推荐解释，以达到最佳解释效果。"
  },
  "4推荐解释评价": {
    "context1": "对于推荐解释的评价，主要考虑的是可解释推荐算法是否增加了用户对推荐结果的接受率，以评估推荐解释的有效性，可分为定量评价和定性评价。"
  },
  "4.1推荐解释的定量评价": {
    "context1": "推荐解释定量评价可分为在线评估和离线评估。其中，在线评估可以根据实验环境中可获取的数据计算推荐效果。例如，当用户点击信息可用时，可以基于点击率（click-through-rate，CTR）进行评估；如果可以跟踪用户的购买行为，那么就可以根据购买率进行评估。例如，Zhang等[17]基于电商网站进行了A/B测试，对浏览手机的用户呈现3种推荐页面，计算每组的点击转换率以评估推荐解释的效果。离线评估是研究中较为常见的算法评价方法，根据可解释推荐模型的不同，其评价计算方法也有所差别。关于推荐可解释性的离线评估大体可划分为针对项目的和针对特征的两种。",
    "context2": "针对项目的离线评估方法，即测量推荐列表中可解释推荐结果的占比，如Peake等[64提出了Fidel-ity公式：",
    "context3": "$$\n\\mathrm { F i d e l i t y } = \\frac { \\left| \\mathrm { \\ e x p l a i n a b l e ~ i t e m s \\cap \\ r e c o m m e n d e d ~ i t e m s } \\right| } { \\left| \\mathrm { \\ r e c o m m e n d e d ~ i t e m s } \\right| }\n$$",
    "context4": "另外，Abdollahi等[65]提出了平均可解释准确率（meanexplainabilityprecision，MEP）和平均可解释召回率（mean explainability recall，MER）指标。可解释准确率（explainability precision，EP）定义为每个用户的Top $. N$ 推荐列表中可解释的项目占比；可解释召回率（explainability recall，ER）定义为Top-$N$ 推荐列表中可解释性推荐结果的数量在目标用户推荐的可解释项目总数中的占比，MEP和MER分别是所有实验用户的EP和ER平均数。",
    "context5": "针对特征的离线评估方法即描述生成特征层面解释与项目真实特征的比较，通常应用于以特征为媒介的推荐解释中。例如，Li等[提出的特征匹配率（feature matching ratio，FMR）：生成的解释中的特征有多少是真实的项目特征；特征覆盖率（fea-ture coverageratio，FCR）：所有生成的解释所包含的不同特征数量与整个数据集中项目特征总数的比值；特征多样性（feature diversity，FDIV）：任意两个生成的解释之间的特征差异。Xie等[提出基于知识图谱的可解释推荐模型，采用用户 $i$ 对项目的评分以及同一条推荐路径上项目特征的相似度来测量推荐的可解释性，计算方法为",
    "context6": "$$\nE _ { i } = \\sum _ { m \\ = 1 } ^ { N } { \\frac { r _ { i , j \\ { \\stackrel { \\_ } { \\_ } { m } } \\ } } { \\operatorname { s u m } _ { \\ - \\ } r _ { i } } } \\times S _ { j _ { \\_ m , j \\ { \\_ } { m ^ { \\prime } } } } \\quad\n$$",
    "context7": "其中， $N$ 为推荐列表的长度； $r _ { i , j \\_ m }$ 是用户 $i$ 对项目$j \\_ m$ 的打分； $\\mathbf { s u m } _ { - } r _ { i }$ 是用户 $i$ 对所有项目的打分；$j \\_ m ^ { \\prime }$ 表示推荐列表中的某个项目；项目 $j \\_ m$ 和项目$j \\_ m ^ { \\prime }$ 是用户 $i$ 的同一条推荐路径上的节点； $S _ { j \\_ m , j \\_ m ^ { \\prime } }$ 表示项目 $j \\_ m$ 和项目 $j \\_ m ^ { \\prime }$ 之间的特征相似度。Tan等[22]在其提出的基于反事实的可解释推荐算法中，针对项目特征的解释，给出了两种类型的评价指标：面向用户的评价和面向模型的评价。在面向用户的评价中，采用用户对项目的评论作为用户购买项目的真实原因。具体来说，从用户 $u _ { i }$ 对项目 $\\nu _ { j }$ 的评论中提取所有的积极情感并记为 $p _ { i j } { = } [ p _ { i j } ^ { 0 } , p _ { i j } ^ { 1 } , \\cdots , p _ { i j } ^ { r } ]$ 的二进制向量，当用户 $u _ { i }$ 对项目 $\\nu _ { j }$ 的特征 $a _ { k }$ 进行了积极的评价时， $p _ { i j } ^ { k } { = } 1$ ，否则， $p _ { i j } ^ { k } { = } 0$ 。相应地，推荐模型会生成向量 $\\pmb { \\Delta } = \\{ \\delta _ { 1 } , \\delta _ { 2 } , \\cdots , \\delta _ { r } \\}$ ，其中所有非零值对应的项目特征构成推荐解释。对于每组用户 $u _ { i }$ 一项目$\\nu _ { j }$ ，将 $p _ { i j }$ 与 $\\pmb { \\triangle }$ 进行比较，通过计算 $\\pmb { \\triangle }$ 中的非零特征在 $p _ { i j }$ 中的准确率和召回率来评价推荐解释，具体为",
    "context8": "$$\n\\mathrm { P r e c i s i o n } = \\frac { \\displaystyle \\sum _ { k = 1 } ^ { r } p _ { i j } ^ { k } \\cdot I \\left( \\delta _ { k } \\right) } { \\displaystyle \\sum _ { k = 1 } ^ { r } I \\left( \\delta _ { k } \\right) } , I \\left( \\delta _ { k } \\right) = \\left\\{ \\begin{array} { l l } { { 1 , \\mathrm { i f } \\delta _ { k } = 1 } } \\\\ { { 0 , \\mathrm { i f } \\delta _ { k } = 0 } } \\end{array} \\right.\n$$",
    "context9": "$$\n\\mathrm { R e c a l l } = \\frac { \\displaystyle \\sum _ { k = 1 } ^ { r } p _ { i j } ^ { k } \\cdot I \\left( \\delta _ { k } \\right) } { \\displaystyle \\sum _ { k = 1 } ^ { r } p _ { i j } ^ { k } } , I \\left( \\delta _ { k } \\right) = \\left\\{ \\begin{array} { l l } { { 1 , \\mathrm { i f } \\delta _ { k } = 1 } } \\\\ { { 0 , \\mathrm { i f } \\delta _ { k } = 0 } } \\end{array} \\right.\n$$",
    "context10": "其中，Precision 即生成的推荐解释中用户真实喜欢的特征；Recall即用户真实喜欢的特征在生成的推荐解释中的占比。",
    "context11": "面向用户的评价回答了生成的解释是否与用户偏好一致，为了测量其解释模型是否正确地解释了推荐模型的推荐机制，进一步提出了特征的必要性概率（probabilityof necessity，PN）和充分性概率（probabilityof sufficiency，PS）的面向模型的评价计算方法。必要性概率即评估一个条件的必要程度，其基本思想是在反事实的情况下，若某个项目特征不存在，则此项目不被推荐给用户的概率，其计算方式为",
    "context12": "$$\n\\mathrm { P N } = \\frac { \\displaystyle \\sum _ { u _ { i } \\in U } \\sum _ { \\nu _ { j } \\in R _ { i k } } \\mathrm { P N } _ { i j } } { \\displaystyle \\sum _ { u _ { i } \\in U } \\sum _ { \\nu _ { j } \\in R _ { i k } } I \\left( A _ { i j } \\neq \\emptyset \\right) } ,\n$$",
    "context13": "$$\n{ \\mathrm { w h e r e } } \\operatorname { P N } _ { i j } = { \\left\\{ \\begin{array} { l l } { 1 , { \\mathrm { i f } } \\nu _ { j } ^ { * } \\in R _ { i k } ^ { * } } \\\\ { 0 , { \\mathrm { e l s e } } } \\end{array} \\right. }\n$$",
    "context14": "其中， $R _ { i k }$ 是用户 $u _ { i }$ 的初始推荐列表； $A _ { i j } \\neq \\emptyset$ 是推荐模型针对项目 $\\nu _ { j } \\in R _ { i k }$ 生成的一个非空解释;$\\boldsymbol { \\nu } _ { j } ^ { * } \\in \\boldsymbol { R } _ { i k } ^ { * }$ 是推荐模型剔除相关特征生成的反实时推荐项目； $\\sum _ { u _ { i } \\in U } \\sum _ { \\nu _ { j } \\in R _ { i k } } I ( A _ { i j } \\ne \\emptyset )$ 是算法成功生成解释的  \n项目总数； $\\sum _ { u _ { i } \\in U } ~ \\sum _ { \\nu _ { j } \\in R _ { i k } } \\mathrm { P N } _ { i j }$ 是若删除某个特征，则导致该项目从推荐列表中删除的解释数量。充分性概率即评估一个条件的充分性程度，其基本思想是，在反实时的情况中，若某个特征是该项目推荐解释$A _ { i j }$ 中的唯一特征，此项目仍被推荐的概率，其计算方式为",
    "context15": "$$\n\\mathrm { P S } = \\frac { \\displaystyle \\sum _ { u _ { i } \\in U } \\sum _ { \\nu _ { j } \\in R _ { i k } } \\mathrm { P S } _ { i j } } { \\displaystyle \\sum _ { u _ { i } \\in U } \\sum _ { \\nu _ { j } \\in R _ { i k } } I \\left( { A } _ { i j } \\ne \\emptyset \\right) } ,\n$$",
    "context16": "$$\n\\mathrm { \\mathrm { : } P S } _ { i j } = \\left\\{ { \\begin{array} { l l } { 1 , { \\mathrm { i f } } \\nu _ { j } ^ { \\prime } \\in R _ { i k } ^ { \\prime } } \\\\ { 0 , { \\mathrm { e l s e } } } \\end{array} } \\right.\n$$",
    "context17": "其中， $\\nu _ { j } ^ { \\prime } \\in R _ { i k } ^ { \\prime }$ 是推荐模型选择某一特征生成的反事实推荐项目； $\\sum _ { u _ { i } \\in U } \\sum _ { \\nu _ { j } \\in R _ { i k } } I ( A _ { i j } \\ne \\emptyset )$ 是算法成功生成解释的项目总数； $\\sum _ { u _ { i } \\in \\textit { U } } \\sum _ { \\nu _ { j } \\in \\textit { R } _ { i k } } \\mathrm { P S } _ { i j }$ 是单独项目特征可生成的推荐数量。"
  },
  "4.2推荐解释的定性评价": {
    "context1": "对于推荐解释的定性评价，通常采用用户研究的方法，通过设计一些问题或者任务，招募实验对象进行回答或者访谈，从调查结果中分析出结论。这是一种直接且灵活的方法，其评估方法通常基于Tintarev等[1提出的推荐解释的7个目标与评价标准，具体如表1所示。",
    "context2": "例如，Vig等[49]基于电影标签为MovieLens 构建了4种推荐页面，通过向用户询问： $\\textcircled{1}$ 知道为什么被推荐这个电影吗？ $\\textcircled{2}$ 是否喜欢被推荐的项目？ $\\textcircled{3}$ 被推荐的项目是否符合用户的情绪？以评估每种可解释性推荐页面的透明性、有效性和情绪相符性。",
    "context3": "表1推荐解释的目标与评价标准",
    "context4": "<table><tr><td>目标</td><td>释义</td></tr><tr><td>透明性</td><td>向用户解释推荐结果产生的原因,推荐模型内部的工作机制。可分为客观透明性和主观透明性。其中,客观透明性是推荐</td></tr><tr><td>（transparency）</td><td>系统的实际算法机制，主观透明性即用户对于推荐结果产生原因的主观感受[67]。</td></tr><tr><td>可审查性</td><td>帮助用户理解推荐,识别和纠正错误的推荐和输入信息。通过可审查性,用户可以了解系统中发生的事情,并通过需求纠 正输入信息,对推荐结果进行改变[68]。</td></tr><tr><td>(scrutability)</td><td>用户对于推荐系统的信心。信任通常源于推荐算法的准确性,也与系统透明性和可审查性密切相关[69]。如果用户理解为</td></tr><tr><td>信任 (trust）</td><td>什么做出了不好的推荐,那么他们可能会更宽容,并对其他较好的推荐结果更有信心[70]。</td></tr><tr><td>有效性</td><td>帮助用户做出更好决策的能力。有效的解释可以帮助用户正确判断推荐项目的真实质量与适用性,过滤掉不合适的项目，</td></tr><tr><td>(effectiveness) 说服力</td><td>显著提升推荐系统的整体适用性和用户体验[48]。 推荐解释在多大程度上可以增加用户对推荐结果的接受程度的能力[48]。如果说服力过高,那么用户可能会高估被推荐项目的</td></tr><tr><td>（persuasiveness）</td><td>质量及适用性。一旦用户意识到他们已经尝试或者购买了自己并非真正想要的东西,则过高的说服力可能会适得其反[71]。 帮助用户更快地做出决定,或者帮助用户通过更少的认知努力找到合适的项目的能力。现有研究中通常是通过测量用户</td></tr><tr><td>效率 （efficiency）</td><td>完成决策任务的时间来衡量效率28]。另外,通过提供给用户竞争选项之间的关系,有助于推荐解释的生成并提高效率，如 对于数码相机,可以通过选择&quot;更少的内存、更低的分辨率和更低的价格&quot;查看竞争选项,据此,用户可以更快地找到满足要</td></tr><tr><td></td><td>求的产品[72]。</td></tr><tr><td>满意度</td><td>在衡量满意度时,需要区分是对推荐结果的满意度还是推荐产品的满意度。用户对推荐系统的总体满意度与项目的质量</td></tr></table>",
    "context5": "Wang等[73]基于观点挖掘的方法构建了多任务学习的可解释性推荐模型（multi-task explainable recom-mendation，MTER），并通过用户研究的方法探讨MTER是否提升了推荐结果的用户满意度，是否帮助用户更了解推荐的项目，以及是否为更有效的解释方式。Chen等[57基于用户评论情感，提出了一种以权衡为导向的推荐解释界面，并通过用户研究和眼动实验结合的方法对其推荐方法的感知有用性、感知透明度、感知质量和购买意愿进行了评估。",
    "context6": "综上，推荐解释评价的方法可划分为定性和定量的评价方法。其中，定量的评价方法又可分为在线评估和离线评估两种，而离线评估可进一步划分为针对项目的解释评估与针对特征的解释评估。近年来，随着可解释推荐研究的兴起，推荐解释的评价也备受关注。在线评估法因其实验环境的限制，难以实施与普及。而推荐解释的离线评估方法因模型而异，难以对不同可解释推荐模型的解释力进行有效的比较。定性评价的方法是一种较为通用且简单的方法，然而现有推荐解释的评价指标之间存在一定的内生性问题，界定尚不够清晰。"
  },
  "5总结与展望": {
    "context1": "本文通过对可解释信息推荐算法与解释机理、推荐解释的媒介与呈现，以及推荐解释的评价3个方面的梳理与总结，对可解释信息推荐关注的3个重要问题- —“who,what,why”，即“向谁解释、解释什么和解释的目的”进行了回答：推荐模型的解释机理和推荐解释的评价主要是向研究人员及系统开发人员描述模型生成推荐项目和解释的计算原理，以及推荐解释的效果，帮助其理解、诊断、调试和改进算法；推荐解释的媒介与呈现主要是向用户解释为什么会向其推荐此项目，以此提升推荐系统的透明度、说服力、有效性、可信度等，从而提升用户的满意度。基于以上3个方面的总结与分析，下文讨论关于可解释信息推荐研究的方向与发展，以期为后续可解释信息推荐领域的研究提供借鉴与思路。",
    "context2": "（1）对于可解释信息推荐技术，其模型的可解释性将一直是学者们关注的话题，即推荐模型的科学性和透明性。第一个是基于深度学习推荐算法，大多数深度模型是一个黑箱子系统，因为深层次神经网络结构中的隐层通常不具有直观的意义，目前基于深度学习的推荐模型更侧重于推荐效果的提升，其解释主要来自输入数据中文本、图像的注意力权重。未来，需要探索深度学习模型本身的解释机制，或者将其中难以理解的隐层网络与实体特征进行有效的对应，促进可解释推荐研究的进展。同时，可促进深度学习模型在自然语言处理、图像识别等领域的应用。第二个是多源数据融合的可解释推荐研究。大数据时代，信息系统通常搭建在多源异构的数据源上。当前的系统大多利用异构信息源来提升搜索和推荐性能，而为了提升解释能力，需要进行大量的研究工作，如通过对齐两个或多个不同信息源进行多模态解释、针对异构信息源的迁移学习、跨领域解释等。第三个是基于因果推断的可"
  }
}