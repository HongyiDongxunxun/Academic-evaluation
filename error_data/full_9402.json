{
  "original_filename": "full_9402.md",
  "计算型情报分析的进展": "",
  "李广建罗立群": {
    "context1": "摘要大数据理念和方法的不断应用，使情报分析在理论和实践上逐渐从定量化分析向计算化分析发展。本文将迄今为止的计算型情报分析的发展历程划分为三个阶段：经验计数分析阶段、精确计量分析阶段、计算型分析阶段,并分别从分析对象、代表成果、主要贡献、主要特征、方法与工具等维度对各阶段进行论述;对情报思维、计算思维、社会计算科学进行辨析，提出了计算型情报分析的主要研究目的和研究内容，并对计算型情报分析的三个主要内容——计算型情报分析模型、计算型情报分析算法、计算型情报分析框架和系统最新的研究进展和研究趋势进行系统的论述和分析。图2。参考文献71。",
    "context2": "关键词计算型情报分析情报分析框架情报分析模型情报分析算法",
    "context3": "分类号G250.2"
  },
  "Progress in Computational Intelligence Analysis": {
    "context1": "LI Guangjian & LUO Liqun"
  },
  "ABSTRACT": {
    "context1": "In the 2lst century，with the wide application of network technology and the rise of big data ideas and methods，inteligence analysis has gradually evolved from simple quantitativeanalysis to computational analysis in theory and practice.Computational inteligence analysis （CIA） is gradually taking shape.The development process of CIA can be divided into three stages:the empirical counting analysis stage，the accurate measuring analysis stage，and the computational analysis stage. This paper discusses these stages from 5 aspects:the analysis objects，the representative results,the main contributions,the main features, the methods and tools.By summarizing the concept“computation” in the area of computational thinking, social computation and social computing science,this paper puts forward the main contents of CIA which include CIA model,CIA framework and system，and CIA algorithm.",
    "context2": "The CIA model is a kind of mathematical models，which is used to abstractand simulate the behavior from the specific task-oriented intellgence analysis subject，the specific intelligence object and the specific procedure of the inteligence transmission.With the introduction of big data analysis models，social network models，complex theoretical models and system dynamics models into intelligence analysis and their fruitful achievements，the construction and application of the CIA models have shown the following characteristics and trends in recent years:First,the CIA model is no longer limited to simple descriptive statistics modes, but tends to be a kind of more comprehensive or combined mathematical mode.Secondly,the construction of the CIA model is transformed from a static model to a complicated dynamic model，that is，variables changing over time and their relationships are introduced into the model.Thirdly，the construction and application of CIA models are based on massve data or big data.Fourthly,the model construction’s focuses shift from evaluating past achievements to predicting and interpreting future outcomes and scientific discoveries.",
    "context3": "The CIA framework mainly refers to the technical framework for intelligence analysis，which consistsof abstract components and messaging methods for the components' instances.The CIA framework can be considered as a constrained support structure designed to solve the open-ended problem in the process of intelligence analysis.A CIA system isan implementation of the CIA framework．In recent years，the development and research of CIA framework and system have shown the following characteristics and trends:First,theanalytical framework and systemare evolving from a single architecture to a distributed, cloud computing architecture.Such framework and system are more in line with the requirements of storage, computing，analysis of multi-source，heterogeneous，massive data. Secondly，the CIA framework and system have changed from a traditional relatively closed，dedicated mode toan open，military-civilian integration mode.Thirdly,the intelligence analysis processs in the framework or system can be customized and automated.Fourthly,the CIA framework and system are becoming more intelligent with the application ofartificial intelligence technologies.",
    "context4": "The CIA algorithm is a series of computation steps and instructions formed under specific intelligence analysis tasks or intellgence analysis scenarios bythe guidance of intellgence thinking.The CIA algorithm is the prerequisites for automated intelligence analysis so that the intelligence analysis model can be calculated by machine and finally obtains the computational results.The CIA algorithm has recently shown some characteristics and trends:First，the explain ability of inteligence analysis algorithm is being initiated. Secondly,the open source intellgence-oriented perception algorithm is increasingly being valued.Thirdly, the algorithm for the fusion of human analyzed results and computer analyzed results has got more atention.",
    "context5": "The CIA isan extensionof traditional intelligence analysis and now itbecomes one of the important directions offuturedevelopment of information science.The CIA will graduallydevelop intoanew discipline that integrates computational science，social science，cognitive science，complex science，biochemical science，engineering, and many other academic subjects.For researchers,opportunities and challenges willcoexist.This requires us to meet the challenges of the future with more innovative，open and bold ideas.2 figs.71 refs."
  },
  "KEY WORDS": {
    "context1": "Computational intelligence analysis.Intelligence analysis framework．Intelligence analysis model.   \nIntelligence analysis algorithms."
  },
  "0引言": {
    "context1": "广泛应用，对情报学特别是情报分析产生了深刻的影响，情报分析无论是在理论上，还是在实践上，都在强调定量化和自动化，并逐渐从简单的定量化分析发展到了计算化分析。国际上，以美"
  },
  "近年来，大数据理念和方法不断完善并得以": {
    "context1": "国为代表的发达国家对情报分析的计算化或计算型情报分析非常重视,理论上已经规划出了计算型情报分析研究体系，实践上对计算型情报分析投入大量的人力、物力、资金。在国内，学者们提出基于事实型数据的情报[1-、工程化情报、计算型情报、面向突发事件的快速响应情报以及情报 $3 . 0 ^ { \\mathbb { 6 } }$ 等新的情报分析理念。这些研究成果的共同结论是，大数据时代下,情报分析应以数据为原始材料,经过一系列的计算与分析，深度解析数据中存在的内容及其关系，帮助分析人员解决情报问题,完成情报任务。由此可见,国内对情报分析的计算化或计算型情报分析的研究已经开始起步，并且越来越重视。"
  },
  "1计算型情报分析的发展历程": {
    "context1": "计算型情报分析本身有一个发展过程，经历从低级到高级的不同阶段，从重在将分析对象转化为可以度量的数值，到重在用数学公式来表示情报计算过程中的一般规律，再到重在方便计算代理进行计算的表示和模型构建。我们将迄今为止的计算型情报分析的发展历程划分为三个阶段,分别是经验计数分析阶段、精确计量分析阶段、计算型分析阶段,如图1所示。",
    "context2": "![](images/d24f7510b533d8fc6278f7274d940b0895fa6066a2cf2e216d02ac2b0be0cfd9.jpg)  \n图1计算型情报分析的发展历程"
  },
  "1.1经验计数分析阶段": {
    "context1": "早期情报分析的基本处理单元是文献整体,通过对文献的研究间接地反映知识的状况，相应的，情报分析也是建立在对文献整体的认知之上的。因此，早期情报分析主要是借助于定量和量化方法对文献的外部特征进行计量,主要的方法是先观察,进而假设,再根据假设进行实验，如果实验的结果与假设不符合，则修正假设再实验。经验计量的典型代表是文献计量的三大定律：洛特卡定律、普赖斯定律和布拉福德定律。美国学者A.J．洛特卡在20世纪20年代经过对科学论文及其作者的分布关系进行长期的观察和计数，发现了科学工作者人数与其所著论文之间的数量关系，并用两组论文数据进行了验证。在洛特卡定律的研究基础上,普赖斯进一步研究了科学家人数与科学文献数量之间的关系[，提出了著名的普赖斯定律,其在《小科学，大科学》中论述“在同一主题中,半数的论文为一群高生产能力作者所撰,这一作者集合的数量约等于全部作者总数的平方根。”洛特卡定律和普赖斯定律都是通过对文献的计数实现了对研究人员(文献作者)的量化研究,而布拉德福定律则是描述文献序性结构的定量经验定律[，该定律指出,如果将科技期刊按其刊载某学科专业论文的数量多少，以递减顺序排列，可以把期刊分为专门面对这个学科的核心区、相关区和非相关区。各个区的文章数量相等，此时核心区、相关区、非相关区期刊数量成 $1 : \\mathrm { n } : \\mathrm { n } ^ { 2 }$ 的关系。维克利进一步将杂志分区的数目推广到大于三个的更普遍的情形，提出了布氏定律的维克利修正式[。从上述文献计量的三大定律发展过程来看，都是先经过观察和计数，获得一定范围内的经验估计和理论估计,再到被后人完善、修正并推广到更为一般或普遍的情况，成为真正意义上的文献计量定律。因而,这种经验计量分析的情报分析也可以看作是计数型情报分析，其主要特征包括以下几个方面。",
    "context2": "(1)计数的对象是文献数量及作者数量（这两个量是文献最为显著的外部特征)。比如洛特卡定律描述了作者人数与其所著论文数量之间是一种倒平方的关系；普赖斯定律描述了不同文献作者之间发表论文数量的定量关系。",
    "context3": "(2)分析结论大多源于研究人员在长期实践工作中的观察，是对经验和规律的总结，在提出假设的基础上，用单一的数学公式进行表示，所得出的公式结论在总体上是正确的，但并不是精确的计量结果或统计分布。",
    "context4": "(3)使用的数学工具还比较简单和单一，主要是通过计数将计量的对象变为数值。数值化是计量研究的基础，定量化首先需要将计量对象进行数值表示，然后再通过计数对文献、作者、时间的维度进行定量分析，仅强调这些计量对象之间的等量关系，与其说是精确的度量，不如说是经验上的理论估计。"
  },
  "1.2精确计量分析阶段": {
    "context1": "计数型情报分析开创了情报分析定量化的先河,为情报分析的精确计量化奠定了基础，也一直是情报学的重要研究内容，进入精确计量分析阶段，定量化的情报分析发展主要体现在三个方面。第一个方面是继续对已有的文献定律进行验证和完善，同时扩大并推广这些定律的应用领域，这部分研究为后来文献计量学的产生奠定了基础。第二个方面是综合运用数学、统计学、情报学的思想和方法，不断探索新的情报分析方法,这其中最为典型的是引文分析。",
    "context2": "20世纪50年代,美国著名情报学家尤金·加菲尔德(Eugene Garfield)发明了引文索引,系统地提出了利用引文检索科技文献的新方法，开创了从引文角度来追踪科学发展动态的新领域，也开后了引文分析的大门。引文分析方法的中心就是测算被引数量，该方法最先被广泛用于评价科研成果的质量和影响力。根据加菲尔德的说法，“引文索引有助于历史学家衡量一篇文章的影响力—即它的‘影响因子'”。此后，Google 的创始人Larry Page[发明了针对Web信息的引用(超链接)算法PageRank，并通过对超链接集合中的元素用数字进行权重赋值，实现了“衡量集合范围内某一元素的相关重要性\"的目的。目前，PageRank的思想和方法除了在搜索引擎中发挥着巨大的作用以外，在社交网络分析、网络舆情分析、文献及科研机构影响力评价、网络用户兴趣分析等方面有着广泛的应用。以引文分析为代表的理论和方法，是精确计量分析阶段最为成熟的计算情报分析的理论和方法。第三个方面是20世纪90年代以来，伴随着计算机技术的广泛应用和深入发展，自然语言理解、信息抽取、自动标引、自动分类、自动文摘、关联规则等技术在情报学中的应用，使得情报计量和分析的对象从文献外部特征转向了文献的内部特征,计量的粒度也从文献的粗粒度演化到章节、信息片段、关键词等细粒度。建立在计算机自动化处理基础上的内容分析法，引起了情报学界的极大关注，成为研究热点，已经逐渐成为与上述两个方面相并列的核心内容[。精确计量分析阶段的主要特征包括以下几个方面。",
    "context3": "(1)精确计量阶段的情报分析逐渐从基于分析人员业务背景及知识积累的业务驱动模式，向重视情报内容中反映出的数量关系从而得出相关结论的数据驱动模式转变。“用数据说话”几乎成了这一阶段情报分析成果的必备要求。但总的来说，除引文分析以外，其他的量化分析仍然处于辅助地位，对数据关系的认识和解释主要还是靠分析人员的主观判断。",
    "context4": "(2)由于广泛地应用了自然语言处理技术和数据挖掘技术，这一阶段的情报分析已经将期刊论文以外的专利文献、政策文本、行业报告、社交网络数据、网页信息、网络日志、政府公开数据等都纳入了自己的分析范围，从这个阶段开始，情报分析开始从文献情报分析或科技情报分析走向了全领域情报分析，情报分析的价值正在凸显，其理论与方法已经渗透到多个不同学科领域。",
    "context5": "(3)分析过程引入了一些更加复杂的统计和数学模型,特别是20世纪末21世纪初以来，定量化的内容分析需要一些复杂的统计模型来揭示内容之间的关系，例如,对文献内部词频的统计,k-means方法可以实现对不同文献的自动聚类分析,支持向量机(SVM）可以实现对不同类别文献的自动分类分析。这一时期的计量过程更加复杂，计量的维度更多，从而能够得到更加丰富、更为深刻的情报分析结果。"
  },
  "1.3计算型分析阶段": {
    "context1": "进入21世纪,随着网络技术的广泛应用以及大数据理念和方法的兴起，计算型情报分析正在逐渐形成。计算型情报分析主要借助于数据建模的方式对情报问题和现象进行刻画和推理,运用计算的方式对大规模数据进行分析，从而获得有价值的结论。例如，Neil Johnson等人[对恐怖主义和叛乱活动升级的模式进行建模，以此来估计致命性攻击的升级速度和时间。乔治城大学的 Kalev Letaru 使用了数百万个开源指标的数据库借助于数学模型准确预测了本·拉登在巴基斯坦Abbottabad的地点。美国国防部高级研究计划署(DAPRA)花费数十亿美元资助XDATA项目，构建基于云计算和大数据的情报分析计算框架，用于从海量来源的异构数据中进行大规模的情报分析以获取有价值的情报,等等。计算型情报分析阶段的特征包括以下几个方面。",
    "context2": "(1)情报分析的对象更加多元化和融合化。在精确计量阶段，情报分析的对象就已经开始多元化了，分析的数据不仅包括论文、专利等科技文献,还包括各种网络资源、统计数据等。但主要还是根据情报任务的需求，对各类型的数据分别做独立的分析。计算型情报分析阶段则更强调在数据多元化的基础上，进行数据的融合,综合利用多种数据相互补充、交叉认证，以获得对所研究事物的全面认识，提高情报分析的准确性和科学性。",
    "context3": "(2)情报分析的模型化。计算型情报分析不再是简单的计数和计量，其目的不是简单的数据拟合，而在于逻辑推理。因此，计算型情报分析十分强调模型的作用，通过建立模型，化繁为简,把复杂的实际问题用数学模型进行抽象和表示，提高情报分析的洞察力。例如，通过对社交网络中流行病数据进行分析建立流行病预测模型,可以对某些区域的流行病流行发生的时间、范围、规模作出预测。另外,经过验证的模型还可以被其他研究依照不同的分析需求进行重组或再利用，从而提升情报分析的可重复性和科学性。",
    "context4": "(3)情报分析过程的自动化。大数据时代，传统的以人工处理为主的情报分析方法，已经无法满足分析多样化海量数据的要求，必须要借助以计算机为代表的信息技术的运算能力来提高分析效率。在以前的发展阶段中，自动化计算处于辅助地位，人的分析处于主导地位，而在计算型分析阶段则正好相反，自动化计算上升到了主导地位，人的工作更多集中于与机器的协同，帮助机器理解人类的思维方式和意图，而不是直接干预分析的过程和对结果的解释，这样才能最大限度地保证情报分析结果的客观性和可靠性。"
  },
  "2计算型情报分析的进展": {
    "context1": "从上述计算型情报分析的发展历程来看，情报分析正在从计量、定量走向计算,其“计算”的特征日渐突出。这里，我们首先梳理学界对“计算\"的理解,进而总结计算型情报分析的内"
  },
  "容及其进展。": {
    "context1": "谈及计算的概念，就必须要提到“计算思维\"（Computational Thinking。“计算思维\"这一概念最早由美国卡内基·梅隆大学计算机系主任周以真(Jeannette M.Wing）[教授提出,她认为,计算思维是一种分析思维，是借助计算这一基本概念来解决问题、设计系统以及理解人类行为的一种方法，具体地说，是对物理世界及其层次、关联关系的抽象（Abstraction）并用自动化（Automation)方式让计算机去处理、解析这些抽象,所谓的计算，就是对抽象的自动化（Computing isthe automation of our abstrac-tions）[。可见,计算概念包含了两个要素：抽象和自动化。Chenglie $\\mathrm { H u } ^ { \\mathrm { \\tiny ~ [ 2 0 } }$ 进一步明确指出，当前计算思维中的计算本质更像是追求“表示和模型\"(Representations and Models),即通过模型构建或表示来说明一个信息被合适的计算代理(ComputingAgents）执行的内部运行机制，其过程必须符合逻辑的、算法的、科学性的、数学的、分析的、面向工程的等原则。",
    "context2": "涉及计算并且与计算型情报分析密切相关的另外两个概念是社会计算和计算社会科学。其中,社会计算中的计算概念是指“计算技术”（Computational Techniques）,当前,社会计算从关注如何开发社会软件来提供他人使用，转变为关注通过多种计算技术辅助人们分析社会行为，同时也关注创建一个更强大的计算基础设施来支持人们的协同工作[。在计算社会科学领域中,Cioffi-Revilla认为计算的概念是建立在信息处理视角下的“计算或可计算的方 法”（Computation or Computational Approa-ches）,即运用大量基于计算机的设备提供从信息抽取算法到计算机仿真模型的方法应用。我国学者也指出，计算社会科学的核心技术是数据挖掘24",
    "context3": "综上可以看出，当前环境下所说的计算，不是简单意义上的数量统计或工具应用，而是一个更为全面和概括性的概念，是学科发展、信息技术创新以及社会需求三者共同作用的结果。计算型情报分析也是如此，在本质上它是情报分析的基本规律在演化过程中，不断被渗透和应用了计算思维，并与社会计算和计算社会科学相交融而形成发展起来，因此，计算型情报分析的内容实际上就是计算概念在情报分析中的具体化，可以概括为情报分析模型、情报分析框架与系统、情报分析算法三个方面，如图2所示。以下从这三个方面讨论计算型情报学的当前研究进展。",
    "context4": "![](images/5c9b0c088e1c591308515537b9a7a736b5cf63cca4987816a2e09606ed86fecf.jpg)  \n图2计算型情报分析研究内容"
  },
  "2.1计算型情报分析模型": {
    "context1": "模型方法一直以来都是情报分析研究和实践中的抽象与具体、理论与实践相互转化的桥梁,也是计算思维中“抽象\"和“表示和模型”的具体体现。抽象的本质是将要解决的问题进行表示和数据建模，建模的过程就是理解问题的过程。计算型情报分析模型首先是一种数学模型[2,它用来对面向特定任务的情报分析主体的行为、特定的情报传递过程或特定的情报对象进行抽象和模拟。例如，构建科研人员研究行为的动力学模型，并借助该模型来分析和预测在科学交流网络中有潜在影响力和创新力的团队和个人。",
    "context2": "情报分析有建模的优良传统并已积累了丰硕的成果,例如H指数、G指数以及其变种，都是用来评价个体学者的已有学术成就和影响力的数学模型[2。近年来，随着大数据及人工智能技术的发展,后现代数学方法和工具的应用，为情报分析注入了新活力。研究人员将大数据分析模型、社会网络模型、复杂理论模型、系统动力学模型等引入到了情报分析过程中，取得了非常丰富的成果。其中最为典型的代表是2013年以来发表在《科学》（Science、《自然》（Naturd、《物理评论》(Physical Revieu)、《美国科学院院刊》(PNAS)等世界顶级杂志上的一系列有关创新成果识别、团队影响力、科学发展预测方面的论文，充分体现了计算型情报分析模型的最新发展动态。这些研究采用复杂网络、结构方程、随机过程、动力学等模型,或者是通过机器学习的方法，用大量数据训练出模型，再用历史数据或其他相关数据进行验证，从而使该模型能够描述、预测科学发展及科学家影响力的趋势;或者基于复杂网络理论，构建随机网络模型，并根据样本数据构建出与现实最为吻合的理想模型，来刻画研究科学创新的内在驱动机制和发展规律，据此解释、预测科学论文的影响力。",
    "context3": "总的来看,近年来有关模型的构建和应用，呈现出如下特点和趋势。",
    "context4": "第一,不再仅局限于单纯的描述性统计，而是趋向于综合或组合使用描述性统计、复杂网络模型、高级计量经济学方法、机器学习模型、数学分析和计算机模拟模型等，情报分析中的计算特征越来越突出。例如，Kyebambe等人综合运用专利引用分析方法和监督学习法通过自动标记数据来构建预测新兴技术的模型,该模型在一年内的预测精度达到 $70 \\%$ 。Lee等人2借助前馈多层神经网络模型来捕获特定时间段内能够识别新型技术的指标之间复杂非线性关系，从而识别出处于早期阶段的新兴技术,并运用动力学模型来预测一项技术随着时间的推移可能出现的变化。Nsoesie等人运用一种仿真优化的方法(SIMOP)预测流感流行曲线的时效,旨在结合使用模拟、分类、统计和优化技术来预测流行病曲线，并在流感爆发期间推断出潜在的模型参数，该方法预测了弗吉尼亚州、迈阿密、西雅图和周边大都市区的蒙哥马利县的社交网络上流行病演变情况,结果显示该模型能够在前七周就预测到高达 $9 5 \\%$ 的流行病。",
    "context5": "第二,分析模型的构建从静态模型向复杂的动态模型转化，也就是在模型中引入随时间变化的量及其关系。例如,Sinatra 等人于2016年在《科学》杂志上发表了《个体科学家影响力演变的量化》,对科学家影响力(通过有影响力的出版物来衡量)的演变过程进行研究，加入了时间维度来量化科学家职业生涯中影响力和生产力的变化，发现这些影响力在科学家的出版物序列中是随机分布的。根据这个发现，他们通过随机影响力的规则构建了一个随机模型，将发表产量、个人能力和运气的影响作为参数，该模型能够揭示出科学研究成功的普遍模式,并能够准确地预测出科学家影响力的演变，包括H指数累计引用以及学术获奖等。YianYin等人在对三个大型数据集(美国NIH基金、美国创业企业VentureXpert数据库、全球恐怖主义数据库)中有关成功和失败的数据分析的基础上,开发了用来表示成功和失败的动力学模型,该模型能够根据动力学信息所得到的早期信号将成功者和无法获得成功者区分和识别出来。这些例子都表明,当前包括文献分析在内的情报分析远远超出了以往计量分析过程中所做的简单统计分析，在以往揭示情报分析对象中相关属性之间的关系等结构特征的基础上，更强调构建能够揭示情报分析对象中相关属性之间随时间变化而变化的规律模型，从而能够得出更多、更有价值的分析结果。",
    "context6": "第三，情报分析模型构建与应用以海量数据或者是大数据为基础。例如,Brian Uzz 等人在研究科学论文的影响力时，分析了WebofScience收录的1950—2000 年间出版的15613种期刊上的1790万篇研究论文，所构造的引文随机网络模型中包含了3.02亿条边（引用）。通过将该引文网络中的引文频率与实际的引文频率作比较,进而计算出引用的Z分数(标准分数)来反映某个论文的新颖性。该项研究得出结论,创造了新知识又不脱离主流研究领域和范式的科研成果，具有较强的科技影响力。又例如,Dashun Wang等人在《长期的科学影响力的量化》一文中运用复杂网络中的动力学模型,开发了一种反映引文动态变化的论文引用机制模型(MechanisticModel），用来发现长期的论文引用规律，这项研究使用的数据来自于美国物理学会(ASP)提供的1893至2010年的《物理评论》语料,共45万篇论文及其引文，同时为了避免模型的学科依赖性，还使用《自然》《科学》等12种综合性及理、工、医学等领域的知名期刊在1990、1995、2000三年发表的全部论文以及2011以来对这些文章的引用文章。",
    "context7": "第四，研究的重心从评价过去的成果向预测和解释未来的成果以及科学发现转变。例如，上述BrianUzzi等人对科学论文影响力的研究,不仅发现了什么类型的研究更容易被学界接受，更为重要的是，他们所构建的论文引用随机网络模型，还可以用来预测具有创新性的研究成果及其未来的影响力，这是该研究的重要目标。另一个典型的例子是2016年由南加州大学维特比工程学院信息科学研究所举办的“混合预测竞赛”（Hybrid Forecasting Competition,HFC)项目[35-3d,该项目的目标是对世界范围内的社会经济和地缘政治问题进行更准确的预测,例如疾病爆发、股市波动、选举和国家冲突等。该项目开发了一种融合机器自动预测和“众包\"预测的模型，能够融合人类和机器系统的优势，通过人机交互，帮助分析人员对疾病爆发、股市波动、选举和国家冲突等进行有效的预测。"
  },
  "2.2计算型情报分析算法": {
    "context1": "模型建立只是计算型情报分析的一个步骤,为了让计算机帮助求解,需要虚拟的符号来代替数学模型里的每个变量和运算规则，即把解题思路用程序语言完整地描述给机器。算法（Algorithm）就是解题方案准确而完整的描述，是一系列解决问题的清晰指令[37-38。情报分析的算法是建立在通用的算法设计、实现思路和方法的基础之上，是在情报思维的指导下面向特定的情报分析任务或情报分析场景而形成的一系列计算步骤和指令，它是机器进行情报分析自动化的前提，它用机器可以理解的方式把情报分析的思路和过程进行描述，使得情报分析模型得以用机器加以计算并最终获得计算的结果。",
    "context2": "近10年来,云计算技术、物联网技术、大数据技术、人工智能技术等领域均取得重大进展，极大地推动了情报分析算法的研究和实践，西方情报强国都积极地投入大量人力和资金研发先进的情报分析算法,诸如 Darpa Maven、AI-Next [4d、Big-Mechanism[41]、World Modler[等项目。这一类的研究项目具有两方面的特点，第一，研究内容都是面向情报领域重大、基础的颠覆性技术和算法，这类算法在未来的情报活动中具有不对称优势;第二，研究的算法重点解决面向海量、异构、多源的数据挑战且提供的情报服务具有较高的实时性。除了专门研究算法的项目以外,研究人员还针对专门领域的情报分析任务开发了解决具体问题的算法，这些领域包括人道主义危机[4、大规模暴力和骚乱[、大规模移民、疾病爆发[4、经济危机[、资源短缺和自然灾害[4,等等。",
    "context3": "近年来，有关情报分析算法的研究和实践呈现出以下特点和趋势。",
    "context4": "第一，情报分析算法开始注重可解释性。与大数据分析不同，情报分析除了注重相关性之外,还十分重视结论背后的原因[4。近年来，情报分析领域越来越认识到，仅仅是发现相关性是不够的，大数据分析算法所分析出的数据中的“关联\"只是情报分析人员认知世界和识别事物的第一步，相关性背后的因果性探索仍有必要,数据的关联性预测并不能替代和取消情报分析中的解释功能,解释是情报分析任务中非常重要的要素，单纯的没有解释说明的分析结果本身是不可靠的。近年来，在医疗保健50-5]、法律、军事等领域的情报分析十分重视所使用的情报分析算法的可解释性,并逐渐推广到其他领域[54-5d。例如,D Gunning [5i提出了一种“可解释的人工智能”（EXplainableArtificial Intelligence,XAI)研究计划,该计划针对现有机器学习算法存在的问题,如深度学习、SVM算法、随机森林等算法虽然学习性能较好，但是可解释性较差，所得到的分析结论只能回答是什么，而不能回答为什么，旨在对这些机器学习方法进行改进,以使机器学习得到的模型具有可解释性,从而能够协助情报分析人员在情报分析的人机交互过程中理解分析的结果。该计划拟对自反射性深度学习（Reflexive andRational Deep Learning）叙事生成因果关系建模（Narrative Generation Causal Modeling）、三级解释的模式理论（3-Level Explanation PatternTheory+）、验收测试自适应程序（Acceptance Tes-ting Adaptive Programs）、交互式训练认知建模（Interactive Training Cognitive Modeling）、可解释的强化学习（ExplainabilityRL）、基于展示和讲述解释的深度学习（ Show and Tell ExplanationsDeep Learning）、基于论证和教育的深度学习（Argumentation and Pedagogy Deep Learning)、基于决策图的概率逻辑（Decision Diagrams Proba-bilisticLogic）、交互式可视化模拟学习(Interactive Visualization Mimic Learning）、基于贝叶斯教学的模式归纳（Bayesian TeachingModel Induction）等11类算法进行改进,使改进后的算法不仅具有较强的学习(预测)能力,而且还具备较强的解释能力,最终能够使用具有解释性的学习算法构建基于人类解释的模型。又例如,施乐帕洛阿尔托研究中心(PARC)研发了一种可解释的自主决策智能体COGLE,其界面为用户提供了对COGLE推理的解释和见解。",
    "context5": "第二，越来越重视面向开源情报的感知算法。随着计算机算力的不断提升和自然语言处理技术的突破，开源情报采集的方法已经从传统的爬虫向更加智能的情报感知系统转型，相应的实现算法不仅包括传统的PageRank算法、链接解析算法等，还广泛地使用情感分析、隐喻识别、实体识别、关系抽取的方法，并将这些方法与分析算法相融合，形成一种新的分析算法一一感知算法,利用这种算法，情报分析系统或情报分析人员可以从开源、开放的网络环境中提前察觉到现实世界发生的有价值的“信号”，并尽可能敏锐和准确地预测出可能会发生的事件。Kejriwal等人提出了一种面向开源情报的感知算法,能够在缺乏语料资源(如孟加拉语、印度尼西亚语、旁遮普语、菲律宾宿雾族语和斯瓦希里语)的语言环境下从新闻和社交媒体中提取和处理群体意见和舆论，从而提前发现可能发生的人道主义灾难。从特定的Web信息源中获取有价值的犯罪线索，是打击人口贩运、武器走私等领域长期关注的研究问题[，Szekely等人[提出了一种从多源、异构、海量的Web页中提取关键实体信息并构建人口贩运知识图谱的算法，它利用语义技术融合从不同来源获得的数据，通过增量扩展提取了数十亿个三元组,形成了一个巨大的人口贩卖关系网的知识图谱，该项算法已经在多个执法机构和非政府组织中得到了应用，在帮助执法机构或其他组织查找贩运者并解救受害者方面发挥了作用。",
    "context6": "第三,人机融合算法得到关注和重视。为充分发挥人的聪明才智，面向未来的情报分析和情报服务更加注重人机融合的分析过程，也就是说，在机器计算的同时，充分考虑人脑思考的结果，并将这种结果与机器计算的结果融合起来,形成最终的分析结论。只是这个融合的过程是由人机融合算法来自动完成的，而不是由人来主观完成的。例如，美国情报高级研究计划署(The Intelligence Advanced Research Pro-jectsActivity，IARPA）开展了名为FUSE(Foresight and Understanding from Scientific Expo-sition)的研究项目，设计一种能够融合人的预测与机器预测的算法,以识别当今未知但可能在三到五年内出现的颠覆性技术。FUSE开发的自动化方法，利用已发表的科技文献和专利中的信息，根据既定的量化指标自动提名已知和新的技术术语，并对这些技术进行系统、连续和全面的评估，同时,利用众包的方式向特定专家群体提问，征询他们对新技术的预测意见，最终将机器预测与专家群体预测进行融合，以识别或预测出特定领域的新技术。"
  },
  "2.3计算型情报分析框架和系统": {
    "context1": "计算型情报分析框架主要是指实现情报分析的技术框架，是为解决情报分析过程中开放性问题而设计的具有一定约束性的支撑结构，表现为一组抽象构件及构件实例间交互的方法。计算型情报分析框架本身并不解决具体的情报分析问题，它只是为实现计算分析而给出一个用于插接、组合解决问题的相关组件的基础。一方面,它界定了实现计算分析的技术边界,进而将相关的软件组件约束在这个边界内，从而保持解决情报分析问题时手段的内聚性;另一方面，它还用来提供支撑解决情报分析问题的可选的配套软件组件或工具。利用计算型情报分析框架，可以根据具体情报分析问题来扩展、安插更多的组成部分,从而更迅速和方便地构建完整的面向情报任务和问题解决的情报分析系统。从某种意义上说,计算型情报分析框架是构建情报分析系统的元标准。",
    "context2": "随着大数据的产生和广泛应用，数据的多源、异构、复杂、不确定性等特征给情报分析工作带来的挑战越来越大，情报分析技术正在从小数据集的分析向大数据的分析发展，情报分析技术正在从封闭的框架和软件生态向开放合作的框架和软件生态发展。在这种背景下，计算型情报分析框架成为计算型情报分析重要的研究和实践内容。这其中的典型代表是美国国防部高级研究计划署（DefenseAdvancedResearch Projects Agency,DARPA)花费数十亿美元资助的XDATA项目，该项目旨在开发包括资源采集、清洗与转换、数据建模、数据分析、结果可视化、用户交互、信息查询等功能在内的面向各种领域和数据的情报分析的通用技术框架，目前该项目已经基本构建完成了一个技术成熟、体系完善的情报计算框架和生态体系，相关的情报部门可以在其基础框架之上快速地搭建个性化的面向具体领域情报工作的情报处理系统和平台。",
    "context3": "近年来，计算型情报分析框架与系统的发展与研究呈现出以下特点和趋势。",
    "context4": "第一，由于大数据在计算和分析上带来的挑战，分析框架和系统正在从单一架构向分布式、云计算的构架发展，这类框架更加适合多源、异构、海量数据的存储、计算、分析等需求。Hadoop、MonoDB、Storm等分布式存储/处理技术和框架的出现，为情报的分析和处理提供了方便、成熟的面向服务的调用接口(API）,使得研究人员更加关注面向应用场景的框架设计与研究。例如,Sprague框架是学界和业界最为广泛接受的决策支持系统（Decision Support Systems,DSS)框架。为了能够适应于海量、异构数据存储和处理技术,Watson等人基于该框架提出了一种面向大数据情报决策的演变框架，能够将不同来源的数据通过大数据集群统一存储在数据湖(DataLake)中。又例如,图计算在情报的分析与推理中具有重要的地位，许多实际的模型例如引文随机网络模型、社交网络模型等都涉及图计算。在某些情况下构建的网络图会有数十亿个顶点、数万亿个边缘,这对计算来说是一个非常巨大的挑战。Grzegorz等人提出了一种适合图任务的分布式计算框架—Pregel,能够在数千台通用型计算机上构建图分析集群并且能够支持高效、可扩展和容错的部署。Simmhan等人提出了一种叫Goffish 的面向大规模图处理的计算框架,相对于Pregel它的性能提高了好几个数量级，该框架同时还设计"
  }
}