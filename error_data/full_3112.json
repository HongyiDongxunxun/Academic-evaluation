{
  "original_filename": "full_3112.md",
  "国内外近年Web Archive技术研究与应用进展黄新平 王萍": {
    "context1": "【摘要】在对国内外近年相关研究文献和网络存档项目调研的基础上，参照OAIS模型，把网络信息资源长期保存的基本流程归纳为采集、管理、保存、利用等主要阶段，并依此为主线，构建一个系统化的研究框架，在该框架下对Web Archive流程中不同阶段目标的实现所涉及的技术及其应用进行梳理、识别和分析。通过总结近年国内外Web Archive技术的研究成果和洞悉未来网络资源保存技术的发展趋势，以期为我国网络资源保存的研究与实践提供参考和借鉴。"
  },
  "【关键词】Web Archive网络资源长期保存 技术应用": {
    "context1": "Abstract:On the basis of recent literature review and Web Archive project investigationat home andabroad，according to the OAIS model，this paper summaries the basic processof network informationresource long-termpreservationas the mainstagesofcollection，management，preservation，utilizationand soon.On this basis，itconstructsasystematic researchframework，and under the framework sortsoutand analyzes technologyapplicationof Web Archive eachflow.By summarizing therecent research results of Web Archive technologyand predicting the future development trend of Web Archive technology in the future，the authors aim at providing reference for Web information presevation in China.",
    "context2": "Key words: Web archivenetwork resourcelong-term preservationtechnology application DOI:10.15941/j.cnki.issn1001-0424.2016.18.005",
    "context3": "随着网络技术的不断发展，互联网已经成为当今社会重要的“文化集散地”。在网络上人们能够参与信息的创建、发布、传播、利用活动，这些信息汇集了当今的流行事件、热点新闻、网络舆论、动态趋势等，记录了人类网络时代的生活痕迹，作为社会的“公众记忆库”，具有重要的历史回顾、参考凭证、学术研究等价值，是当前数字资源长期保存的重要对象。目前，世界上许多国家的图书馆和档案馆等文化记忆机构都在积极开展网络资源保存（Web Archive）的理论研究和实践探索，其中，网络信息资源归档保存的相关技术与应用是主要研究内容之一。",
    "context4": "本文以Web Archive技术研究为逻辑起点，通过文献搜集和网络调研的方法，对Web Archive技术研究与应用的发展状况进行梳理，并指出其未来发展趋势。研究数据来源于ACM、Springer-Link、EBSCO、LISTA、Emerald、Elsevier Science、Web of Science、IET Electronic Library、中国知网等文献数据库，以及利用谷歌、百度等搜索引擎搜集到的相关网络资源。在文献检索过程中限定的时间范围为2000年至2016年，检索使用的关键词主要有“Web Archive”“Web Archiving”“ntermet Archive”“网络信息资源保存”“网页存档”“网页保存”“网页档案馆”等，经过对文献的主题筛选，共获得Web Archive技术研究相关的中英文文献139篇。从文献分析可以得出，Web Archive涉及到网络信息资源的采集、管理、长期保存和访问利用等阶段，各个阶段目标的实现，都需要有一系列的技术作支撑。如采集中的网络爬虫、网页重要性评价技术，管理中的待归档网络资源的自动分类、元数据管理技术，长期保存中的云存储、数据安全保护技术，访问利用中的多媒体信息检索、智能检索、网页重现、Web 数据挖掘、数据可视化等，都是Web Archive技术研究与应用的重点内容。"
  },
  "1Web信息采集技术与应用": {
    "context1": "Web 信息采集作为网络资源长期保存的起点，是构建Web Archive的基础，在整个Web Archive过程中具有重要意义。所谓“采集”，是指利用相关工具，以既定的频率和方式，及时选择和获取值得保存的Web信息。其中，主要涉及采集对象的选择、采集方式的确定、采集内容的获取等技术问题。"
  },
  "1.1采集对象的选择": {
    "context1": "如何在海量的网络信息资源中选择重要的、有保存价值的信息并将其作为采集对象，是网络信息采集要解决的首要问题。对于该问题，国内外不少学者在Gogle的PageRank算法和IBM的HITS算法的基础上，提出了一些网页重要性评价的改进算法和评价模型。如国外的Md.Hijbul Alam等学者在借鉴PageRank算法的若干重要性指标的基础上，添加链接结构、inter-host链接、页面标题、主题相关性等评价指标，实现了一个页面重要性评价算法——FPR-title-host算法。国内的张芳等学者在传统的PageRank 和 HITS 算法的基础上，构建了一种基于更新时间、网页权威性和用户对网页反映的相关排序算法。许彬类比PageRank算法，采用链接作为网页重要性的评价指标，建立用户查询和网页点击率之间的联系，提出类PageRank算法，并在算法中添加时间函数和用户兴趣度函数，得到增强型类PageRank算法。过仕明分析了传统PageRank技术在网页重要性评价上存在的不足，并结合搜索引擎的第一定律（相关性定律）和用户对页面的点击率判断网页重要性的方法，建立了网页重要性的综合评价模型。这些算法和模型的应用，为网页存档中网页重要性评价提供了有效的解决方案，为Web信息采集对象的选择提供了重要的技术支撑。"
  },
  "1.2采集方式的确定": {
    "context1": "采集方式的确定决定着网络信息资源保存的内容、特点和整个存档过程，在网络信息资源保存中起着至关重要的作用。在调研国内外主要Web Archive项目的基础上，以采集的信息广度为依据把采集方式分为定域采集、定题采集和定点采集3种。",
    "context2": "（1）定域采集。定域采集即基于特定网络域（如.gov、.edu、.com等）的完整性采集，英文中一般用“Whole Domain Harvesting”进行表述。这种信息采集技术主要是利用网络机器人（Robot）、网络爬虫（Crawler)等网络信息收割工具从一些种子URL扩充到特定网络域中整个Web的自动化采集。由于这种信息采集的采集范围和数量非常巨大，因此对采集速度要求很高。同时，由于这种信息采集一般并行的采集器数量较多，所以还要重点解决URL分配等关键问题。",
    "context3": "瑞典国家图书馆负责的Kulturarw3项目所采用的Combine Crawler是一个典型的基于特定网络域的信息采集器，由它实现了对.se（瑞典国家域名）网站以及服务器在瑞典的.com网站信息的自动采集。Combine Crawler采用的是分布式、异步I/O工作模式，为了提高获取页面的速度，设计了一个专门的URL Server，在其调度和管理下，采集URL队列由分布式存在的多个采集器共同维护，而且每个采集器可通过异步I/O方式一次同时打开很多个URL链接。另外，为了避免URL的重复分配，Combine Crawler利用哈希函数计算目标服务器的IP地址，并将同一站点服务器获取的URL添加到同一个队列中，从而保证来自不同站点的URL被分配到不同的采集器中。",
    "context4": "(2）定题采集。定题采集主要是针对某一预先定义好的主题（关键词、样本文件、重要事件、特定网页等)进行的有针对性的信息收割方式。与定域采集相比，定题采集只采集那些与主题有关的页面，保存的页面数量少且能获得较快更新，比较接近Web当前的真实状况。",
    "context5": "对定题采集技术的研究源于1999年S.Chakrabarti等人研究开发的Focused Crawling系统。该系统采用基于样本文件学习扩展的主题采集方法，首先建立一套完善的主题分类体系，并为每一个主题分类保存一些样本文件，然后由用户通过选定样本文件来确定所采集的信息主题。随后，其他许多学者也对面向主题的Web信息采集进行了研究。如Javad Akbari Torkestani提出了一种基于机器学习的自适应定题采集算法，该算法的思路是先搜集一些网页文档作为训练集，并通过机器学习方法实现对这些训练集网页文献主题的自动分类，并从中挖掘关键词和主题分类之间的联系，利用网络爬虫对含有主题相关关键词的网页文档进行采集。刘炜基于本体和语义分析的相关理论与技术，设计并实现了一种基于语义分析的主题信息采集模型，与传统的面向主题的Web信息采集模型相比，该模型具有较高的信息采集准确率。",
    "context6": "在Web Archive实践方面，澳大利亚的PANDORA项目采用面向主题的Web信息采集技术开发了PANDAS 信息采集系统，该系统通过识别和选择项目采集指南中明确规定的主题分类来完成信息采集[。此外，英国的 WebArchive项目在 Heritrix开源爬虫技术的基础上，设计了特定的抓取逻辑，通过引入定向抓取包含某一特定内容网页的算法，实现了面向本国主要事件（如2005伦敦恐怖袭击、2012奥运会等)、时事（如历年英国大选等）及专题（如英国乡村风情、社会文化等）等各种特定主题网页内容的采集[。",
    "context7": "（3）定点采集。定点采集即是按照既定的规则，从指定信息来源中挑选出具有保存价值的站点，如门户网站、专题报导等，对这些站点进行 $\\mathrm { \\mathbb { W } e b }$ 信息采集。该采集方式通常用于保存易逝的网络信息和达到一定评估标准的网站信息。其中增量式Web信息采集（Incremental Web Crawling）是实现定点采集的主要技术方法，与以上两种采集方式所采用的周期性Web信息采集不同，增量式Web信息采集仅对站点中新产生的或者发生变化的页面进行采集，对于没有变化的页面则不需要进行采集，这样就可以大大地降低页面的采集数量，进而减少采集的时空开销[4。这些优势使其成为 Intemet Archive、Wayback Machine、Google等大型搜索系统的首选，基于该信息采集技术的定点采集方式也在当前国内外的Web Archive项目中被广泛采用。",
    "context8": "由于Web信息资源具有复杂性、异构性和动态性的特点，如何判断某个页面是否发生变化，以及如何根据页面的变化情况来设计合理的采集策略以提高信息采集的效率，是应用增量式Web信息采集技术要解决的主要问题。对于该问题，IBM采用了一种适应性的方法，即根据先前采集周期里采集结果实际变化率的调整来控制采集的策略，并依此设计和开发了实现增量式Web信息采集的信息采集器 Web Fountain。此外，Myriam Ben Saad等学者[针对网页更新频繁的站点，通过分析其页面改变的时间演化归类，提出了一个及时发现页面变化的模型，并将其应用于法国电视网网站网页归档中，结果表明，该模型的应用可以提高网页采集的质量。"
  },
  "1.3采集内容的获取": {
    "context1": "随着Web Archive项目的不断深入开展，许多网站信息保存研究机构已经开发出了一些专门的用于网站信息采集的工具。目前，网站信息采集常用的开源工具主要包括 Heritrix、HTTrack、Nutch、Smart Crawler等，具体如表1所示。为了节约成本，综合考虑现有网站信息采集工具的特点，当前不少Web Archive实践项目，如澳大利亚的PANDORA项目、英国的UKWAC项目、美国的Web at Risk项目等均选择在 Heritrix和HTTrack 这两款开源工具的基础上进行优化和扩展，来实现网站信息的采集[。其中，由IA和IIPC成员图书馆负责开发的 Heritrix采用广度优先算法来抓取完整的、精确的站点内容，它对网站采集的精确度和完整度都很高。因此，可以利用它来完成大规模网站信息的完整性采集。而由法国图书馆设计和实现的HTTrack 则具有较强的链接分析功能，它可以从服务器获得网站的所有结构，因此，非常适合用于完成重要网站网页信息的深度采集。这两款网页采集工具，在实施信息采集前均能够对要采集的网站网页信息的更新频率进行评估，而且在采集时可以通过增加爬行的数目，使网页捕获频率与网页更新频率尽可能地保持一致，从而能有效地确保网站信息采集的质量。",
    "context2": "表1Web Archive常用的网站信息采集开源工具",
    "context3": "<table><tr><td rowspan=1 colspan=1>工具名称</td><td rowspan=1 colspan=1>开发者</td><td rowspan=1 colspan=1>功能特点</td><td rowspan=1 colspan=1>软件许可</td></tr><tr><td rowspan=1 colspan=1>Heritrix</td><td rowspan=1 colspan=1>IA、IIPC成员图书馆</td><td rowspan=1 colspan=1>可扩展、可配置，易用性强，广度优先，站点内容精确复制</td><td rowspan=1 colspan=1>GNU、LGPL</td></tr><tr><td rowspan=1 colspan=1>HTTrack</td><td rowspan=1 colspan=1>法国图书馆</td><td rowspan=1 colspan=1>链接分析功能较强，配置丰富简单，适合小规模的抓取</td><td rowspan=1 colspan=1>GNU、GPL</td></tr><tr><td rowspan=1 colspan=1>Nutch</td><td rowspan=1 colspan=1>Apache</td><td rowspan=1 colspan=1>可扩展，命令型工具，可定制性略差，采集覆盖原有内容</td><td rowspan=1 colspan=1>Apache License V2. 0</td></tr><tr><td rowspan=1 colspan=1>Smart Crawler</td><td rowspan=1 colspan=1>IA、英国、法国图书馆、美国国会图书馆</td><td rowspan=1 colspan=1>智能爬虫，Heritrix的升级版</td><td rowspan=1 colspan=1>GNU、LGPL</td></tr></table>"
  },
  "2Web管理技术与应用": {
    "context1": "Web管理是将那些采集的具有保存价值的网站信息进行自动分类、编目著录、鉴定整理等操作，使无序信息有序化，并实施有效控制，为以后的存储、检索、利用工作做好准备。"
  },
  "2.1自动分类": {
    "context1": "利用采集工具收集到的网站网页多是杂乱无序的，还应根据一定的规则，按照设定的分类方案实现网页的自动分类，进而对这些网站信息进行有序组织，以改善资源利用时信息检索的效率和性能，提高归档网站信息资源的利用率。针对该问题，Ross Harvey等学者提出应用有指导的机器学习方法实现大规模网站网页的自动分类，该方法因实现简单且应用效果好，目前已被广泛地应用到数字图书馆、信息检索、信息过滤以及搜索引擎的目录导航服务等领域。这种网页自动分类方法的基本流程是“设定网页文档训练集 专家进行人工分类 机器学习 训练分类器 网页自动分类”。"
  },
  "2.2编目著录": {
    "context1": "对采集到的政府网页还应通过获取、分析、组织和记录关于网站内容、结构、管理过程、形成背景以及管理系统的信息，以形成对所描述对象及其构成部分的准确表述，即实现对这些政府网页的编目著录。通过对国内外一些Web Archive项目调研发现，DC（都柏林核心元数据集）作为一个通用数据描述格式，目前已经被广泛地应用，同时考虑到重新创建一种描述元数据具有一定的风险性，因此，大部分项目采用发展相对成熟的DC元数据标准作为网站网页信息编目著录的数据描述格式2。DC标准简单，易于应用，尽管只有15个核心元素（如表2所示)，但这些元素几乎全面地概括了一个网站的主要特征，而且各个元素都是可选和可重复的，具有很强的灵活性，从而可以实现对网站网页信息简洁灵活而充分的著录。",
    "context2": "表2DC的核心元素",
    "context3": "<table><tr><td rowspan=7 colspan=1>描述资源内容的元素</td><td rowspan=1 colspan=1>Title</td><td rowspan=1 colspan=1>资源的名称</td></tr><tr><td rowspan=1 colspan=1>Subject</td><td rowspan=1 colspan=1>资源主题</td></tr><tr><td rowspan=1 colspan=1>Description</td><td rowspan=1 colspan=1>对资源内容的描述</td></tr><tr><td rowspan=1 colspan=1>Source</td><td rowspan=1 colspan=1>资源源文件的有关信息</td></tr><tr><td rowspan=1 colspan=1>Language</td><td rowspan=1 colspan=1>资源采用的语种</td></tr><tr><td rowspan=1 colspan=1>Relation</td><td rowspan=1 colspan=1>相关资源之间的关系</td></tr><tr><td rowspan=1 colspan=1>Coverage</td><td rowspan=1 colspan=1>资源所覆盖的时空特征</td></tr><tr><td rowspan=4 colspan=1>描述知识产权的元素</td><td rowspan=1 colspan=1>Creator</td><td rowspan=1 colspan=1>资源制作者</td></tr><tr><td rowspan=1 colspan=1>Publisher</td><td rowspan=1 colspan=1>负责制作资源的实体</td></tr><tr><td rowspan=1 colspan=1>Contributor</td><td rowspan=1 colspan=1>为资源创建做出贡献的个人或者团体</td></tr><tr><td rowspan=1 colspan=1>Rights</td><td rowspan=1 colspan=1>产权管理说明</td></tr><tr><td rowspan=4 colspan=1>描述资源属性的元素</td><td rowspan=1 colspan=1>Date</td><td rowspan=1 colspan=1>资源获取的日期</td></tr><tr><td rowspan=1 colspan=1>Type</td><td rowspan=1 colspan=1>资源类型的划分</td></tr><tr><td rowspan=1 colspan=1>Format</td><td rowspan=1 colspan=1>资源的数据格式</td></tr><tr><td rowspan=1 colspan=1>Identifier</td><td rowspan=1 colspan=1>唯一识别资源的标识符</td></tr></table>"
  },
  "2.3鉴定整理": {
    "context1": "网站网页信息是一种有特定内容、结构、背景信息的电子文件，因此电子文件鉴定的一些方法可以应用到网站网页文件的鉴定中。国内学者周毅提出了借鉴电子文件鉴定的方法，指明网站网页文件的鉴定整理主要包括文件的识别以及文件的可用性判断，其中，文件的识别就是将网站网页文件与非文件类信息加以区分，并将文件的构成要素组合在一起，确保归档网站网页文件长期可用的元数据、保存方式等数字要素齐全。文件的可用性判断即是通过对网站网页文件保存价值和内容质量进行检测，以及对网页信息的来源、内容、时间和形式等特征进行全面分析，保证归档网站信息的真实性、完整性、有效性。此外，针对采集的网站信息大数据量的特点，国外的Elena Demidova等学者利用云计算提供的海量数据处理技术，提出实现海量网站信息智能鉴定的解决方案，即应用云计算环境下的MapReduce模式，通过建立基于专家知识库的网站信息归档智能鉴定系统，实现海量待归档网站信息的自动鉴定。其中，专家知识库的构建，以及如何建立动态的鉴定过程、如何对鉴定信息进行处理与分析是实现该系统要重点解决的问题。"
  },
  "3Web保存技术与应用": {
    "context1": "网站的动态性、链接性等特点以及未来对其访问的需求，使得网站信息保存不同于一般的数字资源保存，它更依赖能够保证归档网站的可访问性和长期使用性的长久保存策略，能够根据需要实现存储空间动态扩展的存储架构方式，以及能够确保归档网站网页数据保密性、真实性、完整性、可靠性的安全保护方法等。"
  },
  "3.1长久保存策略": {
    "context1": "网站信息长久保存策略涉及存储数据格式的选择及数据检测、备份、迁移等技术的采用。目前针对Web",
    "context2": "Archive的长期保存技术方法中还没有一种可以实现所有类型网页信息资源长期保存的方法，通过文献和网络资源调研发现国内外主要的Web Archive项目多是以因特网媒体类型表MIME中的常用媒体格式为存储格式类型参考，采取定期检测和备份（异地备份和跨平台备份）的维护方式，针对要保存的网站信息资源的不同格式类型，采用按需迁移、格式迁移和UVC仿真相结合的长期保存技术策略。譬如，国内的Web InfoMall网络资源长期保存项目综合采用MD5检测方法、XML文档格式迁移、UVC仿真等数据抽验和备份机制完成对保存网站信息的完整性检测和数据恢复。而美国的DuraCloud项目则是通过异地备份机制将已归档保存的数据跨平台迁移到AmazonS3、EMC Atmos 等多个商业云存储平台上"
  },
  "3.2存储架构方式": {
    "context1": "存储架构是指根据归档Web资源的保存需求而采用的存储技术及其相关设备。网站信息归档作为一项持续性保存活动，不断增加的保存数量对存储管理提出了新的挑战，如何有效解决海量存储问题、如何进行数据的高效存取、如何快速响应大数据量的访问需求等是完成存储架构选择要着重解决的问题，而云存储的提出为这些问题的解决提供了一种新的、有效的解决方案。与当前数字资源长期保存常用的 SAN、NAS、DAS等传统网络存储技术相比，云存储技术具有存储构架易扩展、支持非结构化数据的海量存储、高性能、稳定、易于管理、节约成本等优势。目前，国外已经有相关机构将云存储应用到网络资源的长期保存研究中，Fedorazon 和 DuraCloud是其中两个有代表性的项目，它们利用云存储提供的各种服务实现归档网络资源的长期可访问及便利使用的功能，具体包括访问、保存、再利用和云分享等。"
  },
  "3.3数据安全保护方法": {
    "context1": "为了确保归档网络资源的可靠、可信及长期可用，使其具备传统档案所具有的原始性、凭证性和长期可读性，实现归档网站数据信息的安全保护是实施Web Archive要解决的一个关键问题。基于此，国内外一些学者通过对可信云计算、数据隔离、数据保护等关键技术展开研究，提出了相应的解决方案。如冯朝胜等学者利用云计算的虚拟化技术和可信平台模块，提出了一种基于用户信任等级与角色分配融合驱动的数据隔离访问机制，实现对云存储平台中数据访问的隔离保护；程勇提出了一种基于谓词加密的动态计算数据保护方法，通过设定谓词访问规则，允许用户访问满足谓词访问规则的数据，该方法可以保证用户在“云端”对数据进行插入、删除和修改等动态操作过程中的数据安全；Katharine Stuart等学者基于数据分片存储和数据分片加密技术，提出一种静态云存储数据安全管理策略。通过采用数据分片存储方法将归档的网站信息存储于文件系统的不同节点，提高数据传输的效率，减小数据存储的开销。同时为了保障数据的安全、可靠、可用，结合文件分片存储的特点，对数据进行分片加密，并设计和实现了相应的加密密钥生成方法。"
  },
  "4Web 利用技术与应用": {
    "context1": "网站信息保存的根本目的就是实现归档资源的利用，以发挥资源的保存价值。为了提高归档资源的利用率，还应借助先进的信息技术手段，如多媒体信息检索、智能检索、网页重现、Web数据挖掘及数据可视化等技术对归档保存的海量网络资源进行深层的价值挖掘与开发利用，为社会公众、研究机构、政府部内等不同类型的用户提供永久的浏览查询、网页重现、价值挖掘、数据可视化分析等多元化Web利用服务功能。"
  },
  "4.1归档多媒体信息的智能检索服务": {
    "context1": "浏览查询是实现归档网络资源利用服务的关键，如何在海量的存储信息中高效、准确地找到所需的资源，还需要依赖一个完善的检索系统。由于归档保存的Web资源中有不少信息是以包含多种模态数据的多媒体文档形式存在，而传统的基于单一模态对多媒体文档进行检索时存在语义含混不清的问题，容易导致检索结果出错。针对该问题，澳大利亚的PANDORA项目应用基于多模态的多媒体文档检索这样一种精确高效的多媒体信息检索方法，并基于Agent的智能信息检索以及基于本体的智能信息检索的相关研究，利用智能Agent和语义分析的有关知识，为归档网络资源信息检索服务建立一个专门的检索系统——Trove，利用该检索系统，用户可以按字顺、主题、区域、媒体类型等方式进行资源的浏览，也可以按关键词、短语、URL、域名检索等方式实现资源快速、精确的智能化查询。"
  },
  "4.2归档网站网页重现的无缝导航服务": {
    "context1": "为了解决用户访问网站时所遇到的网页“丢失”或无法“链接”或无法“显示”的问题。国外一些相关项目，如美国奥多明尼奥大学的“Tols fora Preservation-Ready Web”、日本京都大学的“Past Web Browser”等项目应用HTML重写、超链接重写、ProxyURL技术方法来实现某个时间节点内归档网站网页的重现，并利用网页重定",
    "context2": "向、域名重定向以及“URL $^ +$ 时间戳”的技术方式恢复归档网站网页原有的超链接情景，实现归档网站信息的自动重定向功能，即当用户访问这些网站遇到浏览器的404（NotFound）错误信息时，将被自动重定向到对应的归档网站网页信息，实现归档网站网页保存和利用的有效整合，从而为归档网站网页重现提供无缝导航服务"
  },
  "4.3归档网站信息的价值评估与挖掘服务": {
    "context1": "利用数据挖掘技术对存档网络信息资源的价值进行评估和深度挖掘，是当前Web Archive研究领域的一个重要技术应用。如英国政府Web档案馆项目从Web内容挖掘、Web 结构挖掘和Web使用挖掘的3个分类出发对Web数据挖掘的关键技术，包括数据仓库、数据可视化、聚类分析、决策树、神经网络、支持向量机、遗传算法等进行系统的研究，并利用这些技术对归档保存的海量网站信息进行深层次分析和研究，从那些公众感兴趣的，具有参考价值、凭证价值、研究价值且政府关注的归档网站信息中获取隐含其中的有用知识，并将提取的知识以概念、规则、规律、模式等形式传递给用户，进而为社会公众的信息需求、研究机构学术问题的研究、政府部门的决策和规划等提供重要的参考和依据。"
  },
  "注释": {
    "context1": "[]焦晓静，王兰成．知识图谱的概念辨析与学科定位研究[．图书情报工作，2015（15)：5－11.",
    "context2": "[秦长江，侯汉清．知识图谱——信息管理与知识管理的新领域[．大学图书馆学报，2009（1)：30-37.",
    "context3": "[] 陈悦，刘则渊．悄然兴起的科学知识图谱[．科学学研究，2005（2)：149－15",
    "context4": "陈悦，陈超美，刘则渊等.CiteSpace知识图谱的方法论功能[．科学学研究，2015（2)：242-253.",
    "context5": "刘则渊，许振亮，庞杰等．现代工程前沿图谱与中国自主创新策略．科学学研究，2007（2)：193－203.",
    "context6": "刘则渊，陈立新．国际物流研究领域的知识可视化分析[．图书情报工作，2010（8)：140－143.",
    "context7": "］侯海燕，刘则渊，陈悦等．当代国际科学学主流学术群体及其代表人物[．：科学学研究，2006（2)：161－165.",
    "context8": "侯海燕，刘则渊，栾春娟．基于知识图谱的国际科学计量学研究前沿计量分析[．科研管理，2009（1)：164－170.",
    "context9": "赵蓉英，陈瑞．跨语言信息检索的知识图谱研究[．情报理论与实践，2011（10)：96－100.",
    "context10": "[0]赵蓉英，王静．社会网络分析（SNA）研究热点与前沿的可视化分析[．图书情报知识，2011（1)：88-94.",
    "context11": "]邱均平，赵月华，赵蓉英．国外图书情报领域可视化研究之分析[．情报理论与实践，2013（1)：124－128.",
    "context12": "[2]邱均平，方国平．基于知识图谱的中外自然语言处理研究的对比分析．现代图书情报技术，2014（12)：51-6",
    "context13": "[13]宗乾进，袁勤俭，沈洪洲．国外社交网络研究热点与前沿[．图书情报知识，2012（6)：68－75.",
    "context14": "[4]宗乾进，袁勤俭，沈洪洲，等.2001-2010年国内情报学研究回顾与展望——基于知识图谱的当代学科发展动向研究[．情报资料工作，2012(1)：10-15.",
    "context15": "[5]汤建民：学科知识图谱的绘制及在学科发展监测与评价中的应用[．情报理论与实践，2009（10)：55-59.",
    "context16": "[6] 汤建民，余丰民．国内知识图谱研究综述与评估：2004－2010年[．情报资料工作，2012（1)：16-21.",
    "context17": "[7]刘后元，叶鹰．文献题录信息挖掘技术方法及其软件 SATI的实现——以中外图书情报学为例Ⅲ．信息资源管理学报，2012（1)：50-58.",
    "context18": "[8]陈悦，刘则渊，陈劲等．科学知识图谱的发展历程[．科学学研究，2008（3)：449－460.",
    "context19": "[9] 曹树金，吴育冰，韦景竹等：知识图谱研究的脉络、流派与趋势——基于SSCI与CSCI期刊论文的计量与可视化[．，中国图书馆学报，2015 (5)：16-34.",
    "context20": "20]赵蓉英，许丽敏．文献计量学发展演进与研究前沿的知识图谱探析[．中国图书馆学报，2010（5)：60-68.",
    "context21": "[2]许振亮，刘则渊，侯海燕．基于知识图谱的国际高等工程教育学科前沿的研究[．中国科学学与科技政策研究会学术年会.2008：74-76.",
    "context22": "[22]侯海燕．科学知识图谱：最有影响的50位科学计量学家[．科学学研究，2007（3)：404-406."
  },
  "翟倩祝琳琳吉林大学管理学院。": "",
  "(上接第35页)": {
    "context1": "[0] 冯朝胜，秦志光，袁丁．云数据安全存储技术[．计算机学报，2015（1)：150－160.",
    "context2": "[1]程勇．云存储中密文访问控制机制性能优化关键技术研究[]．长沙：国防科学技术大学，2013.",
    "context3": "B2]KatharineSartavidBroageCurentateofPlaRecodsagementandtheCudRecosaageentJoual，O（)： 225.",
    "context4": "33] PANDORA EB/O1]．016 -07-23] .http//Pandora. nla.gov.au/.",
    "context5": "B4]王萍，黄新平，张楠雪．国外Web Archive资源开发利用的途径及趋势展望[．图书馆学研究，2015（23)：43-49.  \nβ5]向菁，吴振新，孙志茹．基于Web Archive的网页重现方法及应用研究[．数字图书馆论坛，2009（7)：17-21.  \nB6] UK Web Archive [EB/Ol]．[016-07-26].htp://www. webarchive.org.uk/ukwa/.",
    "context6": "黄新平吉林大学管理学院信息管理系，博士研究生，通讯作者。",
    "context7": "王萍吉林大学管理学院信息管理系，教授，博士生导师。"
  }
}