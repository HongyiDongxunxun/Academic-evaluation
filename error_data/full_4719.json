{
  "original_filename": "full_4719.md",
  "基于语义学习的自动图像标注技术研究述评1)": {
    "context1": "张志武阚德涛（南京邮电大学图书馆，南京210003）",
    "context2": "摘要 自动图像标注技术是图像检索技术的最新发展,已经成为机器学习、图像语义理解和信息检索研究领域的热点。本文对自动图像标注目前国内外的研究概貌进行了分析，按照自动图像标注中的关键要点—语义学习的不同，将现有文献中的自动图像标注技术分为三个类别，并对这三个类别分别进行描述，同时总结了自动图像标注派生出的两个新的研究方向。最后对目前研究中存在的问题进行了讨论，并探讨了自动图像标注领域的进一步研究方向。",
    "context3": "关键词 自动图像标注图像检索语义鸿沟语义学习"
  },
  "A Review on Automatic Image Annotation Techniques Based on Semantic Learning": {
    "context1": "Zhang Zhiwu and Kan Detao",
    "context2": "(Library of Nanjing University of Posts and Telecommunications,Nanjing 210003)",
    "context3": "Abstract Automatic image annotation is a new development of image retrieval and has emerged as a hot topic in the fieldsofmachine learning，image semanticunderstandingand information retrieval.Thispaper givesanoverviewof the currentstudyonautomaticimageanotation，dividesresearchtechniquesofexisting literatures intothreecategoriesbased ondifferentsemantic learning，then deseribesthese threecategories indetails，and summaries twonewresearch directions derivedfromthisfield，inally，discussestheshortcomingsofcurentstudy,ndpredicts futureresearchdirectionsinthe automatic image annotation area.",
    "context4": "Keywords automatic image annotation， image retrieval，semantic gap，semantic learning"
  },
  "1引言": {
    "context1": "随着数码产品的普及和互联网技术的发展，越来越多的数字图像得以涌现和传播，如何快速有效地组织和检索这些海量的图像信息，已经成为学术界和工商业界迫切需要解决的问题。自20世纪70年代以来，图像检索领域展开了大量的研究，总的来说，图像检索方法的研究成果可分为三种类型：第一种方法是基于文本的图像检索（Text-Based ImageRetrieval,TBIR），图像首先被人工标注关键词，然后利用成熟的文本检索技术进行检索，但是文本描述难以充分表达图像的丰富含义，而且人工标注大量的图像是不现实的[]；第二种方法是基于内容的图像检索（Content-Based Image Retrieval,CBIR）,图像通过低层视觉特征(如颜色、形状和纹理等)进行自动索引和检索，然而，研究表明在低层视觉特征与人们用来解释图像的语义内容之间存在着巨大的“语义鸿沟”[2]；第三种方法是基于语义的图像检索（Semantic-Based ImageRetrieval,SBIR）,语义图像检索包含了人对图像内容的理解，希望计算机按照人的主观感觉和理解来索引和检索图像，是一种更合",
    "context2": "理的图像检索方式[3,4]。",
    "context3": "由于“语义鸿沟”的存在，采用低层特征进行检索并不能充分表达图像的高层语义。因此，建立图像语义表示和检索机制势在必行，解决该问题的关键就是对图像进行自动语义标注。自动图像语义标注就是让计算机自动地给无标注的图像加上能够反映图像内容的语义关键词。它利用已标记的图像样本或其他信息自动学习语义概念空间与视觉特征空间的关系模型,并用学得的模型让计算机自动地标注未知语义的图像，这在一定程度上可以解决“语义鸿沟”问题。一旦图像用语义标记标注后，图像可以用关键词检索，这类似于文本文档检索。自动图像语义标注最典型的特点是综合基于文本的标注和基于内容的图像检索的长处。",
    "context4": "自动图像语义标注是图像检索研究领域中非常具有挑战性的工作，是实现图像语义检索的关键。若能实现自动图像标注，则图像检索问题就可以转化为相当成熟的文本检索问题。自动图像标注涉及计算机视觉、机器学习、信息检索等多方面的内容，具有很大的研究价值和潜在的商业应用，如医学图像管理[5]、人脸识别[6、知识产权保护（商标检索)[7]、互联网图像广告自动投放[8]等应用。",
    "context5": "本文对基于语义学习的自动图像标注的相关内容进行了研究,通过检索式（（（\"automatic imageannotation\" or“ image automatic annotation\"）WNKY）AND（（semantic）WNKY））于2012年12月",
    "context6": "31日在Web of Science 和EiVillage2外文数据库上分别检索到 $2 0 0 0 \\sim 2 0 1 2$ 年相关文献112篇和220篇，各年度分布见图1(a)和(b)。通过检索式（（（\"自动图像标注\"or\"图像自动标注\"）WNKY）AND（（语义）WNKY)）于2012年12月31日在中国学术文献网络出版总库和维普数据库上分别检索到$2 0 0 4 \\sim 2 0 1 2$ 年相关文献79篇和10篇，各年度分布见图1的(c)和(d)。",
    "context7": "论文采用如下的组织结构：在第二部分，对自动图像语义标注的研究现状进行了总体概括；第三部分对该领域的相关研究进行了分类描述；第四部分对自动图像语义标注的派生研究进行了探讨；最后给出研究述评，对目前存在的问题和以后的研究方向给出了建议。"
  },
  "2自动图像语义标注研究的总体概貌": {
    "context1": "图像的语义标注涉及计算机视觉、人工智能、机器学习以及信息处理等多个研究领域，受到学术界的广泛关注。近几年的国际顶级学术会议以及学术期刊发表了大量关于图像语义标注的研究成果,其中,会议包括 ACM SIGIR、ACM MM、ACM CIVR、ACM MIR、ACM CIKM、IEEE CVPR、WWW、WSDM、ECCV、ECIR、ICME以及ICIP等,期刊包括IEEETPAMI、IEEE TMM、IEEE TIP、IEEE TCSVT、IJCV以及PR等。特别值得一提的是IEEETPAMI在2008 年第11期推出了以James.ZWang等为特邀编辑的专刊,专刊的主题是“Real-World ImageAnnotationand Retrieval”（真实世界的图像标注与检索）。",
    "context2": "![](images/cdbb37aea597b61c937d08d74c69d71d48013d43d26aad448ae09788cfea698c.jpg)  \n图1中外文数据库中自动图像标注研究文献的年度分布",
    "context3": "Mori等[9]在1999年提出共生模型（Co-occurrenceModel）,开辟了自动图像标注领域的研究。Duygulu等[10]提出的翻译模型,将图像的标注问题转换为从图像视觉关键词到语义关键词的翻译过程。Jeon 等[11]提出了一种交叉媒体相关模型（Cross-media Relevance Models，CMRM）,用视觉关键词与语义关键词的联合概率进行标注。Monay等[12]提出了一种基于PLSA模型的图像自动标注方法。Bamard等[13]提出了一个利用多模扩展将多个LDA模型进行融合的方法，并用该方法对图像区域和标注词的联合分布进行学习，从而获得图像的语义标注。在文献［13］的基础上，Putthividhya等[14]又提出了基于主题回归多模LDA模型的图像标注方法。",
    "context4": "Carneiro等[15]提出了一种有监督多分类图像标注模型，在图像标注过程中可以为图像进行多标签分类。Yang等[6]提出了一种基于非对称SVM的多例学习算法，利用多例学习和非对称SVM进行图像标注。路晶等[17]提出了一种基于多例学习的启发式SVM算法的图像自动标注方法。Fan等[18]采用层次分类方法进行图像的语义标注，并且在标注过程中考虑到了类别间的层次关系。",
    "context5": "卢汉清等[19]提出了一种基于图学习的图像标注框架。Pan等[20]提出了一种基于图模型的图像标注方法，将图像、图像的区域以及标注词作为图的顶点，并通过它们之间的相关度构造图。Liu等[21]对文献[20]的工作进行了扩展，提出了一种基于图学习的图像标注方法，该方法综合考虑了图像之间的关系、图像与标注词之间的关系以及标注词之间的关系，并利用流形排序将这些信息在图上进行传播，从而获得图像的语义标注。",
    "context6": "Wang等[22]开发了一个利用搜索引擎和数据挖掘进行图像标注的系统（Annosearch）。Tseng等[23]提出了一种融合图像视觉特征和相关文本信息的Web 图像标注方法。Feng等[24]对Web图像的视觉特征和文本特征分别建立两个分类器，用协同训练的方法对Web图像的标注词进行学习。Cao 等[25]提出了一种基于标签传播策略的个人相册标注方法。"
  },
  "3自动图像语义标注技术的分类": {
    "context1": "从对收集到的国内外刊物和会议上的文章分析来看，根据图像语义标注的方式来划分，目前该领域内的相关研究可以大致归纳为三种类型的自动图像语义标注技术：第一类是使用传统分类方法的单标记语义标注;第二类是使用贝叶斯方法用多个概念标注一幅图像的多标记语义标注；第三类是使用元数据标注图像的基于网络的图像语义标注。"
  },
  "3.1使用二类分类器的单标记语义标注": {
    "context1": "在这种方法中，低层特征从图像内容中抽取，这些特征直接输人到能给出“是”或“否”表决的传统的二类分类器，分类器的输出是用来进行图像标注的语义概念。常用的方法包括支持向量机（SVM）、人工神经网络（ANN)和决策树（DT）。",
    "context2": "支持向量机是一个有监督的分类器。它在高维数据分类器中是非常有效的，特别是当训练数据集很小时。一个SVM从根本上来说是个二类分类器，然而，自动图像分类和标注需要多类分类器。最普遍的做法是对每个概念训练一个单独的SVM，每个SVM各自产生一个概率值，在测试阶段，所有分类器的决策融合到一起形成一个最终的测试样本的类标记标注。Chapelle等[26]使用基本的SVM框架针对14个图像层概念训练了14个SVM分类器。Shi等[27]首先对图像使用k-均值算法进行分割,然后用23个SVM分类器进行训练得到23个区域层的语义概念。Cusano等[28]使用SVM对图像进行分割同时进行分类。Goh等[29]使用三层框架方法把图像分类到116个语义概念中的其中一个。Qi和$\\mathbf { H a n } ^ { [ 3 0 ] }$ 使用类似于Goh 的框架,但采用了不同的决策融合方法。",
    "context3": "人工神经网络是一个能够从样本中学习并能够判别一个新样本的学习网络。不同于一次只学习一个类的普通分类器，人工神经网络能一次学习多个类。一个人工神经网络由多层相互连接的结点构成，这些结点被称为神经元或感知器。因此，一个神经网络也称为多层感知器。第一层是输入层，它拥有的神经元数等于输人样本的维数。输出层的神经元数目等于类数目。Frate等[31]使用四层神经网络对卫星图像进行分类，他们使用的是两个隐藏层的神经网络，每个隐藏层包含20个神经元。Kim等[32]使用三层神经网络把图像分为目标和非目标图像。Kuroda和 Hagiwara[33]使用四个不同的三层神经网络去分层次地分类图像区域。",
    "context4": "决策树是一个多步决策制定或分类的工具。根据树中的每个内部结点上决策数目，可以把决策树分为二叉树和 $\\pmb { n }$ 叉树，决策树中的输人输出关系能够用人类理解规则(如\"如果—那么”规则)去表述。一个决策树用一个有标记的训练样本集进行训练，样本用一定数量的属性进行表示。在训练过程中，一个决策树的建立是通过递归地把训练样本划分成非重叠的多个集合，样本每次被划分时，用于分割的属性被丢弃，这一过程持续到一组中所有样本属于同一类或者当没有属性剩下用来分割时树达到它的最大深度。为了标注一个新样本，根据新样本的属性值，树从根结点遍历到叶子结点。样本的决策是样本所到达的叶子结点的输出。一些决策树算法在文献中提出，包括 $\\mathbf { I D 3 } ^ { [ 3 4 ] }$ 、 $\\mathbf { C 4 } . 5 ^ { [ 3 5 ] }$ 和CART[36]。这些决策树算法的不同在于属性类型、属性选择准则和输出等方面。Sethi和Coman[37]使用CART把户外图像分成四类。Wong和Leung[38]使用DT算法把场景图像分成10类。不同于用于分类的单一决策树，Maree等[39]使用组合多个决策树进行图像标注和分类。",
    "context5": "在单标记语义标注方法中，一旦图像被划分到不同的种类，每个种类都标注上一个概念标记，如飞机、哺乳动物、建筑物等。图像种类的检索是直接通过输入概念标记相对应的关键词，这种方法的好处在于这种检索是有效的，因为没有必要像其他图像检索方法那样去做图像索引和费时的在线匹配。这种方法的不足之处在于它没有考虑到许多图像属于多个种类的事实。结果,如果使用者没有输人完全正确的关键词，许多相关图像就从检索结果中丢失。一种解决这种问题的方法是用在种类里反应不同主题的多个关键词去标记每一个种类。单标记语义标注的另外一个问题是每一个种类里的图像是不连接的，这导致检索准确度的降低。"
  },
  "3.2使用贝叶斯方法的多标记语义标注": {
    "context1": "不同于上节中的二类分类器方法，多标记方法用多个语义概念或种类去标注一幅图像。多标记方法的概念与多实例学习有关，或者更具体地说与多实例多标记学习有关。在多实例多标记中，一幅图像用一个特征包或者区域包(多实例)去表示，如果包中任何一个区域或实例与标记有关，图像就用这个概念标记去标注。结果，一幅图像就用多个标记标注。一个典型的多实例多标记是使用类似于贝叶斯方法的概率工具。贝叶斯方法是在图像或区域的一定特征的观测值给定情况下，寻找一幅图像属于任何一个特定概念的后验概率。这使得指派一幅图像到多个概念和根据概率排列同一概念的多幅图像成为可能。给定一个来自于给定语义类集合 $\\left\\{ \\mathbf { c } _ { 1 } \\right.$ ，$c _ { 2 } , \\cdots , c _ { n } \\}$ 的图像集 $\\{ I _ { 1 } , I _ { 2 } , \\cdots , I _ { N } \\}$ ,贝叶斯模型试图从条件概率和先验概率中决定后验概率。假设，一幅图像 $\\pmb { I }$ 是用特征向量 $X$ 表示，给定先验概率 $\\pmb { p } ( \\pmb { c } _ { i } )$ 和条件概率密度 $p ( { \\pmb X } \\vert { \\pmb c } _ { i } )$ ，一幅未知图像 $\\pmb { I }$ 属于类 $\\pmb { c } _ { i }$ 的概率由(1)式决定：",
    "context2": "$$\np \\big ( c _ { i } | X \\big ) = \\frac { p \\big ( X | c _ { i } \\big ) p \\big ( c _ { i } \\big ) } { p \\big ( X \\big ) }\n$$",
    "context3": "从(1)式中可以看出，一个贝叶斯框架本质上  \n由四部分组成：一个输出项 $p \\left( \\boldsymbol { c } _ { i } \\left[ \\boldsymbol { X } \\right) \\right.$ 和三个输入项：  \n$p ( c _ { i } ) \\lrcorner p ( X \\mid c _ { i } )$ 和 $p ( X )$ 。因为 $p ( X )$ 的分布对于所  \n有类通常是一致的，图像 $\\pmb { I }$ 的类别可以使用最大后  \n验概率准则求得：/",
    "context4": "$$\n{ \\hat { c } } = \\arg \\operatorname* { m a x } _ { c _ { i } } p \\left( c _ { i } | X \\right) \\approx \\arg \\operatorname* { m a x } _ { c _ { i } } { \\{ p \\left( X | c _ { i } \\right) p \\left( c _ { i } \\right) \\} }\n$$",
    "context5": "贝叶斯标注的关键部分是建立条件概率模型，因为先验概率 $\\pmb { p } ( \\pmb { c } _ { i } )$ 能够通过计算样本属于第 $c _ { i }$ 概念的频率来求得，贝叶斯模型是根据如何建模条件概率 $p ( { \\cal X } | c _ { i } )$ 的不同而变化的。通常有两种类型的方法建模条件概率一一无参方法和参数方法。",
    "context6": "在无参方法中，条件概率是在没有任何图像特征分布先验假设条件下计算得到的。当然，实际的特征分布是从使用确定统计的训练样本的特征中学到的。在实际中，图像特征首先运用某一聚类算法量化到聚类中，接着，连续特征被聚类质心所替代，这一处理离散了图像特征空间，每一个类的条件概率通过寻找样本属于该类的频率而求得。Vailaya等[40]使用这个模型对图像进行分类标注，替代图像分割，他们直接聚类全局图像特征进行计算条件概率。Mori等[41]对训练图像分块,然后对分块进行聚类，每一个块继承其源图像的所有标注，每一个聚类是包含在它之中的所有块的语义概念的集合。Duygulu等[10]提出的翻译模型，通过学习方法标记聚类，区域于是就能用与它们最近的聚类进行标注。Jeon 等[11]提出了一种交叉媒体相关模型（CMRM），指派关键词到整个图像而不是特定的块，用视觉关键词与语义关键词的联合概率进行标注。Yavlinsky等[42]使用传统核平滑技术学习一个实际特征分布的估计。",
    "context7": "在参数方法中，假设特征空间遵循某一已知的连续分布，因此，条件概率 $p \\left( \\pmb { X } \\mid \\pmb { c } \\right)$ 是用它的特征分布进行建模的,特征或区域首先进行聚类和量化，接着每一个聚类(或块)的条件概率模型被建立，这个条件概率 $p ( X \\vert c )$ 通常被建模成一个多元高斯分布。Yang等[43]使用多元高斯分布建模条件概率。Li和$\\widetilde { \\mathbf { W } } \\mathbf { a n g } ^ { [ 4 4 ] }$ 首先把每一个概念中的训练图像分解成用LUV颜色和小波纹理特征表示的区域，然后把这些区域聚类到称为原型的簇中，对每一个原型,学得一个高斯模型，最后，一个混合高斯模型（GMM)就建立起来。Carmeiro等[15]假设图像特征符合一定的高斯分布，使用期望值最大化算法(EM)在一个概念内对每个训练图像直接学习一个GMM。",
    "context8": "在多标记语义标注中，一旦模型学得，标注过程就相当类似于基于内容的传统图像检索中的在线匹配和排序。因此,每次使用者输入一个关键词，为了测试相对于关键词的所有图像，整个标注过程在线不断重复,并且有可能花费很长时间。替代做法是，数据库中的图像采用离线标注，然后用反向文件索引，图像于是就可以像文本文件一样检索。然而，在每种情况下，都使用费时的在线匹配,这是与单标记语义标注相比一个主要的缺点。"
  },
  "3.3合并元数据的图像语义标注": {
    "context1": "万维网是影像和文本信息的丰富来源，网页图像通常伴有文本描述、URL和HTML代码等，这些信息可用于图像标注和检索[45]。一些网页图像标注技术相继提出，其中大部分是结合元数据和视觉特征来进行精确的图像语义标注[46.47]。因此,这些方法被称为混合方法。",
    "context2": "Cai等[46]提出了一个两层标注和聚类机制：语义标注的文本聚类和每个语义种类内的图像重组的视觉聚类。网页图像首先用三个类型的特征表示：文本特征（来自周围的文本）、连接图（来源于三个复杂的超链接矩阵)和视觉特征(来源于局部傅里叶变换的色矩）。文本特征和连接图用来把图像聚类到语义种类，这等同于标注。然而，每个语义种类里的图像可能不是视觉上相似。因此，他们在每个语义种类上使用一个基于视觉特征的第二层聚类去重组图像到聚类中。这种方法的主要问题是文本特征特别是连接图特征不可靠，正像现有的图像搜索引擎中出现的情况一样。Wang等[22]提出了一个基于搜索和数据挖掘技术的Web图像语义自动标注系统，由两步来完成，首先在网络上搜索语义和视觉上相似的图像;第二步在一个有准确标注的语义类似的图像的基础上进行基于内容的图像检索，挖掘周围的关联文本信息标注图像。但该系统要求至少一个准确的初始关键词作为种子来执行基于文本的图像搜索，如果没有初始关键词或初始关键词不正确，标注的性能将大大降低。许红涛等[48]综合考虑了Web图像的视觉特征和关联文本对预测图像语义的贡献，通过带约束的分段惩罚加权回归模型将关联文本权重分布估计和先验知识约束有机地结合在一起，自适应地对图像语义在其关联文本上的分布进行建模。Lu等[49]提出一个建模语义鸿沟并按照增长的语义鸿沟排列候选标记词集合的系统。他们利用网页图像开发了一个基于语义鸿沟的词典（标注单词或概念)分类目录，并且首次基于网页图像文本和视觉相似性进行一个筛选的网页图像的聚类，每个聚类的可用单词按照文本排列技术进行排列，所有聚类中的单词的排序是融合到一起形成最终的排序。已有的标注方法能够使用这个排序去决定哪些概念应该学习，因为目录中排序靠前的单词比靠后的单词更容易学习。",
    "context3": "从文本描述中进行图像标注可能有噪声，这些标注需要精炼，这是基于网页的图像标注的特殊需求，因为每幅图像通常用可能彼此不相关的多个关键词进行标注。在精炼阶段，保留强相关的标注，去掉那些彼此弱相关的标注。另外一个重要的问题是定义恰当的语义层，这在网页图像应用中特别重要，因为网页文本中的噪声是普遍的而且那些应该使用的标注难以理解。例如,对于一个含有袋鼠的图像，概念“澳大利亚”就比“袋鼠\"更抽象。"
  },
  "4图像标注的派生研究": {
    "context1": "通过图像的自动标注来实现图像的语义学习已成为当前的研究热点与重点。随着许多图像标注算法的相继提出，图像标注工作已经取得了很大的进展，但标注性能还无法达到令人满意的程度。针对这一现状，自动图像标注派生出两个新的研究方向：图像标注改善（Image Annotation Refinement）和基于 Search的标注算法。"
  },
  "4.1图像标注改善": {
    "context1": "图像标注改善是指利用已有的图像标注方法获得候选标注词集，去掉其中的噪声词并填补上可能遗漏的词汇，将改进后的标注词作为图像标注改善的结果，从而保证最终的标注结果具有良好的语义一致性[21]。在基本图像标注阶段得到的候选标注信息可能是不完整的，或者包含了一些与图像不相关的标注信息。这主要是由于现有的标注算法将每个语义关键词单独分析，并没有考虑到关键词之间的语义关联。而通常情况下，词汇与词汇之间的语义联系还是非常紧密的，通常词汇间包括层次关系和相关性信息。例如“老虎”和“草地”两个词的语义联系比较紧密，当一幅图像标有关键词“老虎”时，其标有“草地”的概率也相应提高。因此利用词汇与词汇之间的相互关系，从候选词汇中挑选出紧密相关的词汇，滤除那些无关的噪声词汇，是改善图像标注性能的重要手段之一。",
    "context2": "Jin等[50]最早提出利用基于知识的词汇网络（WordNet)来进行图像标注改善。词汇网络是一个超过15万个单词按层次组织的在线词典，词汇网络中的单词保持着“是某某的一种\"或“是某某的一部分”关系，这种关系用来挖掘单词之间的相似性。在相对较小的候选标注词集中，可以通过计算基于WordNet的语义距离去除不相关的标注。该算法能够保留彼此高度相关的标注，与其他候选标注不相关的标注则被去除。该算法主要有两点不足： $\\textcircled{1}$ 尽管WordNet包含词与词之间的关联信息，但它的局限是它与图像内容不相关，无法反映图像的视觉信息，同时，它不能处理WordNet中不存在的词； $\\textcircled{2}$ 旦候选标注词确定了，图像标注改善过程将与待标注图像无关。此方法仅考虑候选标注间的语义关系,因此,当候选标注词集中噪声词过多时该方法并不适用。",
    "context3": "Wang等[51]提出了一个基于RWR（RandomWalkwithRestarts）的图像标注改善算法,试图解决文献[50]的问题。该算法不仅用到了特定图像库的信息，而且利用了原始图像标注的排序和置信度信息。然而，尽管基于RWR的图像标注改善方法解决了文献[50]中的第一个问题，但是整个标注改善过程仍与待标注图像无关，因此该算法的性能对候选标注词集的规模非常敏感。当候选标注集很小时，进行标注改善得意义不大；而如果候选标注集很大，则最终标注结果中可能会有较多的噪声词。",
    "context4": "随后，Wang等[52]对图像标注改善问题又做了进一步的工作,对于一个待标注图像,首先用已有的图像标注方法产生一组候选标注，然后用图像标注改善算法对这些候选标注进行重排序，并保留排序位次高的标注词。他把图像标注改善过程表示成一个马尔可夫过程，并把候选标注定义成马尔可夫链的不同状态。为了解决文献［50]和文献［51]中的问题，文献[52]利用待标注图像的视觉特征和图像库的信息，动态地建立一个具有“待标注图像相关的转移矩阵”的“待标注图像相关的马尔可夫链”。该方法不仅解决了前面提到的文献[50]中的第一个问题,也在一定程度上解决了文献[50]中的第二个问题。",
    "context5": "Jin 等[53,54]又提出了一个基于知识和图算法的图像标注改善方法。该方法的核心是将图像标注改善问题转化为图的分割问题，用候选标注词及其语义关系构造带权图，用最大割算法将图的顶点分为两部分，选择其一作为最终标注结果。该方法主要存在两点不足： $\\textcircled{1}$ 标注改善过程没有考虑图像的视觉特征信息； $\\textcircled{2}$ 从最大割算法得到的两个标注词集合中选择其一的策略不够合理，存在误选的可能性。"
  },
  "4.2基于Search的自动图像标注算法": {
    "context1": "基于Search的图像标注算法通过有效地融合基于内容的图像检索技术，将未标注的图像看作是查询图像，根据检索技术找到查询图像的一些相关图像集合，然后从相关图像的标注词的集合中，应用文本分析技术挖掘出标注结果。",
    "context2": "Wang等[22,55]提出了一种基于Search的图像标注算法，该算法属于一种数据驱动且与模型无关的标注算法。文献[22]提出融合检索技术进行标注的方法，即AnnoSearch方法，算法首先将未标注图像作为查询图像，由用户给查询图像提供一个初始的标注词；然后，根据基于文本的图像检索技术，在Web中检索到与查询图像相关的图像集合，同时也得到一个相关图像的标注词集合;最后，对这个标注词集合进行聚类，给出相关标注词的排序列表，从中决定查询图像的标注结果。该方法的检索精度依赖于用户提供的初始标注词,因此，在一定程度增加了用户的负担，而且还具有用户的主观性。为了简化标注过程，文献[55]改进了文献[22]的工作，该方法无须用户提供初始标注词，实现了检索与标注的全自动化。基于Search的标注方法避免了复杂的参数学习的过程。而且，由于通过检索找到相关的图像，因此该方法不受训练集或者标注词集合的限制[56] 。"
  },
  "5研究述评": "",
  "自动图像语义标注是实现图像语义检索的关": {
    "context1": "键，它是一个多学科交叉的研究课题，从现有的论文来看，虽然已经有大量相关研究，但这是一个非常有挑战的领域，距离实际应用还有很长的路程。论文旨在分析现有的关于自动图像语义标注的相关研究，在前人研究的基础上归纳出现有研究的分类和相关焦点问题，提出现有研究中的不足和研究发展趋势，给以后的研究提供一些参考。论文对自动图像语义标注目前国内外的研究现状进行了分析，描述了现有的文献中的三个研究种类，并总结了自动图像语义标注派生出的两个新的研究方向。",
    "context2": "从上面的讨论可以看到，自动图像语义标注的相关课题国内外已经有很多学者进行了研究，但相对于基于文本和基于内容的图像检索中的关键技术而言，自动图像语义标注这种图像语义检索发展趋势中的关键技术，还缺乏统一的标准和体系，要达到自动图像语义精确标注，现有的研究水平显然是不够的，还有很多需要改进的地方：",
    "context3": "(1)高维特征分析问题。由于“维数灾难”的原因，当特征维数非常高时，自动标注的性能显著下降。因此,特征需要进一步挖掘以选择正确的特征数目和正确的标注特征。最近的子空间研究进展有望在这点上提供解决方案。",
    "context4": "(2)怎么去建立一个有效的标注模型。多数已有的自动图像语义标注模型是从低层图像特征中学得的，当样本图像的数目还不足以训练一个准确的模型时，应该运用文本信息或者元数据以求提高标注的准确性。然而，通常元数据既不准确又不充足。如何融合低层视觉信息和高层文本信息到一个连贯的标注模型中是一个有挑战性的问题。前面提到的一些混合的标注方法可以提供一些解决这一问题的线索。",
    "context5": "(3)在多标记语义标注方法中当前的标注和排序是同时在线完成，这对图像检索来说不是高效的。取代的做法是像单标记方法那样离线标注，从标注中分离排序，即图像首先用一个概念或种类进行离线标注，排序是在标注后的离线操作。一旦图像是离线标注和排序，检索就是瞬间的。",
    "context6": "(4)为了提高检索准确性，怎么样在单标记技术中产生的每个种类中排列图像。由于每个种类里的图像表现出一定的分布模式，一个遵循最大后验概率排序的高斯混合模型给出了一个实际的解决办法。",
    "context7": "(5)缺少标准的标注词汇表和分类系统。在这种情况下，任意的词汇表被用于自动图像标注，所以不知道图像应该怎样去归类。我们需要一个图像语义分级模型去正确地归类图像。一个分级的分类系统不仅标准化标注词汇表，而且允许更现实的逐步标注。",
    "context8": "(6)没有一个普遍可接受的图像数据库用以自动开展图像语义标注训练和评价。所有的自动图像语义标注方法需要大量的预标记的图像样本用来训练模型。在这种情形下，不同的自动图像语义标注方法使用不同的图像库进行训练和评价，使得很难去对比它们的性能。数据库问题直接与分类系统问题有关。如果一个标准的图像语义分类系统可用，一个标准的数据库可以相应地被创建。",
    "context9": "上面所有的问题指出自动图像语义标注领域未来研究方向，必将成为计算机视觉、人工智能和情报信息检索领域学者研究的热点。"
  },
  "参考文献": {
    "context1": "[1]Tamura H,Yokoya N. Image database systems:A survey [J]．Pattern recognition，1984，17(1）：29-43.   \n[2] Jain A K，Vailaya A．Image retrieval using color and shape[J].Pattern recognition,1996,29(8）：1233-1244.   \n[3] 张玉峰,蔡昌许.基于语义的图像检索系统研究［J]. 中国图书馆学报，2004,30(5）:66-69.   \n[4] Zhang D，Islam M M，Lu G.A review on automatic image annotation techniques [J]. Pattern Recognition, 2012,45(1):346-362.   \n[5] Tommasi T,Orabona F,Caputo B.Discriminative cue integration for medical image annotation［J]．Pattern Recognition Letters，2008，29(15）：1996-2002.   \n[6] Fang Y,Geman D,Boujemaa N. An interactive system for mental face retrieval［C]//Proceedings of the 7th ACM SIGMM international workshop on Multimedia information retrieval.ACM,2005：193-200.   \n[7] 张学福，冷伏海．商标数据库信息检索技术研究［J]. 情报学报，1999,18(5）：404-410.   \n[8] 玉凤.图像检索中自动标注技术的研究[D].北京： 北京交通大学,2009.   \n[9] MoriY,Takahashi H,Oka R.Image-to-word transformation based on dividing and vector quantizing images with words [C]//First International Workshop on Multimedia Intelligent Storage and Retrieval Management.1999.   \n[10] Duygulu P,Barnard K,de Freitas JFG,et al.Object recognition as machine translation：Learning a lexicon fora fixed image vocabulary[M]//Computer VisionECCV 2002.Springer Berlin Heidelberg,2006：97-112.   \n[11]Jeon J,Lavrenko V,Manmatha R.Automatic image annotation and retrieval using cross-media relevance models[C]// Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval．ACM,2003：119-126.   \n[12] Monay F,Gatica-Perez D.Plsa-based image auto-annotation: constraining the latent space[C]//Proceedings of the 12th annual ACM international conference on Multimedia. ACM,2004:348-351.   \n[13] Barnard K,Duygulu P,Forsyth D,et al. Matching words and pictures[J].The Journal of Machine Learning Research，2003，3：1107-1135.   \n[14] Putthividhy D,Attias HT,Nagarajan S S.Topic regression multi-modallatentdirichletalocatonforimage annotation[ C ]//ComputerVisionandPattern Recognition（CVPR），2010 IEEE Conferenceon. IEEE,2010:3408-3415.   \n[15] Carneiro G,Chan A B，Moreno P J,et al. Supervised learning of semantic classes for image annotation and retrievalJ].Patt AalysisdMacineIeligece IEEE Transactions on,2007,29(3）：394-410.   \n[16]Yang C,Dong M,Hua J.Region-based image annotation usingasymmetrical support vectormachine-based multiple-instance learning[C]//Computer Vision and Patterm Recognition，2006 IEEE Computer Society Conference on. IEEE,2006,2:2057-2063.   \n[17] 路晶，马少平．使用基于多例学习的启发式 SVM 算 法的图像自动标注[J]．计算机研究与发展，2009， 46(5) : 864-871.   \n[18] Fan J,Gao Y,Luo H.Hierarchical classification for automatic image annotation [C]//Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. ACM,2007:111-118.   \n[19] 卢汉清，刘静．基于图学习的自动图像标注[J]．计 算机学报,2008,31(9)：1629-1639.   \n[20] Pan JY，Yang H J,Faloutsos C，et al. Automatic multimedia cross-modal correlation discovery $[ \\textbf { C } ] / /$ Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM,2004: 653-658.   \n[21]Liu J,Li M,Liu Q,et al. Image annotation via graph learning[J].Pattern Recognition，2009,42（2）: 218-228.   \n[22] Wang X J, Zhang L, Jing F, et al. Annosearch: Image auto-annotation by search [C]//Computer Vision and Pattern Recognition，2006 IEEE Computer Society Conference on.IEEE,2006,2:1483-1490.   \n[23] Tseng V S, Su JH, Wang B W,et al. Web image annatatinn hu fiaing viaal faatrae and tavtial information[C]//Proceedingsof the 2007ACM symposium on Applied computing. ACM，2007: 1056-1060.   \n[24] Feng H，Shi R,Chua T S.A bootstrapping framework for annotating and retrieving WWW images $[ \\textbf { C } ] / /$ Proceedings of the 12th annual ACM international conference on Multimedia.ACM,2004：960-967.   \n[25]Cao L, Luo J, Huang T S. Annotating photo colections by label propagation according to multiple similarity cues [C]//Proceedings of the 16th ACM international conference on Multimedia.ACM,2008：121-130.   \n[26] Chapelle O,Haffner P，Vapnik V N. Support vector machines for histogram-based image classification[J]. Neural Networks,IEEE Transactions on,1999,10(5）: 1055-1064.   \n[27] Shi R，Feng H, Chua T S,et al. An adaptive image content representation and segmentation approach to automatic image annotation [M]//Image and Video Retrieval． Springer Berlin Heidelberg，2004：545-554.   \n[28] Cusano C,Ciocca G,Schettini R.Image annotation using SVM[C]//Electronic Imaging 2004．International Society for Optics and Photonics,2003：330-338.   \n[29] Goh K S,Chang EY,Li B.Using one-class and twoclass SVMs for multiclass image annotation [J]. Knowledge and Data Engineering， IEEE Transactions on,2005,17(10):1333-1346.   \n[30] QiX,Han Y.Incorporating multiple SVMs for automatic image annotation[J]．Pattern Recognition，2007，40 (2): 728-741.   \n[31] Del Frate F,Pacifici F,Schiavon G,et al. Use of neural networks for automatic classification from high-resolution images[J].Geoscience and Remote Sensing，IEEE Transactions on,2007,45(4）:800-809.   \n[32] Kim S,Park S,Kim M. Image classification into object/ non-object classes[M]//Image and Video Retrieval. Springer Berlin Heidelberg,2004；393-400.   \n[33] Kuroda K, Hagiwara M. An image retrieval system by impression words and specific object names-IRIS [J]. Neurocomputing,2002,43（1）：259-276.   \n[34] Quinlan JR.Induction of decision trees[J]．Machine Learning,1986,1(1): 81-106.   \n[35] Quinlan JR. C4.5：programs for machine learning [M].Morgan kaufmann,1993.   \n[36] Breiman L,Friedman J,Ohlsew R,et al. Classification and Regression Trees[ M]. Chapman & Hall,California, USA,1984.   \n[37]Sethi IK,Coman IL, Stan D. Mining association rules hetween low-level image features and high-level concents",
    "context2": "[J]．Proceedings of the SPIE Data Mining and",
    "context3": "Knowledge Discovery，2001,3：279-290.   \n[38]．Wong R C F,Leung C H C.Automatic semantic annotation of real-world web images[J]．Pattern Analysis and Machine Intelligence, IEEE Transactions on， 2008，30 (11):1933-1944.   \n[39] Maree R,Geurts P,Piater J,et al. Random subwindows for robust image classification [C]//Computer Vision and Pattern Recognition，2005．CVPR 2005．IEEE Computer Society Conference on.IEEE,2005,1:34-40.   \n[40] Vailaya A,Figueiredo M A T,Jain A K,et al. Image classification for content-based indexing [J].Image Processing,IEEE Transactions on,2001,10(1）:117-130.   \n[41] Mori Y,Takahashi H,Oka R.Image-to-word transformation based on dividing and vector quantizing images with words[C]//First International Workshop on Multimedia Intelligent Storage and Retrieval Management. 1999.   \n[42] Yavlinsky A，Schofield E，Ruger S. Automated image annotation using global features and robust nonparametric density estimation[M]//Image and video retrieval. Springer Berlin Heidelberg，2005：507-517.   \n[43] Yang C，Dong M,Fotouhi F. Image content annotation using Bayesian framework and complement components analysis[C]//Image Processing，2005．ICIP 2005. IEEE International Conference on．IEEE,2005,1：I1193-6.   \n[44] Li J，Wang JZ. Real-time computerized annotation of pictures[J].Pattern Analysis and Machine Intellgence, IEEE Transactions on,2008,30(6):985-1002.   \n[45] 熊回香．Internet上的图像信息检索技术［J].情报学 报,2005,24(2):222-227.   \n[46] Cai D,He X,Li Z,et al．Hierarchical clustering of WWW image search results using visual, textual and link information[C]//Proceedings of the 12th annual ACM international conference on Multimedia. ACM, 2004:952-959.   \n[47] Jing F，Wang C,Yao Y,et al. IGroup:web image search results clustering[C]//Proceedings of the 14th annual ACM international conference on Multimedia. ACM，2006:377-384.   \n[48] 许红涛,周向东,向宇,等.一种自适应的Web图像语 义自动标注方法[J].软件学报，2010,21（9）： 2183-2194.   \n[49] LuY,ZhangL,Tian Q,etal.What are the high-level concepts with small semantic gaps?[C]//Computer Vision and Pattern Recognition，2008．CVPR 2008. IEEE Conference on. IEEE,2008：1-8.   \n[50] Jin Y，Khan L，Wang L,et al. Image annotations by combining multiple evidence and Wordnet $[ \\textbf { C } ] / /$ Proceedings of thel3th annual ACM international conference on Multimedia, 2005:706-715.   \n[51] Wang C, Jing F,Zhang L，et al. Image annotation refinement using random walk with restarts [C]// Proceedings of the 14th annual ACM international conference on Multimedia.ACM,2006：647-650.   \n[52] Wang C, Jing F, Zhang L,et al. Content-based image annotation refinement [C ]//Computer Visionand Pattern Recognition,2007.CVPR07.IEEE Conference on．IEEE,2007:1-8.   \n[53] Jin Y,Jin K,Khan L,et al.The randomized approximating graph algorithm for image annotation refinement problem [C]//Computer Vision and PatternRecognition Workshops,2008.CVPRW'O8．IEEE Computer Society Conference on. IEEE,2008：1-8.   \n[54] Jin Y,Khan L,Prabhakaran B. Knowledge based image annotation refinement[J]. Journal of Signal Processing Systems,2010,58(3):387-406.   \n[55] Wang X J,Zhang L,Li X,et al. Annotating images by mining image search results[J]．Pattern Analysis and Machine Intelligence, IEEE Transactions on,2008, 30(11):1919-1932.   \n[56] 鲍泓,徐光美，冯松鹤，等.自动图像标注技术研究进 展［J].计算机科学,2011,38(7）：35-40."
  }
}