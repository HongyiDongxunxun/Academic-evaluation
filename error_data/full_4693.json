{
  "original_filename": "full_4693.md",
  "基于综述型文献的跨学科领域信息源地图绘制": {
    "context1": "The Mapping of Interdisciplinary Information Sources Based on Literature Reviews",
    "context2": "代君」李佶壕²秦岩’王文欣(.武汉大学信息管理学院,武汉,430072；2.平安普惠企业管理有限公司,深圳,518000)",
    "context3": "[摘要］本文研究了基于综述型文献的跨学科领域信息源信息抽取、聚合与可视化方法，结合实例从高质量的综述型文献中抽取信息源信息,构建了机器学习\"跨学科领域信息源地图。首先,在对搜集文献预处理的基础上,识别篇章关系，构建辅助词典使用词典及辅助词典进行分词、完成实体识别和词性标注等工作结合一定的语法逻辑规则,实现句子级的抽取和信息源数据抽取对多篇文献中相同信息源信息进行整合最后，利用D3工具绘制信息源地图，从时间和来源两个维度对跨学科领域高价值信息源进行导航。实验证明上述方法取得了较好的效果，信息抽取的查全率和查准率较高，有助于跨学科领域科研人员快速了解领域发展过程、高价值信息源、涉及学科及不同学科的研究方向特征。",
    "context4": "［关键词］跨学科信息源地图综述型文献信息抽取实体识别可视化[中图分类号] $\\mathtt { G 2 5 0 . 2 }$ [文献标识码］A [文章编号]1003-2797 &018)06-0061-14 DOl:10.13366/.dik.2018.06.061",
    "context5": "Abstract]Thisstudyinvestigates themethodsof extracting，aggregating and visualizing interdisciplinary information sources basedonliterature reviews，and theinformation source map inthe interdisciplinary domain of machine leaming”has benbuiltbytakingthe information-source informationfromhighqualityliterature.Firstly,textpreprocessing wascarriedout onthecollectedliteratures;secondly,theauxiliarydictionaryhasbeenconstructedonthebasisofrecognizingthecontextrelationship，thewordsegmentation has beenfinishedbyusing dictionariesandauxliarydictionaries，andtheentityrecognition andpartofspeech taging have beencompleted.According totheresult ofentityrecognition andrulesof syntax logic，sentenceextractionandinformationsourcedataextractionhave beenachieved;Moreover,informationfromthesame information sourcein multiplearticles has been integrated.Finall,themapof informationsourcehas beenaccomplishedbyusing D3 tool fromthedimensionsof imeand source.Experiments indicate that this methodcould leadtogoodresults with highrecall and precisionratio，whichishelpfulfor interdisciplinaryresearcherstoquicklymasterthedevelopingprocessofthefield,thehigh value information source and the characteristics of research of direction different disciplines.",
    "context6": "Keywords]Interdisciplinary；Informationsource map；Literaturereviews ;Information extraction;Entityidentification； Visualization",
    "context7": "跨学科”(nterdisciplinary)的概念最早由美国心理学家R.S.Woodworth于1926 年在美国社会科学研究理事会的学会上使用，用以表示超越一个已知学科的边界而进行的涉及两个或两个以上学科的研究领域。数字图书馆技术的发展使得科研人员获取文献越来越便捷，但如何快速找到跨学科研究所需要的广泛而优质的资源依然十分困难。目前有不少专业人员使用科学大数据、文献计量方法和可视化工具来从事这些研究,而大量从事跨学科研究的人员并不具备这样的信息素养和能力。通常情况下，他们以文献计量文章和综述型文献为获取信息源的最佳捷径。但由于目前这类文献分布分散,要搜集、筛选、整合这些文献中的信息源所需要的工作量很大。如何利用技术将大量的高质量综述型文献中的信息源及相应的评价内容抽取出来,绘制成信息源地图，为相关研究人员提供信息源导航，是一项具有很强理论意义和实践价值的研究。",
    "context8": "本文拟采用文本信息抽取和可视化技术研究综述型文献信息源地图绘制的思路、步骤、方法，并结合实例验证方法的有效性。"
  },
  "1研究综述": "",
  "1.1信息抽取": {
    "context1": "信息抽取是从自然语言中提取指定类型的实体、关系、事件等信息，并将其结构化呈现的一种处理文本的技术。本文中的信息抽取是从综述型文献中抽取提及到的信息源信息，并将其结果转变为结构化的数据格式输出。其核心内容包括实体识别、指代消解、关系抽取、事件抽取等方面,目前国内外信息抽取领域和研究也基本集中在这些方面。",
    "context2": "早期的命名实体识别的主要目的是识别出自然语言文本中的人名、地名等专有名词和有价值的时间、日期等数词短语并加以标记。随着人们对这些名词进行更细致的划分，对特定领域的命名实体进行识别也较为普遍。文献5针对军事领域,提出了使用条件随机场与规则相结合的方式对军事命名实体进行识别文献6针对社交媒体文本中存在大量的电影、歌曲等，提出使用统计模型隐马尔可夫模型和规则相结合的方式对歌手名、歌曲名、专辑名进行实体识别这献]针对生物医学领域,提出基于FCG 的半监督方法结合CRF自动识别文献中的药物名称。",
    "context3": "指代消解的目的是简化、统一实体的表述方式，并提高信息抽取结果的精确度。2011年,Raghunathan 等人提出了一种基于多次筛选的指代消解方法。2007年,周俊生等采用基于图的方法对指代消解问题进行建模，将共指消解的过程转变为图的分割过程，提出了一种有效的无监督中文共指消解方法。",
    "context4": "关系抽取 Relation Extraction)首次于 1998 年在MUC-7会议上被提出，主要任务是确定两个实体之间的语义关系。目前关系抽取技术已经被广泛应用到疾病-基因－药物关系挖掘[0]、蛋白质交互关系等众多应用领域。",
    "context5": "事件抽取是从非结构化的信息中识别并提取出用户感兴趣的事件，并以结构化的形式呈现给用户，可分为元事件抽取和主题事件抽取。目前事件抽取技术应用于生命医学领域的事件抽取系统的研发[2]和事件类别的识别等[3]。",
    "context6": "总体而言，目前对于信息抽取的研究已经有了很大的进展,但在中文篇章处理、跨语言处理等方面还有较大的提升空间。同时,主题事件抽取与面向开放文本的信息抽取也逐渐成为研究的重点，这也是信息抽取领域未来的理论发展方向。"
  },
  "1.2信息源地图": {
    "context1": "本文利用信息抽取方法从综述型文献中抽取信息源实体信息，再对信息源实体信息进行可视化处理,绘制成的图谱即为跨学科领域信息源地图。",
    "context2": "信息源地图可以看作是以信息源为主题的主题地图,其具体构建实际上是对信息源数据进行的可视化操作,主要参考主题地图领域和信息可视化领域的相关理论和技术。",
    "context3": "主题地图是一套用来整合信息的方法，使用这种方法可以提供最佳的信息资源导航，它既可以定位知识概念的资源位置，也可以描述知识概念之间的关系[4]。国际上已经有了很多成熟的主题地图工具，主要分为三大类型：主题地图引擎、主题地图编辑器以及可视化工具i5]。比较突出的有开源主题图引擎TM4J（opic Maps for Java)和 Ontopia 公司开发的主题图工具OKS Samples。此外,刘洪星等{]提出用主题地图的方法来实现某一领域的知识管理,例如通过提取软件工程领域的知识概念实体进行主题地图的编码与构建。",
    "context4": "信息可视化是将数据信息转化为可视情况的过程,可以增强信息呈现的效果，让用户以直观交互的方式实现对数据的观察和阅览，从而发现数据中潜藏的特征、关系和模式]。可视化数据分为7类：一维、二维、三维、时间序列、多维、树形、以及网络数据[8]，目前国内外研究的热点是对于后4类数据的可视化。1985年Inselberg[9最早利用平行坐标系法用来处理可视化的问题。Bertini等开发的SpringView&o]整合了放射坐标系法和平行坐标系法，将每个坐标轴扩展到星形图空间中，便于数据比较和交互，以此来解决高维数据问题。",
    "context5": "总体而言，国内在主题地图方面的研究较为成熟，而在信息可视化方面的研究与国外还有较大差距。"
  },
  "2面向综述型文献的信息源信息抽取": "",
  "2.1综述型文献写作特点": {
    "context1": "综述型文献在三种按体裁划分的科技期刊发表的论文中,文献数量仅次于首位的研究型文献。它主要是从各个角度对某一学科领域一段时间以来的研究成果进行梳理和归纳，分析该领域的研究现状及未来的发展趋势，其中包含了大量对于该领域内高质量信息源的描述。另外,综述型文献不仅有着科技文献共有的特点用词严谨,少有歧义,少用修辞,同时在行文逻辑、篇章结构、语义模式等方面也有着明显的标准化特征。其篇章行文结构大致为对研究现状的简要总结、对研究现状的具体阐述、对发展趋势的归纳分析。",
    "context2": "较之于其他一般学科领域,跨学科领域的综述型文献具有以下特点 $\\textcircled{1}$ 结构化程度更弱一些。为了追根溯源,跨学科领域综述型文献在陈述学科领域发展历史方面落墨较多，有关研究主题、研究团队以及传播渠道等的描述都可能掺杂在其中，一些细枝末节和关键节点信息也可能混在一起。 $\\textcircled{2}$ 跨学科领域的综述型文献对有关学科交叉、学术交流的陈述可能比一般学科更细致，篇章之间因细粒度信息多而导致差异的可能性更大。 $\\textcircled{3}$ 文献的出版物及其传播渠道与领域有很大关系，信息源种类和粗细粒度都不能事先预设,只能根据文字内容来构建文献结构。",
    "context3": "由于跨学科领域综述型文献的这些特点，对信息源抽取、序化和可视化就提出了诸如以下要求所述的更高要求需要更细致地追溯学科领域发展历史，需人工或自动去剥离、序化掺杂在一起的不同维度的信息源需要甄别和处理综述型文献之间信息源及其评价的差异需要结合领域特点，生成和更新信息源地图结构等等。",
    "context4": "本文定义想要抽取的信息源信息包括文献中提及的作者、名称文献、工具、方法等）、期刊、机构、会议等可以帮助非专业人员了解某一领域的途径，相应的关联要素还有时间信息。文献中包含信息源的语句即使在具体描述中有所区别，但也不会脱离有限的几种语义模式，因为在综述型文献中，提及信息源的部分都遵循着统一的逻辑规范，即作为作者阐述某领域研究现状的依据。",
    "context5": "在大多数情况下，提及某个信息源的句子只会与句子的下文有关，如果将存在语义联系的相关句子连接起来,组成片段,那么提及信息源的句子一般会作为片段的开头部分。在相关的下文里,可能出现的主要内容有对信息源的进一步介绍和对信息源的效果评价。所以本文提出的方法首先实现句子级的抽取，再在此基础上进行信息源信息的详细抽取，句子级的抽取对象就包括明确提及信息源的语句和对信息源的评价语句。",
    "context6": "其次,鉴于综述型文献中存在大量文献引用情况,且参考文献列表中的信息源信息更为全面，在本研究中,如果句子中存在引用现象，则以参考文献列表中的资源描述为主。而当提及的信息源没有文献形式或网址形式的参考时，选择粒度更细的实体来代表整体。",
    "context7": "此外,抽取含有关联多个信息源实体的多条信息源信息的句子时,需要对句子中提及的所有实体进行关联划分判断。"
  },
  "2.2面向综述型文献的信息源信息抽取": "",
  "2.2.1总体框架": {
    "context1": "本文提出的面向综述型文献的信息源信息抽取的大体流程为：首先实现文本预处理，然后在识别篇章关系的基础上,构建辅助词典,再使用词典及辅助词典进行分词、完成实体识别和词性标注等工作，最后根据实体识别的结果并结合一定的语法逻辑规则，实现句子级的抽取并进行信息源数据抽取。图1为信息抽取流程图。",
    "context2": "![](images/4726d3bd61bf1607a0d716d8443371f095cafd7116c4feb064ed9ff24330f34e.jpg)  \n图1综述型文献信息源信息抽取流程"
  },
  "2.2.2文本预处理": {
    "context1": "本研究的文本预处理工作主要包括三个部分源始 pdf文档格式转换汶本的分句、分词,并标注词性；读取并存储参考文献列表。",
    "context2": "关于原始 pdf文档格式转换,首先借助 pdf-box 和itext开源组件实现将pdf 格式文件转为txt文件，再去除包括乱码、标点符号全/半角形式不统一、文本行不成段等干扰因素。其中，关于干扰因素的去除，本文制定了下列规则 $\\textcircled{1}$ 去除中英文比例小于0.3的文本行 $\\textcircled{2}$ 去除以图”、表\"开头的文本行 $\\textcircled{3}$ 去除包含当前文献作者名或文献名的文本行 $\\textcircled{4}$ 将常见标点符号逗号、句号、分号、冒号)的半角形式替换成全角形式 $\\textcircled{5}$ 除了前后字符都为数字或前一个字符为数字且为行首的情况，其余情况下将点符号替换成句号。",
    "context3": "关于段落划分,文献&1]提出的一种段落识别算法,通过对换行符号、文本行长度和标点符号的综合利用来判断txt文档的段落信息，然后在分隔段落的文本行末尾添加段落标记，根据段落标记重新分段。算法流程如图2所示。",
    "context4": "关于文本分句,首先以句号为分隔，将文献内容划分成一个个句子,并记录下句子和段落的归属，生成段落一句子序列。然后对每个句子进行分词操作。",
    "context5": "![](images/584478b98a2f07395e5ad34e49d1d51108d6dfd1232b6ada1a257b4d73b99e37.jpg)  \n图2段落识别算法流程图",
    "context6": "关于分词及词性标注，本文使用的分词工具是张华平博士开发的NLPIR 汉语分词系统。这是一个开源的软件工具包,主要功能包括：中文分词、词性标注、实体命名识别、用户词典等。在NLPIR系统的标注集中,不仅包含了各种基础词性如动词（）、名词6)、形容词 adj)等,还包含了细分的子集如人名6r)、地名 6s)、机构团体名 6t)等。此外,还支持结合用户字典自己设置特殊词性。",
    "context7": "在实际应用中，中文分词和词性标注是由同一条命令统一执行,实体命名识别的功能可以单独使用，但其效果也包含在词性标注功能之中。在综述型文献中,不包含引用文献的情况下,最常出现的信息源实体及相关要素词汇是作者、机构、时间。其中，NLPIR系统对于中文人名和时间的识别率很高,对于英文人名、机构名的识别率较差,需要利用该工具的用户词典功能,额外构建判断辅助词典提高实体命名识别的准确率。",
    "context8": "关于解析并存储参考文献列表，综述型文献的参考文献列表部分比正文包含的信息源描述详细、准确，且根据序号跟正文中的引用部分存在一一对应的关系,所以本文的信息抽取方法在处理包含引用符号的句子时，优先考虑参考文献列表中对应的信息源信息。本文采用的方法是以每一条参考文献文本的前两个英文句号为分隔分成三个部分,对各部分可能出现的情况进行综合分析，可以满足大多数参考文献文本字段的解析。第一部分内容是文献的作者，多个作者间以逗号分隔，基本不会出现例外。第二部分的主体是文献的标题字段，但经常会在标题字段后以“/符号连接文献所属的会议字段;当第三部分的内容为空,即参考文献字段中不含有机构、期刊等信息时，表示时间的字段信息也会出现在第二部分。第三部分包含的信息最多，最常见的是机构或期刊信息,还有可能包含地名、会议、网址。",
    "context9": "鉴于上述情况,本文在解析参考文献字段时，除作者和标题外,主要目标是解析出有非常明显文本特征的时间信息和会议信息，其余部分作为该信息源的来源\"属性。如会议字段几乎不在中文格式中出现、英文会议字段一定以‘Proc\"或“/开头、可以几种正则表达式匹配几乎所有可能包含时间字段的格式等。此外,也有一些特殊情况需要单独考虑，如整条参考文献字段的内容就是一个网址等。",
    "context10": "对于参考文献列表的存储，本文规定每条参考文献字段代表一条完整的信息源实体，每个实体包含作者、标题、会议、来源、综述5个属性,每个属性值可以为空，也可以多值。对于直接从正文中抽取的信息源信息，也以这样的形式进行存储。"
  },
  "2.2.3辅助词典构建": {
    "context1": "构建信息源实体判断辅助词典的目的是利用分词系统的用户词典功能，提高实体关系识别的准确率。词典中每一个词的表述形式为‘词\"加‘词性”。词汇来源如下：",
    "context2": "首先,鉴于综述型文献中提到的研究机构大多数是某大学或其下属的某机构,本文通过网络检索获取了2017年世界排名前 500的大学的中英文名称和国内211院校的名称,将其作为机构名添加进词典。另外,本文通过爬取万方数据知识服务平台下的中国学术期刊数据库和中国学术会议数据库获取了其中的期刊名和会议名，也将其添加进了词典中。",
    "context3": "其次是人工定义的特殊词汇，主要是定义一些特殊的词汇与词性来针对某些特殊情况的判定和抽取以及消除某些常见的实体判别误差。首先通过对多篇综述型文献进行实体命名识别操作,人工判断其中错误的实体识别，并选择其中有可能经常出现词汇，定义为普通名词,避免其被判定为信息源实体词。比如高维”一词会被判定为人名,但在数学、计算机科学等领域是一个常见概念，因其影响较大,需要在词典中专门定义以避免误差。另外,本文的信息抽取目标之一就是抽取表示领域或学科阶段性发展的关键信息,这一类句子通常包含如“…世纪…年代”、首次\"等特殊词汇,这些词汇也通过人工判读的方式被选取出来重新定义词和词性，然后添加进词典中。",
    "context4": "最后是参考文献列表中的实体词汇,这部分词汇会在分词和实体命名识别之前添加到词典中。与上述两个词汇来源不同，这部分词汇的添加是一个没有终点的动态过程,并且因为辅助词典是一个独立的文件,所以每处理一篇文档，词典都会永久记录下从参考文献列表中提取的词汇。"
  },
  "2.2.4篇章关系识别": {
    "context1": "在本研究中不仅要抽取包含信息源信息以及领域阶段性发展信息的句子,还希望抽取正文中对提及的信息源进行效果评价的句子，所以除了需要利用实体命名识别之外,还需要考虑篇章关系的识别。具体到本文的研究中，篇章关系指被抽取的句子与同段落内下一个被抽取的句子之间的其他句子的关系,在综述型文献中，主要是解说关系和评价关系。当下文的句子与被抽取的句子存在评价关系时,在被抽取句子中提及的信息源一般会作为下文句子的主语，结合综述型文献的特点,本文列出了以下判别规则：",
    "context2": "相邻句且以该次>这…\"开头；  \n包含“…该此方法……”；",
    "context3": "包含“…这种/类/些…技术/方法/算法…”；",
    "context4": "包含“实验表/证明”",
    "context5": "包含被抽取句子中的信息源实体词汇。",
    "context6": "抽取符合判定规则的下文句子，然后将其与原先被抽取的句子连接起来,形成新的片段。图3为对文献机器学习及其算法和发展研究》2进行句子抽取并形成片段的结果。",
    "context7": "1.最近，由谷歌旗下DeepMind公司开发的基于深度卷积神经网络和蒙特卡洛树搜索算法的围棋智能程序AlphaGo以4：1的悬殊比分战胜世界围棋冠军李世石，充分展示出机器学习的强；  \n2.与人脑相比，深度学习目前在处理问题的能力上还有巨大差距，即使在结构、功能、运行机制上都与人脑有很大的差距[1]，并且近期深度学习研究与应用的突飞猛进主要得益于大数  \n3.1943年，WarenMcCuloch和WalterPits提出了神经网络层次结构模型[2]，确立为神经网络的计算模型理论，从而为机器学习的发展奠定了基础。  \n4.1950年，“人工智能之父”图灵发提出了著名的“图灵测试”，使人工智能成为了计算机科学领域一个重要的研究课题。  \n5.1957年，康内尔大学教授FrankRosenblat提出Perceptron概念，并且首次用算法精确定义了自组织自学习的神经网络数学模型，设计出了第一个计算机神经网络，这个机器学习算  \n6.1959年美国IBM公司的A，M.Samuel设计了一个具有学习能力的跳棋程序，曾经战胜了美国一个保持8年不败的冠军。  \n7.1962年，Hubel和Wiesel发现猫脑皮层中独特的神经网络结构可以有效降低学习的复杂性，从而提出著名的Hubel-Wiesel生物视觉模型，以后提出的神经网络模型均受此启迪。  \n8.1969年，人工智能研究的先驱者MarvinMinsky和SeymourPapert出版了对机器学习研究具有深远影响的著作《Perceptron》，虽然提出的XOR问题把感知机研究送上不归路、此后  \n9.1980年夏，在美国卡内基·梅隆大学举行了第一届机器学习国际研讨会，标志着机器学习研究在世界范围内兴起。  \n10.1986年，《MachineLearning》创刊，标志着机器学习逐渐为世人瞩目并开始加速发展。  \n11.1982年，Hopfield发表了一篇关于神经网络模型的论文[3]，构造出能量函数并把这一概念引入Hopfield网络，同时通过对动力系统性质的认识，实现了Hopfield网络的最优化求解  \n12.1986年，Rumelhart、Hnton和Wilams联合在《自然》杂志发表了著名的反向传播算法(BP)[4]，首次阐述了BP算法在浅层前向型神经网络模型的应用，参见图1[5]，不但明显降  \n13.1989年，美国贝尔实验室学者YanLeCun教授提出了目前最为流行的卷积神经网络（CNN）计算模型，推导出基于BP算法的高效训练方法，并成功地应用于英文手写体识别。  \n14.进入90年代后，多种浅层机器学习模型相继问世，诸如逻辑回归、支持向量机等，这些机器学习算法的共性是数学模型为凸代价函数的最优化问题，理论分析相对简单，训练方法也  \n15.基于统计规律的浅层学习方法比起传统的基于规则的方法具备很多优越性[6]，取得了不少成功的商业应用的同时，浅层学习的问题逐渐暴露出来，由于有限的样本和计算单元导致对  \n16.2006年，在学界及业界巨大需求刺激下，特别是计算机硬件技术的迅速发展提供了强大的计算能力。  \n17.机器学习领域的泰斗GeofryHinton和Ruslan-Salakhutdinov发表文章[7]，提出了深度学习模型，主要论点包括：多个隐层的人工神经网络具有良好的特征学习能力;通过逐层初始化  \n18.2012年，Hinton研究团队采用深度学习模型赢得计算机视觉领域最具影响力的ImageNet比赛冠军，从而标志着深度学习进入第二个阶段。  \n19.随着Hinton、LeCun和AndreWNg对深度学习的研究，以及云计算、大数据、计算机硬件技术发展的支撑下，参见图2[8]，深度学习近年来在多个领域取得了令人赞叹的进展，推出  \n20.深度学习是目前最接近人类大脑的分层智能学习方法，通过建立类似于人脑的分层模型结构，突破浅层学习的限制，能够表征复杂函数关系，对输入数据逐层提取从底层到高层的特  \n21.无监督学习更近似于人类的学习方式，被AndrewNg誉为：人工智能最有价值的地方[10]。"
  },
  "2.2.5信息源数据抽取": {
    "context1": "对句子抽取和篇章关系识别形成的包含一个或多个句子的片段进行处理,抽取详细的信息源数据，包括信息源实体及其各属性的值,以及对片段整体情感分析得到的信息源情感评分，将非结构化的自然语言文本片段转化成结构化的数据。其详细抽取的大体流程如图4所示。",
    "context2": "在抽取信息源实体属性方面，如果片段中包含引用符号，直接从已解析并结构化存储的参考文献列表中抽取对应的数据;如果不含引用符号，则需要设计专门的语法规则来辅助抽取。首先,当同一片段中包含两条或两条以上信息源信息时，需要对每条信息涉及的文本区域进行划分。通过对该情况下的大量句式分析后发现,不同信息源一般在句中属于并列关系,关联的实体词数量、属性、顺序一致,且机构名或时间的顺序靠前。本文以片段中信息源关联的第一类实体词来划分文本区域。其次，某些可以作为信息源标题\"的字段不是较为统一规范的专有名称，而是综述作者对其的概括描述,如‘某人提出的基于的方法\"等。本文的方法规定：如果片段中包含“人名>机构名提出/开发/设计)的系统/工具/方法”,则将“系统/工具/方法\"部分文本字段提取出来作为信息源的标题\"属性。",
    "context3": "![](images/1297d212632a0d74ed05c0cc36e62312b83fbdd9247877d2bdac6a369db9fd83.jpg)  \n图3句子级抽取结果   \n图4信息源数据抽取流程",
    "context4": "在获取信息源情感评分方面,本文使用了NIPIR分词系统中的情感分析组件包，其基本原理是借助情感词典,判断片段中包含的正面情感词汇和负面情感词汇的个数,两者的差值输出为片段的情感评分。本研究中抽取的片段都是对信息源的描述和评价，一般不会出现包含其他主题的无关内容,所以本文中以片段情感评分作为片段中提及的信息源情感评分。另外,对于包含领域阶段性进展信息的片段，由于其在一篇文献中出现的数量很少且很难对其中的内容进行结构化的数据处理，所以对其进行人工处理。信息源数据抽取部分效果 不包含情感评分)如图5所示。",
    "context5": "图5信息源数据抽取部分效果"
  },
  "3基于抽取信息源信息的地图绘制": "",
  "3.1抽取信息的存储与处理": {
    "context1": "本文使用Mysql搭建关系型数据库存储数据。对每一篇综述型文献建立主表，存储综述型文献的编码、作者、标题等信息对综述型文献使用的信息源建立子表,存储相应信息源的作者、标题、发表的会议表、期刊/机构,时间、评价打分以及部分通过人工处理得到的领域阶段性发展等信息。",
    "context2": "再考虑多篇文献的信息源整合，当多篇文献对同一信息源有不同评价时，需要对每篇文献的信息源子表格进行调用、判断和处理。如果信息源的‘作者\"和标题\"属性都不为空且两个属性相同时，则将信息源定义为重复，就对这几篇文章中同一信息源的打分字段的值计算平均数，作为该信息源最终的评价得分。"
  },
  "3.2信息源信息可视化": {
    "context1": "考虑到信息源实体具有不同维度的属性以及各维度属性之间的关系，信息源信息可以从不同的维度进行展示。本文中进行可视化操作形成的数据图像整体以树状结构分布。各层级结点的值可以根据以不同维度为主的展示方式进行调整。例如，当以时间 年份)为主维度来展示信息时，层级从高到低可以表示为根节点一年份一信息源一详细数据,将所有信息源以年份为准按时间分类并顺序排序，时间\"属性为空的信息源暂不考虑。层级中的信息源\"值用来代表整条信息源的某个属性值，本文中各属性粒度从细到粗为标题、作者、会议、来源,取不为空的最细粒度属性值作为信息源\"层级的节点值。",
    "context2": "当信息源的评分高于某个阙值时，本文中定义其代表该信息源被综述文献作者认为有更高的价值，在信息源地图中以特殊显眼颜色表示。另外，对于表示领域阶段性发展的关键信息，在信息源地图中也以特殊颜色表示。",
    "context3": "本文使用D3进行数据可视化操作。D3是Data-Driven Documents 数据驱动文档)的简称,是一个用来使用Web 标准做数据可视化的JavaScript库,也是目前最流行的数据可视化库。D3中为用户提供了12种布局，包含了所有主流图表，且各布局可以结合使用，几乎能够满足所有的数据可视化需求。本文采用的是D3中的树状图布局，可以直接使用是JsOn 格式的数据。Json是一种用于数据交换的文本格式,可以清晰地表示数据间层级关系和归属关系，可以很容易地被人或计算机识别,且表示相同内容时比xml格式的长度更短、读写更快。",
    "context4": "本文中数据可视化部分的基本流程包括：搭建数据库,存储并处理数据;确定主维度;读取数据库数据，转化为Json 格式,生成Json 文件;使用D3,读取Json 文件,生成图谱。读取数据并生成Json文件使用Java语言编程实现;调用D3生成图谱使用JavaScript语言编程实现。",
    "context5": "另外,在进行Json 格式数据转换的同时,对其中表示高评分和阶段性发展信息的部分数据需要添加标记,并在进行D3编码时加入对应的判断语句,实现了相应结点文本的颜色改变。"
  },
  "4实验结果和分析": "",
  "4.1实验过程": {
    "context1": "实验分为两个部分：信息抽取和绘制信息源地图。信息抽取实验部分具体流程如下：",
    "context2": "()以“机器学习\"作为关键词,分别从万方知识服务平台、中国知网数据库中进行检索,选取了相关度排序靠前且有一定被引量的20 篇综述型文献。",
    "context3": "&)进行 pdf文档解析,将其转化为txt格式,去除乱码并分段。",
    "context4": ")解析并存储参考文献列表。",
    "context5": "4)对文档分句并记录句子序列,对句子分词并",
    "context6": "完成实体命名识别和词性标注。",
    "context7": "6)抽取包含信息源描述、信息源评价、领域阶段性发展信息的句子并形成片段。",
    "context8": "6)抽取信息源详细数据。",
    "context9": "绘制信息源地图实验部分流程如下：",
    "context10": "()构建Mysql数据库,存储信息源详细数据。",
    "context11": ")选取某些跨学科领域的信息源数据抽取结果,从数据库中读取数据并整合。",
    "context12": ")将数据转换为json 格式文件。"
  },
  "4.2预处理工作": {
    "context1": "除去无法解码或乱码严重影响正文的文献 体实验中无法使用的文献大多属于无法从知网或万方获取高清版本的pdf 文件),以最后剩下的15 篇文献作为信息抽取实验的基础数据。"
  },
  "4.3信息抽取实验结果": {
    "context1": "对于片段抽取和信息源数据抽取结果的性能评价指标为：",
    "context2": "$$\nF - s c o r e = { \\frac { 2 P R } { P + R } }\n$$",
    "context3": "其中,P为查准率,R为查全率,其定义分别为：",
    "context4": "$$\nP = { \\frac { M } { N } } , R = { \\frac { M } { C } }\n$$",
    "context5": "其中， $\\mathsf { M }$ 为被正确抽取的句子数或信息源数,N为实际被抽取的句子总数或信息源总数,C为文献中应该被抽取的句子数或信息源数。",
    "context6": "对于片段抽取的效果,由于片段可能包含复数个句子,难以直接判断其准确性,所以包含信息源评价的句子与包含信息源描述的句子等价参与计算。另外,对于信息源数据抽取的效果计算，不考虑去重。信息抽取结果由表1所示。",
    "context7": "表1面向综述型文献的信息源信息抽取结果",
    "context8": "<table><tr><td rowspan=1 colspan=1>信息种类</td><td rowspan=1 colspan=1>总数目C)</td><td rowspan=1 colspan=1>识别数</td><td rowspan=1 colspan=1>正确识别数W</td><td rowspan=1 colspan=1>查准率P)</td><td rowspan=1 colspan=1>查全率R)</td><td rowspan=1 colspan=1>F值</td></tr><tr><td rowspan=1 colspan=1>片段</td><td rowspan=1 colspan=1>647</td><td rowspan=1 colspan=1>621</td><td rowspan=1 colspan=1>604</td><td rowspan=1 colspan=1>97.3%</td><td rowspan=1 colspan=1>93.4%</td><td rowspan=1 colspan=1>0.955</td></tr><tr><td rowspan=1 colspan=1>信息源</td><td rowspan=1 colspan=1>592</td><td rowspan=1 colspan=1>554</td><td rowspan=1 colspan=1>536</td><td rowspan=1 colspan=1>96.8%</td><td rowspan=1 colspan=1>90.5%</td><td rowspan=1 colspan=1>0.933</td></tr></table>",
    "context9": "从表1可以看出,本文提出的信息源信息抽取方法对于片段和详细信息源数据都有超过 $90 \\%$ 的查全率和查准率，这是因为在综述型文献参考文献部分描述的信息源信息在全文提及的信息源里占了很大的比重,而参考文献部分也因其规范化的格式较容易解析且准确性较高。另外,本文针对直接从正文中抽取数据的情况所做的工作也发挥了较好的效果，使得最终信息抽取的效果较好。"
  },
  "4.4信息源地图绘制结果": {
    "context1": "利用D3进行数据可视化操作,绘制主题信息源地图。首先,选取表示跨学科领域机器学习\"的15篇综述型文献进行信息抽取,并分别以时间 年份)和来源为主维度进行可视化表示。其中高评分信息源以红色字体表示,领域阶段性发展信息以橙色字体表示，并且支持通过对节点的点击操作来进行子节点的缩放。",
    "context2": "时间为主维度的绘制结果如图6、7、8所示，部分年份\"结点收缩，小部分‘信息源\"结点展开。图形中有的只有作者、时间及其贡献，没有文章和期刊，表明这些是从文章中抽取的信息，没有标注相应的参考文献。来源为主维度的绘制结果如图10、11所示，显示了机器学习\"的分枝领域‘文本分类\"的高价值信息",
    "context3": "源等信息。",
    "context4": "鉴于本研究搜集到的综述文献对‘机器学习\"领域发展过程的阶段性划分没有一致的提法，本文分三个时间片段来可视化展示：1955年之前，1956—1985年,1986年至今。图6、7、8反映了这一发展过程中各阶段的特点。",
    "context5": "()1955年之前",
    "context6": "如图6所示,20世纪50年代中期之前为该领域发展的源头，这期间被评述的信息源数量少，包括：1943年，麻省理工学院神经心理学家兼精神病学家麦卡洛克和皮茨合作的论文 :A logicalcalculus of theideas immanentin nervous activity,贝叶斯的 An Essaytoward Solving a Problem in the Doctrine of Chances。重要学者包括：贝叶斯、沃伦斯·麦卡洛克、沃尔特·皮茨、图灵、明斯基等先驱科学家。由期刊名及主要学者可知涉及学科包括哲学、数学、生物物理、计算机科学。",
    "context7": "![](images/c4e223cf330dafdb35c6d24349ec2e5f3b25b3daa4ee7bd0b4e75f78c9d09b62.jpg)  \n图6“机器学习\"领域的信息源地图(1955年之前）",
    "context8": ")1956—1985年",
    "context9": "由图7可以了解人工智能和认知科学是在20 世纪50年代中期开始形成自己独特的领域,期间的高价值文献有:1958年Luhn的文学文摘的自动创作》,Baxendale的技术文献索引的机器生成》。机器学习的理论基础形成于二十世纪六十年代,期间的高价值文献有：1962年,美国神经生物学家 Hubel 和Wiesel的Hubel-Wiesel生物视觉模型》。1969年,人工智能研究先驱者Minsky和Papert出版了对机器学习研究具有深远影响的著作感知器》。20世纪70年代形成了计算科学范围内带有机器学习特点的实用算法，期间的高价值文献有:1972年,Novik的关于感知机的收敛证明》,1974年,Antoniak的狄利克雷过程的混合与贝叶斯非参数问题的应用》。1980年,在美国卡内基梅隆大学举行第一届机器学习国际研讨会，标志着机器学习研究在世界范围内兴起,增强学习成为热点问题，期间的重要文献有:1983年，Simon的 为什么机器可以学习 $\\mathfrak { P }$ ,MICHALSKIRS的 机器学习:一种人工智能方法》,1984,Breiman L的 分类及回归树》等。",
    "context10": "主要期刊有:IEEE Trans on Information Theory、Journal of the ACM (ACM)、The Annals of Statistics,",
    "context11": "涉及学科包括信息论、计算机科学、神经生物学、统计学、人类学等,分别从不同的角度探讨机器的学习能力即人工智能的可能性。",
    "context12": "![](images/675d4590c81c1562ddf2fa7188ddbf56ec101e6d3f6f0ff470a232774094990d.jpg)  \n图7“机器学习\"领域的信息源地图(1956一1985年)",
    "context13": ")1986年至今",
    "context14": "如图8由于数据源多，在此只显示了2001—2006年),从20世纪八十年代中期起,机器学习领域已经发展成熟为一门新的边缘学科，在研究方向上不断扩展，实用方法越来越突出，各学科之间的联系也日益紧密。为了展示繁荣期间研究主题变化，本文结合文献标题的分词处理如图9所示)，发现从1986年开始的10年期间,除了认知科学,更加致力于数据挖掘”、贝叶斯网络”、分类器“自动文本摘要”等方面的研究，到2006、2007年增加了‘增强学习”、支持向量机”、大数据”、深度\"等主题词,可见机器学习领域的研究更新很快，到现在最新的研究继续聚焦在文本分类”、深度学习”、大数据\"等方面技术的同时，开展了很多应用领域的研究。重要期刊有",
    "context15": "Machine Learning Research，Machine Learning,IEEE Transactions on Pattern Analysis and Machine Intelligence,IEEE Transactions on Systems和Artificial Intelligence Research等。",
    "context16": "由于机器学习成熟期数据源多，不好展示高价值数据源和学科分布。本文选取了其中一个重要分支——文本分类\"来构建以来源为主维度的信息源图，按照‘来源\"字段可能包含的内容，首先分为‘国内”、国外”、网址”、无来源\"四类。图10为国外”结点展开,大部分信息源\"结点收缩的情况图11为国内\"结点展开，大部分信息源\"结点收缩的情况。",
    "context17": "通过阅读图10、11,读者首先可以迅速发现该研究主题的相关学科及重要期刊。以图11为例，读者可以通过文献来源期刊快速了解到文本分类”的研"
  }
}