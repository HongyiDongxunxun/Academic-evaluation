{
  "original_filename": "full_4633.md",
  "基于用户多类型兴趣波动趋势预测分析的个性化推荐方法": "",
  "丁浩李树青": {
    "context1": "(南京财经大学信息工程学院南京 210023)",
    "context2": "摘要：【目的】构建一种基于用户多类型兴趣波动特征预测的推荐方法以提升推荐效果。【方法】针对每种类型用户评分数据加人时间衰减因子并使用神经网络对数据波动线性拟合，选择最优参数结果并对比评估方法有效性。【结果】通过5组不同的用户数据进行仿真实验，结果表明，本文方法预测结果的MAE和RMSE分别较对比方法最高降低幅度达到 $4 7 . 6 3 \\%$ 和 $4 4 . 6 1 \\%$ 。【局限】由于时间波动的分析依赖用户历史数据，当历史数据量过于稀疏时需采用额外冷启动算法对数据进行预处理。【结论】该方法结合用户对不同商品类型兴趣漂移特征的波动分析和预测，使推荐结果更准确。",
    "context3": "关键词：时间序列兴趣类型波动分析个性化推荐分类号：TP391DOI:10.11925/infotech.2096-3467.2019.0370"
  },
  "1引言": {
    "context1": "随着互联网的快速发展，信息过载成为互联网信息发展的难题之一。推荐系统的出现有效缓解了这一问题，其中应用最广泛的协同过滤推荐算法，其核心思想是通过建立用户和信息间的联系过滤掉冗余无关信息，将更符合用户兴趣的内容提供给用户[1]。在实际情况中，由于用户和项目数量庞大种类繁多，传统协同过滤存在计算量过大和数据稀疏性等问题，为解决这一问题，很多学者对传统的协同过滤算法进行改进[2],在算法中引入用户(产品)之间的隐含关系[3]，但此类方法忽略了用户偏好可能会随着时间动态变化的特点，这会导致推荐效果随时间推移而不稳定。",
    "context2": "本文通过分析用户对不同类型商品的兴趣波动特征，利用神经网络训练用户对不同商品类型的兴趣变化趋势的特征模型，并提取特征参数对样本数据进行预测。本文主要的贡献有:",
    "context3": "(1）利用用户对不同商品类型兴趣变化的波动特征预测用户兴趣变化趋势，用线性方法描述兴趣波动性变化的延伸性和有向性。",
    "context4": "(2）结合用户兴趣漂移特征的特点对用户历史兴趣影响衰减，使用神经网络训练最优特征系数。",
    "context5": "(3）无需繁杂的社会网络信息，建模训练所需信息更易获取，利用线性关系预测可降低时间复杂度,进一步增强系统响应性能，提升用户满意度。"
  },
  "2相关工作": "",
  "2.1基于概率依赖的时序预测模型": {
    "context1": "基于概率的时序模型主要是利用随机过程中事件概率分布依赖对用户行为预测，应用较广的有马尔可夫模型,Liu等利用用户行为的周期性特征处理用户行为并改进马尔可夫状态计算方法，对电影分级数据集进行时序推荐[4]。Rendle 等引入基于马尔可夫链的个性化转移矩阵以捕捉时间信息并解决转移矩阵的稀疏问题[5]。此类方法可以建立随机事件的预测模型，但更侧重于现在状态对未来时刻的影响，而与过去的历史无直接关系，不利于中长期预测。"
  },
  "2.2基于隐式反馈的时序预测模型": {
    "context1": "隐式反馈为不直接表现用户倾向的历史数据，是推荐系统信息来源的重要部分[。隐式反馈信息量比显示反馈大很多，反馈来源于用户的自然表现，更接近于真实指标。在现有推荐系统中运用最为广泛的为矩阵分解法7，基于时间因素的矩阵分解系统则是将时间因素与现有模型结合，通过对时间变化特征的学习进一步提高推荐准确率[8]。Koren 提出 TimeSVD $^ { + + }$ 算法，将时间信息加入到用户和产品的特征向量中,有效解决兴趣漂移问题[9]。除此之外，因式分解方法也被用于隐式反馈的时序建模。Hosseini 等构建了循环泊松因式分解(Recurrent Poisson Factorization,RPF)框架，该框架利用泊松过程对隐式反馈进行建模，RPF模型将时间视为模型的自然组成部分，并将一系列丰富的时间敏感因子构建时序行为模型，在相应的时间向用户推荐[10]。隐式反馈建模方法时间复杂度较高,在实际运用中有很大的限制。"
  },
  "2.3基于神经网络的时序预测模型": {
    "context1": "近年来，神经网络算法已经广泛运用于图像处理[1]、语音识别[12-13]、文本分类等方面[14-15]，除此之外神经网络也成功运用在时序预测方面[16-17]。Yu 等提出一种新的基于递归神经网络的动态循环模型(Dynamic REcurrent bAsket Model,DREAM),该方法引入排名框架(Bayesian Personalized Ranking,BPR)作为目标函数，捕捉用户在不同时间的动态兴趣特征,有利于提高推荐效果[18]。使用神经网络的优点在于数据利用率高，可以充分整合不同维度数据，数据处理方式灵活，可以采用分布式计算等方法增强运算吞吐量。其缺点是信息维度较少时训练精确度较低。",
    "context2": "上述相关研究工作都有不同的改进，但仍有许多不足，例如：已有算法时间或空间复杂度较高，数据获取难度大，缺乏对时序的有向性和延伸性研究，未充分考虑历史数据对用户的影响等。本文基于时序建立用户偏好预测模型，结合不同的商品类别的兴趣波动特征，考虑用户历史行为对未来的影响，对于有向的兴趣特征进行建模，利用兴趣趋势的延伸性预测用户兴趣趋势，并使用神经网络算法优化训练预测模型,据此提出一种高效的推荐方法。"
  },
  "3主要工作": "",
  "3.1问题描述": {
    "context1": "用户在选择商品前会通过各种途径了解商品信息，所收集的信息会对其选购行为产生影响。随着时间推进，用户根据购买经验逐步建立自己的兴趣类型评判标准，对商品所包含的某种或多种类型保持稳定的兴趣变化水平。比如，不喜欢恐怖类型电影的用户可能因信息中透露出恐怖相关的信息而给出较低评分，并且随着时间推移，用户兴趣关注类型的电影评分可能随着偏好改变而发生变化。本文重点研究商品类型与用户兴趣变化波动的趋势，结合用户兴趣时序下波动特征预测未来数据。"
  },
  "3.2时间片数据模型": {
    "context1": "为了进一步研究用户对不同商品类型偏好度与时间变化的关系，需先对商品类型进行划分。用户偏好的类型可能是单类型也可能是多重类型的组合，所以考虑构建用户基于类型评分的数据模型。商品通常被划分为多种单一类型，为确定用户感兴趣的类型集合，将每个用户 $U _ { i }$ 对应每种单类型或者多种单类型的组合看作一种用户偏好类型，记为 $G _ { j }$ ，将包含偏好类型的商品评分 $R _ { n }$ 所构成的评分向量表示如公式(1)所示。",
    "context2": "$$\n\\pmb { R } ( U _ { i } , G _ { j } ) = ( R _ { 1 } , R _ { 2 } , \\cdots , R _ { n } ) ^ { \\mathrm { T } }\n$$",
    "context3": "用户选购行为可看作按时序发生的事件向量，为研究用户对商品兴趣趋势变化的情况，将每个用户的类型评分按时序划分，将用户 $U _ { i }$ 的某种商品类型 $G _ { j }$ 中按时序划分的 $m$ 个评分数据作为一个时序数据片段$S _ { j , k }$ ，按照时序方向重新排列每一种类型的评分，基于时间片划分的类型评分矩阵 $I _ { R U _ { i } } ^ { \\prime }$ 如公式(2)所示。其中， $I _ { R U _ { i } j \\times \\operatorname* { m a x } ( k _ { 1 } , k _ { 2 } , \\dots , k _ { n } ) } ^ { \\prime } , n \\in \\mathrm { N }$ 。",
    "context4": "$$\n\\begin{array} { r } { I _ { R U _ { i } } ^ { \\prime } = \\left[ \\begin{array} { l l l l l l l l } { ( G R _ { 1 , 1 } } & { \\cdots } & { G R _ { 1 , m } ) _ { S _ { 1 , 1 } } } & { ( G R _ { 1 , m + 1 } } & { \\cdots } & { G R _ { 1 , 2 m } ) _ { S _ { 1 , 2 } } } & { \\cdots } & { ( G R _ { 1 , ( k _ { 1 } - 1 ) m + 1 } } & { \\cdots } & { G R _ { 1 , n _ { 1 } } ) _ { S _ { 1 , k _ { 1 } } } } \\\\ { ( G R _ { 2 , 1 } } & { \\cdots } & { G R _ { 2 , m } ) _ { S _ { 2 , 1 } } } & { ( G R _ { 2 , m + 1 } } & { \\cdots } & { G R _ { 2 , 2 m } ) _ { S _ { 2 , 2 } } } & { \\cdots } & { ( G R _ { 2 , ( k _ { 2 } - 1 ) m + 1 } } & { \\cdots } & { G R _ { 2 , n _ { 2 } } ) _ { S _ { 2 , k _ { 2 } } } } \\\\ { \\vdots } & { \\vdots } & { \\vdots } & { \\ddots } & { \\vdots } & { \\vdots } \\\\ { ( G R _ { j , 1 } } & { \\cdots } & { G R _ { j , m } ) _ { S _ { j , 1 } } } & { ( G R _ { j , m + 1 } } & { \\cdots } & { G R _ { j , 2 m } ) _ { S _ { j , 2 } } } & { \\cdots } & { ( G R _ { j , ( k _ { n } - 1 ) m + 1 } } & { \\cdots } & { G R _ { j , n _ { m } } ) _ { S _ { j , k _ { n } } } } \\end{array} \\right] } \\end{array}\n$$"
  },
  "44 数据分析与知识发现": "",
  "3.3时序类型偏好特征构建": {
    "context1": "(1）用户行为趋势分析",
    "context2": "通过分析用户每种类型的时序序列找出其演变趋势特征 $\\boldsymbol { F } ^ { G } ( t ) = \\left[ f _ { 1 } ( t ) , f _ { 2 } ( t ) , \\cdots , f _ { | F | } ( t ) \\right] ^ { \\mathrm { T } }$ ，利用最优特征值进行趋势延展性变化拟合并进行预测。为进一步挖掘用户兴趣变化趋势，使用实验中的数据集分析用户对不同类型的评分数据方差随时间推移所呈现的变化趋势，判断数据的收敛程度。",
    "context3": "按每个用户评分的时间戳分别使用年、月、日三种时间尺度将数据集划分为时间数据片段，发现在三种时序尺度下分别有 $7 9 . 2 8 \\%$ 、 $7 9 . 0 4 \\%$ 、 $7 3 . 9 5 \\%$ 的用户某些类型的时间数据片段中的评分方差随时间推移而缩小，通过数据分析发现评分发生收敛的用户在时间维度上对某些类型评分变化趋向于逐步稳定，用户兴趣点也会随时间推移逐渐落在特定的类型范围内。"
  },
  "(2）趋势分析方法": {
    "context1": "进一步利用线性关系拟合用户总体趋势变化，基本思想是利用最小二乘原理使实际数据 $\\mu _ { t }$ 与预测结果 $\\tilde { \\mu } _ { t }$ 的误差 $E _ { t }$ 的平方和达到最小，参考文献[19]，计算方法如公式(3)所示。",
    "context2": "$$\n\\begin{array} { r } { ( \\sum _ { t = 1 } ^ { n } E _ { t } ^ { 2 } ) _ { \\operatorname* { m i n } } = ( \\sum _ { t = 1 } ^ { n } ( \\mu _ { t } - \\tilde { \\mu } _ { t } ) ^ { 2 } ) _ { \\operatorname* { m i n } } } \\end{array}\n$$",
    "context3": "为描述变量与预测结果的关系，本文构建趋势特征方程，如公式(4)所示。",
    "context4": "$$\n\\tilde { \\mu } _ { t } = \\sigma \\cdot W ( S ^ { G } ( t ) , \\theta ) + \\delta + \\nabla _ { t } ^ { \\prime }\n$$",
    "context5": "其中, $\\sigma$ 和 $\\delta$ 是待定系数，取决于所满足最小值的条件条件极值； $\\theta$ 是时间片长度; $\\nabla _ { t } ^ { \\prime }$ 是用户在 $t$ 时刻兴趣变化的偏置；函数 $W$ 是变换函数，主要是将时间片段内的评分数据提取数据均值。用户对于商品的兴趣随着时间推移不断变化，因此考虑预测数据与实际数据误差的同时也考虑时间对误差的影响，将误差按照时间远近赋予权重，从预测精度的角度来说，在具有稳定趋势变化的数据中，离当前时间越近的时间片数据误差比越久远的误差更重要，按照时序将由远及近的评分误差和分别赋予权重因子 $\\varepsilon ^ { 0 } , \\varepsilon ^ { 1 } , \\varepsilon ^ { 2 } , \\cdots , \\varepsilon ^ { | S | - 1 }$ ，误差和[1]计算如公式(5)所示。在公式(5)中加入权重后展开得到公式(6)。",
    "context6": "$$\nL = \\sum _ { t = 1 } ^ { n } ( \\mu _ { t } - \\tilde { \\mu } _ { t } ) ^ { 2 }\n$$",
    "context7": "$$\nL _ { \\cal Q } = \\varepsilon _ { | S | } ^ { n - 1 } ( \\mu _ { n - 1 } - \\tilde { \\mu } _ { n - 1 } ) ^ { 2 } + \\varepsilon _ { | S | - 1 } ^ { n - 2 } ( \\mu _ { n - 2 } - \\tilde { \\mu } _ { n - 2 } ) ^ { 2 } +\n$$",
    "context8": "$$\n\\cdots + \\varepsilon _ { 2 } ^ { 1 } ( \\mu _ { 1 } - \\tilde { \\mu } _ { 1 } ) ^ { 2 } + \\varepsilon _ { 1 } ^ { 0 } ( \\mu _ { 0 } - \\tilde { \\mu } _ { 0 } ) ^ { 2 }\n$$",
    "context9": "基于文献[19]所提误差计算方法，结合本文所提趋势特征方程，将函数 $\\tilde { \\mu } _ { t }$ 与公式(4)分别代人公式(6),化简后如公式(7)所示。",
    "context10": "$$\nL _ { \\mathcal { Q } } ^ { \\prime } = \\sum _ { t = 1 } ^ { n } \\varepsilon _ { | \\mathrm { S } | - t + 1 } ^ { n - t } ( \\mu _ { t } - \\sigma \\cdot W ( \\mathrm { S } ^ { G } ( t ) , \\theta ) - \\delta - \\nabla _ { t } ^ { \\prime } ) ^ { 2 }\n$$",
    "context11": "其中, $0 < \\varepsilon < 1$ ，显然最近的误差 $\\varepsilon ^ { 0 } { = } 1$ ，表明最近的误差有最高的权重。根据时间的远近权重因子 $\\varepsilon$ 按比例递减，且因子衰减的速度取决于 $\\varepsilon$ 值, $\\varepsilon$ 越接近0衰减越快，越接近1衰减越慢。",
    "context12": "为使 $L _ { \\mathcal { Q } } ^ { \\prime }$ 达到最小，使用多元函数极值法对待定系数 $\\sigma$ 和 $\\delta$ 求偏导数,求导过程如公式(8)和公式(9)所示。",
    "context13": "$$\n\\frac { \\partial L _ { Q } ^ { \\prime } } { \\partial \\delta } = - 2 \\sum _ { t = 1 } ^ { n } \\varepsilon _ { | S | - t + 1 } ^ { n - t } \\cdot \\mu _ { t } + 2 \\delta \\sum _ { t = 1 } ^ { n } \\varepsilon _ { | S | - t + 1 } ^ { n - t } +\n$$",
    "context14": "$$\n2 \\sigma \\sum _ { t = 1 } ^ { n } \\varepsilon _ { | S | - t + 1 } ^ { n - t } \\cdot W ( S ^ { G } ( t ) , \\theta ) + \\Delta _ { b i a s } ^ { \\delta }\n$$",
    "context15": "$$\n\\frac { \\partial L _ { Q } ^ { \\prime } } { \\partial \\sigma } = - 2 \\sum _ { t = 1 } ^ { n } \\varepsilon _ { | S | - t + 1 } ^ { n - t } \\cdot \\mu _ { t } \\cdot W ( S ^ { G } ( t ) , \\theta ) + 2 \\delta \\sum _ { t = 1 } ^ { n } \\varepsilon _ { | S | - t + 1 } ^ { n - t } .\n$$",
    "context16": "$$\nW ( S ^ { G } ( t ) , \\theta ) + 2 \\sigma \\sum _ { t = 1 } ^ { n } \\boldsymbol { \\varepsilon } _ { | S | - t + 1 } ^ { n - t } \\cdot \\boldsymbol { W } ^ { 2 } ( S ^ { G } ( t ) , \\theta ) + \\Delta _ { b i a s } ^ { \\sigma }\n$$",
    "context17": "其中， $\\Delta _ { b i a s } ^ { \\delta }$ 和 $\\Delta _ { b i a s } ^ { \\sigma }$ 是用户兴趣偏置在不同参数下求导的偏移量，联立公式(8)和公式(9)，令偏导数$\\frac { \\partial L _ { Q } ^ { \\prime } } { \\partial \\delta } = \\frac { \\partial L _ { Q } ^ { \\prime } } { \\partial \\sigma } = 0$ ，解得待定系数 $\\sigma$ 和 $\\delta$ 的值，可使得$L _ { \\mathcal { Q } } ^ { \\prime }$ 取得最小值,此时 $\\sigma$ 和 $\\delta$ 的值为最优兴趣特征系数。"
  },
  "3.4基于多类型趋势的神经网络推荐框架": {
    "context1": "(1）训练方法",
    "context2": "在模型框架中，将转化好的数据分为若干段，再通过时间片评分方差的收敛程度判定数据趋势特征是否满足稳定的延伸趋势，如果满足则使用趋势预测模型进行训练，方法是通过初始化数据预测下一时间点用户可能给出的数据,并计算与真值的误差，在上一次结果的基础加入新的训练数据进行预测和验证，并通过调整用户时序兴趣偏置，最终使趋势的预测模型与实际数据的误差和最小；如果用户所选购商品中不含有趋势延伸特性的类型，则使用协同过滤方法进行预测。",
    "context3": "(2）目标函数及预测方法",
    "context4": "实验训练模型分为输入转化、训练、转化输出三个部分，如图1所示。 $\\textcircled{1}$ $\\textcircled{3}$ 属于输入转化模块, $\\textcircled{4}$ $\\textcircled{5}$ 属于训练模块, $\\textcircled{6} - \\textcircled{7}$ 属于转化输出模块。",
    "context5": "![](images/2702d16bc640cd9c19c94b640b32e3c5610b57508f974913bb077f458253710e.jpg)  \n图1模型框架示意图",
    "context6": "将用户对不同商品类型评分从集合 $G$ 中按时间顺序取出，分别放入集合 $V _ { u _ { i } } = \\{ S _ { 1 } , S _ { 2 } , \\cdots , S _ { k _ { n } } \\}$ ，作为框架的输入层(InputLayer)。输入层的数据传入数据转换模块，在转换模块中进行扁平化处理,将数据通过类型分类，并按照时间序列以二维矩阵的形式存储。转化后的数据通过步骤 $\\textcircled{3}$ 进行预筛选处理，对数据初步分析，找出可能会影响拟合训练精度的数据，摒除冗余噪声数据，将符合条件的数据重新按分类、按时序预测，在隐藏层中按照选定的超参 $\\theta$ -时间片长度，根据每种类型进行拟合训练。本文通过线性关系构建预测函数，如公式(10)所示。",
    "context7": "$$\n\\varphi ( x ^ { ( t ) } , \\Theta ) = \\Theta _ { 0 } + \\Theta _ { 1 } x _ { 1 } ^ { ( t ) }\n$$",
    "context8": "其中， $\\mathcal { O } _ { 0 }$ 为偏移量, $\\Theta _ { 1 }$ 为系数, $x ^ { ( t ) }$ 表示 $t$ 时刻样本点， $\\varphi ( { x } ^ { ( t ) } , \\theta )$ 表示估计值，因为超参 $\\theta$ -时间片长度的设置影响实验框架整体输出，因此在后续实验中将继续讨论其设置。为统一矩阵化便于计算，给每个坐标点 $x$ 增加一维，如公式(11)所示。",
    "context9": "$$\n( x _ { 1 } ^ { ( t ) } , y ^ { ( t ) } ) {  } ( x _ { 0 } ^ { ( t ) } , x _ { 1 } ^ { ( t ) } , y ^ { ( t ) } ) , { \\forall } x _ { 0 } ^ { ( t ) } = 1\n$$",
    "context10": "联立公式(10)和公式(11)则有:",
    "context11": "$$\n\\varphi ( x ^ { ( t ) } , \\Theta ) \\to \\Theta ^ { \\mathrm { T } } x\n$$",
    "context12": "为找出最优兴趣特征系数，根据文献[19-20]，使用误差和构建目标函数，在此基础上加入时间衰减因",
    "context13": "子 $\\boldsymbol { w } ^ { ( t ) }$ ，同时防止过拟合在目标函数中加入正则化项,正则化处理后的目标函数如公式(13)所示。",
    "context14": "$$\nL \\left( \\overleftrightarrow { \\mathbf { \\Gamma } } \\right) = \\frac { 1 } { 2 k } \\sum _ { t = 1 } ^ { k } w ^ { ( t ) } \\left( y ^ { ( t ) } - \\varphi ( x ^ { ( t ) } , \\overleftrightarrow { \\mathbf { \\Gamma } } ) \\right) ^ { 2 } + \\frac { \\lambda } { 2 } \\sum _ { i = 1 } ^ { n } \\overleftrightarrow { \\mathbf { \\Gamma } } _ { i } ^ { 2 }\n$$",
    "context15": "其中, $k$ 表示时间样本点数量， $y ^ { ( t ) }$ 是 $t$ 时刻用户数据的真值, $\\boldsymbol { \\Theta }$ 为待优化兴趣特征系数， $\\lambda$ 是正则参数, $\\textstyle \\sum _ { i = 1 } ^ { n } { \\mathcal { C } } _ { i } ^ { 2 }$ 是正则项，目标函数中常数项 $\\mathcal { O } _ { 0 }$ 并未正则化，因此 $\\lambda$ 不宜设置过大，否则会导致所有参数过小而因变量接近常数出现欠拟合。 $\\boldsymbol { w } ^ { ( t ) }$ 表示 $t$ 时刻误差项的权重，权重因子 $\\varepsilon$ 是一组范围在[0,1]的常数,根据时序由远到近衰减速度由快到慢衰减误差项，本文提出表示方式如公式(14)所示。",
    "context16": "$$\n{ \\boldsymbol { w } } ^ { ( t ) } \\to { \\boldsymbol { \\varepsilon } } ^ { k - t }\n$$",
    "context17": "因所求目标函数是加权误差和，为得到使误差最小的系数 $\\boldsymbol { \\Theta }$ ，根据文献[20]的优化方法选择随机梯度下降法(Stochastic Gradient Descent, SGD)对目标函数进行优化。对公式(13)求导，过程如公式(15)所示。",
    "context18": "$$\n\\begin{array} { r l } & { \\cfrac { \\partial L ( \\theta ) } { \\partial \\theta } = \\cfrac { w ^ { ( t ) } } { k } ( y ^ { ( t ) } - \\varphi ( x ^ { ( t ) } , \\theta ) ) \\cdot \\cfrac { \\partial } { \\partial \\theta } \\Bigg ( \\underset { t = 1 } { \\overset { k } { \\sum } } ( \\theta ^ { \\mathrm { T } } x ^ { ( t ) } - y ^ { ( t ) } ) \\Bigg ) + } \\\\ & { \\cfrac { \\lambda _ { \\theta } } { 2 } \\cdot \\cfrac { \\partial } { \\partial \\theta } \\underset { i = 1 } { \\overset { n } { \\sum } } \\theta _ { i } ^ { 2 } \\propto \\cfrac { w ^ { ( t ) } } { k } ( y ^ { ( t ) } - \\varphi ( x ^ { ( t ) } , \\theta ) ) x _ { \\theta } ^ { ( t ) } + \\lambda _ { \\theta } \\underset { i = 1 } { \\overset { n } { \\sum } } \\theta _ { i } ( 1 5 ) } \\end{array}\n$$",
    "context19": "进而使用随机梯度下降法优化，对所有样本点每一次迭代沿梯度的反方向更新参数，直至收敛，如公式(16)所示。",
    "context20": "$$\n\\boldsymbol { \\theta } \\gets \\boldsymbol { \\Theta } + \\alpha \\Bigg ( \\frac { 1 } { k } \\sum _ { t = 1 } ^ { k } \\boldsymbol { w } ^ { ( t ) } ( \\boldsymbol { y } ^ { ( t ) } - \\boldsymbol { \\varphi } ( \\boldsymbol { x } ^ { ( t ) } , \\boldsymbol { \\Theta } ) ) \\boldsymbol { x } _ { \\boldsymbol { \\theta } } ^ { ( t ) } + \\lambda _ { \\boldsymbol { \\theta } } \\sum _ { i = 1 } ^ { n } \\boldsymbol { \\Theta } _ { i } \\Bigg ) (\n$$",
    "context21": "其中， $\\alpha$ 为学习因子，用于控制学习速率，对于训练过程仅作为特征提取，不设置激活函数。在训练过程中利用数据训练每个用户对不同商品类型的兴趣特征系数，每种类型选择误差和小于阈值的 $m$ 组兴趣特征系数构建预测模型，其中误差和的阈值取对应类型的所有误差总和均值。对于满足条件的兴趣特征系数，用于预测用户相应类型的评分，假设用户当前选购评分行为是 $t$ 时刻，下一次评分行为即将发生在 $t { + } 1$ 时刻, $t { + } 1$ 时刻用户 $U$ 对包含类型 $G$ 的项目评分预测方法如公式(17)所示。",
    "context22": "$$\n\\boxed { \\begin{array} { c } { \\displaystyle { \\sum _ { j = 1 } ^ { n _ { G } } ( \\frac { \\sum _ { i = 1 } ^ { m } ( \\underline { { \\theta } } _ { 0 } ^ { ( i ) } + \\theta _ { 1 } ^ { ( i ) } x _ { \\theta _ { i } } ^ { ( i ) } ) } { m } \\times | x _ { j _ { G } } ^ { ( i ) } | } } } \\\\ { \\displaystyle { P r e d i c t R ( U _ { G } ^ { \\scriptscriptstyle { t + 1 } } ) = \\frac { \\sum _ { j = 1 } ^ { n _ { G } } ( \\sum _ { i = 1 } ^ { m } ( x _ { j _ { G } } ^ { ( i ) } ) } { \\sum _ { j = 1 } ^ { n _ { G } } | x _ { j _ { G } } ^ { ( i ) } | }  } } \\\\ { \\displaystyle {  = \\frac { \\sum _ { j = 1 } ^ { n _ { G } } ( \\frac { \\sum _ { i = 1 } ^ { m } \\Theta _ { i } ^ { \\mathrm { T } } x _ { \\theta _ { i } } ^ { ( i ) } } { m } \\times | x _ { j _ { G } } ^ { ( i ) } | ) } { \\sum _ { j = 1 } ^ { n _ { G } } | x _ { j _ { G } } ^ { ( i ) } | } } } \\end{array} \n$$",
    "context23": "其中， $\\boldsymbol { \\Theta }$ 表示符合条件的兴趣特征系数， $x _ { \\mathcal { O } _ { i } } ^ { ( t ) }$ 表示在某刻用户对 $G$ 类型的评分, $n _ { G }$ 表示包含类型 $G$ 的样本集合总数量, $\\left| x _ { j _ { G } } ^ { ( t ) } \\right|$ 表示包含类型 $G$ 的样本集合内样本数量。"
  },
  "(3）模型优化": {
    "context1": "当用户评分的商品类型包含所有的初始类型时,会产生大量复合类型，虽然在实际情况中不可能覆盖全部初始类型，但随着复合类型的元素增多，组合的长度也随之增加，复合类型的评分数量趋于稀疏，同时复合类型过于冗长还易导致训练集数据过拟合，即使用训练集以外的数据测试时精确度较低；另一方面,大量的冗余组合数据会导致运算效率严重下降。针对这些问题需要对矩阵 $I _ { R U _ { i } } ^ { \\prime }$ 的数据进行预优化处理，由于在完全划分的情况下包含评分数量少于两个的复合类型数量较多，因此可将此类复合类型与其子集合并,从而改善预测效果。"
  },
  "4实验": "",
  "4.1数据集和评价方法": {
    "context1": "MovieLens数据集是美国明尼苏达大学GroupLens项目组公开的电影评分数据集，包含从IMDB、TheMovieDataBase上得到的用户对电影的评分信息。本文使用的数据是MovieLens20M数据集,其数据规模如表1所示。",
    "context2": "表1数据集规模",
    "context3": "<table><tr><td>用户数量</td><td>电影数量</td><td>评分数量</td><td>稀疏度(%)</td></tr><tr><td>138 493</td><td>27278</td><td>20 000 263</td><td>0.5294</td></tr></table>",
    "context4": "本实验中Dropout值设为0.5，误差正则化系数y设置为0.0002，学习率 $\\alpha$ 设置为0.001，训练迭代次数分别设为5、10、15次。",
    "context5": "为更准确地评估本文的推荐算法，使用数据集里的用户模拟在线用户，用户与用户之间相互独立，随机抽取5000名用户进行实验，将其平均分为5组，每组之间互不相交。首先对用户的数据进行预处理，把每个评分里电影对应的初始Genre集合作为新的一列附加在对应评分后，然后将每个用户数据按照时间戳排序，将每个用户的评分按照评分时间先后顺序的前$7 5 \\%$ 作为训练集，后 $2 5 \\%$ 作为测试集，训练集和测试集类型划分如表2所示，划分完数据之后，每个测试集的训练集和测试集数据约按照3:1分布，满足测试的需求。",
    "context6": "参考文献[21]的评价方法，使用平均绝对误差(Mean Absolute Error,MAE)和均方根误差(Root MeanSquaredError,RMSE)作为评价指标。假设使用测试集生成预测评分 $\\{ p ^ { ( 1 ) } , p ^ { ( 2 ) } , \\cdots , p ^ { ( i ) } \\}$ ，相对应的实际评分$R ( x ^ { ( i ) } )$ ,MAE 和RMSE的计算方法分别如公式(18)和公式(19)所示。",
    "context7": "$$\n\\ M A E = \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } | p ^ { ( i ) } - R ( x ^ { ( i ) } ) |\n$$",
    "context8": "$$\nR M S E = \\sqrt { \\frac { 1 } { N } \\sum _ { i = 1 } ^ { N } ( p ^ { ( i ) } - R ( x ^ { ( i ) } ) ) ^ { 2 } }\n$$",
    "context9": "这两种误差值越小，表示算法的预测准确度越高。",
    "context10": "表2测试数据划分标签数量",
    "context11": "<table><tr><td rowspan=\"2\">Genre\\Set</td><td colspan=\"2\">Set#1</td><td colspan=\"2\">Set#2</td><td colspan=\"2\">Set#3</td><td colspan=\"2\">Set#4</td><td colspan=\"2\">Set#5</td><td colspan=\"2\">Total</td></tr><tr><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td><td> Train</td><td>Test</td><td>Train</td><td>Test</td><td>Train</td><td>Test</td></tr><tr><td>Action</td><td>31 344</td><td>11 022</td><td>30990</td><td>11 147</td><td>27434</td><td>9686</td><td>30954</td><td>10891</td><td>30 661</td><td>10 924</td><td>151383</td><td>53 670</td></tr><tr><td>Adventure</td><td>24134</td><td>8561</td><td>24306</td><td>8679</td><td>21295</td><td>7528</td><td>23980</td><td>8 611</td><td>24 704</td><td>8763</td><td>118 419</td><td>42 142</td></tr><tr><td>Animation</td><td>5576</td><td>2559</td><td>5661</td><td>2533</td><td>5206</td><td>2275</td><td>5707</td><td>2520</td><td>6046</td><td>2722</td><td>28196</td><td>12 609</td></tr><tr><td>Children</td><td>9317</td><td>2 945</td><td>9180</td><td>2988</td><td>8220</td><td>2 602</td><td>8907</td><td>2819</td><td>10 115</td><td>3122</td><td>45 739</td><td>14 476</td></tr><tr><td>Comedy</td><td>42 591</td><td>14 162</td><td>42 343</td><td>13 892</td><td>37222</td><td>12 000</td><td>40770</td><td>13 269</td><td>44 719</td><td>14 557</td><td>207 645</td><td>67880</td></tr><tr><td>Crime</td><td>18 343</td><td>6071</td><td>18 627</td><td>6178</td><td>16251</td><td>5478</td><td>17 945</td><td>5953</td><td>18248</td><td>6207</td><td>89 414</td><td>29887</td></tr><tr><td>Documentary</td><td>906</td><td>800</td><td>897</td><td>799</td><td>760</td><td>750</td><td>875</td><td>786</td><td>941</td><td>848</td><td>4379</td><td>3983</td></tr><tr><td>Drama</td><td>48023</td><td>16 793</td><td>49 602</td><td>17 172</td><td>42 774</td><td>15 218</td><td>47 443</td><td>16580</td><td>49 783</td><td>17 723</td><td>237 625</td><td>83486</td></tr><tr><td>Fantasy</td><td>11 197</td><td>4472</td><td>11 210</td><td>4498</td><td>9873</td><td>3881</td><td>10 979</td><td>4357</td><td>11 578</td><td>4562</td><td>54 837</td><td>21 770</td></tr><tr><td>Film-Noir</td><td>1274</td><td>276</td><td>1223</td><td>324</td><td>1063</td><td>276</td><td>1278</td><td>306</td><td>1324</td><td>316</td><td>6162</td><td>1498</td></tr><tr><td>Horror</td><td>9156</td><td>3095</td><td>7674</td><td>2619</td><td>7544</td><td>2552</td><td>7678</td><td>2 655</td><td>8451</td><td>2707</td><td>40 503</td><td>13 628</td></tr><tr><td>IMAX</td><td>2 175</td><td>1424</td><td>2276</td><td>1485</td><td>1825</td><td>1268</td><td>2130</td><td>1374</td><td>2391</td><td>1491</td><td>10 797</td><td>7042</td></tr><tr><td>Musical</td><td>4828</td><td>1560</td><td>5025</td><td>1609</td><td>4298</td><td>1443</td><td>4814</td><td>1440</td><td>5256</td><td>1710</td><td>24 221</td><td>7762</td></tr><tr><td>Mystery</td><td>8895</td><td>2961</td><td>8707</td><td>2 929</td><td>7734</td><td>2 624</td><td>8494</td><td>2827</td><td>8817</td><td>2966</td><td>42 647</td><td>14 307</td></tr><tr><td>Romance</td><td>21 445</td><td>6704</td><td>22305</td><td>7008</td><td>18 970</td><td>5936</td><td>21486</td><td>6452</td><td>23009</td><td>7135</td><td>107 215</td><td>33235</td></tr><tr><td>Sci-Fi</td><td>18 223</td><td>6129</td><td>17 597</td><td>5988</td><td>15823</td><td>5342</td><td>17 444</td><td>6001</td><td>17 545</td><td>5949</td><td>86632</td><td>29 409</td></tr><tr><td>Thriller</td><td>30 174</td><td>10 228</td><td>29 597</td><td>10 126</td><td>26384</td><td>9126</td><td>28868</td><td>9893</td><td>29 582</td><td>10 154</td><td>144 605</td><td>49 527</td></tr><tr><td>War</td><td>5959</td><td>1732</td><td>6025</td><td>1836</td><td>5119</td><td>1520</td><td>6049</td><td>1816</td><td>6251</td><td>1855</td><td>29403</td><td>8759</td></tr><tr><td>Western</td><td>2 608</td><td>893</td><td>2357</td><td>805</td><td>2085</td><td>693</td><td>2360</td><td>798</td><td>2399</td><td>870</td><td>11 809</td><td>4 059</td></tr><tr><td>Total</td><td>296168</td><td>102 387</td><td>295 602</td><td>102 615</td><td>259 880</td><td>90198</td><td>288161</td><td>99 348</td><td>301820</td><td>104 581</td><td>1441 631</td><td>499 129</td></tr></table>"
  },
  "4.2参数影响": {
    "context1": "在本文所提 TGE (Time Genres Embedded)推荐算法中， $\\theta$ 参数的大小代表时间数据片段长度，过长的时间片段会造成片段内样本数量过于稀疏，导致趋势延伸准确度下降；而过短的时间片会造成时间片内数据量过少，造成时间片的特征值不精确，同时也会形成过多的冗余数据，因此时间片长度取值会对预测结果有较大影响，为探究 $\\theta$ 值与推荐效果之间的关系，实验分别按照不同训练迭代次数进行测试比较。",
    "context2": "参数 $\\theta$ 变化对评价指标MAE和RMSE 的影响如图2所示，可以看出参数 $\\theta$ 对实验结果影响较为明显。当 $\\theta$ 取值不同时，两种评价指标的结果也都发生了明显变化。为保证每个时间片内有足够的评分数量计算方差敛散度，参数 $\\theta$ 的初始值从3开始增长。随着 $\\theta$ 增长,MAE和RMSE的值逐渐减小。当 $\\theta$ 达到某个阈值之后(本实验阈值为10)，两指标的值开始逐渐增加。推荐效果随着参数 $\\theta$ 变化而变化的情况，反映出时间片长度所包含信息数量以及时间片的数量对推荐结果产生的影响，决定推荐效果的好坏。",
    "context3": "![](images/4109cb69cfa45852c90e0e74db54611118e07fe27a9ff49e840387ca52165539.jpg)  \n图2每种迭代参数 $\\theta$ 对预测的影响"
  },
  "4.3预测结果": {
    "context1": "本文选取4种经典推荐算法与TGE的评估结果进行比较:",
    "context2": "(1）NormalPredictor:假设训练集是正态分布情况下随机预测评分。",
    "context3": "(2)KNNBasic:一种基础的协同过滤算法。",
    "context4": "(3) $\\mathrm { S V D + + }$ ：在 SVD算法基础上考虑用户隐式评分的扩展。",
    "context5": "(4)NMF:一种基于非负矩阵分解的协同过滤算法。",
    "context6": "对于TGE的交叉验证，初始数据Init给定训练集的 $50 \\%$ 。再分别按迭代次数去将训练集平均划分若干有序数据段 $X _ { 1 }$ ， $X _ { 2 }$ ，…， $X _ { \\vert c \\nu \\vert }$ ，并将有序数据段分为训练段和测试段，每迭代一次再从上一次的测试段中抽出一段数据 $X _ { k }$ 按时序放入训练段，直至训练段数据完全被使用。最终各个算法的实验结果如表3所示。",
    "context7": "表3不同迭代参数和分组的各种算法MAE 和RMSE 比较结果",
    "context8": "<table><tr><td rowspan=\"3\">参数 方法</td><td rowspan=\"3\"> cv@n</td><td colspan=\"10\"> Group of Experimence (△)</td><td rowspan=\"2\"> Mean(∑Δ)</td></tr><tr><td colspan=\"2\">△=1</td><td colspan=\"2\">△=2</td><td colspan=\"2\">△=3</td><td colspan=\"2\">△=4</td><td colspan=\"2\">△=5</td></tr><tr><td> MAE</td><td>RMSE</td><td>MAE</td><td>RMSE</td><td>MAE</td><td>RMSE</td><td>MAE</td><td>RMSE</td><td> MAE</td><td>RMSE</td><td>MAE RMSE</td></tr><tr><td rowspan=\"3\">NormalPredictor</td><td>cv@5</td><td>1.1673</td><td>1.463</td><td>1.1224</td><td>1.4084</td><td>1.1498 1.44</td><td>1.1348</td><td>1.422</td><td>1.1265</td><td>1.4117</td><td>1.14016</td><td>1.429</td></tr><tr><td>Cv@10</td><td>1.1666</td><td>1.461</td><td>1.1241</td><td>1.4106</td><td>1.149 1.4385</td><td>1.1373</td><td>1.426</td><td>1.1273</td><td>1.4124</td><td>1.14086</td><td>1.4297</td></tr><tr><td>Cv@15</td><td>1.1689</td><td>1.464</td><td>1.1225 1.4083</td><td>1.1476</td><td>1.4386</td><td>1.1349</td><td>1.423</td><td>1.1301</td><td>1.417</td><td>1.1408</td><td>1.4302</td></tr><tr><td rowspan=\"3\">KNNBasic</td><td>cv@5</td><td>0.7346</td><td>0.96</td><td>0.7118</td><td>0.9326</td><td>0.7336</td><td>0.9537</td><td>0.715</td><td>0.93</td><td>0.7132 0.9244</td><td>0.72164</td><td>0.9401</td></tr><tr><td>Cv@10</td><td>0.7288</td><td>0.953</td><td>0.7064</td><td>0.9256</td><td>0.7283</td><td>0.9465</td><td>0.71 0.925</td><td>0.7085</td><td>0.9190</td><td>0.7164</td><td>0.9337</td></tr><tr><td>CV@15</td><td>0.7272</td><td>0.951</td><td>0.7049 0.924</td><td>0.7265</td><td>0.9449</td><td>0.7082</td><td>0.922</td><td>0.7069</td><td>0.9173</td><td>0.71474</td><td>0.9319</td></tr><tr><td rowspan=\"3\">SVD++</td><td>cv@5</td><td>0.6753</td><td>0.884</td><td>0.6533</td><td>0.8589</td><td>0.675</td><td>0.8807 0.6581</td><td>0.857</td><td>0.6601</td><td>0.8608</td><td>0.66436</td><td>0.8683</td></tr><tr><td>Cv@10</td><td>0.6706</td><td>0.879</td><td>0.6481</td><td>0.8529</td><td>0.6692</td><td>0.8742</td><td>0.6532 0.852</td><td>0.6558</td><td>0.8562</td><td>0.65938</td><td>0.8629</td></tr><tr><td>CV@15</td><td>0.6681</td><td>0.875</td><td>0.6465 0.8507</td><td>0.6687</td><td>0.873</td><td>0.6519</td><td>0.850</td><td>0.6533</td><td>0.8536</td><td>0.6577</td><td>0.8604</td></tr><tr><td rowspan=\"3\">NMF</td><td>cv@5</td><td>0.7173</td><td>0.939</td><td>0.6938</td><td>0.9074</td><td>0.7195</td><td>0.9346 0.7023</td><td>0.911</td><td>0.6986</td><td>0.908</td><td>0.7063</td><td>0.9199</td></tr><tr><td>Cv@10</td><td>0.7140</td><td>0.932</td><td>0.6892</td><td>0.9017</td><td>0.7119</td><td>0.9244</td><td>0.6966 0.905</td><td>0.6932</td><td>0.9005</td><td>0.70098</td><td>0.9127</td></tr><tr><td>Cv@15</td><td>0.7102</td><td>0.928</td><td>0.6878</td><td>0.8998 0.7115</td><td>0.924</td><td>0.6944</td><td>0.902</td><td>0.6929</td><td>0.9001</td><td>0.69936</td><td>0.9108</td></tr><tr><td rowspan=\"3\">TGE-CF</td><td>cv@5</td><td>0.6341</td><td>0.852</td><td>0.6233</td><td>0.8354</td><td>0.6334</td><td>0.8426</td><td>0.6289 0.840</td><td>0.6317</td><td>0.8472</td><td>0.63028</td><td>0.8434</td></tr><tr><td>Cv@10</td><td>0.6127</td><td>0.814</td><td>0.601</td><td>0.8115</td><td>0.6279</td><td>0.8393</td><td>0.5997 0.796</td><td>0.6176</td><td>0.8214</td><td>0.61178</td><td>0.8164</td></tr><tr><td>Cv@15</td><td>0.6023</td><td>0.795</td><td>0.5862</td><td>0.7822</td><td>0.6146</td><td>0.8081 0.5895</td><td>0.782</td><td>0.596</td><td>0.7941</td><td>0.59772</td><td>0.7922</td></tr></table>",
    "context9": "不同分组的测试结果比较如图3所示。TGE 算法与几种经典的算法相比有较大提高，即使在迭代次数最少的情况下，效果仍好于其他算法，充分说明了本文所提用户时序下商品类型兴趣变化关系的合理性和有效性。此外，TGE 推荐算法需要的电影类型信息和时间戳序列在实际场景中比较容易集中获取，不需要复杂的社交网络关系信息或是难以获取的用户标签信息，所以此方法在实际场景中应用更为广泛。",
    "context10": "![](images/4cfc43ef8c90298651d79dbc844c5560a0fde24eb02a4c97ee33217ee7e48ed4.jpg)  \n图3不同分组的测试结果比较"
  },
  "4.4时间评估": {
    "context1": "针对各种算法每次迭代和响应的具体时间做比较，实验运行环境为 Intel Core i5 CPU，主频为3.4GHz,8GB 的运行内存,Windows7系统,将5次迭代的时间平均值作为平均每次迭代的时间，响应时间指迭代更新后到程序完成结果计算一共消耗的时间,最终结果如表4所示。",
    "context2": "表4每次迭代的运行时间和响应时间",
    "context3": "<table><tr><td>评估方法</td><td>运行时间(s)</td><td>响应时间(s)</td></tr><tr><td>NormalPredictor</td><td>0.15</td><td>0.18</td></tr><tr><td>KNNBasic</td><td>0.50</td><td>2.79</td></tr><tr><td>SVD++</td><td>558.98</td><td>9.81</td></tr><tr><td>NMF</td><td>7.04</td><td>0.19</td></tr><tr><td>TGE-CF</td><td>1.15</td><td>0.15</td></tr></table>",
    "context4": "从表4 可知, $\\mathrm { S V D + + }$ 迭代和响应时间最长，远超过其他算法，这是因为 $\\mathrm { S V D + + }$ 算法在矩阵的填充和分解过程消耗了较多时间，在实际场景中随着数据增多会消耗大量时间，显然该算法时间效率太低。其次耗时较长的是基于非负矩阵分解的 NMF 算法，由此可以看出，在迭代过程中考虑关系越复杂则时间复杂度越高。NormalPredictor算法假设训练集是正态分布进行随机评估，没有考虑用户之间和商品之间的关系,对算法结果的精度影响很大。KNNBasic 只考虑邻居关系，每次迭代更新后查询相似的邻居会消耗很多时间，速度取决于用户邻居和评分数量。TGE 算法根据用户偏好类型时序波动变化趋势迭代预测，在保证推荐效果的同时，迭代时间在可接受范围且响应时间最短，在实际应用中能够快速响应用户的请求。"
  },
  "5结语": {
    "context1": "针对用户选购商品的行为，本文提出一种基于时序的用户对多类型兴趣波动趋势预测的推荐算法TGE，以用户对类型偏好随时间片变化的特征预测为目标。首先建立基于时间片划分的时序数据模型，初步抽取时间片特征，再对满足条件的用户类型兴趣波动趋势建模。通过训练框架提取训练特征，利用时序类型趋势特征的延伸性预测用户对商品的偏好度。实验结果表明，TGE 算法取得较好的预测效果，与其他经典算法相比，时间复杂度也得到改善，有效提升推荐系统的准确性和用户满意度。",
    "context2": "此外 TGE算法还有一些可改进的方面，例如对商品类型可以划分得更细，将用户社交评论与购买行为融合，结合时序挖掘用户在多种异源信息下更多的偏好特征变化趋势，以进一步改善推荐效果。"
  },
  "参考文献：": "",
  "50 数据分析与知识发现": {
    "context1": "[1] Goldberg D,Nichols D,Oki B M, et al.Using Collaborative Filtering toWeaveanInformationTapestry[J]. Communications of the ACM,1992,35(12): 61-71.   \n[2] Ma H,King I,Lyu MR.Learning to Recommend with Social Trust Ensemble[C]// Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval.ACM,2009:203-210.   \n[3] Konstas I, Stathopoulos V,Jose JM.On Social Networks and Collaborative Recommendation[C]//Proceedings of the 32nd International ACM SIGIR Conference on Research& Development in Information Retrieval.ACM,2009:195-202.   \n[4] Liu Z,Tan K,Wang XQ,et al.ALearning Framework for Temporal RecommendationWithout Explicit Iterative Optimization[J]. Applied Soft Computing,2018,67:529-539.   \n[5] Rendle S,Freudenthaler C,Schmidt-Thieme L.Factorizing PersonalizedMarkovChainsforNext-Basket Recommendation[C]// Proceedings of the 19th International Conference on World Wide Web. Springer, 2010:811-820.   \n[6] 印鉴，王智圣,李琪,等．基于大规模隐式反馈的个性化 推荐[J]．软件学报,2014,25(9):1953-1966.(Yin Jian,Wang Zhisheng,Li Qi,et al.Personalized Recommendation Based on Large-Scale Implicit Feedback[J]. Journal of Software, 2014,25(9): 1953-1966.)   \n[7] Jamali M,Ester M.A Matrix Factorization Technique with TrustPropagationforRecommendationinSocial Networks[C]// Proceedings of the 2010 ACM Conference on Recommender Systems.ACM,2010:135-142.   \n[8] Liu J,Wu C,Xiong Y, et al.List-Wise Probabilistic Matrix Factorization for Recommendation[J]. Information Sciences, 2014,278: 434-447.   \n[9] Koren Y. Collaborative Filtering with Temporal Dynamics[J]. Communications of the ACM,2010,53(4): 89-97.   \n[10]Hosseini S,Alizadeh K,Khodadadi A,et al.Recurrent Poisson Factorization for Temporal Recommendation[C]//Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.ACM,2017: 847-855.   \n[11] Xu Z, Yang Y, Hauptmann A G.A Discriminative CNN Video Representation for Event Detection[C]// Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition.IEEE,2014:1798-1807.   \n[12] Graves A,Mohamed AR, Hinton G. Speech Recognition with Deep Recurrent Neural Networks[C]// Proceedings of the 2013 IEEE International Conference on Acoustics,Speech and Signal Processing.IEEE,2013:6645-6649.   \n[13]Weng C,Yu D,Watanabe S,et al.Recurrent Deep Neural Networks for Robust Speech Recognition[Cl//Proceedings of the 2014 IEEE International Conference on Acoustics,Speech and Signal Processing.IEEE,2014: 5532-5536.   \n[14]Arevian G, Panchev C.Optimising the Hystereses of a Two Context Layer RNN for Text Classification[C]// Proceedings of the 2O07 IEEE International Joint Conference on Neural Networks.IEEE Press,2007:2936-2941.   \n[15]Wang C,Jiang F,Yang H.A Hybrid Framework for Text Modeling with Convolutional RNN[C]// Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery & Data Mining.ACM,2017:2061-2070.   \n[16] Selvin S,Vinayakumar R,Gopalakrishnan E A,et al.Stock Price Prediction Using LSTM，RNN and CNN-Sliding Window Model[C]// Proceedings of the 2017 International Conference on Advances in Computing.IEEE,2017:1643-1647.   \n[17]Madan R,Sarathimangipudi P.Predicting Computer Network Traffic:A Time Series Forecasting Approach Using DWT, ARIMA and RNN[C]//Proceedings of the 11th International Conference on Contemporary Computing.IEEE,2018:1-5.   \n[18] Yu F,Liu Q,Wu S,et al.A Dynamic Recurrent Model for Next Basket Recommendation[C]// Proceedings of the 39th International ACM SIGIR Conference.ACM,2016:729-732.   \n[19]田垅，刘宗田．最小二乘法分段直线拟合[J].计算机科学, 2012,39(S1): 482-484.(Tian Long,Liu Zongtian. Leastsquares Method Piecewise Linear Fitting[J]. Computer Science,2012,39(S1): 482-484.)   \n[20]Bottou L.Large-Scale Machine Learning with Stochastic Gradient Descent[C]//Proceedings of COMPSTAT'2010.2010:177-186.   \n[21] Chai T,Draxler R R.Root Mean Square Error (RMSE）or Mean Absolute Error (MAE)?- Arguments Against Avoiding RMSE in the Literature[J]. Geoscientific Model Development, 2014,7(3):1247-1250."
  },
  "作者贡献声明：": {
    "context1": "丁浩：采集、清洗和分析数据，进行实验，论文起草;  \n李树青：提出研究思路，设计研究方案，论文最终版本修订。"
  },
  "利益冲突声明：": {
    "context1": "所有作者声明不存在利益冲突关系。"
  },
  "支撑数据：": {
    "context1": "支撑数据由作者自存储,E-mail:415058975@qq.com。  \n[1]丁浩．商品类型分类数据.dat.实验分类数据.  \n[2]丁浩．时序化评分数据.dat.实验评分数据.",
    "context2": "收稿日期:2019-04-08   \n收修改稿日期:2019-06-12"
  },
  "Personalized Recommendation Based on Predictive Analysis of User's Interests": {
    "context1": "Ding HaoLi Shuqing (School of Information Engineering,Nanjing University of Finance and Economics,Nanjing 210o23, China)",
    "context2": "Abstract: [Objective] This paper tries to construct a time series prediction model based on the fluctuation of users' historical interests,aiming to improve therecommendationresults.[Methods] We added time atenuation factor to the ratings by each type ofusers and linearly fit the data fluctuation with neural network.Then,we chose the optimal parameters to compare the effectivenessof the proposed method. [Results] We conducted five rounds ofuser simulation tests and found the MAE and RMSE errors of the proposed method were reduced by $4 7 . 6 3 \\%$ and $4 4 . 6 1 \\%$ . [Limitations] Analysis oftime fluctuation relies onusers'historical data,thus,additional cold-start algorithm is needed to preprocess the data.[Conclusions] The proposed method could efectively analyze and predict the changing of interests in different commodities, and provide more accurate recommendation lists.",
    "context3": "Keywords: Time SeriesInterest Type Fluctuation AnalysisPersonalized Recommendation"
  }
}