{
  "original_filename": "full_9227.md",
  "自然语言检索中的中文分词技术研究进展及应用": {
    "context1": "何莘，王琬芜²",
    "context2": "(1.西安石油大学 机械工程学院，陕西 西安710065;2.浙江大学 信息科学与工程学院,浙江 杭州 310058)",
    "context3": "摘要：中文分词技术是实现自然语言检索的重要基础，是信息检索领域研究的关键课题，无论是专业信息检索系统还是搜索引擎都依赖于分词技术的研究成果。本文通过在国内外著名数据库中进行相关检索，分析了研究中文分词技术及其在著名搜索引擎中的应用。",
    "context4": "关键词：中文分词；自动分词；分词算法",
    "context5": "中图分类号：TP391,G354 文献标识码：A 文章编号:1007—7634(2008)05—0787—05"
  },
  "Research and Application of Chinese Word Segmentation Technical Based on Natural Language Information Retrieval": {
    "context1": "HE Xin’， WANG Wanwu²",
    "context2": "(1. School of Mechanical Engineering， Xi'an Shiyou University， Xi'an 71O065，China; 2.School of Irformation Science and Enginering，Zhejiang University，Hangzhou 31Oo58，China)",
    "context3": "Abstract:Chinese word segmentation technique is the important foundation that realize the natural language re trieval,also is the key topic of the research in information retrieval domain $\\cdot ^ { \\ast }$ Professional information retrieval system and search engine both depend on the research achievements of word segmentation technique ·This paper in dexes in the domestic and international famous database,then Chinese word segmentation technique has been analyzed in famous search engines is summarized.",
    "context4": "Key words :Chinese word segmentation ; automatic word segmentation ;word segmentation algorithm"
  },
  "1分词及分词算法": {
    "context1": "从中文自然语言句子中划分出有独立意义词的过程被称为分词。众所周知，英文是以词为单位的，词和词之间是靠空格隔开，而中文是以字为单位。由于中文词与词之间没有明确的边界，因此，中文分词技术中文信息处理的基础是机器翻译、分类、搜索引擎以及信息检索。中文分词技术属于自然语言处理技术的范畴，是语义理解过程中最初的一个环节，它将组成语句的核心词提炼出来供语义分析模块使用，在分词的过程中，如何能够恰当地提供足够的词来供分析程序处理，计算机如何完成这一过程？其处理过程就称为分词算法。现有的分词算法可分为三大类：基于字符串匹配的分词方法、基于理解的分词方法和基于统计的分词方法。"
  },
  "1.1基于字符串匹配的分词方法": {
    "context1": "这种方法又叫做机械分词方法，它是按照一定的策略将待分析的汉字串与一个“充分大的”机器词典中的词条进行匹配，若在词典中找到某个字符串，则匹配成功 (识别出一个词)。按照扫描方向的不同，串匹配分词方法可以分为正向匹配和逆向匹配；按照不同长度优先匹配的情况，可以分为最大（最长）匹配和最小（最短）匹配；按照是否与词性标注过程相结合，又可以分为单纯分词方法和分词与标注相结合的一体化方法。",
    "context2": "(1）正向最大匹配法（MM 法)。其基本思想为：设D为词典，MAX 表示D中的最大词长，str为待切分的字串，MM 法是每次从str 中取长度为MAX长度的子串与D中的词进行匹配，若成功，则该子串为词，指针后移MAX个汉字后继续匹配，否则子串逐次减一进行匹配。",
    "context3": "(2）逆向最大匹配法（RMM法）。RMM法的基本原理与MM法相同，不同的是分词的扫描方向，它是从右至左取子串进行匹配。统计结果表明，单纯使用正向最大匹配的错误率为1/169，单纯使用逆向最大匹配的错误率为1/245，显然，RMM 法在切分的准确率上比MM法有很大提高。",
    "context4": "（3）最少切分。可以将上述各种方法相互组合，例如：可以将正向最大匹配方法和逆向最大匹配方法结合起来构成双向匹配法。由于汉语单字成词的特点，正向最小匹配和逆向最小匹配一般很少使用。一般逆向匹配的切分精度略高于正向匹配，遇到的歧义现象也较少。统计结果表明，单纯使用正向最大匹配的错误率为 $1 / 1 6 9$ ，单纯使用逆向最大匹配的错误率为 $1 / 2 4 5$ 。但这种精度还远远不能满足实际的需要。实际使用的分词系统，都是把机械分词作为一种初分手段，还需通过利用各种其它的语言信息来进一步提高切分的准确率。",
    "context5": "一种方法是改进扫描方式，称为特征扫描或标志切分，优先在待分析字符串中识别和切分出一些带有明显特征的词，以这些词作为断点，可将原字符串分为较小的串再来进行机械分词，从而减少匹配的错误率。另一种方法是将分词和词类标注结合起来，利用丰富的词类信息对分词决策提供帮助，并且在标注过程中又反过来对分词结果进行检验、调整，从而极大地提高切分的准确率。"
  },
  "1.2基于理解的分词方法": {
    "context1": "这种分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。它通常包括：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。由于汉语语言知识的笼统、复杂性，难以将各种语言信息组织成机器可直接读取的形式，因此目前基于理解的分词系统还处在试验阶"
  },
  "1.3基于统计的分词方法": {
    "context1": "从形式上看，词是稳定的字的组合，因此在上下文中，相邻的字同时出现的次数越多，就越有可能构成一个词。因此字与字相邻共现的频率或概率能够较好的反映成词的可信度。可以对语句中相邻共现的各个字的组合的频度进行统计，计算它们的互现信息。定义两个字的互现信息，计算两个汉字X、Y的相邻共现概率。互现信息体现了汉字之间结合关系的紧密程度。当紧密程度高于某一个阈值时，便可认为此字组可能构成了一个词。这种方法只需对语句中的字组频度进行统计，不需要切分词典，因而又叫做无词典分词法或统计取词方法。但这种方法也有一定的局限性，会经常抽出一些共现频度高、但并不是词的常用字组，例如“这一”、“之一”、“有的”、“我的”、“许多的”等，并且对常用词的识别精度差。实际应用的统计分词系统都要使用一部基本的分词词典（常用词词典）进行串匹配分词，同时使用统计方法识别一些新的词，即将串频统计和串匹配结合起来，既发挥匹配分词切分速度快、效率高的特点，又利用了无词典分词结合上下文识别生词、自动消除歧义的优点。到底哪种分词算法的准确度更高，目前并无定论。对于任何一个成熟的分词系统来说，不可能单独依靠某一种算法来实现，需要综合不同的算法来处理不同的问题。"
  },
  "2　搜索引擎中的中文分词技术": {
    "context1": "要实现专业信息查询的中文搜索引擎，首要的问题就是中文分词。搜索引擎技术的研究，国外比中国要早近10年，从最早的Archie，到后来的 Excite，以及altvista、overture、google 等搜索引擎面世，搜索引擎发展至今，已经有十几年的历史，而国内开始研究搜索引擎是在上世纪末本世纪初。在许多领域，都是国外的产品和技术一统天下，特别是当某种技术在国外研究多年而国内才开始的情况下。例如操作系统、字处理软件、浏览器等等，但搜索引擎却是个例外。虽然在国外搜索引擎技术早就开始研究，但在国内还是陆续涌现出优秀的搜索引擎，如百度、中搜等。目前在中文搜索引擎领域，国内的搜索引擎已经和国外的搜索引擎效果上相差不远。之所以形成这样的局面，一个重要的原同，这其中对于计算机涉及的技术就是中文分词。",
    "context2": "对于搜索引擎技术，雅虎中国网页搜索部总监张勤认为，中文分词是搜索技术的基础，只有做好了分词，才能有好的搜索。分词速度及其准确性对搜索引擎来说十分重要，因为搜索引擎需要处理数以亿计的网页，如果分词耗用的时间过长，会严重影响搜索引擎内容更新的速度。因此对于搜索引擎来说，分词的准确性和速度，二者都需要达到很高的要求。目前在中文分词过程中，有两大难题一直没有完全突破。一是歧义识别，二是新词识别，这些还需要进一步解决。雅虎在中文分词技术上花了很多力气，在美国成立了研究所，共有300多人进行相关研究。目前，雅虎的搜索就是基于自己开发的中文分词技术。据了解，Google 的中文分词技术采用的是美国 Basis Technology 公司提供的中文分词技术，百度使用的是自己公司开发的分词技术。由此可见，中文分词的准确度，对搜索引擎结果相关性和准确性有相当大的关系。",
    "context3": "对于搜索引擎来说，分词的准确性和速度二者都需要达到很高的要求。目前国内研究中文分词的大多是科研院校，清华、北大、中科院、北京语言学院、东北大学、IBM研究院、微软中国研究院等都有自己的研究队伍，而真正专业研究中文分词的商业公司很少。科研院校研究的技术，大部分不能很快产品化，而一个专业公司的力量毕竟有限，看来中文分词技术要想更好的服务于更多的产品还需很长一段路。",
    "context4": "中文分词是其他中文信息处理的基础，搜索引擎只是中文分词的一个应用。其他的比如机器翻译(MT)、语音合成、自动分类、自动摘要、自动校对等等，都需要用到分词。因为中文需要分词，可能会影响一些研究，但同时也为一些企业带来机会，因为国外的计算机处理技术要想进入中国市场，首先也是要解决中文分词问题。在中文研究方面，相比外国人来说，中国人有十分明显的优势。"
  },
  "3国内外中文分词技术文献研究": {
    "context1": "（1）在国外，关于中文分词技术研究的国外文献 (本文定义为国外数据库中的文献)，我们在EngineeringVillage检索平台的三个数据库（IN-SPEC、EI、NTIS）进行了检索，在题目字段用检索式chinese and segmentation 进行检索，时间段限制在1990一2007，检索日期2007年8越27日，共检索到相关文献353 篇。其中EI数据库139 篇，IN-SPEC 数据库中214篇。对检索结果进行如下分析。",
    "context2": "作者分布。在353篇相关文献中，发表论文排名第一的作者是清华大学的 Ding xiaoqing，共 10篇，第二的是上海交通大学的 Shi，Peng Fei，共7篇。第三的是清华大学的 Jiang yan共6篇。其次发表5篇论文的5人，发表4篇论文的11人，发表论文3篇的 25人。发表论文2篇的有16人。",
    "context3": "作者单位分布。在353 篇相关文献中，发表论文前几名的作者单位分布如表1所示。",
    "context4": "表1作者单位分布表",
    "context5": "<table><tr><td>Author affiliation</td><td>命中 篇数</td></tr><tr><td>Dept·Of Electron·Eng·,Tsinghua Univ·, Beijing</td><td>6</td></tr><tr><td>Inst · Of Image Process ·Pattern Recognition,Shanghai Jiaotong Univ·</td><td>5</td></tr><tr><td>Natl Taiwan Univ</td><td>4</td></tr><tr><td>Tsinghua Univ</td><td>4</td></tr><tr><td>Sch· Of Inf ·Eng·,Beijing Univ·Of Posts Telecommun·</td><td>4</td></tr><tr><td>Inst · Of Image Process ·Pattern Recognition,Shanghai Jiao Tong Univ·</td><td>3</td></tr><tr><td>Dept · Of Syst·Eng· Eng·Manage·,Chinese Univ·Of Hong Kong</td><td>3</td></tr><tr><td>Dept·Of Electr·Eng·,Nat·Taiwan Univ·,Taipei</td><td>3</td></tr><tr><td>Inst · Of Commun·Eng.,Pla Univ· Of Sci·Technol., Nanjing</td><td>3</td></tr><tr><td>Inst · Of Opt·Sci·,Nat·Central Univ·,Chung—Li</td><td>3</td></tr><tr><td></td><td></td></tr><tr><td>Dept · Of Comput·Sci · Eng·,Chinese Univ · Of Hong Kong,Shatin</td><td>3</td></tr><tr><td>Dept·Of Comput·Sci ·Eng·,Harbin Inst·Of Technol ·</td><td>3</td></tr><tr><td>Dept·Of Inf ·Syst·Comput ·Sci·,Nat· Univ· Of Singapore</td><td>3</td></tr><tr><td>Dept · Of Comput·Sci·Inf ·Eng., Nat·Chiao Tung Univ·, Hsinchu</td><td>3</td></tr><tr><td>Coll·Of Comput Sci·Technol·,Jilin Univ·,Changchun</td><td>3</td></tr></table>",
    "context6": "国家分布。在353 篇相关文献中，发表论文前几名的国家分布如图1所示。",
    "context7": "发表论文的语种。在353 篇相关文献中，语种分布如图2所示。",
    "context8": "文献出版的年代分布。在353篇相关文献中，每年发表的文献数如图3所示。",
    "context9": "（2）在CNKI数据库中，我们用检索式： $\\textcircled{1}$ 中文and 分词， $\\textcircled{2}$ 汉语and分词， $\\textcircled{3}$ 自动and分词，检索时间段 $1 9 9 0 - 2 0 0 7$ 年，检索时间：2007年8月27日。检索结果如下：",
    "context10": "检索式 $\\textcircled{1}$ 检索结果：中文全文数据库80篇，中国优秀硕士学位论文19 篇，中国从重要报纸全文数据库2篇，中国博士学位论文全文数据库0篇，中国重要会议论文全文库9篇。共110篇。",
    "context11": "检索式 $\\textcircled{2}$ 检索结果：中文全文数据库146 篇，中国优秀硕士学位论文21篇，中国从重要报纸全文数据库0篇，中国博士学位论文全文数据库1篇，中国重要会议论文全文库14篇。共182篇。",
    "context12": "检索式 $\\textcircled{3}$ 检索结果：中文全文数据库122 篇，中国优秀硕士学位论文22篇：中国从重要报纸金文数据库（篇，中国博士学位论文全文数据库1篇，中国重要会议论文全文库11篇。共156 篇。",
    "context13": "![](images/5d10a24007b67674e35f407124d24fc22a9cc20953791c40672063e49781aaea.jpg)",
    "context14": "![](images/bbb5dbdc7d751ba7f7b66c864368798a71dd4f71dc06e0328b489b213c6e0f21.jpg)  \n图1发表论文前几名的国家分布图",
    "context15": "![](images/fb5060ccc48d03be3b3fff6e4c1c271a142ec67bcfc195602872deaf11b5d696.jpg)  \n图2发表论文前几名的语种分布图  \n图3年代分布图",
    "context16": "通过对检索出的文献进行被引情况分析，可以得出学术关注度如图4所示。",
    "context17": "![](images/cfdce8223825e7e54b5e2fc1596a72fadc97e3e5defa694ba875fefcd2f95b79.jpg)  \n图4学术关注度"
  },
  "热点年份自动分词的相关高频被引文章——这": {
    "context1": "些文章影响着学术发展的潮流。",
    "context2": "关于学术关注度，CNKI数据库中是这样定义的：以CNKI总库中与关键词最相关的文献数量为基础，统计关键词做为文献主题出现的次数，形成的学术界对某一学术领域关注度的量化表示。",
    "context3": "热点年份自动分词的相关高频被引文章一—这些文章影响着学术发展的潮流",
    "context4": "A利用汉字二元语法关系解决汉语自动分词中的交集型歧义",
    "context5": "孙茂松，黄昌宁，邹嘉彦，陆方，沈…-被引次数55次",
    "context6": "【作者单位】清华大学计算机科学与技术系；香港城市大学语言资讯科学研究中心;",
    "context7": "【文献出处】计算机研究与发展，1997年05期",
    "context8": "B基于无指导学习策略的无词表条件下的汉语自动分词",
    "context9": "孙茂松，肖明，邹嘉彦一 被引次数13次",
    "context10": "【作者单位】清华大学智能技术与系统国家重点实验室；香港城市大学语言资讯科学研究中心北京；",
    "context11": "【文献出处】计算机学报，2004年06期",
    "context12": "通过用户在CNKI系列数据库中所下载文章的数量，可以得出自动分词技术文献的用户关注度如图5所示。",
    "context13": "![](images/876a0eaab0b9c0a9c19a7243a4438015ffa9f758bd5cf5104ea78df6ecde1cf6.jpg)  \n图5用户关注度",
    "context14": "热点月份自动分词的相关高频浏览文章——这些文章当月被最多您的同行所研读",
    "context15": "A汉语自动分词与内容分析法研究2005年9月一知网节浏览次数13次B 汉语自动分词的研究现状与困难2005年12月－知网节浏览次数60 次C 中文信息处理中自动分词技术的研究与展望2006年3月一知网节浏览次数121次D 中文信息处理中自动分词技术的研究与展望2006 年5月一知网节浏览次数105 次E 汉语自动分词的研究现状与困难"
  },
  "4中文自动分词研究的重要历史成果": {
    "context1": "中文自动分词的研究起步于1980 年前后，当时国内学者开始对中文分类自动标引技术进行深入研究，目前已经能通过对文中反映主题的关键词的自动抽取与筛选，实现主题自动标引。自从1980年我国在中文自动分词方面取得初步进展之后，就逐步向中文文献自动标引方面深入。1983 年北航梁南元副教授第一个完成实现了第一个汉语自动分词系统CDWS，实现了对250O万字的现代汉语词频统计工作。此后又有数个系统问世，并提出了12 种分词方法，已经实现的自动分词系统就有六、七个。这些分词方法概括起来可分为两类：一类是基于统计的机械分词方法，一类是基于规则（知识）的专家系统的分词方法。这两类方法都存在切分错误，需要人工干预。1987年，作为国家“七五”攻关课题之一的现代汉语分词规范和自动分词方法，已由北京航空航天大学，北京语言学院等十几家单位同时承担，并取得了可喜的进展，目前正向实用化发展。我国在1989 年到1993年期间兴起了一股研究单汉字研究的热潮，由于后来研究自动标引的方向转向自动分词的研究，单汉字标引逐渐走入低潮。1990 年末，北京师范大学何克抗教授的课题组完成了实用的自动分词系统。台湾的“计算语言学学会”ROCLING）在1991年开始草拟分词规范，初步订定了中文分词的原则，并于1995年下半年起研拟《资讯处理用中文分词规范》希望能为中文资讯科技提供一套通用的参考，减少彼此之间的差异，为自然语言处理环境奠定良好基础。1995 年，叶新明通过对现有中文自动分词算法的分析，提出了适于中文文献的自动分词算法，该算法通过建立机读词表，以《中图法》作为分类标准，对中文文献实现了自动分类，在财政金融类文献上的测试准确率达到 $79 \\%$ 。1998 年初，由国家科委基础研究高技术司、国家高技术863计划智能计算机系统主题专家组、全国信标委非键盘输入分技术委员会组织的机器翻译系统、自动分词与标注、汉字识别系统、语音识别系统的测评结果，对229 个测试点的交集型歧义切分字段定点测试，北京工业大学计算机学院提交的系统，准确率为$6 8 . 5 6 \\%$ ，对 20 个测试点的多义组合型歧义切分字段定点测试，北京工业大学计算机学院提交的系统，准确率为 $40 . 0 0 \\%$ 。1998 年的863 测试包括自动分词和词性标注两项内容，在自动分词方面没有明显进展。"
  },
  "参考文献": {
    "context1": "1美国《工程索引》数据库·Engineering Village 检索平台 $\\left[ \\mathrm { E B } \\right]$ OL] · http://ww $\\because$ engineeringvillage2.org· $\\mathbf { c n } /$ ,2007—8-27.  \n2中国期刊网.CNKI检索平台·ttp://www $\\cdot$ cnki $\\cdot$ net[EB/OL].学术趋势， $2 0 0 7 - 8 - 2 7 $ ·  \n3梁南元·书面汉语自动分词系统——CDWS[J]·中文信息学报，1987,1(2):44-52.  \n4 周钦强·基于人工智能技术NaiveBayes文本自动分类系统研究[D].广东工业大学硕士学位论文,2005.  \n5许超,陈小荷·试评两种商用机译软件的汉语分析能力[D].机器翻译研究进展——2002年全国机器翻译研讨会论文集,2002.  \n6 李瀛寰·雅虎中文搜索从分词开始[N]·中国计算机报，2006—07—10.  \n7孙茂松·汉语自动分词研究的最新进展与应用一—清华大学相关工作介绍[D]·辉煌二十年——中国中文信息学会二十周年学术会议论文集,2001.20一41.",
    "context2": "(责任编辑：孙晓明)"
  },
  "（上接第786页）": {
    "context1": "4杨得前,严广乐,李红.产学研合作中的机会主义及其治理[J]·科学学与科学技术管理,2006,(9).38一41.  \n5江海,马强·重构适合高校的产学研合作模式[J]·科技管理研究,2004,(5)：18—20.  \n6刘本盛·关于产学研有机结合的模式研究[J]·管理世界,2000,(6):201—202.  \n7柳卸林·基于本土资源的重大创新——汉字处理系统案例研究[J].中国软科学,2006,(12)：44-57.  \n8肖渡,沈群红·产业资本与知识资本的合作——对东南大学吴锡应用科学和工程研究院产学研模式的分析[J].科研管理,1999,20,(6).39-46.  \n9 Cohen W,Levinthal D.Absorptive capacity :a new perspective onlearning and innovation[J]·Administrative Science Quarterly,1990,35(1):128-52."
  }
}