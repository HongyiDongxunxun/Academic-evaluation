{
  "original_filename": "full_1583.md",
  "《图书馆论坛》网络首发论文": {
    "context1": "题目： 以善治促善智——2024 世界人工智能大会人工智能治理专题综述  \n作者： 胡奕，李旭光，王子琰，王曼，陆颖颖，池毛毛  \n收稿日期: 2024-10-11  \n网络首发日期： 2024-12-30  \n引用格式： 胡奕，李旭光，王子琰，王曼，陆颖颖，池毛毛．以善治促善智 -2024世界人工智能大会人工智能治理专题综述[J/OL]．图书馆论坛.https://link.cnki.net/urlid/44.1306.g2.20241226.0955.002",
    "context2": "网络首发：在编辑部工作流程中，稿件从录用到出版要经历录用定稿、排版定稿、整期汇编定稿等阶段。录用定稿指内容已经确定，且通过同行评议、主编终审同意刊用的稿件。排版定稿指录用定稿按照期刊特定版式（包括网络呈现版式）排版后的稿件，可暂不确定出版年、卷、期和页码。整期汇编定稿指出版年、卷、期、页码均已确定的印刷或数字出版的整期汇编稿件。录用定稿网络首发稿件内容必须符合《出版管理条例》和《期刊出版管理规定》的有关规定；学术研究成果具有创新性、科学性和先进性，符合编辑部对刊文的录用要求，不存在学术不端行为及其他侵权行为；稿件内容应基本符合国家有关书刊编辑、出版的技术标准，正确使用和统一规范语言文字、符号、数字、外文字母、法定计量单位及地图标注等。为确保录用定稿网络首发的严肃性，录用定稿一经发布，不得修改论文题目、作者、机构名称和学术内容，只可基于编辑规范进行少量文字的修改。",
    "context3": "出版确认：纸质期刊编辑部通过与《中国学术期刊（光盘版)》电子杂志社有限公司签约，在《中国学术期刊（网络版)》出版传播平台上创办与纸质期刊内容一致的网络版，以单篇或整期出版形式，在印刷出版之前刊发论文的录用定稿、排版定稿、整期汇编定稿。因为《中国学术期刊（网络版)》是国家新闻出版广电总局批准的网络连续型出版物（ISSN2096-4188，CN11-6037/Z），所以签约期刊的网络版上网络首发论文视为正式出版。"
  },
  "《图书馆论坛》2025年": {
    "context1": "$2 ^ { * }$ 本文系青年泰山学者工程专项\"依托社交网站的消费者虚拟社区创新性知识转移研究”、国家自然科学基金面上项目\"共享平台供给者数字韧性的形成与作用机制研究：基于复杂适应系统视角”（72272138）和湖北省长江文化保护传承弘扬研究课题\"数字文旅赋能湖北乡村旅游民宿高质量发展对策研究”（项目编号：HCYK2024Y27）研究成果。"
  },
  "以善治促善智": "",
  "-2024世界人工智能大会人工智能治理专题综述\\*": {
    "context1": "胡奕，李旭光，王子琰，王曼，陆颖颖，池毛毛",
    "context2": "摘要文章围绕2024世界人工智能大会人工智能治理专题八场论坛，系统梳理专家发言，人工智能面临的风险，包括：技术层面存在数据、模型和系统挑战，社会层面存在伦理、经济和环境风险，国际层面包括全球安全、地缘政治和全球不平等以及资源分配不均等问题；提出人工智能的双重治理目标，包括：社会可持续发展与人本理念为核心；建议通过前沿技术方法研究，社会伦理与政策法律保障，多主体、跨行业、跨学科协同，以及全球治理深化，推动人工智能为人类社会可持续发展做出更大贡献。",
    "context3": "关键词 人工智能风险治理措施治理目标 会议综述引用本文格式 胡奕,李旭光,王子琰,等.以善治促善智——2024 世界人工智能大会人工智能治理专题综述[J].图书馆论坛,2025"
  },
  "Good Governance Promoting Good Intelligence: Summary of Special Topic on Artificial Intelligence Governance of the 2024 World AI Conference": {
    "context1": "HU Yi, LI Xuguang, WANG Ziyan, WANG Man, LU Yingying, CHI Maomao",
    "context2": "AbstractThis paperfocusesontheeight forums onartificial intellgencegovernanceat theO24 WorldArtificial Intelligence Conference, systematically reviewing expert speeches.Itidentifies the risks artificial intellgence faces, including technical challngesrelated to data,models,andsystems;societal risks involvingethics,economyand theenvironment；and interational isues suchas global securitygeopolitics,lobal inequalityandunevenresourcedistribution.It puts forwardthe dual governance goals of artificial intellgence, which mainly include sustainable social development and people-oriented concepts. Itisrcommended to promote artificial intellgence to makegreatercontributions tosustainable human development through researchoncuting-edge technological methods,the guarantee of social ethics,policies,andlaws,thecoordiation among multiple entities,across different industries and disciplines,and the depening of global governance. Key words artificial intellgence; risks; governance measures; govermance goals; conferencereview"
  },
  "0引言": {
    "context1": "在数字化转型背景下，人工智能（Artificial Intelligence，AI）成为高质量发展的关键。2024年7月4—6日，来自50多个国家和地区的1,300位科学家、企业家、政府官员等汇聚上海，参加了主题为\"以共商促共享，以善治促善智\"的\"2024 世界人工智能大会暨人工智能全球治理高级别会议”，共同探讨AI的发展方向和全球治理问题。国务院总理李强在致辞中呼呼在AI创新发展和安全治理方面深化创新合作、推动普惠发展和加强协同共治，以促进AI更好地服务于全球发展和增进人类福祉[1]。",
    "context2": "AI技术为社会带来新机遇的同时，也带来了巨大的治理挑战。积极探索治理措施体系以促进其可持续发展至关重要，因此AI治理成为本次会议的核心议题。AI技术具有巨大的经济价值与市场潜力2]，在带来效率增长和服务优化的同时，也存在冲击经济结构、影响就业市场、威胁个人隐私与数据安全、决策过程不够透明和可解释等风险[3]。当前全球积极探索AI治理措施，各国相继出台政策法规来规范和引导AI发展。例如，2023年8月，中国出台《生成式人工智能服务管理暂行办法》；2024年3月，欧洲议会通过《人工智能法案》。在产业界，科技巨头如谷歌、IBM等设立伦理治理的专门部门，制定内部治理准则[4]。在学术界，相关研究涵盖技术伦理、数据隐私、算法透明度等[5]]。尽管在政策、产业和学术研究领域已取得显著进展，但AI治理仍存在政策法规滞后、跨国协调困难、技术伦理难题等不足。为此，本文选定\"人工智能治理\"这一会议核心主题展开专题综述，提供AI治理方案与框架。与专题紧密相关的8个分论坛为\"前沿人工智能安全与治理论坛”（以下简称\"治理论坛\"）、“人工智能前沿技术的治理挑战与应对措施论坛”（以下简称\"措施论坛”）、“智能社会论坛——智能社会与全球治理框架”（以下简称\"社会论坛\"）、“隐私计算：助力大模型与数据可信融合发展论坛”（以下简称\"发展论坛”）、“人形机器人的法治与伦理论坛”（以下简称\"伦理论坛\"）、“国际AI安全前沿技术论坛”（以下简称\"技术论坛\"）、“AIGC 技术前瞻与产业实践”（以下简称\"AIGC论坛\"）、“人工智能新进展与社会科学的未来论坛”（以下简称\"未来论坛\"），聚焦于AI安全、前沿技术治理、智能社会建设、隐私计算、法律伦理、安全技术、生成式AI应用及跨学科影响，代表了最前沿的研究动态和实践经验，能够为AI的治理和发展提供全面深入的洞见。本文采用多渠道的数据收集以实现互相辅正：其一，观看相关论坛直播，并实时记录与截屏分析，最后小组成员间进行交叉核实；其二，运用专业辅助工具将会议发言的语音内容转为文字记录，对文字内容进行智能校对和整理；其三，从大会官网及多个权威平台收集与会议相关的新闻和信息，从不同视角丰富会议内容，确保了会议内容的可靠性和完整性。在此基础上，对收集到的会议内容展开深入分析，整理、归纳并分类专家建议，结合已有文献，提炼大会中的核心风险、治理目标与治理措施。通过统计不同分论坛中专家发言的频率，分析各个议题在人工智能治理中的重要性，评估专家观点的一致性。经过小组间的反复讨论和对比，修正并完善分析结果，最终构建全面治理框架，旨在推动全球AI治理的科学化和规范化，实现以\"善治促善智\"的目标。"
  },
  "1人工智能整体治理模型": {
    "context1": "专家在各个论坛深入讨论AI治理的核心问题，提出切实可行的方案和建议。通过对这些论坛内容进行分类归纳，本文描绘出一个AI整体治理模型。",
    "context2": "（1）风险管理：技术、社会和国际三层风险。AI治理首先面临的任务是有效识别并应对各种风险。技术层面的数据安全问题可能导致隐私泄露、模型的不透明可引发决策不可信、系统集成风险会影响技术应用效果等，这些风险直接威胁 AI技术的可靠性和安全性。社会层面的伦理、经济和环境风险，以及国际层面的全球安全、地缘政治和不平等问题，都与技术风险相互关联。专家在大会中剖析了这些风险，指出它们是制约AI健康发展的重要因素，治理措施必须针对这些风险进行有效防控。",
    "context3": "（2）治理目标：以社会可持续发展与人本理念为核心。AI治理的目标不仅要促进技术进步，还要确保其与社会的可持续发展紧密契合。专家指出，社会可持续发展包括推动绿色计算和提高能源效率、促进经济增长以及加强社会应用的融合与创新。同时，治理必须坚持“以人为本\"原则，保障公众在AI发展中的知情权和参与权，强化AI系统的适应性与可控性。",
    "context4": "（3）治理措施：技术、政策法规与国际合作等多维保障。治理措施在目标的指引下积极应对风险。",
    "context5": "首先，前沿技术方法研究推动治理，通过开发新的测试方法和改进技术工具，确保AI技术层面的风险得以缓解。技术层面的改进不仅提升AI系统的透明性和可控性，为人本化的技术创新提供坚实基础，而且确保其在多样化环境下的稳定应用，为社会可持续发展提供了技术保障。",
    "context6": "其次，制定政策法规，推动绿色计算和提升能源效率、加大税收优惠和政策补贴，促进AI在各个行业的绿色发展和经济可持续驱动；明确伦理原则和价值观体系并将其内化到 AI设计中，推动构建智能向善的AI治理框架。确保AI技术的发展与人类价值观和社会需求相一致，进一步巩固了社会可持续发展和人本目标的伦理和法律基础。",
    "context7": "再者，多主体、跨行业、跨学科的共同治理，通过综合各方的专业知识和资源，制定全面的治理策略，有利于解决经济、环境和社会层面的复杂风险。这种跨界合作不仅提升了AI技术的全面适用性和多方安全性，而且通过集体智慧有效解决了多领域的难题，为人本化的多主体协同发展和社会可持续的跨领域融合进步提供了动力。",
    "context8": "最后，全球视角下的治理，根据本国经济发展阶段和产业优势，出台促进AI与传统产业深度融合的政策，实现国内经济可持续发展；深化国际对话与合作，各国相互学习，共谋发展；通过建立国际层面统一的标准规范，减少数据跨国流动的风险。这种全球发展与治理不仅减少技术转移中的纠纷和数据泄露，缓解社会层面经济与环境等方面的风险，还减轻了全球不平等和资源分配不均的压力，为全球范围内以人为本的设计和社会可持续发展提供了国际支持。",
    "context9": "综上所述，治理目标为AI发展明确了方向，治理措施是在目标的指引下化解风险的具体行动策略，三者共同构成AI整体治理模型，如图1所示。",
    "context10": "![](images/a0e324cfa26260ac85b71d76e8ba1aa9a2ef73a299bdb2038635fd9ef6a9a1b2.jpg)  \n图1人工智能整体治理模型"
  },
  "2人工智能风险": {
    "context1": "与会专家指出，新一代AI技术形成诸多风险，这些风险不仅影响技术本身的可靠性和安全性，还涉及伦理、经济、环境等社会层面的重大问题，更对国际关系和全球治理体系提出了新的挑战。"
  },
  "2.1技术层面的风险": {
    "context1": "（1）数据安全与可用性风险。当前数据问题使企业和个人面临巨大经济和声誉损失风险。姚期智7、魏凯等8提出数据安全是核心难题，涵盖数据泄露、隐私保护不足、合规性问题、数据投毒和劫持等风险，威胁个人隐私和企业安全。余超凡针对大模型生命周期的预训练阶段，提出要关注内容安全，防止爬取的数据含有敏感信息，导致数据安全风险，这是对数据安全在特定阶段的具体关注。金耀初强调数据偏见影响决策公平，突出数据可用性的重要性，即数据不仅要安全，还要高质量、无偏见。张凌寒补充了数据质量和完整性的重要性，如果数据存在缺陷或不完整，AI模型的输出会受到影响，导致决策失误。",
    "context2": "（2）模型透明度与可解释性风险。许多模型的决策过程如同黑箱，难以被清晰地理解和解释。高文等和吴志强指出，模型的透明度与可解释性对增强用户信任具有关键作用，特别是在复杂决策过程中，用户需要理解模型的决策依据。姚期智[1]阐述了模型不可解释性带来的诸如信息误导和滥用的风险，以及可能引发的严重后果，如知识产权侵犯。",
    "context3": "（3）模型鲁棒性与可靠性风险。AI系统在面对对抗性攻击和异常输入时的脆弱性已成为突出问题，不仅关系到技术本身的稳定性，也关系到用户和社会安全[1]。模型鲁棒性与可靠性是AI技术的关键问题，风险的具体表现包括对抗性样本攻击、缺乏有效的通用防御机制、系统化以及鲁棒性不足。金耀初在此基础上补充影响模型鲁棒性的因素，模型对不确定性和噪声的敏感性可能影响其鲁棒性，导致任务处理错误。姚期智7和张亚勤[12]进一步将风险扩展到智能体失控层面，包括物理智能和生物智能领域的潜在威胁，如设计缺陷或外部干扰可能导致的意外伤害，以及生物实验室事故或生物武器误用的风险，这些都对人类健康和生态环境构成严重威胁。",
    "context4": "（4）系统集成与互操作风险。推动AI与其他技术的集成与互操作性是实现技术融合和创新的关键[13]。然而，在自动驾驶、智能家居等复杂应用场景中，系统集成与互操作性的风险日益凸显。在技术论坛圆桌讨论中，陈思恒指出，自动驾驶系统集成多种传感器和数据源时，可能引发新的安全问题。常永波进一步扩展到不同场景中的AI系统，特别是云端到云边端协同等系统集成过程中安全机制可能存在的不完备情况。"
  },
  "2.2社会层面的风险": {
    "context1": "（1）社会伦理风险。社会伦理问题研究从关注个体道德行为，到如今对整个社会系统的伦理考量。周伯文指出偏见和歧视等问题随技术进步日益凸显；王战则通过电信诈骗案例阐释技术对弱势群体的伤害，如AI换脸和变声对老年人构成的威胁。邵怡蕾将讨论扩展到人形机器人领域的新伦理问题，提出关于机器人是否应具有法律人格，以及人与机器人之间的情感依赖等。Peter Railton警示，AI系统的自主性可能导致其目标与人类目标不一致，甚至存在脱离人类控制的风险。",
    "context2": "（2）经济风险。关于AI经济风险的研究，从早期对就业岗位的简单分析，到如今对整个经济结构和社会公平的综合考量[14]。魏凯等[12]和BenjamiReichenbach关注AI技术对劳动力市场的直接影响，包括就业岗位的消失和新岗位的创造。苏竣扩展了该讨论，强调 AI不仅替代体力劳动，还可能替代创造型劳动和知识型劳动，对金融、医疗、法律等行业产生重大影响。Yoshua Bengio 进一步提出技术鸿沟加大和市场集中度提高导致社会不平等和资源分配不公，甚至使资源和财富集中在少数国家和公司，加剧全球经济不平等。",
    "context3": "（3）环境风险。AI发展消耗大量能源，不合理使用也会加剧环境风险[15]。魏凯等从实际的应用场景中指出AI的能耗问题突出，强调AI的计算密集型特性，特别是数据中心和大模型训练对能源消耗和碳排放的显著影响。韦韬关注AI行业发展模式和投资行为对环境的影响，特别是行业从通算向智算转变过程中的过度投资问题，以及由此带来的能源消耗挑战。苏竣[和 YoshuaBengio指出AI技术可能潜藏与可持续发展理念的不匹配。AI技术的发展若缺乏整体合理规划，则会与绿色发展存在矛盾，加剧能源需求压力。"
  },
  "2.3国际层面的风险": {
    "context1": "（1）全球安全风险。全球安全风险不仅局限于技术层面，更深入地触及数据隐私、社会稳定乃至全球战略安全的核心问题。Christoph Kronke警告说，如果没有统一的国际数据保护标准，数据泄露和滥用的风险增加，进而对全球安全构成威胁。杨波强调，若是很难保障数据的可信流通，不仅对个人和社会造成损害，还会对全球安全带来极大挑战。Duncan Cass-Beggs[7从AI技术应用本身角度指出，AI在全球范围内的应用增加了像失控的超级智能和武器化这样的风险。与Kronke观点类似，他进一步提到由于缺乏统一的框架公约和国际法规，各国在AI领域往往各自为政，使得对AI技术的监管更加困难，进一步加剧了对全球安全的威胁。",
    "context2": "（2）地缘政治风险。各国在AI领域的技术封锁和对抗时有发生，对国际合作产生了负面影响。薛澜[8]、胡郁和Mariano-Florentino(Tino) Cuellar从整体状况评价，地缘政治关系恶劣阻碍国际AI合作，而国际AI恶性竞争又会使地缘政治关系更加恶化。Matt Sheehan[9和薛澜[具体阐述中美竞争在这方面的影响，认为AI竞争不仅会导致技术发展的不均衡，还可能进一步加剧地缘政治紧张局势。Irene Solaiman通过实例展现地缘政治风险对国际 AI合作的具体阻碍，阐述很多公司对某些国家限制API访问的现象，不仅体现了地缘政治对企业行为的影响，也反映了技术合作在政治压力下的脆弱性。",
    "context3": "（3）全球不平等和资源分配不均。AI发展不仅造成技术差距，还在就业、数据获取和信息平权等方面加剧了全球不平等[17]。薛澜[和GaelVaroquaux 关注到AI发展导致的技术鸿沟问题。Varoquaux 进一步认为技术和资源的集中会导致落后的国家和地区难以跟上发展步伐，加剧全球不平等和社会不稳定。周伯文对AI可能引发的就业结构变化及社会系统性风险表达担忧，他认为这种变化在发展中国家可能更加明显，加剧了这些国家的社会不平等和资源分配不均。在未来论坛的圆桌对话中，熊易寒预测未来超级人类与亚人分化的可能性，强调在资源分配和机会获取方面可能加剧信息平权失衡与数字鸿沟风险。",
    "context4": "综上所述，AI技术虽为人类社会带来巨大进步,但也伴随着交织交融的诸多风险。首先，技术层面的数据泄露问题可能导致个人隐私侵害和社会不信任，而数据偏见问题会导致 AI系统在决策中存在不公现象，进一步加剧社会偏见和经济差距。由于发展中国家在技术和资源上处于劣势，难以应对这些风险，因此这些社会问题最终会影响到全球不平等和资源分配不均风险。其次，技术风险中的数据安全问题也能直接影响国际层面风险。大量敏感数据在全球范围内流动，如果数据保护不力，导致重要数据被窃取或滥用，可能涉及国家机密和战略资源，从而产生全球安全风险。最后，国际层面的风险也会反过来影响社会和技术层面。地缘政治风险导致技术冲突和贸易壁垒增加，限制技术的交流与合作，从而阻碍技术的创新和发展。而在社会层面，全球不平等和资源分配不均的国际风险，导致一些社会群体无法享受到AI带来的福利，可能加剧社会分裂和不稳定。如图2所示。",
    "context5": "![](images/900d530024a43ff59c441ec808321a1af569bd7af242b8f14af44501edd58a8f.jpg)  \n图2人工智能风险"
  },
  "3人工智能治理的双重目标": {
    "context1": "专家们在多场论坛中指出，AI领域风险的根源不仅源于技术本身的局限性，更深层次的原因在于AI的设计和应用未能充分考虑到社会可持续发展和以人为本的核心价值[18]。AI快速发展往往侧重于技术创新和经济效益的最大化，忽视了技术发展与社会需求之间的深度契合。AI发展若不以人为本，容易脱离人类的实际需求，甚至造成对个体隐私、自由与尊严的侵犯。因此，与会专家呼呼，AI治理目标应当与社会可持续性发展的长期目标、以人为本的伦理价值观相结合才能有效缓解这些风险，推动AI更好地造福社会。"
  },
  "3.1社会可持续发展的治理目标": {
    "context1": "推进AI助力联合国可持续发展目标的实现是联合国密切关注和重点推进的议题，也成为我国政府、学界、产业界的共识[19]。专家们强调，AI治理实现社会可持续发展需聚焦于环境、经济和社会3方面的核心任务[20][21]。"
  },
  "3.1.1推动人工智能的绿色发展": {
    "context1": "根据专家研讨的观点，要推动在全球范围内构建一个绿色、高效和可持续的AI治理体系，确保技术发展的同时带来环境效益和社会福祉。在发展论坛中，金和平指出AI应用生态构建需要算力、算法和数据支持，因此绿色能源和绿色算力是AI走向绿色发展、提升能源效率的必经之路。基于此，苏竣在社会论坛中的观点强调了通过技术创新实现绿色发展的重要性，认为需要运用AI技术减少碳排放和提高能源效率。韦韬则为提升AI能源效率提供了具体思路，认为未来密态算力的普及有望降低数据流通成本，促进数字经济的绿色发展。曹建农在 AIGC 论坛中提出将大模型在云上训练好再部署到边缘设备上，以提升计算资源的利用效率和减少能源消耗的方案。AI的绿色发展不仅仅是对环境风险的回应，更是应对未来技术发展的可持续性挑战的必由之路。"
  },
  "3.1.2促进人工智能的经济可持续驱动": {
    "context1": "想让AI持续为经济发展注入源源不断的动力，不仅要关注其在微观层面的具体应用和实际效益，还需深入探究宏观层面的发展趋势与政策引领[22]。",
    "context2": "从微观层面看，AI在经济领域的应用和效益是促进其经济可持续驱动的关键。在社会论坛中，钟宁桦以AI模型在上海出口预测和城投债务风险预测中的应用为例，指出AI有望带来新一波经济繁荣。程浩在圆桌对话中进一步具体化企业在 AI方面的投入和共创，通过翻译和知识问答系统的应用案例强调技术的实际应用效果，展示AI在企业中的实际效益。",
    "context3": "从宏观角度而言，政策引领和对未来趋势的精准把控是推动AI实现经济可持续驱动的重要力量。刘敬谦在发展论坛中指出，国家政策和行业内生需求是推动大模型发展的关键因素，强调大模型可以为行业带来新的变现路径，提高数据的商业价值，从而促进整体技术进步。傅徐军在未来论坛的圆桌对话环节中认为，AI能极大提高工作效率，改变企业内部的信息管理方式，并预测未来AI原生组织的出现将带来生产力的质变。",
    "context4": "AI不仅是经济增长的动力源泉，也可以成为解决经济不平等和就业冲击的重要工具。通过推动AI应用的普及，尤其是在不同行业和领域的应用，可以有效促进经济结构的转型和社会资源的再分配，减少技术鸿沟和资源分配不均的全球性风险。同时，政策引导和社会创新将有助于缓解技术发展带来的社会冲击，推动经济增长与社会公平之间的平衡。"
  },
  "3.1.3强化人工智能的社会融合与创新应用": {
    "context1": "AI时代需追求经济与社会效益的协同提升，探寻可持续发展路径。",
    "context2": "首先，在理论层面，王浩[23]在社会论坛中强调科技创新的重要性，认为AI技术的广泛应用是推动社会各领域发展的关键。苏竣进一步阐释AI如何作为一种新质生产力，影响生产要素和产业结构，从而推动社会结构和人的观念的变革。在未来论坛的圆桌对话环节中，Toby Walsh从社会科学研究角度讨论了如何通过AI生成和综合信息的能力，推动社会科学研究方法的创新和发展。",
    "context3": "其次，在实际应用层面，吴志强9从城市规划角度出发，以深圳为例展示AI如何确保城市运行的平稳和安全，以及在武汉“封城”的特殊情况下如何帮助社会恢复信心，这体现了AI技术在实现社会可持续发展中的具体作用。",
    "context4": "AI创新应用不仅能推动社会进步，还能增强社会的整体融合。通过在城市管理、公共服务等领域的应用，AI能够提升决策透明度和公正性，帮助弥合不同社会群体之间的鸿沟，助力解决社会伦理风险。同时，社会的整体融合增强能减少地缘政治风险对技术发展的影响，推动国际合作与文化融合，确保AI技术能够在全球范围内促进共同繁荣与社会和谐。"
  },
  "3.2以人为本的治理目标": {
    "context1": "关于实现以人为本的 AI 治理目标[24][25]，与会专家的观点集中于立足\"智能向善\"的基本理念，提升AI系统的开放性和透明度，增强AI系统的适应性和可控性。"
  },
  "3.2.1立足“智能向善\"的基本理念": {
    "context1": "智能向善，意在规范AI在法律、伦理和人道主义层面的价值取向，确保AI发展安全可控[2。一方面，在\"智能向善\"理念深化和拓展上，吴志强在社会论坛中提出\"Human andAI（HAI）主义\"概念，指出所有技术进步都应以人为本，AI发展必须立足人的需求。张凌寒和高文在治理论坛中分别从价值取向和社会影响两个角度出发，深化了智能向善的理念。张凌寒提出构建\"基于价值\"的 AI 治理体系，强调技术创新要注重法律伦理和人道主义的价值取向。高文则提出AI技术不仅要高效安全，还要对社会产生正面影响。另一方面，从\"智能向善\"具体行动层面出发，应对论坛上发布的《中国人工智能重大应用场景白皮书》中的智能向善（AIforGood）倡议书，提出加强场景示范以提升应用推广，加强伙伴互动来共谋合作发展，组织活动会议并参与国际对话，加强专业培训以壮大人才队伍等一系列措施，提供了实现全球共识的具体行动指南。",
    "context2": "AI技术发展必须紧密对接社会实际需求，避免技术走向脱离人类关切的方向，防止可能出现的社会伦理问题，如侵犯个人隐私、歧视性决策等。通过确保技术进步与人类的伦理价值观相一致，降低技术带来的社会不稳定性，避免技术滥用对全球安全和社会秩序的负面影响。"
  },
  "3.2.2提升人工智能的开放性和透明度": {
    "context1": "开放和透明的AI治理是实现以人为本目标的重要途径[27]。Irene Solaiman 在治理论坛中强调开放性的重要性，不仅关注模型，还包括数据集、反馈数据集、评估数据集等。她认为，开放性有助于社区分享不同的观点与专业知识，增强公众参与度。GaelVaroquaux 的开源观点与Solaiman的开放性理念相辅相成，他认为开源是促进创新和消除偏见的关键。Mariano-Florentino(Tino)Cuellar和RobertF.Trager 将开放性和透明度的议题放在国际层面上。Cuellar提到国际合作的重要性，特别是在技术变革和地缘政治影响下。Trager提出要建立国际报告制度，为实现开放性提供了一种可能的机制。他认为，这种制度将有助于跟踪和管理AI 的开发和部署，进一步增强AI模型的透明度和问责制。在应对论坛中，郭毅可[7讨论了区块链技术、加密和匿名化技术的透明性和不可篡改性，通过提升数据安全水平来支持AI技术的发展，符合以人为本的治理理念。",
    "context2": "提升AI发展的透明度至关重要，通过信息公开和加强透明度，保障公众的知情权和参与权，确保技术决策过程不被垄断。开放性不仅体现在数据、模型和算法的共享上，还包括对 AI应用过程中潜在风险的公开讨论和监督。公平的参与机制尤其能为发展中国家提供更多资源，帮助缩小数字鸿沟，进而缓解全球不平等和资源分配不均等问题。"
  },
  "3.2.3增强人工智能的适应性和可控性": {
    "context1": "“以人为本\"的要求促使开发者努力提高系统的适应性，根据不同的场景灵活调整和优化，以更好地满足人类多样化的需求；并且加强可控性，确保人类能够对 AI的行为和结果进行有效的监督和干预，以避免潜在的风险和危害[28]。",
    "context2": "首先，在提升AI系统的适应性方面，隐私计算产品能够实现多源数据的融合与共享、在不同的组织或机构之间进行联合训练，从而适应更多样化的任务和场景。在此基础上，杨波和王磊分别提出要基于不同场景进行隐私计算产品的安全考量和分级，制定分级标准。同时也要开发更多防御措施，适应不同场景的需求，满足不同安全分级要求，更大程度上地提升AI系统的适应性。",
    "context3": "其次，在提升AI系统可控性方面，StuartRussell从系统设计的底层逻辑入手，提出使用逻辑和概率理论重新构建AI系统，确保其内部操作透明。曾毅则探讨了AI安全边界的重新定义和新的红线类别，划定了AI系统不能逾越的界限，为AI治理提供了更为明确的安全指导。郭毅可[12]在应对论坛中从制度和管理层面，为AI系统的运行建立严格的规范和约束机制，强调制定明确的政策框架、有效的数据分类和归类、访问控制和权限管理的重要性。",
    "context4": "AI系统必须具备足够的适应性，能够应对复杂多变的社会需求，确保技术的安全性和可控性，为此需要解决AI模型不可解释性、系统脆弱性等技术性问题。同时，稳定的技术架构不仅有助于减少因技术差异引发的国际地缘政治风险，也能在全球范围内推动 AI技术更加平等和可持续发展，从而缓解由技术进步不均衡带来的社会冲突和国际紧张关系。",
    "context5": "AI治理的双重目标如图3所示。",
    "context6": "![](images/9bb4a34da0bb6d544d5435913c08b1f8c4c010a42c89ebd67a3db667932b6fd8.jpg)  \n图3人工智能治理的双重目标"
  },
  "4人工智能治理的具体措施": {
    "context1": "本次会议关于“人工智能治理\"报告范围不仅包括前沿技术方法的研究，还涵盖社会伦理和政策法律的制定与执行，多主体、跨行业、跨学科的协同治理以及全球视角下的AI 治理措施。"
  },
  "4.1前沿技术方法研究": {
    "context1": "在各场专业技术报告与深度交流环节，专家们的观点强调三大核心技术路径：技术标准化与优化、对抗性攻击与防御机制构建、隐私计算与数据管理融合。三大路径从根本上强化AI安全性与稳定性，为AI技术\"智能向善”、服务社会的可持续进程指明了方向。"
  },
  "4.1.1技术标准化与优化": {
    "context1": "工信部等部门指出，在AI等关键领域需加快研制一系列重要技术标准，强化关键技术领域标准攻关；通过不断优化技术，提升标准的适用性和有效性，从而加强标准化与科技创新之间的良好互动[29]。",
    "context2": "在治理论坛中，高文首先提出包括模型设计、训练方法、数据集和安全保障的标准化，通过优化算法和硬件技术，确保 AI系统的安全性和可靠性。张凌寒进一步强调标准化技术在数据处理中的重要性，提出通过匿名化技术和加密技术保障数据安全。在技术论坛中，杨耀东则展示了技术标准化在提升AI系统性能和稳定性方面的成功应用，提到对齐技术的重要性，包括使用RHF 进行对齐、改进预训练阶段以减少模型弹性、开发BeaverTell和 Beaver模型等技术手段。在发展论坛的圆桌讨论中，余超凡进一步说明了标准化技术在各阶段的必要性，提到密态技术在预训练、微调和推理阶段的应用对于保护IP安全性至关重要。最后，在 AIGC 论坛上，曹建农强调优化措施对于确保AI系统的安全性同样关键，提出大模型在云上训练好再部署到边缘设备上，并强调采用协作式的边缘计算和联邦学习/联邦微调。AI技术的标准化与优化不仅确保系统安全性和可靠性，还通过数据保护和隐私保障提升整体性能，推动技术在各个阶段的安全应用与创新发展。"
  },
  "4.1.2对抗性攻击与防御机制": {
    "context1": "通过不断优化对抗性攻击的防御机制，有效提升AI系统的鲁棒性，增强其在面对恶意攻击时的稳定性，从而推动AI技术的安全可控发展。在治理论坛中，YoshuaBengio 首先指出，现有的安全保护措施，如传统的加密技术和访问控制，在面对诸如模型反转攻击、数据投毒等新型对抗性手段时，容易被绕过或突破，这迫切需要研发更先进有效的防御机制。ChrisMeserole建议，通过建立基准和自动化的评估方式来评估AI系统的性能和安全性，同时通过对抗性防御和表征工程来提高AI的透明度和安全性。这一观点得到Dawn Song的补充，她强调开发防御方法以提高模型的鲁棒性和抗扰动能力，常用方法包括对抗训练、梯度遮蔽、随机化/正则化和去噪等。在技术论坛中，Zico Kolter 总结了当前对抗攻击的常用防御方法，如对抗训练、输入输出过滤和提示重写，还提出包括慢速对抗训练、主成分分析和断路器等改进方法。对抗性攻击防御机制的研究亟须创新，现有方法虽然有效但在白盒环境下仍存在突破的风险，持续优化和开发更强大的防御技术是保障AI系统安全性的关键。"
  },
  "4.1.3隐私计算与数据管理的融合": {
    "context1": "通过综合性的技术与管理措施，可以确保AI技术在保护数据安全和隐私的同时，实现“可信\"的融合发展，让AI在安全可靠的环境下稳定运行。在发展论坛圆桌讨论中，刘敬谦提出，为确保数据的合法使用和安全存储，必须管理数据的全生命周期，包括数据获取、标注、使用和存储，并监控数据流向；隐私计算应融入业务流程，与网络技术结合，以提升数据传输过程中的安全性。余超凡从大模型的生命周期角度出发讨论密算技术在预训练、微调和推理阶段的应用，强调在这些阶段中保护数据资产和用户隐私的重要性。刘健提倡使用隐私计算算法实现快速的隐私推理，并探索硬件加速技术以提高性能，同时在实时性要求较低的场景中先行应用隐私计算技术，以促进技术的实际发展和普及。袁博强调隐私计算和大模型结合的性能评估的重要性，提出功能性、安全性和可用性3个关键评估指标，呼呼制定新的标准以适应大模型应用；建议发展开源数据集和语料库，推动生态合作，以促进性能与算法的提升，平衡安全性和可用性。隐私计算与数据管理的融合是确保AI安全、可靠运行的关键，需在全生命周期中保护数据资产和用户隐私。",
    "context2": "前沿技术方法层面的各项治理措施与AI治理目标深度关联。技术标准化与优化为实现绿色发展提供了技术支撑，促使AI系统在能源利用等方面遵循统一标准，减少能耗，同时有助于经济节约，通过标准化降低行业应用成本，提升效率，进而推动社会融合创新。在以人为本方面，保障了系统的安全性和可靠性，体现“智能向善”，增强公众信任；对抗性攻击与防御机制的强化有助于在社会层面维护关键领域系统稳定，减少经济损失和避免社会混乱，从技术层面提升鲁棒性，契合以人为本对技术安全可控的要求；隐私计算与数据管理融合既推动数据要素合理利用促进经济可持续发展，又在社会层面保护隐私提升公众信任，有利于社会融合创新，同时体现了对个体权益的重视，有助于构建可持续且以人为本的AI发展格局。",
    "context3": "各项治理措施对AI领域风险起到了很好的防治作用。通过优化算法、硬件技术以及相关的隐私计算技术，缓解技术层面的数据安全性与可用性、模型透明度与可解释性风险；最新的对抗性攻击防御方法，能够帮助解决模型鲁棒性与可靠性风险。这不仅能防止技术失效和误用，还能防止技术滥用和恶意使用，因此也能减少社会层面的伦理和经济风险，提升AI技术的可信度和社会接受度。同时，标准化技术可以促进统一的框架公约和国际法规制定，有助于减少国家间的技术竞争和对抗，从而缓解全球安全风险和地缘政治风险。"
  }
}