{
  "original_filename": "full_9492.md",
  "论文被引频次标准化方法研究进展": {
    "context1": "周群,左文革（中国农业大学 图书馆，北京100193)",
    "context2": "摘要：【目的/意义】梳理论文被引频次标准化过程中参照标准的选择和主要方法的研究进展,有助于构建全方位的学术论文评价体系，为当前的科技评价提供有力的信息支撑和公平保障【方法/过程】利用文献调研方法对相关理论进行梳理和归纳分析【结果/结论】在对比分析被引端标准化和施引端标准化方法的基础上,指出随着网络与信息技术的发展，数据源和评价模式也不断拓展，在进行传统引文分析评价方法的同时,还应充分借鉴基于引文内容的论文评价和替代计量学评价方法,进而在更高的信息集成水平上形成更具权威性的意见。",
    "context3": "关键词：被引频次；标准化；学术影响力；被引端；施引端 中图分类号：G250.2 DOI:10.13833/j.issn.1007-7634.2018.02.030"
  },
  "Research Progress of Normalization Methods of Citation Counts": {
    "context1": "ZHOU Qun, ZUO Wen- ge (Library of China Agricultural University,Beijing 100193, China)",
    "context2": "Abstract:【Purpose/significance】The paper reviews research progressof normalization methods of citation counts and the choiceof reference standard.It is helpful to construct a comprehensive evaluationsystem of academic papers and provide powerful information support andfair guarante for thescientific and technological evaluation.【Method/process】The paper uses theliterature investigationmethod to sort outand analyzetherelevant theories.【Result/conclusionBasedonthecomparisonofthe methodsof cited-side normalizationandciting-side nrmalization,it ispointedoutthatwith the development of network and information technology,thedata source and evaluation modearealsoexpanding.Inthe proces oftraditional citationanalysis,weshoulddrawamoreauthoritativeopiniononthehigherlevelofinformationintegration withreference to citation content analysis and altmetrics.",
    "context3": "Keywords: citation counts; normalization; cited-side; citing-side"
  },
  "1引言": {
    "context1": "1955年，Garfield首次提出应用论文被引频次作为评价其学术水平和影响力的计量指标，随后，以引文分析为代表的文献计量评价逐渐打破了同行评议在科技评价中的主导地位。目前，论文被引频次已经成为衡量论文学术影响力最具代表性的指标，作为绩效评价中的主要工具，基于被引频次的文献计量指标广泛应用于研究水平测度、科研绩效评价、学术期刊评价等方面。",
    "context2": "论文被引频次从定量角度衡量文献被学术领域科研人员利用的程度，反映了论文的质量和影响力，是科研评价中最重要和最常用的指标。在实际运用过程中，不仅需要比较某学科领域内各个研究实体的学术影响力,还需要在不同学科领域之间进行比较。由于不同学科领域的引用行为和引用潜力都存在较大的差异，不同学科领域的论文被引频次不能直接进行比较。为了消除不同学科领域之间引用行为的差异性，论文被引频次必须经过标准化处理才能尽可能公平可靠地比较不同领域的学术影响力。",
    "context3": "目前，论文被引频次标准化主要是学科标准化方法，标准化过程中的学科背景因素一般称为参照标准(ReferenceStandard),参照标准的确定为被引频次标准化奠定了基础，从而可以支持不同学科领域间论文质量的比较。本文在概述目前参照标准的选择与改进的基础上，分别论述论文被引频次标准化的相关指标和研究实践,为文献计量指标改进和学术影响力评价的深入研究提供参考。"
  },
  "2 参照标准的选择": {
    "context1": "可用于引文分析的数据库主要有Web of Science Scopus和Google Scholar,作为被引频次标准化研究的主要数据源，其学科分类体系也是常用的参照标准，其中以Webof Sci-ence的JCR主题类最为常用。固定的学科分类体系通常是为了方便检索而设置,用于科技评价并不合适[],在分类上过于宽泛导致主题交叉重叠,多学科期刊文章无法归入具体学科[3]。基于JCR主题类的标准化指标容易受到论文聚类水平的影响，在不同聚类水平可以得出同样合理但截然不同的观点[4。在论文被引频次标准化过程中,研究人员对参照标准进行了许多有益的改进与探索。",
    "context2": "(1)在JCR主题类的基础上进行改进；Glanzel[提出将多学科期刊如Nature或Science中的文章根据其参考文献重新分配到相应的学科中，解决了多学科期刊论文无法分类的问题;国内有学者采用参考文献分析方法与团队地址认知词分析方法，对综合性期刊Science中单篇论文进行学科划分；针对JCR主题类的多学科主题交叉重叠问题,Rons利用PBFN(Partition-Based Field Normalization)方法来获得更详细的分类体系，PBFN把评测论文中所涉及到的主题类重叠区域单独划为一个独立主题类来实现被引频次标准化，因而可以减少由于学科交叉带来的不确定性。",
    "context3": "(2)选择其他学科分类体系或专业领域数据库;除了上述三大数据库中的学科分类体系意外，不同的国家和地区也有各自不同的学科分类体系。对于某些特定学科领域的评估,Bornnman[]建议直接利用如化学文摘数据库(ChemicalAbstracts)[]或医学主题词表(MeSH terms)[0]等。",
    "context4": "(3)有研究人员提出新的学科分类体系;Waltman等[提出一种基于文章直接引用关系聚类的科学分类体系(algo-rithmically constructed classification systems,ACCS）,可以覆盖所有科学领域且每篇文章只归人唯一的学科领域。Kost-ofr2-13认为只有在主题相似文献集中评价某篇论文,并将其引文数量与主题相似文献集的引文数量做比较时,标准化方法才有意义。但该方法中主题相似文献集必须由领域专家手动获取，增加了具体实施的难度。Colliander[4在2015年提出类似的方法，即基于共有的参考文献和主题词代替专家获得相似文献集，简化了数据集的获取流程。",
    "context5": "(4)除上述采用固定的学科分类体系外，根据论文的参考文献、引证文献或期刊等生成的相关文献记录(Related Re-cords)也可以作为论文的参照标准;Schubert等[5在评测研究绩效时利用论文所属期刊作为参照标准来计算相对影响指标,并进一步探索利用Web of Science 中的Relation Records来构建论文的参照标准;Hutchins等[通过构建论文共引网络作为论文的参照标准,提出了一种基于论文水平的学术影响力评价指标。上述参照标准的确定为论文被引频次的标准化奠定了基础,也为绩效评价的实施提供了多种选择。"
  },
  "3 论文被引频次标准化方法": {
    "context1": "不同学科领域间的评价比较需要对论文被引频次标准化处理已经成为共识,对现有指标的不断改进,并在此基础上探索新的评价指标成为当前信息计量学领域的重要任务之一[17]。目前,论文被引频次标准化处理主要有两种方式：通过固定的学科分类体系来修正不同学科领域之间引用行为的标准化方法，即被引端标准化(cited-side normaliza-tion);修正基于不同学科领域施引论文或期刊引用行为的标准化方法,即施引端标准化(citing-side normalization)。"
  },
  "3.1被引端标准化方法": {
    "context1": "基于被引端的标准化方法研究由来已久，1981年，Ya-novsky[8就提出了“引用因子\"来衡量期刊学术影响力，随后,研究人员在此基础上不断提出新的标准化指标。本文将被引端标准化分为以下三种方法：基于篇均被引频次的标准化、基于篇均参考文献数(被引端的参考文献)的标准化和基于百分位数的标准化。"
  },
  "3.1.1 基于篇均被引频次的标准化": {
    "context1": "相对引用指标(Relative Citation Rate,RCR)是最常用的标准化指标，最早由Schubert等[提出，它是指以论文被引频次除以论文期望被引频次得到论文相对被引频次，期望被引频次即为参照标准中所有论文的平均被引频次。根据计算顺序的不同,相对影响指标可以分为AoR(averages of ra-tios)和RoA(ratios of averages)两种实现方式,其中RoA类型的代表性指标CPP/FCSm由荷兰莱顿大学CWTS(Centre forScience and Technology Studies)提出,曾被称为\"Crown Indi-cator”。该指标分别计算篇均被引频次和篇均期望被引频次的总和,再将两项相除。但Leydesdorff等[2o]认为应该首先对参照标准中每篇论文的被引频次进行标准化处理，上述计算方法忽略了单篇论文被引频次的标准化。2011年，CWTS在CPP/FCSm 指标的基础上提出 MNCS(Mean Normalized Cita-tion Score)并将其作为新的\"Crown Indicator\"[21l。该指标改变了CPP/FCSm的计算顺序,将每篇论文的被引频次除以期望被引频次之后累加，再将总和除以文章总数。",
    "context2": "$$\n\\mathrm { M N C S } { = } \\frac { 1 } { n } { \\sum _ { i = 1 } ^ { n } } \\frac { c _ { i } } { e _ { i } }\n$$",
    "context3": "其中， $\\mathrm { c _ { i } }$ 指论文i的被引频次， $\\mathrm { e _ { i } }$ 指参照标准所有论文的篇均被引频次，也即被引频次期望值，一般来说,如果相对影响指标值大于1则说明研究实体的研究水平高于该学科领域或世界的平均研究水平，反之则低于该学科领域或世界的平均研究水平。大多数研究更倾向于认同以MNCS为代表的AoR类型指标,其应用也最为广泛。近几年来，基于篇均被引频次的标准化方法仍不断出现[22-23],大多是针对引文的偏态分布特征，基于数理计算方法转换为正态分布后再进行比较。如对论文被引频次取自然对数，再用Z分数进行标准化处理后的分布更接近正态分布，只有当原始分布近似正态分布时,基于Z分数的标准化方法表现较好,基于篇均被引频次的标准化法更适用于偏态引文分布[24],说明基于算术平均的相对影响指标用于研究绩效评测具有一定的合理性。",
    "context4": "2015年，Abramo [25]提出了FSS(Fractional ScientificStrength,FSS)评估科学家个人学术影响力，进而评估科学家群体所属的机构，该指标在论文被引频次与篇均被引频次比值的基础上,将论文发表时间长度和作者贡献率纳入计量范围,以期全面衡量科学家的学术产出效率，Abramo[2比较了MNCS 和FSS对大学绩效分数和排名的影响,他认为所有只考虑论文比值的指标都是无效的,任何在此基础上的改进都是徒劳。因为MNCS衡量论文集的篇均影响力，忽略了产量的增加,当新的文章发表,反而会导致MNCS值降低[7]。尽管FSS同时强调了科研产出的数量和影响力，兼顾投入与产出的关系，但许多学者认为科研绩效评价的核心应该更加注重影响力，而不是生产力或产出效率，而纳入更多的考虑因素会导致结果不够精确，缺乏可操作性[28-30]。"
  },
  "3.1.2 基于百分位数的标准化": {
    "context1": "基于百分位数的标准化指标在关于相对引用指标的讨论中提出，随后被逐渐应用于研究绩效评价。基于论文被引频次的偏态分布特征,Leydesdorf3提出应使用非参数统计方法,Bornmann等32]也认为应该用分布来描述而不是用算术平均值来评测,进而提出将百分位数指标代替平均值算法用于学术影响力的评价。",
    "context2": "百分位数指标基于被引频次将论文集合的论文分成若干等级,不再使用数学平均值的计算方法,而是用分布情况来描述被引频次,Bornmann 等33提出使用6个百分位等级(PR6)来评估引文的分布，即确定待评估的研究实体的文章所在的文章集合，通过相同出版年、相同文章类型和相同学科领域等标准化，得到标准的参考文献集。然后，按照被引频次从高到低将其分为 $1 \\% . 1 \\% - 5 \\% . 5 \\% - 1 0 \\%$ 、 $1 0 \\% -$ $2 5 \\% . 2 5 \\% - 5 0 \\%$ 和最后 $5 0 \\%$ 共6个百分位区段的论文。每篇论文根据其所在的百分位区段，分别赋予不同的权重，前$1 \\%$ 区段的论文的权重为6,并以此类推，最后 $5 0 \\%$ 的论文权重为1。对各个百分位分布概率进行加权平均,即可得到百分位数等级分数(PRS)。",
    "context3": "百分位数针对的是单篇论文的评价，而在研究绩效评价中更多会涉及到论文集合的整体评价。因此，根据不同的论文集合和评价目的，基于百分位数的文献计量指标可以分为三种类型：百分位等级分数(Percentiles Rank Scores,PRS)、综合影响指标（Integrated Impact Indicator,I3）和$\\mathrm { t o p 1 0 \\% ^ { [ 3 4 ] } }$ 。它们在实际应用中各有侧重,其中I3是一个绝对值指标，表示论文权值的总和，体现I3定义的新的学科影响力评价方式[3]。而 $\\mathrm { t o p l 0 \\% }$ 在莱顿大学排行榜中又被称为Excellect Indicator,只将论文划分被引频次 top $10 \\%$ 的高被引论文与其他两个等级,top $10 \\%$ 高被引论文权值为1,其他为0。 $\\mathrm { t o p l 0 \\% }$ 高被引文章的比例不能用于评估在$\\mathrm { t o p l 0 \\% }$ 没有或很少文章的期刊或研究实体，因此,在比较专利期刊和不够优秀的研究实体时，Leydesdorff等[3]建议使用 $\\mathrm { t o p } 2 5 \\%$ 指标。",
    "context4": "基于百分位数的标准化指标使用无参统计的方式评价偏态分布的论文被引频次，且能使用标准差来检验评价结果,期望更加贴合评价对象的实际学术影响力。但在应用中百分位数指标仍与参照标准有关，需要获取论文所属学科领域的引文数据。此外,被引频次的非连续分布和被引频次相同的论文簇也会影响百分位区段的精确划分。但相比于基于平均值算法的计量指标,百分位数指标不考虑引文的偏态分布情况,避免使用平均值算法，不会受到引文分布中极端值的影响；百分位数指标的计算可以以论文集合为参照标准,不仅可以实现不同数据库、学科领域以及不同规模的论文集合之间的比较,还可以加入“灰色文献\"或无来源期刊的文献进行比较。"
  },
  "3.1.3 基于篇均参考文献数的标准化": {
    "context1": "Garfield[3认为衡量某领域论文引用潜力最准确的指标是该领域篇均参考文献的数量，在一定程度上反映了不同主题领域被引用的可能性，基于此，Kosmulski[38提出成功论文数(NSP,Number of SuccessfulPublications)指标,即单篇论文的被引频次除以其参考文献数,所有比值大于1的论文被认为是成功论文。随后，研究人员将论文集合的平均参考文献数代替单篇论文的参考文献数，以降低人为操作的影响，并称为“成功指数\"[39]。2016年,Bormnman[4提出一种基于参考文献数的标准化方法 CSNCR(citation score normalized bycited references），该方法继承了基于引用潜力评价论文学术影响力的思路，首先,采用上文PBFN方法获取参照标准，即基于文章的主题类重叠区域定义新的领域，例如,所有同时分布在\"化学,有机\"和\"化学,物理\"中的文章,将在化学(有机和物理)中重新定义一个重叠的更细粒度的领域,篇均参考文献数量取上述两个领域中的所有文章计算。为了获取更可靠的参考文献数期望值,在计算过程中舍弃参考文献平均数量低于10篇的学科领域。其次，计算参照标准内论文集合的篇均参考文献数，即引文潜力值ei,并限定参考文献时间窗口与引文时间窗口相同,如发表于2012年的文章，如果确定引文时间窗口时间为3年，即2013-2015年，则参考文献的时间窗口也是3年,即2008-2011年。最后，计算论文被引频次 $\\mathrm { { c } _ { i } }$ 与引文潜力值ei的比值，即CSNCR。该比值是一种单篇论文影响力评价的标准化指标，在评价研究实体的论文集时，计算其总和的篇均值即可得到不依赖于论文规模的平均化指标MCSNCR(Mean CSNCR）。",
    "context2": "$$\n\\mathrm { M C S N C R } = \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } \\frac { c _ { i } } { e _ { i } }\n$$",
    "context3": "可知,MCSNCR和MNCS的数学表达式完全一样,二者均将期望值ei视为引文潜力的表征,但其含义不同,前者表示篇均参考文献数，后者表示篇均被引频次。",
    "context4": "表1 SNCS的不同计算方法",
    "context5": "<table><tr><td>基本公式</td><td>计算依据</td><td>a含义</td><td>时间窗口说明</td></tr><tr><td rowspan=\"3\">M SNCS(1)=</td><td>基于引文分数统计</td><td>第i篇施引文献的参考文献数 第i篇施引文献所在期刊中所有</td><td>例：发表于2008 年文献在 2010 年被文献i引</td></tr><tr><td>基于 audience factor</td><td>论文的平均活跃参考文献数 SNCS(1)=) M 1</td><td>用（引文时间窗口为4年，即2008-2011年）， 则a为文献i所在期刊2010年所有论文的参 考文献平均值或总数(参考文献时间窗口与</td></tr><tr><td>基于p指数</td><td>pia ai指第i篇施引文献的活跃参考 文献数，pi指引用文献所在期刊 当年所有论文中至少包含一篇活 跃参考文献的比例</td><td>引文时间窗口保持一致，即 2007-2010年，该 时间段以外和其他来源的引文忽略不计)。</td></tr></table>",
    "context6": "评价指标研究中，指标的检验和对比分析是将指标应用于实践的前提和重要环节之一,Bormnman[4通过\"公平性测试\"比较了CSNCR与MNCS、SNCS和百分位数等常用标准化指标,发现在被引频次的标准化处理方面CSNCR不如MNCS指标合适，但优于施引端标准化的SNCS类指标。Mingers等4通过比较MNCS和CSNCR等标准化方法,指出Google Scholar数据用于科研绩效评价的可能性。目前，CSNCR作为一种新的标准化方法,具有一定的一致性和稳定性等特性,但同样存在参照标准的选择问题,其有效性和适用性还需要进一步在不同的评价对象和具体的学科领域评估与探讨。"
  },
  "3.2施引端标准化方法": {
    "context1": "基于施引端的标准化方法由Small等[42首次应用于共被引分析，用于平衡不同学科或领域论文共被引值的差异。近几年来不断受到研究人员的关注，在研究中也被称为引文分数统计(fractional countingof citations）[43]或引用源标准化（source normalization)[44]等。该方法以施引文献所在的期刊或学科领域的参考文献数作为引文潜力的表征，以施引文献的参考文献数量为基数来标准化施引文献对被引文献(即参考文献)的贡献,从而跨学科地比较被引文献的学术影响力。",
    "context2": "2008 年,Zitt等[45]提出活跃参考文献(active references)的概念。活跃参考文献指论文(或期刊)的施引文献在特定时间段内来源于JCR的参考文献，该时间段以外或其他来源的参考文献忽略不计，活跃参考文献对施引文献的参考文献设置了时间和来源的限制,为施引端标准化指标的发展奠定了理论基础。Waltman借鉴上述不同算法提出施引端标准化引文分数(Souce Normalized Citation Score,SNCS),基本计算公式如下表,ai指基于施引文献参考文献的加权因子,根据计算依据有以下三种实现方式,见表1。",
    "context3": "引文分数统计基于单篇施引文献的参考文献数量标准化不同学科的论文引用频次，从而跨学科地比较论文的学术影响力，基于引文分数统计的SNCS计算方法是最简单的实现方式, $\\mathrm { a } _ { \\mathrm { i } }$ 指第i篇施引文献的参考文献数量。Zitt等[45]基于活跃参考文献提出audience factor指标用于期刊规范化，对被引频次设置了权重 ${ \\mathbb { W } _ { \\mathrm { s } } }$ ，",
    "context4": "$$\n\\mathrm { W } _ { s } ( \\mathrm { t } , \\mathrm { T } ) { = } \\frac { m _ { s } ( t , \\textit { T } ) } { m _ { i } ( t , \\textit { T } ) }\n$$",
    "context5": "其中， $\\mathrm { { m } _ { i } ( \\mathrm { { t } , T ) } }$ 为施引文献所在期刊i中所有文献在 时间窗口T ${ \\mathrm { ( ~ t ) } } = [ { \\mathrm { t } } - 1 \\cdots , { \\mathrm { t } } -$ T]来源于JCR的平均参考文献数, $\\mathrm { { m } _ { \\mathrm { s } } ( \\Omega t , \\Omega }$",
    "context6": "T)为所有学科期刊的文献的平均活跃参考文献数。可知施引期刊的活跃参考文献越少,其被赋予的权重就越大,从而在一定程度上消除了不同学科期刊的引用潜力差异。Walt-man 借鉴活跃参考文献的概念,基于期刊水平提出 SNCS第二种实现方式,其中a为第i篇施引文献所在期刊中所有论文的平均活跃参考文献数",
    "context7": "上述两种算法均基于施引文献的参考文献数量来加权引文影响力,但是不同学科的活跃参考文献数的比例同样存在显著差异,有些学科的参考文献时间跨度较长,超出可考虑的时间窗口范围,而社会科学类期刊的参考文献的其他来源文献和图书著作等比例明显高于自然科学类期刊[46]。为了消除学科间的差异,Waltman引人了p:指数[47]。p:指引用文献i所在期刊当年所有论文中至少包含一篇活跃参考文献的论文比例。计算步骤为： $\\textcircled{1}$ 确定归属于某学科期刊的第i篇论文; $\\textcircled{2}$ 统计该论文所属期刊在同年发表的论文数量； $\\textcircled{3}$ 计算含有至少一篇活跃参考文献的论文在总论文数中所占比例pi。对于某些高引文密度学科例如细胞生物学， $\\mathrm { p } _ { \\mathrm { i } }$ 的值接近于1,但是对于低引文密度学科如数学领域,pi的值很低,因此可以有效降低不同被引密度学科在计量中所产生的差异,类似方法已经在实证研究中得到证明[48]。",
    "context8": "Waltman等[49将上述三种不同算法的SNCS与MNCS进行比较发现,基于施引端的标准化方法更适用于不同学科领域之间的学术影响力比较,其中以基于audience factor和基于p:指数的算法表现最好,基于引文分数统计的算法并不能消除不同学科领域和引文时间窗口的差异性。此外,国内有学者基于论文的引用与被引并存的特点进一步修正 SNCS的算法[50],将评价论文称为节点,通过节点文献的施引文献与被引文献,构建基于节点文献的文献网络体系对不同学科文献进行标准化修正。"
  },
  "4结语": {
    "context1": "目前,在论文被引频次标准化的两种方法中,被引端标准化方法更为常见,其中,相对影响指标应用历史较长,应用范围较广泛,基于百分位数的指标提出相对较晚,是近年来受到更多关注和研究的新兴指标，而CSNCR作为新的标准化指标，其依赖于论文参考文献数的计算方式,容易受到人为因素的影响,其应用和不足还需要进一步的探讨。施引端标准化方法不需要考虑学科分类体系的引用行为差别,避开了期刊分类陷阱，就不同学科的论文评价而言更为合理。但由于数据获取与计算较为复杂，在实际应用中并不多见。",
    "context2": "引文分析方法通过论文引用与被引用关系建立科学计量学指标体系，其计量因素同样受到引文关系的限制,在纳入其他因素时缺乏相应的理论基础,难以兼顾数理统计和评价实践的合理性。许多科研绩效评价指标在实际科研评价过程中得不到应用,除了指标计算的复杂性等原因外,数据源的选择,数据收集的完整性和恰当性等方面也有制约。许多学者借助同行评议结果对两种标准化方法的优劣进行比较和验证，大多数研究认为被引端标准化方法优于施引端标准化方法，但也有一些研究提出了不同意见。在实际运用中，两种方法都能从其自身角度反映研究实体的研究绩效和学术影响力，需要根据不同的评价客体与目的,选择适当的指标参与评价，最终形成对评价客体立体、客观的评价结果。",
    "context3": "随着网络与信息技术的发展，数据源和评价模式也不断拓展,基于引文内容的论文评价和替代计量学已经成为传统引文分析方法的有力补充,通过深入论文内容分析和引入替代计量指标,更加精确、全面地评价学术论文，构建全方位的学术论文评价体系，为当前的科技评价提供有力的信息支撑和公平保障，有助于专家掌握足够的信息，进而在更高的信息集成水平上形成更具权威性的意见。"
  },
  "参考文献": {
    "context1": "1Garfield E.Citation indexes for science.A new dimension in documentation through association of ideas[J]. Science,1955,(122):108-11.   \n2Opthof T,LeydesdorffL.Caveats for the journal and field normalizations in the CWTS (\"Leiden\") evaluations of research performance[J]. JOURNAL OF INFORMETRICS,2010,4(3):423-430.   \n3Van Eck NJ,Waltman L,van Raan AF,et al.Citation analysis may severely underestimate the impact of clinical research as compared to basic research[J]. PloS one,2013,8(4):e62395.   \n4 Adams J，Gurney K，Jackson L.Calibrating the zoom—A test of Zitt's hypothesis[J]. Scientometrics, 2008,75(1):81-95.   \n5Glänzel W, Schubert A,Czerwon H.An item-by-item subject classification of papers published in multidisciplinary and general journals using reference analysis[J]. Scientometrics,1999,44(3):427-439.   \n6 华萌,陈仕吉,周群,等.多学科期刊论文学科划分 方法研究[J].情报杂志,2015,(5):76-80.   \n7 Rons N. Partition-based field normalization: An approach to highly specialized publication records[J]. Journal of Informetrics,2012,6(1):1-10.   \n8Bornmann L,Mutz R,Neuhaus C,et al.Citation counts for research evaluation: standards of good practice for analyzing bibliometric data and presenting and interpreting results[J]. Ethics in science and environmental politics, 2008,8(1):93-102.   \n9 Bornmann L,Daniel H D.Selecting manuscripts for a high -impact journal through peer review: A citation analysis of communications that were accepted by Angewandte Chemie International Edition, or rejected but published elsewhere[J]. Journal of the American Society for Information Science and Technology,   \n2008,59(11):1841-1852.   \n10 Bornmann L,Mutz R,Neuhaus C,et al. Citation counts for research evaluation: standards of good practice for analyzing bibliometric data and presenting and interpreting results[J]. Ethics in science and environmental politics,2008,8 (1):93-102.   \n11 Waltman L,van Eck N J. A new methodology for constructing a publication-level clasification system of science U]. Journal of the American Society for Information Science and Technology,2012,63(12):2378-2392.   \n12 Kostoff R N. Citation analysis of research performer quality [J]. Scientometrics, 2002,53(1):49-71.   \n13Kostoff R N, Martinez WL. Is citation normalization realistic?[J]. Journal of information science,2Oo5,31(1):57-61.   \n14 Colliander C.A novel approach to citation normalization: A similarity- based method for creating reference sets[J]. Journal of the Association for Information Science and Technology,2015,66(3):489-500.   \n15Schubert A,Braun T.Reference standards for citation based assessments[J]. Scientometrics,1993,26(1):21-35.   \n16 Hutchins B I, Yuan X,Anderson J M,et al.Relative Citation Ratio (RCR):A New Metric That Uses Citation Rates to Measure Influence at the Article Level[J]. PLOS Biology,2016,14(9):e1002541.   \n17Mingers J,Leydesdorff L.A review of theory and practice in scientometrics[J].European Journal of Operational Research,2015,246(1):1-19.   \n18Yanovsky V. Citation analysis significance of scientific journals[J]. Scientometrics,1981,3(3):223-233.   \n19 Schubert A, Braun T. Cross-field normalization of scientometric indicators[J]. Scientometrics,1996,36(3):311-324.   \n20 Leydesdorff L,Bornmann L,Mutz R,et al. Turning the tables on citation analysis one more time: Principles for comparing sets of documents[]. Journal of the Association for Information Science and Technology,2011,62(7):1370-1381.   \n21 Waltman L, van Eck N J, van Leeuwen T N,et al. Towards a new crown indicator: An empirical analysis[J]. Scientometrics, 2011,87(3):467-481.   \n22 Thelwall M. The precision of the arithmetic mean, geometric mean and bercentiles for citation data: An exberimental simulation modelling approach[J]. Journal of informetrics, 2016,10(1):110-123.   \n23Fairclough R, Thelwall M. More precise methods for national research citation impact comparisons[J]. Journal of Informetrics,2015,9(4):895-906.   \n24 Zhang Z, Cheng Y, Liu N C. Comparison of the effect of mean-based method and z-score for field normalization of citations at the level of Web of Science subject categories[J]. Scientometrics,2014,101(3):1679-1693.   \n25 Abramo G,D Angelo C A. A methodology to compute the territorial productivity of scientists: The case of Italy[]. Journal of Informetrics,2015,9(4):675-685.   \n26 Abramo G, D Angelo C A. A comparison of university performance scores and ranks by MNCS and FSS[]. Journal of Informetrics,2016,10(4):889-901.   \n27 Abramo G,D Angelo C A. A farewel to the MNCS and like size-independent indicators[]. Journal of Informetrics, 2016,10(2):646-651.   \n28Glänzel W, Thijs B,Debackere K.Productivity，performance，efficiency， impact—What do we measure anyway? J].Journal of Informetrics,2016,10(2):658-660.   \n29 Ruiz-Castillo J. Research output indicators are not productivityindicators[J].Journal of Informetrics，2016,10(2): 661-663.   \n30 Thelwall M. Not dead, just resting: The practical value of per publication citation indicators[J]. Journal of Informetrics,2016,10(2):667-670.   \n31 LeydesdorffL,Bornmann L, Mutz R,et al. Turning the tables on citation analysis one more time: Principles for comparing sets of documents[]. Journal of the Association for InformationScienceandTechnology， 2011,62(7): 1370-1381.   \n32 Bornmann L. Towards an ideal method of measuring research performance: Some comments to the Opthof and Leydesdorff (2010) paper[J]. JOURNAL OF INFORMETRICS,2010,4(3):441-443.   \n33 Bornmann L,Mutz R.Further steps towards an ideal method of measuring citation performance: The avoidance of citation (ratio） averages in field-normalization[J]. Journal of Informetrics,2011,5(1):228-230.   \n34 周群,左文革,陈仕吉.基于百分位数的文献计量指标 研究综述[].现代图书情报技术,2013,29(7/8):82-88.   \n35 陈福佑,杨立英.新科研影响力评价指标分析.情报杂 志,2014,(7):81-85,62.   \n36 LeydesdorfL. Alternatives to the journal impact factor: I3 and the top $- 1 0 \\%$ (or top $\\scriptscriptstyle { - 2 5 \\% }$ ）of the most-highly cited papers[J]. Scientometrics, 2012,92(2):355-365.   \n37 Garfield E,Merton R K. Citation indexing: Its theory and application in science， technology，and humanities[M]. New York:Wiley New York,1979:84.   \n38 Kosmulski M. Successful papers: A new idea in evaluation of scientific output[J]. Journal of Informetrics，2011,5(3): 481-485.   \n39Franceschini F,Maisano D,Mastrogiacomo L.Evaluating research institutions: the potential of the success-index[J]. Scientometrics,2013,96(1):85-101.   \n40 Bornmann L,Haunschild R.Citation score normalized by cited references (CSNCR): The introduction of a new citation impact indicator[]. Journal of Informetrics,2016,10(3): 875-887.   \n41 Mingers J, Meyer M. Normalizing Google Scholar data for use in research evaluation[J]. Scientometrics, 2017,(9):1-11.   \n42 Small H, Sweeney E. Clustering the science citation index using co-citations:I.A comparison of methods[J].Scientometrics,1985,7(3-6):391-409.   \n43Leydesdorff L, Opthof T. Scopus's source normalized impact per paper (SNIP) versus a journal impact factor based on fractional counting of citations[J]. Journal of the American Society for Information Science and Technology,2010, 61(11):2365-2369.   \n44Moed H F. The Source-Normalized Impact per Paper (SNIP) is a valid and sophisticated indicator of journal citation impact[EB/OL].https://arxiv.org/abs/1005.4906,2010- 11-12.   \n45 Zitt M, Small H. Modifying the journal impact factor by fractional citation weighting: The audience factor[]. Journal of the American Society for Information Science and Technology,2008,59(11):1856-1860.   \n46 Nederhof A J. Bibliometric monitoring of research performance in the social sciences and the humanities:A review [J]. SCIENTOMETRICS,2006,66(1):81-100.   \n47 Waltman L, van Eck N J, van Leeuwen T N, et al. Some modifications to the SNIP journal impact indicator[J]. Journal of Informetrics,2013,7(2):272-285.   \n48 Glänzel W,Schubert A,Thijs B,et al. A priori vs.a posteriori normalisation of citation indicators. The case of journal rankingD]. Scientometrics,2011,87(2):415-424.   \n49 Waltman L, van Eck N J. A systematic empirical comparison of different approaches for normalizing citation impact indicators[J]. Journal of Informetrics,2013,7(4):833-849.   \n50 丁媛,王红.不同领域科学家影响力评价文献回顾 及实证分析m 情招± 2016(1m):10-105",
    "context2": "(责任编辑：孙晓明)"
  }
}