{
  "original_filename": "full_10147.md",
  "面向综述论文的语义情报内容挖掘方法研究": {
    "context1": "胡懋地1,2,3 于倩倩1,2,3 钱力1,2,3 常志军1,2,3 张智雄1,2,31（中国科学院文献情报中心北京 100190)2（中国科学院大学经济与管理学院信息资源管理系北京100190)3（国家新闻出版署学术期刊新型出版与知识服务重点实验室 北京 100190)",
    "context2": "摘要：【目的】为充分挖掘综述论文的语义情报内容,提出相关情报要素体系及其挖掘任务的形式化定义，构建相应的信息抽取技术框架。【方法】针对综述论文专业性强、术语分布稀疏、标注难度大等问题,通过多任务学习实现跨任务标注数据的信息互补，并引人自监督学习实现未标注数据中潜在信息的挖掘利用。",
    "context3": "【结果】本文所提技术框架显著增强了各项任务的性能表现,尤其是在要素间关系识别任务中,准确率提高8.32个百分点。此外,通过自监督学习,整体F1值进一步提升约2个百分点。【局限】在信息抽取过程中,未考虑图片、表格等文本之外的数据。结论】提出了综述论文语义情报内容挖掘的方法流程,并引人多任务学习和自监督学习技术,利用跨任务标注数据及未标注数据提升挖掘效果。",
    "context4": "关键词：信息抽取阅读理解多任务学习自监督学习分类号：TP391DOI: 10.11925/infotech.2096-3467.2023.0828",
    "context5": "引用本文：胡懋地，于倩倩，钱力等.面向综述论文的语义情报内容挖掘方法研究[J].数据分析与知识发现,2024,8(11):91-101.(Hu Maodi, Yu Qianqian,Qian Li,etal. Semantic Information Extraction Methods forReview Papers[J]. Data Analysis and Knowledge Discovery, 2024, 8(11): 91-101.)"
  },
  "1引言": {
    "context1": "综述论文是科技工作者对某一领域深度剖析的智慧结晶,包含丰富的科学研究发展证据,是学科进步的见证和基石，也是科技情报研究的高价值数据。在影响力方面,综述论文篇均被引频次显著高于其他论文均值。高质量的综述论文不仅能对学科的发展起到引领和推动作用，还有助于提升期刊的影响力[1]。",
    "context2": "综述论文具有较高的信息情报价值、学术交流价值和科研宏观指导价值[],如何对综述论文中的语义情报内容进行组织和挖掘值得探索。综述论文不仅能反映学术专家对某一领域或专题的系统回顾与展望，还能反映某一特定研究问题的新动态、新趋势、新技术等。因此,可以从中提炼出领域级的重大研究问题、主要技术方法、未来发展方向、领域研究热点等语义情报内容。",
    "context3": "在研究问题方面，本文针对综述论文的情报特点，定义了较为完善的语义情报要素体系，不仅涵盖问题、方法、指标等基本要素以及要素之间的关联关系,还加入了重要性、描述层次等要素标签，拓展问题场景。基于本文提出的语义情报要素体系，可以全面刻画要素类型(方法、问题等）、要素重要性（当前热点、未来突破点等）、要素描述层次(领域级、次领域级）、要素关系(用于、属于等)等综述各维度的信息。此外,通过将语言表达个性化、组织形式复杂、篇幅冗长的综述论文转化为相对标准化、结构化、精简化的语义情报内容,有助于快速了解领域的主要研究对象和研究成果,为探究发现历史、当前、未来等不同阶段的重点方向提供抓手。",
    "context4": "但是,综述论文内容具有领域专业性强、信息类型广等特点，这些特点带来了一系列语义理解方面的挑战,比如专业词汇分布稀疏、非命名实体的要素较多、评价意图隐晦、逻辑关系交错等，加重了相关信息抽取任务的低资源问题。",
    "context5": "此外,综述论文信息抽取任务还面临领域专业性强、标注难度大等问题,传统方法很难取得较好的性能表现。在技术方法方面，本文针对综述论文的内容特点，将整体任务拆解为要素识别、要素间关系识别以及要素标签识别三种子任务，提出一个综述论文信息抽取技术框架,通过多任务学习(Multi-TaskLearning,MTL)实现跨任务标注数据的信息互补，同时引入伪标签(Pseudo-Labeling)及自监督学习（Self-SupervisedLearning)技术,利用未标注数据进一步提升模型性能,提供了综述论文语义情报内容挖掘的整体性解决方案,在算法性能、易维护性等方面优势明显。"
  },
  "2相关研究": "",
  "2.1语义情报要素体系": {
    "context1": "作为科技情报的重要信息来源，文献中包含的数据主要有两类,分别是作者、机构、关键词等结构化数据,以及摘要、全文等非结构化数据。结构化数据方便实现信息关联，众多学者或情报分析人员利用文献计量、社会网络等分析方法对该类数据进行了合作网络分析[2]、研究热点分析[3]、研究演化分析[4]等研究,相关方法体系比较成熟。对于以文本为主的摘要、全文等非结构化数据,需要利用自然语言处理等技术提炼分析其中的语义情报内容，按照情报要素的粒度可分为粗粒度的句子级识别和细粒度的短语级识别,这是当前研究的热点。",
    "context2": "在针对科技文献的句子级识别工作中，研究及应用较广泛的是摘要结构功能识别,也称语步识别，即识别出摘要中每句话的功能类型，帮助读者更快速、更精准地定位其关注的核心内容。语步识别的分类体系已较为固定，但仍然有较多工作在研究识别的技术手段。Goncalves等[5]利用神经网络技术，对生物医学及计算机科学领域的论文摘要进行句子级识别,分为研究背景、目标、方法、结果、结论等语步类型。除了摘要语步识别之外，定位文献全文中表达特定意图的重要句子[也是一类比较有意义的工作。曹树金等以情报学期刊的科技论文全文为研究对象，识别出全文中的创新句，并进一步细分识别为创新基础句、创新过程句、创新贡献句等。",
    "context3": "细粒度的科技文献短语级识别,其目标主要是识别不同类型的要素实体以及相互之间的语义关系，以支持科技语义检索、领域演化分析等应用，也常作为科技知识图谱构建的重要环节。细粒度实体能够更简洁、直观地反映领域科技文献的核心内涵，在对齐融合后,也便于进一步关联计算推理,对情报分析、战略决策等应用具有重要价值。Yang等8从科技文献中抽取任务、模型、数据集、指标等实体，用于跟踪机器学习研究的前沿结果。章成志等[9对中文论文中指标、工具、资源、方法等实体进行挖掘,并对这些实体的关联网络进行分析。刘悦等[10]基于材料四面体准则定义了晶体结构、合成技术、表征、应用等8种实体和影响、部分、实例等8种关系,构建高质量的材料科学文献挖掘数据集。在这些研究中,通用领域的实体类型已倾向一致，与语步分类类似;但是专业领域的语义情报要素体系难以统一，需要更具体并且与领域更相关的体系设计。",
    "context4": "除了不同粒度的静态信息之外，科技文献中还包含事件、事理等动态信息。例如,黄容[提出基于词汇链和篇章结构的事理知识抽取方法，抽取科技文献中事理相关的属性、事件链等动态关系。其基本思路为：通过词汇链识别构建最强事件链,以谓词-实体结构标识事件链中的抽象事件,并借助篇章修辞结构和物理结构识别链中事件的语义逻辑和主次关系，以此构建科技文献中具有语义关联和层次结构的事理知识。"
  },
  "2.2语义内容挖掘技术": {
    "context1": "针对文本为主的非结构化数据,利用实体识别、关系识别等细粒度信息抽取技术，构建结构化的语义内容支持进一步的序化组织与分析，是自然语言处理及知识图谱技术研究的一个重要方向。实体识别的核心目标在于从文本中找到实体所在的位置并标识其类型。常见的方法可以分为基于分类和基于问答两大类。",
    "context2": "在基于分类的方法中，序列标注是最经典的一类,这类方法判断每个字符或Token是否为某种类型实体的起始或结束位置,简单直观,但无法处理实体嵌套等问题。研究者提出了一系列改进方法，比如片段级别的分类方法，包括通过识别两两字符之间关系划分片段[12]、提取子片段并识别子片段间关系进行关联合并[13]等,解决嵌套实体与不连续实体的识别问题。另外,通过原型匹配[14方式实现分类，可以提升小样本场景下的识别性能。这类方法的模型结构针对实体识别任务进行针对性优化,难以兼容关系识别等问题形成统一框架,并且一般只适用于低资源或者高资源中的一种场景。",
    "context3": "基于问答的方法主要分为生成式抽取方法和阅读理解方法两类。生成式抽取方法不限定从原文中抽取，而是通过生成式预训练语言模型与提示学习等技术,引导模型采用预先设定的文本模式生成信息抽取结果。阅读理解方法的思路与生成式抽取方法类似，同样是根据给定提示语句或查询语句中阐述的问题得到答案,这两类方法都可以在同一框架下解决多种问题,并且因为原文和问题都是自然语言的表达,从原理上都适用于零样本和小样本等低资源场景。方案上的主要区别在于，阅读理解方法将实体识别问题转化为在给定查询语句约束下，原文语句上的序列标注或片段分类任务，即在原文中定位符合特定要求的实体文本;而生成式抽取方法则将问题转化为基于三元组等特定格式的文本生成任务[15],选择空间通常不受限于原文。另外,一些研究在探索采用大模型实现基于生成的实体抽取方法[1,但实验结果表明性能仍不及阅读理解片段抽取等方法。",
    "context4": "实体间的关系识别任务主要通过对主客实体的表征及分类等技术方法实现,近期研究重心主要在两个方向：一是文档级的关系识别[17-19],关注如何借助图神经网络等技术，融合同一实体在文档中被多次提及的信息，增强待关联实体的表征，从而提升关系识别的准确性和全面性；二是关于实体及关系的联合抽取[20],主要是通过多任务学习共享底层模型参数，即在模型输出部分对两类任务的损失函数进行反向传播，使共享的参数同时拟合多个目标，实现信息互补。这些方法对具体任务定制了模型结构，难以在同一框架下支持实体分类等更多任务，并且在低资源条件下的性能表现不佳。"
  },
  "3实现方案": {
    "context1": "本文从语义情报要素体系、数据集以及技术方法三个方面,对综述论文的语义情报内容挖掘方法展开论述，主要贡献在于：",
    "context2": "(1)在问题定义及数据集构建方面，构建了由要素实体、要素间关系、要素标签组成的语义情报要素体系,形成一套综述论文语义情报内容的结构化表示方法，制定相应的数据采集标注流程规范，构建符合真实业务场景的数据集。",
    "context3": "(2)在技术方法方面，在传统监督学习方法的基础上,引入多任务学习及自监督学习技术,利用跨任务标注数据及未标注数据中的信息，提升低资源条件下综述论文情报挖掘的性能。"
  },
  "3.1要素体系定义": {
    "context1": "从综述论文中挖掘什么,预期应用目的如何，是语义情报要素体系构建要考虑的基本问题。综述中对问题、方法、指标、数据集等要素的描述和总结，是作者作为领域专家从大量论文中得到的判断。综述中，问题、方法之间的关系，方法、结果之间的关系，数据集、指标之间的关系等,可以打破科技文献单一描述维度的限制,阐释领域发展的内在机理。基于上述应用需求,本文总结和梳理综述论文中的要素以及要素之间的关系，构建语义情报要素体系，核心内涵如图1所示。",
    "context2": "本文构建的语义情报要素体系包括4部分，分别是要素基本类型、要素间关系、以及重要性和描述层次两种要素标签。要素基本类型(简称类型)包括问题、方法、作者、文献、特征、价值意义、数据集、工具、指标、结果、应用等11种。其中,问题指需求、任务、挑战;方法指方案、思路、算法、模型、手段;作者指文中介绍具体某些文献时提及的人名，通常表现为第一作者的姓名;文献指单篇文献引用或者多篇文献集合,通常表现为序号;特征指算法模型用的特征；价值意义指对于该领域或领域应用方面的价值意义;数据集指问题、方法等要素相关的数据集；工具指工具平台等软件条件;指标指研究中使用的定量和定性指标;结果指性能、功能等表现;应用指具体的落地实践。",
    "context3": "![](images/aea364ca1be288e1f92262f539b30139d3c16e87bdaf8651e2cb1d5d55ba327a.jpg)  \n图1综述论文语义情报要素体系  \nFig.1Semantic Intelligence Element System for Survey Papers",
    "context4": "要素间关系包括属性、用于、提出、产生、组成、代表、属于、等价、先后、度量等10种。属性指特点、特性,类似于“的”，比如问题-属性-方法，表示该方法存在的一些问题;用于指用作条件，比如方法-用于-文献;提出指首次公开,比如作者-提出-方法；产生指因果，比如方法-产生-结果;组成指作为一部分，比如问题-组成-问题,表示前者是后者的子问题；代表指具有代表性的，比如数据集-代表-问题;属于指同类要素之间的上下位，比如方法-属于-方法；等价指两个要素名称指示同一要素，比如方法-等价-方法;先后指要素执行或者提出的顺序,比如方法-先后-方法;度量指评估效果,比如指标-度量-方法。",
    "context5": "此外,本体系还包括对要素重要性和要素描述层次的标注,即判定每个要素是否属于某种重要性或某个描述层次。笔者定义的要素重要性包括“历史里程碑\"\"当前热点\"\"未来突破点\"三种。其中，历史里程碑指在领域发展过程中具有重要意义的文献、问题、特征、方法、指标、材料、结果、应用、工具。当前热点指目前的研究热点，可标注的要素类型与历史里程碑一致。未来突破点指未来可能实现突破的研究内容，可标注的要素类型也与历史里程碑一致。要素描述层次分为领域级和次领域级。其中，领域级指问题、方法、指标等各类型分类体系(通过“属于\"关系形成)中的核心实体(一般为各类型的唯一根节点),比如全文讲述的最核心的问题及方法，一般为宏观实体。次领域级指领域级实体的下位，比较重要的下一级实体，与领域级实体是属于关系，一般为中观实体。"
  },
  "3.2数据集构建": {
    "context1": "目前综述论文相关的语义挖掘研究较少，相关专业领域标注数据集更是缺乏。为解决这一问题，本文遴选高质量的综述论文作为人工标注的基础数据,建立标注规范和管理流程,构建面向综述论文语义情报内容挖掘的数据集，用于模型研发过程中的训练及评测。该模型用于综述论文全文的逐句自动标注，是建立高质量语义情报要素网络的核心驱动力。"
  },
  "(1)综述论文数据遴选": {
    "context1": "第四范式时代[21],科研工作将数据作为科学研究的基础,通过对大量数据的分析和挖掘,揭示隐藏在数据背后的规律和模式。一方面,数据挖掘与机器学习已成为广泛用于解决具体应用问题的基础性实用技术，该领域的论文除了研究技术方法本身，还会从自然科学与社会科学等各领域抽象出数学问题并求解。因此，数据挖掘与机器学习领域具有较强的普适性和代表性，本文选择该领域作为实践场景。另一方面,开放科学、开放获取、预印本等蓬勃发展，为科技文献数据的获取提供了越来越多的渠道，但不同来源的数据规模、质量参差不齐，需根据应用需要进行评估和遴选。通过主题为数据挖掘或机器学习、文档类型为Review、发表年份为2015-2023等限定条件,获取被Webof Science核心合集数据库中收录的数据挖掘与机器学习相关综述论文。利用Spacy工具对论文全文进行分句,然后从分句的结果中随机选择1000条左右语句片段用作人工标注。在人工标注过程中，对不涉及问题拆解、方法对比分析、不同时期研究重点等信息的语句进行剔除,减少无效语句的占比，最终得到769个语句片段，以确保重要信息抽取的能力能够被建模和验证。"
  },
  "(2)语义要素人工标注": {
    "context1": "为保障标注结果的一致性,本文制订标注规范,规定标注原则、标注的要素及示例、标注的要素间关系及示例、标注的要素标签及示例、标注注意事项等。招募三名具有计算机或情报学背景的研究生按照标注规范对遴选的综述论文进行标注，协同两名副高级研究人员对标注结果进行审核。综述论文中包含的要素实体数量、关系数量往往比较多,难以直观发现标注错误。在标注数据质量管理方面，一方面进行全局质量观测,将初始标注数据转换为图数据,以图谱可视化的形式探查整体知识框架,查看是否存在标注错误的情况;另一方面进行局部质量观测,多次随机划分训练集与测试集,输出测试集中预测结果与人工标注不一致的内容,通过算法交叉检验，发现可能存在的标注错误。",
    "context2": "对前述769个语句片段中的要素实体、要素间关系及要素标签进行人工标注,生成4791组问答样本对，构建综述性科技论文语义情报内容挖掘任务的真实业务数据集。该数据集包括前文提到的11种要素实体、10种要素间关系，以及重要性和描述层次这两类要素标签。"
  },
  "3.3内容挖掘技术实现": {
    "context1": "笔者将综述性科技论文的语义内容挖掘任务分解为三个子问题,包括要素识别、要素间关系识别以及要素标签识别,如图2所示。其中,要素识别是首要的一步,依据预先定义的语义情报要素体系,将方法、问题、指标、结果等多种类型的具体要素从原始文本中提取出来,进而构建一个覆盖各类科技要素的术语词表。在此基础上,明确各个要素之间的内在联系,构建要素间的关系网络,为领域的要素体系赋予有机的结构。随后，为每个要素赋予标签,凸显历史上的重要里程碑、当前备受关注的热点等关键标签。",
    "context2": "![](images/fd4c8caf4e697933c9a88e8c61bdc267c1ff631f906a3c1d9923e79df0438801.jpg)  \n图2任务拆解  \nFig.2Task Disassembly",
    "context3": "(1)多任务学习",
    "context4": "多任务学习旨在通过共享模型参数等方式,让同一个模型能够处理多个任务，并提升模型在各个任务上的性能。本文基于机器阅读理解(MachineReadingComprehension,MRC)用于实体识别的任务设计模式，将BERT-MRC模型[22]作为基座，针对综述性科技论文提出一个信息抽取技术框架,整体流程如图3所示。该框架可以应对多种任务需求，对应到每种任务的实现方法都包括两个步骤：查询语句构建,捕捉所需寻找的要素实体目标,例如\"找出文中的人名”;答案片段抽取,将包含问题的查询语句和待抽取的原文语句输入模型,模型预测得到答案片段在文本中的起始和结束位置，即目标实体所在的文本位置。",
    "context5": "$\\textcircled{1}$ 查询语句构建",
    "context6": "本文提出一个通用的模板，以满足综述论文语义情报内容挖掘任务的多样性需求。模板内容为：Findoutthe{描述级别标签}{重要性标签}［基本类型]s{要素间关系的约束条件}。在此基础上,进一步定义{实体间关系的约束条件}子模板，其具体内容为：that［头实体的类型］of［头实体］{关系谓词}。其中，}表示可选项，[]表示必选项。例如，抽取\"作者\"类要素时，在模板中填入相应要素类型,得到查询语句\"Find out theauthors”。如果识别到作者Hu etal.,再构建查询语句\"Find out the methods thatthe authors of Hu et al.proposed.”识别其提出的方法。",
    "context7": "![](images/2dc8272e957b255b03738de64233737481932300705688ee7345d721d0c0e6fb.jpg)  \n图3综述性科技论文信息抽取框架  \nFig.3Information Extraction Framework for Survey Papers",
    "context8": "$\\textcircled{2}$ 答案片段抽取",
    "context9": "答案片段抽取算法的基本思路如下：连接查询语句和待抽取原文中的自然语言文本,Token化后输人BERT语言模型，设 $L ^ { \\mathcal { Q } }$ 表示查询语句对应的Token数， $L ^ { o }$ 表示待抽取原文对应的Token数;BERT模型为每个Token输出一个长度为 $d$ 的向量，设 $\\pmb { T } ^ { i }$ 表示第$i$ 个Token对应的向量;对于待抽取原文中的每个Token,分别计算其为答案片段起始位置和结束位置的概率，其中第i个Token的这两个概率分别记为$P _ { s t a r t } ^ { i }$ 和 $P _ { e n d } ^ { i }$ ,根据这些起止位置概率筛选出候选答案片段；对每一个候选答案片段,计算其为答案的预测概率,其中以i作为起始位置、以j作为结束位置的片段的预测概率记为 $Y ^ { i , j }$ 。最后，选出预测概率 $Y ^ { i , j }$ 较大的文本片段,作为模型预测的答案并输出。详细流程如算法1所示。",
    "context10": "算法1：阅读理解答案片段抽取算法流程",
    "context11": "输人;查询语句,待抽取原文,模型参数 ${ W } _ { \\it { s t a r t } } \\cdot { W } _ { \\it { e n d } } \\cdot { W } _ { \\it { s p a n } }$ ；  \n输出：答案片段集 $S _ { s p a n }$ ；",
    "context12": "初始化：候选起始位置集 $S _ { s t a r t } = \\emptyset$ 、候选结束位置集",
    "context13": "$S _ { e n d } = \\emptyset$ 、答案片段集 $S _ { s p a n } = \\emptyset$ ；",
    "context14": "$\\textcircled{1}$ 获取查询语句和待抽取原文Token化后的BERT输出向量,其中第 $i$ 个Token对应的向量为 $\\pmb { T } ^ { i }$ ；",
    "context15": "$\\textcircled{2}$ 对于所有 $i \\in [ L ^ { \\varrho } + 1 , L ^ { \\varrho } + L ^ { o } ] ,$ 执行：计算 $P _ { s t a r t } ^ { i } = S o f t m a x \\left( \\pmb { T } ^ { i } \\cdot \\pmb { W } _ { s t a r t } \\right)$ 如果argmax $( P _ { s t a r t } ^ { i } ) = 1$ ，将 $i$ 加人 $S _ { s t a r t }$ ；计算 $P _ { e n d } ^ { i } = { S o f t m a x } \\left( { { \\cal T } ^ { i } \\cdot { \\cal W } _ { e n d } } \\right)$ ，如果argmax $( { P _ { e n d } ^ { i } } ) = 1$ ，将 $i$ 加入 $S _ { e n d }$ ；",
    "context16": "$\\textcircled{3}$ 对于所有 $i \\in S _ { s t a r t }$ 和 $j \\in S _ { e n d }$ ,执行：如果 $j \\geqslant i ,$ 计算 $Y ^ { i , j } =$ sigmoid (concat $( \\pmb { T } ^ { i } , \\pmb { T } ^ { j } ) \\cdot \\pmb { W } _ { s p a n } )$ ；如果 $Y ^ { i , j } > 0 . 5$ ，将 $[ i , j ]$ 加人 $S _ { s p a n }$ 。",
    "context17": "其中, $W _ { s t a r t } \\setminus W _ { e n d } \\setminus W _ { s p a n }$ 是需要训练的模型参数,维度大小分别为 $d \\times 2 , d \\times 2 , 2 d \\times 1$ ； Softmax表示Softmax归一化;argmax表示取最大值对应的序号；concat表示向量连接;sigmoid表示sigmoid函数变换。",
    "context18": "在模型训练过程中，使起始位置预测概率、结束位置预测概率、片段预测概率分别拟合人工标注的真实值。设 $\\hat { P } _ { s t a r t } ^ { i } \\hat { \\ 、 } \\hat { P } _ { e n d } ^ { i } \\hat { \\ 、 } \\hat { Y } ^ { i , j }$ 分别为 $P _ { s t a r t } ^ { i } \\mathcal { P } _ { e n d } ^ { i } \\setminus Y ^ { i , j }$ 对应的标注真实值,采用交叉熵损失(Cross-Entropy Loss,CE)及加权和的方式计算目标函数，通过权重 $\\alpha$ 控制片段预测概率损失函数的贡献度，然后反向传播优化整体模型参数。目标函数如公式(1)所示。",
    "context19": "$$\nL _ { s p a n } = \\sum _ { i = L ^ { \\varrho _ { + 1 } } } ^ { L ^ { \\varrho _ { + } } } C E \\left( P _ { s t a r t } ^ { i } \\cdot \\hat { P } _ { s t a r t } ^ { i } \\right) +\n$$",
    "context20": "$$\n\\underset { i = L ^ { \\varrho _ { + 1 } } } { \\overset { L ^ { \\varrho _ { + } } L ^ { o } } { \\sum } } C E \\left( P _ { e n d } ^ { i } \\cdot \\hat { P } _ { e n d } ^ { i } \\right) + \\alpha \\underset { i = L ^ { \\varrho _ { + 1 } } j = L ^ { \\varrho _ { + 1 } } } { \\overset { L ^ { \\varrho _ { + } } L ^ { \\varrho } } { \\sum } } \\underset { j = 1 } { \\overset { L ^ { \\varrho } + L ^ { o } } { \\sum } } C E \\left( Y ^ { i , j } \\cdot \\hat { Y } ^ { i , j } \\right)\n$$",
    "context21": "其中, $\\alpha$ 为超参数，实验发现取值为0.1时性能较好。综述论文的语义情报内容挖掘可以划分为要素识别、要素间关系识别、要素标签识别三种任务。每种任务都可以基于本节介绍的阅读理解多任务学习框架完成,即先根据任务对应的模板构建查询语句,然后以原文中的答案片段作为抽取目标。在构建这三个任务损失函数的基础上，设置三个超参数$\\lambda ^ { 1 } \\setminus \\lambda ^ { 2 } \\setminus \\lambda ^ { 3 }$ 进行加权融合，得到最终的优化目标 $L$ ,如公式(2)所示。",
    "context22": "$$\nL = \\lambda ^ { 1 } L _ { s p a n } ^ { 1 } + \\lambda ^ { 2 } L _ { s p a n } ^ { 2 } + \\lambda ^ { 3 } L _ { s p a n } ^ { 3 }\n$$",
    "context23": "这里不区分这三种任务的重要性，所以 $\\lambda ^ { 1 } \\setminus \\lambda ^ { 2 } \\setminus \\lambda ^ { 3 }$ 取值均为1,实际工程中可以根据需要调整。本框架中的模型参数是所有任务共享的，包括BERT模型参数以及 $W _ { s t a r t } , W _ { e n d } , W _ { s p a n }$ ，因此,各个任务的训练数据不仅对当前任务有效，还能够辅助提升其他相关任务的性能。",
    "context24": "在模型训练完成后，执行要素识别任务，为待抽取的各要素类型分别构建查询语句,得到要素实体，即各要素类型对应的文本片段。基于识别出的要素实体,构建要素间关系识别任务与要素标签识别任务的查询语句,完成要素间关系、重要性标签、描述层次标签等识别。一个完整的流程示例如图4所示。",
    "context25": "![](images/516d84c41b2e862f7655dbfada985a044aa5318fa22381acf64a89de5f1666a7.jpg)  \n图4任务流程示例  \nFig.4Exemplification of Task Procedure",
    "context26": "(2)自监督学习信息抽取任务的人工标注成本较高,尤其是对于专业领域的综述论文，需要有专业背景的人员才能够完成标注，这使得相关标注数据更为稀缺。未标注数据虽然不具有类别标签,但包含人工标注数据集未覆盖的原始文本信息，可以帮助模型学习更丰富的文本上下文特征,有助于提升模型的泛化外推能力。自监督学习技术旨在让模型从丰富的未标注数据中学习到更多有效信息，从而在标注数据有限的情况下提升预测性能[23]。本文基于伪标签自监督学习的思想,利用已有少量人工标注数据训练模型,并对未标注数据进行自动打标,然后筛选其中的置信样本纳入模型训练,进一步提升模型性能,基本流程如算法2所示。为简化表述,设 $x$ 表示任意一个文本片段(对应上文中任意一个以 $i$ 作为起始、以j作为结束的片段)， $_ y$ 表示该片段的预测概率(对应上文中 $Y ^ { i , j } =$ sigmoid (concat $( \\pmb { T } ^ { i } , \\pmb { T } ^ { j } ) \\cdot \\pmb { W } _ { s p a n } )$ ）， $\\hat { y }$ 表示该片段的真实标签值(对应上文中 ${ \\hat { Y } } ^ { i , j }$ ）。",
    "context27": "算法2：伪标签自监督学习的算法流程",
    "context28": "输入：有标签样本集 $S _ { l a b e l } = \\{ [ \\ : x , \\hat { y } \\ : ] \\ : \\}$ ,无标签样本集$S _ { u n l a b e l } = \\left\\{ \\begin{array} { r l r } { \\boldsymbol { x } } & { \\ } & { } \\end{array} \\right\\}$ ,阈值 $( \\gamma _ { h } , \\gamma _ { l } )$ ；  \n输出：自监督学习模型 $M _ { s s }$ ；  \n初始化：伪标签样本集 $S _ { p l a b e l } = \\emptyset$ ；  \n$\\textcircled{1}$ 根据公式(2)进行监督学习，利用 $S _ { l a b e l }$ 训练得到基础模型 $M _ { s }$ ；  \n$\\textcircled{2}$ 对于所有样本 $x \\in S _ { u n l a b e l }$ ,执行：计算预测值 $y = M _ { s } ( x )$ ，如果 $y > \\gamma _ { h }$ 或 $y < \\gamma _ { l }$ ，将$\\left[ x , y \\right]$ 加入伪标签样本集 $S _ { p l a b e l }$ ；  \n$\\textcircled{3}$ 根据公式(2)进行监督学习,利用 $S _ { l a b e l } \\cup S _ { p l a b e l }$ 训练得到自监督学习模型 $M _ { s s }$ 。",
    "context29": "其中,阈值上限 $\\gamma _ { h }$ 与阈值下限 $\\gamma _ { l }$ 为超参数，预测值超过阈值上下限范围的样本是置信样本,加入伪标签样本集。该阈值通过评估 $M _ { s }$ 产生的置信样本占比及其F1值确定，下文实验部分将探讨不同阈值对最终模型 $M _ { s s }$ 的性能影响。当伪标签样本的准确性较差时，将引入较多错误的训练样本，反而导致模型性能下降。因此,通过评估伪标签数据集的F1值及置信样本占比,可以平衡质量和规模,达到最佳的性能提升效果。另外,本文仅考虑了一轮自监督学习的情况,伪标签样本集还可以多次迭代扩充,可作为后续研究方向。"
  },
  "4实验结果与分析": "",
  "4.1实验数据": {
    "context1": "为便于实验分析，在3.2节采集标注的数据集基础上，随机划分训练数据集和测试数据集,并保证其原文互不交叉，分别用于模型训练和性能评估。训练数据集包括390段文本，对应2454条问答样本；测试数据集包括379段文本，对应2337条问答样本。每段文本中的要素实体、要素间关系以及要素标签均已完整标注，这三类任务问答样本的占比分别约为 $5 5 \\% . 3 5 \\% . 1 0 \\%$ 。"
  },
  "4.2抽取模型实验": {
    "context1": "综述论文具有专业性较强、篇幅较长等特点，相关标注工作需要具备专业背景的人员深度参与，因此高质量标注数据获取成本极高。在这类低资源场景下，信息抽取任务很难取得较好的性能表现，例如,在WNUT17数据集上实体抽取的最佳F1值低于$0 . 6 ^ { [ 2 4 ] }$ 。另外,综述论文数据有术语分布长尾稀疏等特点，导致训练数据信息对测试数据信息的覆盖率较低,即测试数据中的很多术语较少或没有在训练数据中出现过,进一步提升了问题的难度。",
    "context2": "本节评测了在同样采用BERT-Base-Uncased预训练模型的情况下，阅读理解方法与序列标注方法解决要素识别任务的性能差异。具体选用的阅读理解方法是BERT-MRC[22]。其基本思路为,对各要素类型构建查询语句，预测每个Token是否为指定类型要素在原文中的起始位置，并对候选起始位置围成的片段做二次裁定。BERT-Tagger[25]是最经典并且仍在广泛使用的一种序列标注方法,在大量研究中被用作实验对比的性能基线。其基本思路为，采用BMES标记法(B、M、E分别代表要素实体的开头、中间和结尾,S代表独自成词,O代表其他),将原文中每个Token归为B-X、M-X、E-X、S-X、O中的一个标记类别,基于各Token的标记类型解码得到所有要素实体。其中,X是要素类型,TokenToken标记类别数 $\\scriptstyle \\sum 4 \\times$ 要素类型数 $+ 1$ ,即随着要素类型数增加，BERT-Tagger需要分类的标记类别数也会增加,模型参数量将随之增大。相对地,BERT-MRC的要素类型通过自然语言表达隐含在查询语句中，因此,其模型参数量与要素类型数无关,保证了不同领域下部署环境要求的一致性。BERT-MRC与BERT-Tagger的实验结果对比如表1所示，可以看出BERT-MRC性能更优。",
    "context3": "表1阅读理解模型与序列标注模型的要素识别性能对比 Table1Performance of BERT-Tagger and BERT-MRC",
    "context4": "<table><tr><td>模型</td><td>准确率(%)</td><td>召回率(%)</td><td>F1(%)</td></tr><tr><td>BERT-Tagger</td><td>51.21</td><td>54.58</td><td>52.84</td></tr><tr><td>BERT-MRC</td><td>52.64</td><td>54.81</td><td>53.70</td></tr></table>",
    "context5": "相比于BERT-Tagger分类时各类别的模型参数相互隔离，BERT-MRC采用自然语言方式构建查询语句,能够利用语言模型共享参数的能力学习跨类别的样本信息,对于样本较少、分布稀疏的要素类型更有优势。此外，由于易于扩展、能够处理嵌套问题等特性,该模型更适合用于多任务学习、自监督学习等研究工作。"
  },
  "4.3多任务学习实验": {
    "context1": "在3.3节介绍的技术框架中，通过在相同流程中填充不同的查询语句，能够实现对多种任务的统一解决方案。为验证该框架的性能,采用传统单任务学习方式训练的模型作为基准对照。其中,单任务学习方式针对性地选择任务相关的标注数据进行模型训练，即构建独立同分布的训练集和测试集,例如,对于要素间关系识别任务，只使用该任务的训练集用作模型训练。而在多任务的实验中，采用要素识别、要素间关系识别、要素标签识别三种任务的训练集共同完成模型训练。在单任务和多任务的实验中，每种任务用作性能评估的测试集保持一致,例如,在多任务学习方式的要素标签识别实验中，采用三种任务的训练集进行训练，并采用要素标签识别的测试集进行评估。对比实验的结果如图5所示。",
    "context2": "与传统单任务学习方式相比,本文提出的统一框架采用多任务学习方式取得了更好的性能表现。特别是对于要素间关系识别任务，相比于只采用该任务自身的训练集训练模型,加入要素识别及要素标签识别任务的训练数据后，其准确率提升8.32个百分点( $4 5 . 3 6 \\%$ 至 $5 3 . 6 8 \\%$ )。这说明该框架能够在模型训练过程中，实现不同任务下标注数据的信息互相补充,从而提升了各个任务的预测能力。此外，该框架使用单一模型,不仅对各任务性能有帮助，还能降低模型部署和维护的成本。",
    "context3": "![](images/007a45cf0c027963f348cafe2a3752d6ddea6dfe5f38584009ba4caf4010a20d.jpg)  \n图5单任务学习与多任务学习的性能对比  \nFig.5Performance of Single-task Learning and Multi-task Learning"
  },
  "4.4自监督学习实验": {
    "context1": "对于低资源场景，除了利用跨任务的标注数据之外,本实验还探索利用自监督学习方法,挖掘无标签数据中的更多上下文信息，并将这些信息融入模型进一步提升预测能力。采用上述人工标注的所有任务的训练数据集,基于统一框架进行监督学习，得到基础模型;另外，从论文全文中随机截取了1110段无标注文本构建查询语句,利用基础模型预测得到各任务的答案片段,并在5组不同阈值下分别筛选得到置信样本，形成5个伪标签数据集。表2中展示了人工抽样评估得到的各数据集的F1值,以及它们各自对应的置信样本占比。将每个伪标签数据集分别加入人工标注的训练数据集中进行模型训练，得到5个新的模型,用所有任务的测试集评估每个新模型的性能。",
    "context2": "基于自监督学习思想，伪标签技术能够显著提升模型性能。特别是当阈值为(-5,3)时,伪标签数据集的F1值为 $7 2 . 9 6 \\%$ 、置信样本占比为 $9 6 . 7 8 \\%$ ,测试集F1值增长最大,接近2个百分点，此时伪标签数据集在质量(F1值)与数量(置信样本占比)之间取得了较好的平衡。实验表明,在本文提出的统一信息抽取技术框架下，自监督方法可以有效利用未标注的数据提升模型性能,并且当利用较大规模、较高质量的伪标签数据集时，性能提升较大。",
    "context3": "表2监督学习与自监督学习性能对比 Table2Performance of Supervised Learning and SelfSupervised Learning",
    "context4": "<table><tr><td rowspan=\"2\">方法</td><td colspan=\"3\">伪标签数据集</td><td colspan=\"3\">测试集</td></tr><tr><td>阈值 （下限，上限）</td><td>置信样本 占比(%)</td><td>F1 (%)</td><td>准确 率(%)</td><td>召回 率(%)</td><td>F1 (%)</td></tr><tr><td>监督 学习</td><td></td><td></td><td></td><td>54.35</td><td>50.02</td><td>52.09</td></tr><tr><td rowspan=\"5\">自监督 学习</td><td>-15,5</td><td>90.23</td><td>93.34</td><td>57.55</td><td>48.90</td><td>52.87</td></tr><tr><td>-10,5</td><td>93.98</td><td>80.98</td><td>55.82</td><td>51.83</td><td>53.75</td></tr><tr><td>-5,3</td><td>96.78</td><td>72.96</td><td>54.88</td><td>53.25</td><td>54.05</td></tr><tr><td>-3,1</td><td>98.23</td><td>68.57</td><td>55.25</td><td>52.83</td><td>54.01</td></tr><tr><td>0,0</td><td>100.00</td><td>63.50</td><td>51.54</td><td>55.45</td><td>53.42</td></tr></table>"
  },
  "5结语": {
    "context1": "本文提出了一套针对综述论文的语义情报要素体系,该体系涵盖要素类型、要素间关系、要素重要性等多个关键维度。同时，为解决对应挖掘任务中的技术挑战，构建了支持多种信息抽取任务的统一技术框架。一方面,通过多任务学习方式,充分利用跨任务的标注数据提升整体性能。另一方面,通过引入自监督学习方法，充分利用未标注数据中的潜在信息,在不增加人工标注数据的条件下进一步优化模型表现。值得注意的是，除了本文关注的语义情报要素之外,综述论文中还蕴藏着学科领域相关的其他科技信息，例如方法有效的特定环境条件等，有待进一步深入分析应用。",
    "context2": "参考文献：   \n[1]黄锦华,魏秀菊,王柳,等.国内外科技期刊综述论文发表现状 及影响力分析[J].编辑学报,2019,31(S1):1-5.(Huang Jinhua, Wei Xiuju,Wang Liu,et al. Analysis on Publishing Status and Influence of Review Papers in Chinese Sci-Tech Journals: Comparison with Foreign Sci-Tech Journals[J].Acta Editologica, 2019,31(S1): 1-5.)   \n[2] 李欣哲,鲁晓.国内外科技人才研究领域合作网络及主题分析 [J].科学学研究,2023,41(9):1570-1580.(Li Xinzhe,Lu Xiao. Cooperation Network and Theme Analysis in the Research Field ofScientific and Technological Talents at Home and Abroad[J]. Studies in Science of Science,2023,41(9):1570-1580.)   \n[3] 汪晟,黄青,刘钊丽,等.基于文献计量学的纳米零价铁水污染 控制研究热点分析[J].环境化学,2023,42(11):3729-3744. (Wang Sheng,Huang Qing,Liu Zhaoli, et al. Research Hotspot Analysis of Nano Zero-Valent Iron for Water Polltion Treatment Based on Bibliometrics[J].Environmental Chemistry,2023,42 (11): 3729-3744.)   \n[4] 勇美菁,钟永恒,刘佳,等.国内图书情报领域人工智能研究演 化分析[J].科技管理研究，2020,40(11):155-161.(Yong Meijing,Zhong Yongheng,Liu Jia,et al.Analysis of Artificial Intelligence Research Evolution of Library and Information Field in China[J]. Science and Technology Management Research, 2020,40(11): 155-161.)   \n[5] Goncalves S,Cortez P,Moro S.A Deep Learning Classifier for Sentence Classification in Biomedical and Computer Science Abstracts[J]. Neural Computing and Applications, 2020,32(1): 6793-6807.   \n[6] 李雪思,张智雄,刘熠,等.科技文献研究问题句识别方法研究 [J].图书情报工作,2023,67(9):132-140.(Li Xuesi, Zhang Zhixiong,LiuYi,et al.A Studyon the Methodof Identifying Research Question Sentences in Scientific Articles[J].Library and Information Service,2023,67(9):132-140.)   \n[7] 曹树金,闫颂.基于语义角色信息的科技论文创新段落定位及 功能句识别方法研究——以中文情报学领域论文为例[J].情报 理论与实践,2022,45(11):1-9.(Cao Shujin, Yan Song.Research on Inovative Paragraph Positioning and Functional Sentence Identification Method of Scientific and Technical Papers Based on Semantic Role Information:A Case Study of Papers in the Field of Chinese Intelligence[J]. Information Studies: Theory & Application,2022,45(11): 1-9.)   \n[8] Yang S,Tensmeyer C,Wigington C. TELIN: Table Entity Linker for Extracting Leaderboards from Machine Learning Publications [C]//Proceedings of the 1st Workshop on Information Extraction from Scientific Publications,2022:20-25.   \n[9] 章成志,谢雨欣,宋云天.学术文本中细粒度知识实体的关联 分析[J].图书馆论坛,2021,41(3):12-20.(Zhang Chengzhi, Xie Yuxin,Song Yuntian．Association Analysis of Fine-Grained Knowledge Entities in Academic Texts[J].Library Tribune,2021, 41(3):12-20.)   \n[10] 刘悦,刘大晖,葛献远,等.高质量的材料科学文本挖掘数据集 构建方法[J].物理学报,2023,72(7):41-54.(Liu Yue,Liu Dahui, Ge Xianyuan, et al.A High-Quality Dataset Construction Method for Text Mining in Materials Science[J].Acta Physica Sinica, 2023, 72(7): 41-54.)   \n[11] 黄容.科技文献中事理知识抽取研究[D].武汉:华中师范大学, 2020.(Huang Rong.Research on the Extraction of Rational Knowledge from Sci-Tech Literature[D].Wuhan: Central China Normal University,2020.)   \n[12] Li JY, Fei H, Liu J,et al. Unified Named Entity Recognition as Word-Word Relation Classification[J].Proceedings of the AAAI Conference on Artificial Intelligence,2022,36(10): 10965-10973.   \n[13]LiF,Lin Z C, Zhang M S,et al.A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition[C]// Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 1lth International Joint Conference on Natural Language Processing.2021: 4814-4828.   \n[14]Wang JN, Wang CY,Tan C Q,et al.SpanProto: A Two-Stage SpanBasedPrototypical Network for Few-Shot Named Entity Recognition[C]//Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.2022: 3466-3476.   \n[15]Yan H, Gui T, Dai $\\textrm { J Q }$ ,et al.A Unified Generative Framework for Various NER Subtasks[C]/Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. 2021: 5808-5822.   \n[16]Wang S H, Sun X F,Li X Y,et al. GPT-NER:Named Entity Recognition via Large Language Models[OL].arXiv Preprint, arXiv: 2304.10428.   \n[17] Peng X Y, Zhang C, Xu K. Document-Level Relation Extraction viaSubgraphReasoning[C]//Proceedingsofthe31st International Joint Conference on Artificial Intelligence.2022: 4331-4337.   \n[18] Zeng S,Xu R X,Chang B B,et al.Double Graph Based ReasoningforDocument-LevelRelationExtraction[C]// Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. 2020: 1630-1640.   \n[19] Nan G S,Guo Z J,Sekulic I,et al.Reasoning with Latent Structure Refinement for Document-Level Relation Extraction [C]/Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020:1546-1557.   \n[20]Eberts M,Ulges A.Span-Based Joint Entity and Relation Extraction with Transformer Pre-Training[OL].arXiv Preprint, arXiv: 1909.07755.   \n[21] HeyT,Tansley S,Tolle K,等．第四范式:数据密集型科学发现"
  }
}