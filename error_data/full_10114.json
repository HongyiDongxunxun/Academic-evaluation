{
  "original_filename": "full_10114.md",
  "面向听障用户的数字图书馆信息无障碍智能交互技术研究述评": {
    "context1": "张兴旺 郝彦娜王璐",
    "context2": "【摘要】信息无障碍智能交互（IAII）技术能有效解决数字图书馆残障用户的信息获取与信息服务问题。在对IAII理论、主要技术与听障IAII关键技术等进行分析的基础上，对听障IAII技术发展历史进行了简述，并对其技术框架、相关工具与典型应用进行了深入分析，再对其在数字图书馆中的应用进行了展望。",
    "context3": "【关键词】听障用户数字图书馆信息无障碍智能交互智能交互手语计算",
    "context4": "Abstract: Information accessbility intelligent interaction （IAII） technology can effectively solve the problem of informationacquisitionand information service for disabled users in digital library.Basedon the analysis of IAI theory，main technologiesand key technologies of hearing-impaired IAII，this paper briefly introduces the development history of hearing-impaired IAI technology，and deeply analyzes its technical framework，related tools and typical applications，and then prospects its application in digital library.",
    "context5": "Key words: hearing impaired usersdigital libraryinformation accessbility intellgent interaction （IAI1)   \nintelligent interaction sign language computing   \nDOI:10.15941/j.cnki.issn1001-0424.2020.21.001"
  },
  "1研究背景": {
    "context1": "随着人工智能、5G/6G、物联传感、数字孪生等信息技术的飞速发展，智能人机交互已成为数字图书馆领域的研究热点，尤其是信息无障碍智能交互（Information Accessibility Intellgent Interaction，IAII）更是人机交互领域的前沿课题。自1984年IBM首次研发面向盲人的读屏程序、2000年在日本冲绳召开的八国首脑会议首次正式提出Information Accessbility（以下简称IA）概念以来，IAII技术引起了各国政府和社会各界的广泛关注。2004年，我国举办了第一届信息无障碍（IA）论坛，对相关概念、内涵、特征与类型等进行了分析；2006年，国家工信部将IA工作列为重点工程，组织制定了一系列标准规范；2019年，我国第十四届IA论坛提出，IAII技术与产品研发将会成为未来信息服务领域的重要方向。人机交互、文字/图像/语音识别、手语计算等信息技术也被应用到相关领域，用以弥补残障用户的生理或认知能力的不足，帮助他们便捷地与其他用户、物理实体和信息设备进行信息交互。同时，相关应用已随着嵌入式智能芯片、物联传感、人工智能等技术发展，逐渐渗透到脑机交互、可穿戴设备、虚拟/增强/混合现实（VR/AR/MR）等领域，尽管发展较慢，但社会影响较大。从已有研究来看，目前，关于IA研究主要集中在理论分析、现状调查等方面，关于IAII研究主要集中在技术分析、算法优化等方面，针对具体用户的IAII研究相对较少，关于听障用户的IAII研究更是极少涉及。",
    "context2": "基于此，本文在对IAII进行理论分析基础上，对听障IAII技术发展、关键技术与工具进行分析，并对其相关应用进行对比分析，以期为我国相关领域研究提供参考，并对其在数字图书馆中的应用前景进行展望。"
  },
  "2IAII理论与技术分析": "",
  "2.1IAI理论分析": {
    "context1": "IAII源自IA理论与技术，是IA技术的延伸与实例化。现有关于IA研究大部分是从人文角度展开[-，本文认为，IA作为一个跨领域、跨学科的交叉性研究领域，相关研究除了从人文视角进行阐释之外，还需从技术角度对其进行完善与补充，IAII理论与技术研究亦是如此。在人文情怀方面，IAII着力于弥补残障用户生理与认知能力不足，努力帮助他们无障碍地融合社会，自由生活；在技术实现方面，IAI需通过人工智能、人机交互、物联传感等信息技术，实现残障用户与其他用户、物理世界、信息设备之间的无障碍交流与智能交互。因此，从人文与技术角度对IAII进行概念界定，可认为IAII是指采用人工智能、人机交互等先进信息技术与智能化设施，弥补残障用户生理与认知能力不足，帮助他们在任何情况下都能平等、便捷、无障碍地实现信息获取、利用与智能交互的一种技术方法。",
    "context2": "IAII技术服务特征主要体现在三个方面：（1）服务对象主要以残障人士、老龄人口等生理或认知机能不足的用户群体为主；（2）服务动机是消除因生理、认知、心理、区域与文化差异带来的信息获取与信息利用障碍问题；（3）服务目标是解决残障用户的信息获取、信息利用与智能交互问题。",
    "context3": "从已有研究来看，IAII研究目前还处于初级阶段。在理论上，主要是对相关权益保障5-d、事业发展、服务模式[10-]、研究动态[与网站设计[13-4等问题进行了探讨。在技术上，主要围绕相应的IAII人机交互接$\\sqcap ^ { \\mathtt { [ 1 5 - 1 6 } }$ 、智能化设施[17-1、智能交互技术与算法[19-20等进行了分析。在应用上，简单的IAII应用程序与设备已基本实现，但性能、效率与效果还有待提升，大量应用研究还处于原型系统与概念设计阶段。"
  },
  "2.2 IAI技术分析": {
    "context1": "据统计，我国现有残障人士8502万人。其中，视障、听障、运动障碍与其他残障人士分别为1263、2054、2472、2713万人。在我国人口老龄化现象愈发突出的背景下，各类用户数量仍在持续增加。针对不同类型的用户，采用的IAII技术也有较大差异。根据以上分析，分别对视障、听障、运动障碍三类主要残障用户所需的IAII技术进行分析。"
  },
  "2.2.1面向视障用户的IAII技术分析": {
    "context1": "视障用户服务需求主要包括用户出行、物理实体识别与处理、信息服务与智能化设施交互等方面。（1）针对用户出行的IAII服务技术，主要有基于智能传感体系的复杂环境识别与出行道路识别技术，通过三维声场重建2、低功耗无线震动传感等技术，为视障用户提供环境检测与方向导引服务，或采用助视技术解决儿童盲、低视力与老龄人口等用户的视障问题。但这些技术方法和设备还不够成熟，暂时无法完全替代盲杖，仍需解决更多技术与软硬件问题。（2）针对物理实体识别与处理的IAII服务技术，主要有基于视频-文本[2、图像-文本、文本识别等文本-语音转换技术，如 Microsoft的 Seing AI、Google的Lookout 等。（3）针对信息服务与智能化设施的IAII服务技术，主要采取相应的智能化交互设施来为视障用户提供相应服务，如国内的争渡、晨光、布莱叶、阳光、永德及国外的VoiceOver、NVDA、JAWS、Talkback 等读屏软件。"
  },
  "2.2.2面向听障用户的IAII技术分析": {
    "context1": "面向听障用户的IAII技术主要分为两种：（1）助听技术。采用助听技术、助听设备扩大声音信号，可解决部分听障用户因听觉器官衰退，或因机能损伤带来的听觉功能下降等听力障碍问题。（2）手语技术。采用手语交互、识别与合成等技术，可解决部分听障用户因听觉器官损坏，或机能受损无法恢复等听力障碍问题。其中，手语是目前听障用户信息获取、利用与交互的最有效手段，但因其词法、语法与句法的复杂性，目前仅有少数用户会理解与使用手语，这给听障用户信息交互带来了巨大障碍，同时也为面向听障用户的IAII技术研究提供了重要方向。"
  },
  "2.2.3面向运动障碍（运动控制能力不足）用户的IAII技术分析": {
    "context1": "运动障碍主要指的是因肢体障碍、脑瘫、偏瘫、肌肉萎缩、运动神经元病、帕金森病等带来的运动能力障碍。该类用户大部分因丧失上肢（尤其是手、手指等运动器官）运动控制能力，难以通过传统输入方式进行人机交互。同时，该类用户类型、结构与障碍特征较为复杂，每个用户丧失的运动控制能力的运动器官各不相同。这就需要在识别和解决用户差异性问题的基础上，根据用户实际选择最合适的IAII技术与设施。相应的IAII技术主要有脑机交互、眼动交互等。但这些技术大多存在一定缺点，如眼动交互易误触发、执行精度难以保证“确认”操作执行难度大等。"
  },
  "2.3听障IAII关键技术分析": {
    "context1": "听障用户作为IAII研究关注的重点对象，针对听障用户的用户心理、行为、能力、情感分析[37-3、信息服务39-4d、多模态视听感知4与阅读干预[等方面的研究成果较丰富。而面向听障用户的IAII技术研究还处于起",
    "context2": "步阶段，相关领域需要解决以下几个关键技术。"
  },
  "2.3.1多模态听觉信息理解与识别技术": {
    "context1": "听觉信息是人类获取信息的主要通道，听障用户因部分生理或认知机能缺失，难以完整接收、理解和识别信息，需构建相应的听觉信息理解与识别体系，采用IAII技术智能获取、理解、识别与分析多模态听觉信息的深层语义，将其转化成听障用户能识别与接收的信息与知识资源。其主要包括相应的音频、视频等多模态听觉信息与文字、文本、语言之间的交互转换技术，其中识别率、准确性、精确度与可理解性等是需要解决的关键问题，尤其是在复杂、多干扰项环境下的精准理解与识别，能对相应技术的可用性起到重要作用。"
  },
  "2.3.2听觉信号到视觉信号的智能转化技术": {
    "context1": "现有信息获取、利用与交互技术，大都采用文本、图像、音频、视频等跨媒体形式与用户交互，而听障用户大多只能通过视觉信号获取信息，其信息获取、服务与交互方式很单一。这使听障用户对于人机交互方式与技术有着诸多特定需求，进而影响其信息获取与交互方式。因此，就需解决相应的听觉信号到视觉信号的智能转换问题，优化其信息获取、利用与交互方法。"
  },
  "2.3.3个性化信息服务需求与用户意图理解技术": {
    "context1": "部分听障用户自幼丧失听觉机能，且附带丧失语言能力，故手语交互成为其最为重要的信息获取、利用与交互方式。但受经济、社会、地域、语言与环境等因素影响，以手语为主的信息交互方式存在着较大差异，导致用户个性化信息服务需求的获取与分析、用户意图理解与识别难度较大。"
  },
  "3面向听障用户的IAII技术与工具": "",
  "3.1听障IAII技术发展概述": {
    "context1": "2018年世卫组织调查发现全球有近5亿听障患者，助听、手语是听障用户信息获取与交流最有效的两种方法。助听主要解决单向信息获取问题，手语能实现双向信息交互，故构建基于手语智能交互的IAII技术体系，是目前解决听障用户个性化信息服务需求最有效的技术手段[。优秀的IAII技术要适应听障用户的生理、心理与认知实际，通过智能传感、用户意图智能分析、信息智能交互来设计与构建相应的智能化人机交互模式。",
    "context2": "手语IAII技术研究主要经历了三个阶段，第一阶段始于1983年，数据手套首次被用于手语人机交互；第二阶段始于2005年，手语信息处理、手语计算等逐渐应用于听障用户的智能人机交互4；第三阶段是2012年至今，越来越多的研究关注于手语IAII体系架构与技术方法[46-41，在听障用户行为与认知能力描述、意图识别与推理、智能感知与交互等理论与应用研究方面取得了巨大进展[48-49。这些研究使得手语IAII技术迅速被医学、社会学、民族学、人机交互、数字图书馆、语言计算、新闻传播、特殊教育等领域接纳和广泛使用。"
  },
  "3.2听障IAII技术框架": {
    "context1": "随着嵌入式芯片、大数据、人工智能等技术的飞速发展，智能化、无障碍化人机交互迅速成为信息检索领域的重要趋势，出现了越来越多的手语IAII技术与应用。实际上，根据听障IAII服务需求、开发模式及应用领域的不同，其设计理念与技术体系有较大区别。目前较常用的听障IAII系统设计与体系构建方法各有特色，本文根据其共性交互特征与服务需求，将其体系结构归纳如图1所示。",
    "context2": "![](images/00c97d2a8a5673dcd27a50f80ae94332f13b933b497c0a7dcf720ae8182357de.jpg)  \n图1听障IAII技术框架",
    "context3": "从图1可发现，其IAII技术框架主要涉及到听障用户（HIU)、普通用户（OU)、IAII智慧大脑三个方面的智能交互，由此得出其相应的三种手语IAII技术模式，分别为 $\\mathbf { H I U { \\longrightarrow } O U }$ （普通用户“看懂”听障用户手语）模式、 $\\mathbf { O U } { \\longrightarrow } \\mathbf { H I U }$ （听障用户“听懂”普通用户声音）模式、智能交互系统（Intellgent Interactive System，IIS）。"
  },
  "3.2.1 $\\mathbf { H I U { \\to } O U }$ 技术": {
    "context1": "该模式主要将听障用户大规模连续手语转换（翻译）成普通用户易于理解的文本、声音等，其核心在于如何解决高精度的大规模连续手语表达、理解与识别问题。其基本业务流程为手语数据采集与预处理、手语特征分析与提取、连续手语切分与识别、手势翻译与内容输出。根据其数据采集模式的不同，可将其分为基于智能传感的IAII技术与基于视觉搜索的IAII技术两种类型。",
    "context2": "（1）基于智能传感的IAII技术。该技术主要依赖于听障用户所佩戴的嵌入式智能传感设施，来感知、捕捉和记录其手部结构、手势动作与手型变化，将其按时序特征进行有序编码，提取其手势动作特征向量进行手语理解与识别。目前较常用的传感设备是CyberGlove虚拟手套、EMG和IMU传感器、可穿戴式传感器等。Gao W等采用数据手套采集并构建了5000多个中国手语数据资源，并构建了相应的手势识别系统。Juan$\\mathbf { C } ^ { \\left[ 5 3 \\right] }$ 、Li $\\mathbf { Y } ^ { [ 5 \\AA }$ 等采用表面肌电传感器（sEMG）采集手语数据，对其手语识别算法进行了优化分析。 $\\mathbf { K } \\mathbf { i m } \\textbf { Y } ^ { \\left[ 5 \\right] }$ ，$\\mathbf { H o u \\ J } ^ { \\mathrm { \\tiny \\mathrm { ~ [ 5 8 } } }$ 等分别采用多普勒传感器、可穿戴式传感器采集手势数据，并采用深度学习方法进行了分析。",
    "context3": "尽管基于智能传感的IAII技术的大规模连续手语识别效率高、速度快、精度高，且不易受到环境影响，但也存在诸多不足，如手语数据采集规模小，难以适应复杂的大规模服务需求；现有虚拟数据手套等设备成本较高且应用情境有一定局限性，普及性不强，推广价值不高；现有便携式的嵌入式可穿戴传感器信息感知能力有限，难以适应外部复杂环境等。但在各类信息技术飞速发展的技术背景下，未来嵌入式可穿戴智能传感软硬件体系，必然能够大大提升其IAII技术精确性、可用性与可靠性。",
    "context4": "（2）基于视觉搜索的IAII技术。该技术主要以智能终端作为手语输入设备，获取相应的图像、视频等视觉资源后，采用视觉搜索技术对其进行手语理解与识别。早期该模式主要采用2D摄像设备进行手语数据采集，但该方式会丧失三维物理空间信息。近年来，深度摄像技术除了能有效获取其平面手语数据外，还能采集手语深度信息，从而解决了因环境光线、遮挡等造成的手语数据采集不完整、手语识别不敏感等问题。",
    "context5": "目前，该领域主要存在三个技术制约： $\\textcircled{1}$ 大规模手语数据集（语料库）建设问题。因手语专业性与领域性较强，数据采集难度大，尽管2019年国家发布了《手语常用词表》，中科院也发布了8000多个手语词汇（语句)，但目前国内手语数据集的数据规模仍远远不够。 $\\textcircled{2}$ 大规模连续手语切分技术问题。目前，针对手语视觉资源切分技术已从早期基于运动-保持模型的显式切分[5，逐渐转变为基于视觉关键帧时序关联的隐式切分6。尽管如此，其手语识别精度、效率与准确率仍难以满足现实需求。 $\\textcircled{3}$ 大规模连续手语识别技术问题。近年来，深度学习、大数据等信息技术的发展极大地推动了手语理解与识别技术发展。Rakun $\\mathbf { E }$ 等采用长短时神经网络方法应用于印尼手语识别问题汇总。MittalA等提出了一种改进的基于运动修正模型的连续手语识别LSTM模型。",
    "context6": "尽管 $\\mathbf { H I U { \\longrightarrow } O U }$ 技术一直在不断发展，但基于智能传感的IAII技术没有提供自然、便捷的人机交互方式，受限于智能传感设施的使用情境，进行全面推广使用的难度较大；基于视觉搜索的IAII技术易受环境干扰，实际应用推广效果并不理想。因此，这两种方式都存在一定弊端。相信在不久的将来，可穿戴设备、嵌入式智能传感等多模态软硬件设施，结合人机交互、人工智能、视觉搜索等信息技术，必然能有效解决相关问题。"
  },
  "3.2.2 $\\mathbf { O U } { \\longrightarrow } \\mathbf { H I U }$ 技术": {
    "context1": "该模式主要将普通用户文本、声音信息输入转换（翻译）成听障用户易理解的连续手语图像或视频。其关键在于如何高效地解决流畅、易于理解的连续手语生成与合成问题。根据其手语输出方式不同，可将其分为基于虚拟模型的IAII技术与基于视觉合成的IAII技术两种类型。",
    "context2": "（1）基于虚拟模型的IAII技术。该技术主要是将输入的文本、音频信息转换成手语信息，并以虚拟模型（三维手势模型[、虚拟动画模型等）形式进行多模态手语生成与合成，便于听障用户理解与认知。该技术的前提是需根据智能传感设施预先大量捕捉手势动作结构、手语骨骼模型[等，并构建相应的手语数据集（或语料库、数字图书馆等)，再采用数字建模技术生成相应的虚拟模型。该技术主要存在智能生成难度大、实用性与灵活性不强、准确率不高、生成的手语虚拟模型精确度不高、细节描述不足等问题。因此，相比较而言，基于视觉合成的手语合成模型，更为精细、逼真，理解与表达效果更好。",
    "context3": "（2）基于视觉合成的IAII技术。该技术需按照手语词法、句法、语法与语义，在预先采集真人手语词、短语与句的基础上，根据其实际应用语境，结合其词法、语境、韵律与手势位置等手语信息，进行多维度语义标注、语义合成与语义组织等，从而达到手语视觉合成目的。其基本业务流程如图2所示，手语合成的可识别性、可理解性与流畅性是需解决的关键技术问题。可识别性、可理解性主要采用基于手语规则、基于统计分析与基于深度神经网络等方法进行解决；流畅性主要采取基于深度学习的视觉关键帧最佳拼接[、关键帧光流计算[等方法进行解决。",
    "context4": "![](images/123251879452e6c4134f2251ff93cf3b806b25b4cef35437691c5e566ab9405c.jpg)  \n图2手语视觉合成业务流程"
  },
  "3.2.3智能交互系统（IIS)": {
    "context1": "我国手语信息处理技术研究始于20世纪90年代，至今尽管取得了较多成果，但仍未有获得大众认可的手语IAII系统。200年，中科院计算所研发了我国第一代基于传感器的手语合成与识别系统，尝试识别了5000多个单独手语词元；2004年，又开发了手语IIS并取得了不错的测试效果，但在手语可理解性、句法处理等方面还需提升；目前，该团队联合了多家研究机构研发了基于Kinet传感装置的手语IS系统。WangF等[采用手臂传感器采集手臂肌电EMG数据进行训练，将手语转换成文本、语音信号反馈给听障用户，并构建了相应的手语双向IIS系统。",
    "context2": "在此基础上，更加人性化、高效便捷的IIS研究一直都是研究热点，如中科院计算所研发的“聋哑人-医生”远程实时协同手语智能交互系统、腾讯推出的智能手语翻译系统，以及国外相关团队研发的 SignWriting、ASL-phabet、HamNoSys等手语智能交互系统[。这些研究尽管在准确率、精确性、实时性与实用性等方面取得了巨大进步，但在复杂交互情境、连续手语识别精确率与交互智能性等方面还有一定缺陷。"
  },
  "3.3听障IAII工具": {
    "context1": "听障IAII研究热潮催生了诸多IA工具。目前，相关工具主要分为智能传感设施、数据集（语料库）与开源资源三种类型，如表1所示。",
    "context2": "智能传感设施是听障IAII研究不可或缺的重要工具。封万俊等认为目前听障IAII技术研究主要分为基于手语传感器技术和基于视觉识别技术两种类型。Taehee K等将手语传感设备分为五种，即虚拟数据手套、肌电传感（EMG)、雷达传感、惯性测量单元微传感（IMU）和可穿戴运动传感设备。KumarDA等将手势捕捉设备品牌进行了梳理，将手语传感设备分为手势动作捕捉、手语视觉识别与手语智能传感三大类型。MengXY等[将手语传感器主要分为接触式与非接触式两种类型。",
    "context3": "大规模连续手语数据集建设是手语IAII技术的重难点，也是推动我国听障IAII事业产业化、实用化发展的关键所在。手语数据集主要分为孤立手语集与连续手语数据集两种类型[。其中，前者采集样本量相对较大，可用性不强；后者采集样本量与训练数据集规模较小，可用性强。目前，国际上使用较多的是欧美国家连续手语数据集，如 RWTH-PHONIX-Weather、SIGNUM、ASL-LEX、ChaLearn LAPConGD、6DMG、LSE-Sign、ASLLVD 等数据集 80-8』。国内比较有代表性的是DEVISION、CSLR、现代中国手语等数据集。除此之外，还有相关手语图像、字母表、词汇、手势形状、手部动作等数据集，以及可穿戴设备、数据手套与各类传感器采集到的特殊手语数据集等。",
    "context4": "表1听障IAI工具",
    "context5": "<table><tr><td rowspan=1 colspan=1>工具类型</td><td rowspan=1 colspan=1>工具名称</td><td rowspan=1 colspan=1>主要功能</td><td rowspan=1 colspan=1>特征及用途</td></tr><tr><td rowspan=1 colspan=1>智能传感设施</td><td rowspan=1 colspan=1>Cyber Glove数据手套、EMG传感器、IMU传感器、多普达雷达传感器、HTCVIVE动作捕捉器、HandMocap 手势捕捉器、Kinect设备、能MyVoice手语捕捉器等</td><td rowspan=1 colspan=1>主要用于实现捕捉用户的各种手势动作、手语变化等，具备手语数据传输功</td><td rowspan=1 colspan=1>识别效率高、数据获取速度快、环境敏感度低；但数据手套成本高，使用场景受限；传感器细粒度信息感知能力有限，难以满足复杂场景应用需求</td></tr><tr><td rowspan=6 colspan=1>手语数据集</td><td rowspan=6 colspan=1>RWTH-PHONIX-Weather（德国）、SIGNUM（德国）、ASL-LEX（美国）、ChaLearn LAP ConGD（美国）、LSA64（阿根廷）、LSE-Sign（西班牙）、ASLLVD（美国）、DEVISION（中国）、CSLR（中国）、6DMG（美国）、现代中国手语等</td><td rowspan=6 colspan=1>主要用于测试训练手语数据集，提升大规模连续手语识别率、智能性、可理解性与准确性等功能</td><td rowspan=1 colspan=1>RWTH-PHONIX-Weather:采集9个人的45760视频样本，1200个手语词汇</td></tr><tr><td rowspan=1 colspan=1>SIGNUM:采集25个人的33210个视频样本，450个手语词汇</td></tr><tr><td rowspan=1 colspan=1>DIVISION:采集30个人的4414个手语词汇</td></tr><tr><td rowspan=1 colspan=1>ChaLearn LAP ConGD:采集 21 个人的47939个手势，该领域最常用的训练数据集</td></tr><tr><td rowspan=1 colspan=1>6DMG:采集28个人的5600个手语样本</td></tr><tr><td rowspan=1 colspan=1>ASLLVD:采集6个人的9794个手语样本</td></tr><tr><td rowspan=1 colspan=1>开源资源</td><td rowspan=1 colspan=1>MediaPipe开源技术框架、BlazePalm实时手部/手掌检测模型、Open CV 开源库、TensorFlow开源库等</td><td rowspan=1 colspan=1>主要为研究者提供相应的手语IAII技术框架、算法与脚本等</td><td rowspan=1 colspan=1>可免费获取的开源技术框架、算法库与脚本代码等，使用较灵活，二次开发成本低，且功能齐全</td></tr></table>"
  },
  "4面向听障用户的IAII应用的比较分析": {
    "context1": "由于听障IAII技术仍处于初级阶段，在理论、技术与应用层面存在诸多不足，尽管国内外一些企业、研究机构与高校，开展了大量研究，在理论与技术上取得了巨大进展，出现了一些典型案例，许多技术方法也在实验环境下得到了有效验证，但其应用效果、效率、可用性与可靠性等方面还存在一定问题，可推广性还不强。表2对国内外已有面向听障用户的IAII应用的研究背景、建设模式、关键技术及基本功能等进行了梳理。",
    "context2": "表2听障IAII应用对比分析",
    "context3": "<table><tr><td>名称</td><td>研究背景</td><td>建设模式</td><td>关键技术</td><td>功能描述</td></tr><tr><td>基于Kinect手语 翻译系统</td><td>由 Microsoft亚洲研 究院、中科院计算所 等2013年联合推出， 后陆续推出多个版本</td><td>基于Kinect传感 器模式</td><td>大规模连续手语识 别、高可理解性手语 合成、手语实时生成 等</td><td>可帮助不同文化与语言背景听障 用户实现信息无障碍交流；能识 别多个国家手语，将其实时翻译 成当地语言，并能将文本信息实 时翻译成多个国家手语</td></tr><tr><td colspan=\"1\" rowspan=\"1\">GoogleConnectDirect</td><td colspan=\"1\" rowspan=\"1\">由GoogleAI实验室研发推出，同时设计并提出了一种手语识别算法</td><td colspan=\"1\" rowspan=\"1\">基于视觉搜索模式（基于摄像头捕捉与深度学习)</td><td colspan=\"1\" rowspan=\"1\">手指动态轨迹追踪技术、高精确度手部动作识别、手部特征提取与手语合成技术等</td><td colspan=\"1\" rowspan=\"1\">无需专用设备，只需通过手机、平板等智能终端，就可为听障用户提供IAII实时辅助功能；实时捕捉手部动作轨迹，依据手指关节变化、手掌大小、角度等计算手势形状，将手势与手语关联，再进行实时手语翻译</td></tr><tr><td colspan=\"1\" rowspan=\"1\">AmazonAlexa</td><td colspan=\"1\" rowspan=\"1\">由 Amazon 于 2018年初步研发，但暂时未推广使用</td><td colspan=\"1\" rowspan=\"1\">基于视觉搜索模式</td><td colspan=\"1\" rowspan=\"1\">手势解码与切分、手语捕捉与识别、手语智能转化等</td><td colspan=\"1\" rowspan=\"1\">利用移动智能终端摄像头识别手语，并将其翻译成语音与文本信息；该技术缺点在于能识别手语，但无法将语音或文本翻译成手语，故处于初级研发阶段</td></tr><tr><td colspan=\"1\" rowspan=\"1\">Aiko &amp; JunkoChihira机器人</td><td colspan=\"1\" rowspan=\"1\">由日本东芝公司2014年首次推出，后与大阪大学联合开发，2017年推出新型机器人</td><td colspan=\"1\" rowspan=\"1\">基于传感器（角色机器人）模式</td><td colspan=\"1\" rowspan=\"1\">机器人行为驱动与运动传感、手语运动控制与协调算法、手语表达与识别技术等</td><td colspan=\"1\" rowspan=\"1\">以气压推动机器人手部动作，能表达和识别预先设定的手语；计划2020年推出智能化的手语机器人；目的是为老龄以及老年痴呆用户提供服务，能实现中、英、日三种语言交互，目前处于持续更新状态</td></tr><tr><td colspan=\"1\" rowspan=\"1\"> Project Aslan</td><td colspan=\"1\" rowspan=\"1\">由Antwerp 大学2017年研发推出的机器人手语翻译器</td><td colspan=\"1\" rowspan=\"1\">基于传感器（机器人手臂）模式</td><td colspan=\"1\" rowspan=\"1\">3D打印、手语识别与合成、机器人手臂运动控制与协调算法等</td><td colspan=\"1\" rowspan=\"1\">由3D打印机打印所有部件、控制器与电机等组配成机器人手臂，通过电脑控制机器人手臂的手语表达，实现文字向手语的翻译功能；识别手语手势，将其转化成3D图像，并输出为语言</td></tr><tr><td colspan=\"1\" rowspan=\"1\">优图AI手语翻译机</td><td colspan=\"1\" rowspan=\"1\">由腾讯优图实验室联合深圳IA研究会2019年推出</td><td colspan=\"1\" rowspan=\"1\">基于视觉搜索模式</td><td colspan=\"1\" rowspan=\"1\">复杂手语的捕捉与识别、手语表达与识别、手语生成与合成等</td><td colspan=\"1\" rowspan=\"1\">通过摄像头能初步实现用户手语表达与识别，将其转换成文字、语音形式；能初步实现对中国不同语言（如方言、民族语言等)的复杂连续手语的表达与识别</td></tr><tr><td colspan=\"1\" rowspan=\"1\">AI手语翻译小程序</td><td colspan=\"1\" rowspan=\"1\">2019年由百度为听障儿童量身打造</td><td colspan=\"1\" rowspan=\"1\">基于虚拟模型模式</td><td colspan=\"1\" rowspan=\"1\">手语数据集构建、大规模连续手语合成、虚拟三维动画建模技术等</td><td colspan=\"1\" rowspan=\"1\">完成常用手语词表、聋校语文课程标准等手语数据集制作；采用OCR、AR、NLP等技术将儿童读本翻译成手语，帮助听障儿童解决阅读问题</td></tr><tr><td colspan=\"1\" rowspan=\"1\">手之声</td><td colspan=\"1\" rowspan=\"1\">湖南株洲市2019年搭建的远程视频手语翻译服务系统</td><td colspan=\"1\" rowspan=\"1\">基于第三方代理模式</td><td colspan=\"1\" rowspan=\"1\">第三方平台提供手语翻译员 (真人)</td><td colspan=\"1\" rowspan=\"1\">通过与翻译中心进行视频通话，由真人手语翻译员提供在线实时翻译，实现其信息无障碍交互</td></tr></table>"
  },
  "5听障IAII技术在数字图书馆中的研究展望": {
    "context1": "数字图书馆一直都是先进服务理念和新型信息技术的主阵地，IAII理论与技术研究可能会对其资源建设、信息检索与人机交互模式产生积极影响，同时也可为相关领域未来研究与发展提供一定参考与支撑。本文认为，为有效推进IAII技术在数字图书馆中的应用与发展，图情研究者可从以下几个方面展开研究。"
  },
  "5.1大规模连续手语数据集（语料库）建设研究": {
    "context1": "高质量的大规模连续手语数据集是面向听障用户的数字图书馆IAII技术实现的重要前提之一。现有数字图书馆较少提供面向听障用户的信息服务，但人工智能、计算机视觉、物联传感等信息技术的飞速发展，使得数字图书馆为听障用户提供无障碍的智能化、个性化和多元化信息服务成为可能。",
    "context2": "但由于手语句法、语法与语义复杂、专业性强且数据采集困难，现有手语数据集的数据规模与用户样本量均较小、手语词汇单一孤立、数据采集与建设缺乏统一标准，同时听障用户信息获取、利用与交互服务需求在不断提升，从而使得现有手语数据集建设规模与质量难以满足数字图书馆IAII技术实施需求。",
    "context3": "因此，构建科学、合理的大规模连续手语数据集是亟待解决的重要问题之一，是数字图书馆IAII理论与技术研究的重要内容。这对于丰富和完善数字图书馆人机交互理论与技术体系，具有较为重要的价值与意义。"
  },
  "5.2面向听障用户的手语数字资源建设研究": {
    "context1": "高质量的手语数字资源是面向听障用户的数字图书馆建设的重要内容之一。现有数字图书馆较少提供面向听障用户的手语阅读服务，相应的手语数字资源也比较缺乏，但听障用户的阅读、信息获取与信息利用需求却在不断增加。以听障儿童为例，目前，面向听障儿童的手语阅读绘本极少，与普通儿童先学说话再学识字不同，听障儿童主要通过手语学习知识，受限于词汇量与知识面，大多时候需通过手语翻译才能理解与掌握，而高质量的手语数字资源及辅助学习功能就能帮助其学习识字与阅读理解，实现无障碍学习与无差异成长。",
    "context2": "构建科学、全面、准确的手语数字资源，以IAII技术为听障用户提供多元化、个性化、无障碍化的学习阅读与知识服务，就具有十分重要的价值与意义，同时对于丰富与完善现有数字图书馆资源建设理念与模式，也有一定参考价值。"
  },
  "5.3面向听障用户的数字图书馆手语信息检索技术研究": {
    "context1": "手语信息检索是听障用户进行信息查询和信息获取的主要方式，也是数字图书馆IAII体系构建的关键技术之一。随着信息检索内涵与外延的不断扩大，数字图书馆信息检索模式正逐渐从传统基于关键词检索模式向语义检索、视觉搜索、可视化检索等模式转变，但大部分数字图书馆忽视了听障用户这一特殊的用户群体，其信息检索模式难以满足听障用户的信息检索需求。",
    "context2": "针对听障用户群体特征，理解并分析其信息检索与知识服务需求，研究并设计基于IAII技术的数字图书馆手语信息检索模式，是深化其信息服务内涵、扩大其信息服务外延的有效途径。而一个优秀的信息检索理念与技术，是让技术适应用户的心理、生理与认知特征，而不是让用户适应技术。因此，如何从听障用户视角来设计和构建基于IAII技术的手语信息检索模式，就成为数字图书馆IAII技术需要解决的重要问题。"
  },
  "5.4听障用户个性化信息服务需求与意图理解研究": {
    "context1": "听障IAII技术是以听障用户为中心的智能化人机交互方案，是对传统数字图书馆人机交互的优化与完善。为此，需采用智能交互方法，建立并引入行为、心理、生理的先验知识对听障用户个性化信息服务需求进行分析，建立用户意图理解、用户行为认知、手语表达方式等计算模型，研究其个性化参数的描述方法，从而尽可能精确、完整地描述其个性化信息服务需求。",
    "context2": "听障用户通过手语表达信息服务需求和信息交互意图，但受限于不同听障用户的表达与交互方式的差异，可能导致用户意图理解的不精确性。因此，如何从听障用户连续手语动作中获取其个性化信息服务需求，理解其用户意图，是需要解决的重要问题。"
  },
  "5.5面向听障用户的数字图书馆信息智能呈现研究": {
    "context1": "听障用户对于数字图书馆人机交互界面、信息交互呈现的认知与理解是不完整的，交互决策的行为模型与心理模型具有一定的随机性。高质量的数字图书馆IAII技术，首先需具备对听障用户信息服务需求的预测能力，确定其信息输出内容与呈现方式；再根据听障用户的信息接收能力将信息输出到相应的信息展示系统中;最后根据IAII情境，对信息呈现方式进行智能优化和动态调整，确保听障用户信息接收的准确性、完整性和有效性。"
  },
  "6结语": {
    "context1": "近年来，以手语计算为代表的IAI技术发展迅速，相关应用实践的可用性也在不断提升，但仍难以满足听障用户个性化信息服务需求。未来，随着人工智能、物联网、嵌入式智能芯片等软硬件技术的发展，文本、图像、音视频等多模态信息融合将会给面向听障用户的数字图书馆IAII技术研究提供更有利的理论与技术支撑，也会给数字图书馆资源建设、信息检索与人机交互模式创新提供更丰富的理论与技术支持。同时，图书馆学、语言学、信息科学与社会学等多学科交叉融合，也有助于IAII技术实现与应用推广，从而为推动我国IA事业发展提供一定支持。"
  },
  "注释": {
    "context1": "[Daugherty，ElingerAE，RogersDIformationAccessbityInternationalJournalofhysicalDistribution&LgisticsManagement，1995，25（1):4-17.  \n孙祯祥，张家年，王静生．我国信息无障碍运动研究综述[．图书情报工作，2007（11)：71-74.  \n郭亚军，卢星宇，张瀚文．人工智能赋能信息无障碍：模式、问题与展望[/OL]．情报理论与实践：1-11．[2020-06-26].http://kns.cnki. net/kcms/detail/11.1762.G3.20200331.1650.003.html.  \n李东晓，熊梦琪．新中国信息无障碍70年：理念、实践与变迁[．浙江学刊，2019（5)：14-23.  \n[]章品，赵媛．美国信息无障碍法律法规研究[]．情报理论与实践，2010（5)：116-119.  \n[赵媛，张欢，王远均，等．我国信息无障碍建设法律法规保障体系研究[]．图书馆论坛，2011（6)：266-274.  \n闫慧：信息无障碍理念在我国公益性信息服务业中的应用现状调查[．图书情报工作，2008（2)：124-128，91.  \n图易红，张冰梅，詹洁：以信息弱势群体为导向的公共图书馆信息无障碍服务探究[．图书馆工作与研究，2015（1)：78-82.  \n郭亚军，席俊红，刘燕权．信息无障碍，距离还有多远？——对146家美国城市公共图书馆的调查[．图书馆论坛，2020（2)：151-158.  \n[0]经渊，郑建明．协同理念下的城镇信息无障碍服务模式研究[．图书馆杂志，2017（5)：16-23，40.  \n[EgusaR，amatae，obayashiealPresentIsuesofIforatioessbilitoftSiecuseechcalert,2018，29 (1): 425-435.  \n[2]徐恩元，张赞玥．我国信息无障碍建设进程探究[]．图书馆论坛，2009（6)：237-240，246.  \n[3]Wang HB，HuXQ，GuoHJ，etal.Information Acesbilityof NavigationSoftwarefor VisuallyImpairedUsers.ackagingEngineering，2019，35（11)：321-332.  \n[4赵英，傅沛蕾．基于主客观检测法的半自动网页信息无障碍测评工具研究[]．情报杂志，2016（8)：192-198.  \n[5]OliveiraJ，GuereiroT，NicolauH,etalBlindPeopleandMobileTouch-BasedTextEntry:AcknowledgingtheNedforDierentFlavors[//heProceedings f the13thInternationalACMSGACCESSCofereceonComputersandAccesibiltyACM，:179-186.  \n[ 安兴伟，曹勇，焦学军，等．基于视听交互刺激的认知机理与脑机接口范式研究进展[]．电子测量与仪器学报，2017（7)：983－993.  \n[]ZhangY，DaiL,LuoIformationAccesilityHuman-MachneIteractionSystemofIntellgent WeirBasedonMGJournal of Hua zhong Universityof Science and Technology（Natural Science Edition)，2O11，39（2)：264-267，282.  \n[8]AzenkotS，WobrockJO,Prasain S，etalInputFingerDetectionforNonvisualTouch ScreenTextEntryinPerkinputheProceedings of Graphics Interface，2012:121-179.  \n[19]张淑军，张群，李辉：基于深度学习的手语识别综述[]．电子与信息学报，2020（4)：1021-1032.  \n[20]長鳴，祐二，加藤，等.Technologyof Information Accessbility for Sign Language Communication [．電子情報通信学会誌 $=$ TheJournal of the Institute of Electronics，Information and Communication Engineers，2018，14（3)：101-132.  \n[21]中国残联.2010年末全国残疾人总数及各类、不同残疾等级人数 EB/OL]．2020-06-26].htp://ww.cdpf.org.cn/sjzx/cjrgk/201206/t20120626_ 387581. shtml.  \n[2]卢莉萍，张晓倩．复杂环境下多传感器目标识别的数据融合方法[/OL]．西安电子科技大学学报：1-8．2020-06-27].http：//kns.cnki. net/kcms/detail/61.1076.TN.20200512.2223.002.html.  \n[23]郝运河，张浩峰，於敏杰，等．基于K-means特征的复杂环境下道路识别算法[．计算机应用研究，2016（2)：602-606.  \n[24王松，张聪．两个听音点处三维声场重建方法[/OL]．计算机工程与应用：1-11．[2020-06-27].htp://kns.cnki.net/kcms/detail/11.2127.TP.20200617.1506.036.html.  \n[25]修威国，唐胜武，王政，等．一种超低功耗无线震动传感器设计[．传感器与微系统，2016（2)：84-86，90.  \n[26邓敏，许江涛，苏晓丹，等．儿童盲和低视力的病因与屈光状态及远用助视器康复研究[．国际眼科杂志，2018（9)：1750-1752.  \n[27] 杜蓓，韩丁，简旭，等．低视力患者助视器验配的应用效果评估[]．眼科新进展，2017（10)：951-954.  \n[28]刘波，余琼武，汪辉．光学助视器在老年低视力及盲康复中的应用[]．第三军医大学学报，2007（18)：1793-1796.  \n[29]陈卓，杜昊，吴雨菲，等．基于视觉-文本关系对齐的跨模态视频片段检索[．中国科学：信息科学，2020（6)：862-876.  \n[0]蒋梦迪，程江华，陈明辉，等．视频和图像文本提取方法综述[]．计算机科学，2017（S2)：8-18.  \n[1]徐富勇，余谅，盛钟松．基于深度学习的任意形状场景文字识别[．四川大学学报（自然科学版），2020（2)：255-263.  \n[2]冯亚琴，沈凌洁，胡婷婷，等．利用语音与文本特征融合改善语音情感识别 []．数据采集与处理，2019（4)：625-631.  \n[3]郗昕，曾凡钢．助听技术发展的新趋势 []．听力学及言语疾病杂志，2019（6)：585-586.  \n[4 袁甜甜，赵伟，杨学，等．大规模连续中国手语数据集的创建与分析[．计算机工程与应用，2019（11)：110-116.  \n[5]仲文远，李大海，张进华，等．可穿戴式干电极脑机接口系统设计[．西安交通大学学报，2020（6)：66-74.  \n[6姜婷婷，吴茜，徐亚萃，等．眼动追踪技术在国外信息行为研究中的应用[．情报学报，2020（2)：217-230.  \nB7]NagelsL，GaudrainE，VickersD，tal.Developmentof VocalEmotionRecogitioninchool-AgeChildren:TheEmoHTestforHearing-mpaired Populations [] .PeerJ，2O20（8)：4-18.  \n[8]范佳露，宫慧娜，肖冉．听障人士沟通研究热点的可视化分析[．中国特殊教育，2019（5)：23-28.  \nB9]袁俊，蔡雅云．“互联网 $^ +$ 图书馆”与听障群体服务态[．图书馆工作与研究，2019（1)：42-46.  \n[40]Jang BS.AnAnalysisonIformation SeekingBehaviorandNedsof HearingImpairedCollgeStudents.Journalof theKoreanSociety forInformation Management，2015，32（1)：297-316.  \n[41]RahimanPFK，Jayanthi VS，Jatanthi A N.Speech Enhancement Method Using DeepLearning Aproach for Hearing-ImpairedListeners/OL]．2020-06-28].HealthInformaticsJournal，2020:1-19.htps://journals.sagepub.com/doi/pdf/10.1177/1460458219893850.  \n[42]袁丽华．融合教育背景下听障大学生阅读疗法干预研究[]．图书馆学研究，2020（9)：72-79.  \n[43]杨全，彭进业．采用 SIFT-BoW和深度图像信息的中国手语识别研究[]．计算机科学，2014（2)：302-307.  \n[4El-GayyarMM,IbrahimAS，Wahed ME.Translation fromArabic Speech to Arabic SignLanguage Basedon Cloud Computing.Egyptian Information Journal,2016（3)：295-303.  \n[45]姚登峰，江铭虎，鲍泓，等．手语计算30年：回顾与展望[]．计算机学报，2019（1)：111-135.  \n[46]罗元，李丹，张毅．基于时空注意力网络的中国手语识别[．半导体光电，2020（3)：414-419.  \n[47]Rastgoo R，Kiani K，EascakeraS.HandSignLanguage RecognitionUsing Multi-viewSkeletonExpert Systems withApplications,2020，150(15)：1-12.  \n[48]吴蕊珠，李晗静，吕会华，等．面向ELAN软件的手语汉语平行语料库构建[．中文信息学报，2019（2)：43-50.  \n[49]沈娟，王硕，郭丹．基于Kinect 3D节点的连续 HMM手语识别[．合肥工业大学学报（自然科学版），2017（5)：638-642.  \nβ0AhujaR，JainD，SachdevaD，et al.Convolutional Neural Network Based American SignLanguageStatic Hand GestureRecognition[ . International Journal of Ambient Computing and Intelligence，2O19，1O（3)： 60-73.  \nβ1 ZhouJ，MalricF，Shirmohammadi S.ANew Hand-Measurement Method to SimplifyCalibrationinCyberGlove-BasedVirtualRehabilitation [ .IEEE Transactions on Instrumentation & Measurement，201O,59（10):2496-2504.  \n[2] Naik GR，Acharyya A，Nguyen HT.ClassficationofFingerExtensionandFlexionofEMGand Cyberglove DatawithModified ICAWeight Matrix [l .IEEE Engineering in Medicine and Biology Society，2014（8)：3829-3832.  \nb3]Feri J，RaulLL，Martiez G，etalComparisoofETextileTechquesand MaterialsfrDGestureSensor withBoostedEletrodeDesign [].Sens0rs，2020，20（8)：2369-2375.  \n54Gao W，Fang G，ZhaoD,et al.A Chinese Sign Language Recognition System Basedon SOFM/SRN/HMM.Patern Recognition,2004，37 (12):2389-2402.  \n55]ChengJ，Chen X，LiuAP，etal.ANovelPhonologyandRadical-CodedChineseSignLanguageRecognitionFramework UsingAccelerometer and Surface Electromyography Sensors [1 .Sensors，2015，15（9)：23303-23324.  \ndLiY，Chen X，Zhang X，et al.A Sign-Component-BasedFramework forChinese SignLanguage Recognition Using AccelerometerandsEMG Data [].IEEE Trans Biomed Eng，2012，59（10):2695-2704.  \nβ7]KimY，TomajianB.AplicationofDoplerRadarfortheRecognitionof Hand Gestures UsingOptimizedDeConvolutionalNeuralNetworks [C] //2O171th European Conference on Antennas and Propagation （EUCAP)，Paris，2O17:1258-1260.  \nβ8]HouJ,LiXY，ZhuP，tal.Sign Speaker:AReal-Time，High-Precision Smart Watch-BasedSignLanguage Translator/heProceedings of the 25th Annual International Conferenceon Mobile Computing and Networking，Rome，Italy，2O19:1-15.  \n[59]张兴旺，郑聪．领域导向的数字图书馆移动视觉搜索引擎建设研究[]．图书与情报，2016（5)：40-47.  \nbd DianeB.Efects ofLanguage Modaityon Word Segmentation:AnExperimental StudyofhonologicalFactorsinaSignLanguage.Laboratory Phonolgy，2006（8)：155-164.  \n[1] BrockH,LawF，NakadaiK，etal.LearningThree-Dimensional SkeletonDatafromSignLanguage VideoACMTransactionsonIntelligent Systems and Technology （TIST），2020 （4):370-377."
  }
}