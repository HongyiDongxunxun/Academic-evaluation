{
  "original_filename": "full_3088.md",
  "nothing": {
    "context1": "情报理论与实践 Information Studies:Theory&Application ISSN1000-7490,CN 11-1762/G3"
  },
  "《情报理论与实践》网络首发论文": {
    "context1": "题目：  \n作者：  \n网络首发日期： 发日期：  \n引用格式：  \n国内外算法风险研究：框架、特征及展望  \n马海群，张涛  \n2024-08-07  \n马海群，张涛．国内外算法风险研究：框架、特征及展望[J/OL]．情报理论与  \n实践.https://link.cnki.net/urlid/11.1762.G3.20240807.1551.004",
    "context2": "网络首发：在编辑部工作流程中，稿件从录用到出版要经历录用定稿、排版定稿、整期汇编定稿等阶段。录用定稿指内容已经确定，且通过同行评议、主编终审同意刊用的稿件。排版定稿指录用定稿按照期刊特定版式（包括网络呈现版式）排版后的稿件，可暂不确定出版年、卷、期和页码。整期汇编定稿指出版年、卷、期、页码均已确定的印刷或数字出版的整期汇编稿件。录用定稿网络首发稿件内容必须符合《出版管理条例》和《期刊出版管理规定》的有关规定；学术研究成果具有创新性、科学性和先进性，符合编辑部对刊文的录用要求，不存在学术不端行为及其他侵权行为；稿件内容应基本符合国家有关书刊编辑、出版的技术标准，正确使用和统一规范语言文字、符号、数字、外文字母、法定计量单位及地图标注等。为确保录用定稿网络首发的严肃性，录用定稿一经发布，不得修改论文题目、作者、机构名称和学术内容，只可基于编辑规范进行少量文字的修改。",
    "context3": "出版确认：纸质期刊编辑部通过与《中国学术期刊（光盘版)》电子杂志社有限公司签约，在《中国学术期刊（网络版)》出版传播平台上创办与纸质期刊内容一致的网络版，以单篇或整期出版形式，在印刷出版之前刊发论文的录用定稿、排版定稿、整期汇编定稿。因为《中国学术期刊（网络版)》是国家新闻出版广电总局批准的网络连续型出版物（ISSN2096-4188，CN11-6037/Z)，所以签约期刊的网络版上网络首发论文视为正式出版。",
    "context4": "●马海群¹，张涛²",
    "context5": "（1.黑龙江大学信息资源管理研究中心，黑龙江哈尔滨150080；2.黑龙江大学信息管理学院，黑龙江哈尔滨150080）",
    "context6": "国内外算法风险研究：框架、特征及展望\\*",
    "context7": "摘要：[目的/意义]随着ChatGPT的横空出世，算法应用越来越多地支配着人类的生活，算法黑箱、算法操控、算法共谋、算法偏见、算法歧视等风险也随之而来，这些风险严重影响社会稳定乃至国家安全。对全球算法风险的形势进行研判能够有助于防范与识别算法风险，并为应对全球算法风险治理难题提供中国智慧与构想。[方法/过程]通过系统梳理国内外主要数据库915条核心文献，构建基于“学科领域一研究主题一治理工具一治理措施”的算法风险研究框架，并分析算法风险具有学科的交叉性、复杂的交织性、突出的人为性、泛化的不确定性等特征。[结果/结论]从加强情报学学科对算法风险研究、加强对人工智能算法可解释性研究、加强算法应用向善和算法服务从善研究、加强对全球算法风险治理中国智慧与构想研究4个方面对算法风险研究问题进行展望。",
    "context8": "关键词：算法风险；算法治理；算法向善"
  },
  "Research on Algorithm Risk at Home and Abroad: Framework, Features, and Prospects": {
    "context1": "Ma Haiqun1, Zhang Tao²",
    "context2": "(1. Research Center of Information Resource Management, Heilongjiang University,",
    "context3": "Heilongjiang Harbin 150080:",
    "context4": "2. School of Information Management, Heilongjiang University, Heilongjiang Harbin150080)",
    "context5": "Abstract: [Purpose/significance] With the emergence of ChatGPT, algorithm applications increasingly dominate human life,algorithm black box, algorithm manipulation, algorithm colusion，algorithm bias，algorithm discrimination and other risks also follow, these risks seriously affect social stability and even national security. The research and judgment of the global algorithmic risk situation can help to prevent and identify algorithmic risks, and provide Chinese wisdom and ideas for dealing with the global algorithmic risk governance problems. [Method/process] The article systematically reviews 915 core literature from major domestic and foreign databases, constructs an algorithm risk research framework based on \"subject areas research topics governance tools governance measures\", and analyzes the interdisciplinary, complex interweaving, prominent anthropomorphism, and generalized uncertainty characteristics of algorithm risk. [Result/conclusion] From five aspects: strengthening the research on algorithmic risks in the field of intelligence science, enhancing the interpretability of artificial intellgence algorithms, strengthening research on algorithmicapplication and service improvement, and strengthening research on global algorithmic risk management and China's wisdom and vision, this paper looks forward to the challenges of algorithmic risks.",
    "context6": "Keywords: algorithmic risk; algorithm governance; algorithm for good",
    "context7": "作为人工智能的核心要素之一，算法已经日益成为经济社会发展和公共治理的重要支点，算法应用给人类生活提供极大的便利，但也越来越多地支配着人类的生活，算法黑箱、算法共谋、算法歧视、算法偏见等风险也随之而来，它为社会稳定及国家安全带来了深远的影响。算法风险通常指以网络平台和企业为代表的算法主体在算法研发、运营过程中存在的因其自身逻辑或算法自主学习所外溢于社会的风险，算法风险的影响或后果可以是积极的、消极的或两者兼而有之，并可能带来机遇或威胁。近年来，国内外对算法风险的研究成果逐渐增多，通过何种途径防范算法应用的风险、化解算法所带来的负面影响，使算法能够尽可能安全、充分地发挥其效用，逐渐成为学界与实务界关注的焦点。2021年是中国算法治理元年，国家网信办出台了一系列算法治理规则，如《关于加强互联网信息服务算法综合治理的指导意见》《互联网信息服务算法推荐管理规定》等，不但提出要对算法进行分级分类管理，而且还明确了平台企业要承担算法安全的主体责任。2022年11月，ChatGPT横空出世，也引起了社会各界对GPT算法所存在的知识产权问题、安全和隐私问题、道德和伦理问题的担忧，我国政府快速响应，在2023年7月发布《生成式人工智能服务管理暂行办法》。这些内容也是学术界长期以来研究的热点问题，由此可见对算法风险的学术研究能有效促进政府制定需求导向型的创新政策。系统性梳理国内外算法风险相关研究可以为政府算法风险治理提供参考，还能为促进人工智能产业均衡发展提供决策依据，但当前国内外学术界尚未发现该主题的系统综述文献。本文在对国内外文献系统梳理的基础上构建算法风险研究框架，基于研究框架分析算法风险特征，最终对算法风险研究问题进行展望。"
  },
  "1研究数据": {
    "context1": "本文提出的算法风险主要包括算法自身安全风险、实现算法风险可控及算法应用风险，算法改进、算法优化等虽然也会对算法带来一定程度的风险，但是该类研究多在计算机领域，而这类研究数据量较大，会影响本文的研究主体，因此未将此类数据纳入采集范围。研究团队采取系统综述方法，分别对国内外核心数据库进行文献检索，检索时间为2023年12月。$\\textcircled{1}$ 国内基于CNKI数据库，使用其高级检索功能，选定核心期刊、CSSCI、CSCD，按照如下检索式：(SU $\\% = \"$ 算法风险\")or(SU $\\% =$ \"算法歧视\")or(SU $\\% =$ \"算法黑箱\")or(SU $\\% =$ \"算法偏见\")or (SU $\\% =$ \"算法霸权\")or(SU $\\% =$ \"算法权利\")or(SU $\\% =$ \"算法异化\")or(SU $\\% =$ \"算法共谋\")or (SU $\\% = \"$ 算法囚徒\")or (SU $\\% = \"$ 算法缺陷\")，经过条件筛选和人工筛选，共获取 588条数据。 $\\textcircled{2}$ 国外基于 WOS 数据库，具体检索式如下：( $\\mathrm { T S } { } =$ \"algorithmic risk\"） or$\\mathrm { T S } ^ { = 1 }$ 'algorithmic discrimination\") or ( $\\mathrm { \\Delta T S ^ { = } } ^ { \\prime }$ 'algorithm black box\"） or (TS=\"algorithmic bias\") or（ $\\mathrm { T S } { = }$ \"algorithmic hegemony\") or ( $\\mathrm { T S } { = } \"$ 'algorithmic alienation\") or( $\\mathrm { T S } ^ { = }$ \"algorithmic collusion\")or( $\\mathrm { T } \\mathbf { S } ^ { = 1 }$ 'algorithmic complicity\") or ( $\\mathrm { T S } { } = { }$ \"algorithm prisoner\")or (TS=\"algorithm flaws\"); 同样经过条件筛选和人工筛选，共获取327条数据。总体来说，国内外关于算法风险文献数量较少，而且发展趋势较为一致。如图1所示，其中，首篇文献均是2016年出现，在2019\\~2023 年间国内外文献逐渐上升，算法风险研究热度逐步提升，尤其是 2019 年\\~2021年间，国内算法推荐所引发的问题较为突出，同时国家有针对性地颁布了一系列政策，这也使得算法风险研究成果数量快速上涨，虽然 2022年的文献数量略有波动，但随着2022年11月ChatGPT的横空出世，生成式 AI 算法风险所带来的一系列安全问题推动了学术研究成果持续上升。此后国内外相继出台了一系列算法规制措施，可以预见未来对算法风险研究仍会呈现持续上升趋势。",
    "context2": "![](images/b3f378f1422b97e80b4e9cfde16249b9530e8e418a18c2405c75555814f814bd.jpg)  \n图1国内外算法风险文献数量图  \nFig.1 Quantitative analysis of algorithmic risk literature at home and abroad"
  },
  "2研究框架": {
    "context1": "本文从国内外算法风险研究文献的学科领域视角出发，参考“主题一工具一措施”的三维分析框架[I，构建基于“学科领域—研究主题一治理工具一治理措施”的算法风险研究框架，如图2所示。在综述过程中，以发文时间、期刊影响因子、下载次数、被引用次数等指标作为不同领域研究重点的依据。",
    "context2": "![](images/0f33a22460516584d9f232901f84ee74d2642fb1b2574028c5dad80de91a9b51.jpg)  \n图2国内外算法风险研究框架  \nFig.2 Research framework for algorithmic risk at home and abroad"
  },
  "2.1学科领域分布广": {
    "context1": "将文献样本按照所在学科领域划分，以学科分类为领域划分标准。现有算法风险研究领域覆盖法学、新闻传播学、哲学、金融学、教育学等学科，尤其近年来研究成果快速增长的同时，研究所覆盖领域不断拓宽。",
    "context2": "2.1.1法学领域算法风险法律规制一直是学界研究的热点问题，国内外在法学领域针对算法风险的研究成果较多，且较为全面，学术研究成果推动了国内外多部法规政策的颁布。国内法学领域研究从郑戈提出如何用法律规制算法及如何用算法强化法律[2]，到丁晓东提出算法规制应采取场景化的规制路径，要根据不同场景类型对算法采取不同的规制方式[3]，再到李训虎提出应从包容性规制角度解决算法应用在刑事司法中暴露出数据垄断、算法黑箱以及应用场景设置随意等问题[4]。尤其是在《中国社会科学》连续刊发两篇关于算法风险的法学文章，足以说明算法风险在法学领域研究的重要性，而且这些研究为推动我国颁布算法治理制度发挥了重要作用。而国外研究多集中在司法、宪法、刑法等方面，尤其针对算法偏见和算法歧视带来的法律问题尤为关注。",
    "context3": "2.1.2新闻传播学领域国内外新闻传播领域将算法风险细分为失实风险、决策风险、偏见风险、隐私风险和声誉风险[5]。从个性化推荐到算法传播研究持续演进，不断升温，体现了该领域算法风险研究的广度。 $\\textcircled{1}$ 个性化推荐。个性化推荐是基于用户的行为，通过算法为用户进行定制推荐，进而演化为千人千面。个性化推荐系统自进入新闻传播领域，逐渐成为新闻信息分发的主要形式，与此同时，个性化推荐存在着严重的安全风险，尤其是近几年Facebook、今日头条、抖音等APP基于算法为用户提供精准推送受到诟病。 $\\textcircled{2}$ 算法传播。数智环境下的传播是利用数据和算法缔造的一种组织化传播，在其一系列转型的背后蕴藏着深层次的风险。",
    "context4": "2.1.3哲学领域随着算法越来越多的参与人类活动，接管各种复杂任务，它们已经成为一种调节人、机器和社会之间关系的关键纽结。有学者从实践哲学视角提出不伤害、自保、最小伤害是自动驾驶汽车算法法则的三大价值原则[]。此后算法所引发的伦理问题和意识形态问题变得越来越突出，并且形成了一系列的研究成果。 $\\textcircled{1}$ 算法伦理风险。当前算法被广泛地嵌入人们日常生活当中，所引发的伦理问题被充分显露并广泛关注。而通常理解算法伦理风险包括不确定性、不可理解性、误导性、不公正性、变革性影响和可追溯性等。 $\\textcircled{2}$ 意识形态风险。随着算法技术的深入发展，算法已经形成一种权力，支配个体对主流意识形态的认同或消解，算法从认知解释、价值信仰和目标策略等层面影响主流意识形态认同，而算法在应用过程中带来的\"把关转移\"“信息成瘾\"私人定制\"过滤气泡\"在一定程度上造成了社会思想价值的失序、堕化、分化和区隔，使得作为统合性价值体系的主导意识形态面临凝聚力弱化、权威失落、引导乏力和认同窄化的风险[7]。",
    "context5": "2.1.4金融学领域数据、算法、平台是数字经济发展的关键要素、动能及场域[8]，同时算法超出技术工具范畴影响或替代公权力决策给经济社会发展带来了严重安全隐患，尤其是在金融反垄断和金融科技中对算法风险研究较为广泛。 $\\textcircled{1}$ 金融反垄断。算法共谋和定价歧视是网络交易中的反垄断法律规制的两个重要问题[9]。 $\\textcircled{2}$ 金融科技。以大数据、人工智能为底层技术的金融科技，因其算法所具有的不完备性风险，导致了金融科技在应用过程中陷入巨大的欺诈困境[10]。",
    "context6": "2.1.5教育学领域随着教育逐渐进入人工智能时代，智能算法在改变教育的同时，也在给教育带来不可预知的风险。有学者通过分析美国的教育平权案来探讨算法伦理问题[]，此后国内外从教育学视角对算法风险研究的学者逐渐增多。例如，P.Hacker探讨了欧盟反算法歧视下的人工智能教育公平问题[12]；肖凤翔等从“技术逻辑 风险挑战 公共政策\"的分析框架对算法教育治理进行系统探讨[13]；R.Marachi 等通过对 Canvas 学习管理系统的分析呼呼公众在使用此类系统时应防范算法偏见、算法透明度等风险，并提升道德和法律保护的意识[14]；张庆玲等从算法霸权的操作性评价风险对大学评价中的\"计算主义\"倾向进行分析[15]；R.S.Baker 等基于教育中算法偏见问题提出从未知偏见到已知偏见及从不公平到公平的框架[16];王佑镁等探讨了ChatGPT在教育应用中的伦理风险以及伦理困境的规避之路[17]。此外，算法嵌入课堂教学中的风险[18]，思想政治教育中对算法风险问题也备受关注[19]。在教育学领域更多的关注算法风险与教育公平的问题。 >",
    "context7": "2.1.6其他领域国内外学者在医学、公共管理学、社会学、情报学等领域研究成果逐渐增多。 $\\textcircled{1}$ 医学领域。随着人工智能在医学领域中的迅猛发展，人工智能在大幅度提高医疗诊断和治疗效率、提升患者就医便利的同时，也带来了医疗安全、数据安全、算法偏见等问题。$\\textcircled{2}$ 公共管理学领域。除法律规制外，政策制定也是算法风险防范与化解的重要组成部分。国内外学者从公共政策管理、社会治理视角对算法风险进行研究，其中国内基于公共管理的研究成果较多，而国外学者多从法律规制视角进行研究。 $\\textcircled{3}$ 社会学领域。算法社会中通过技术能够提高社会运转效率、增强社会成员幸福度和安全感，但隐私数据泛滥、黑箱运作、算法妨害等风险却不可回避。 $\\textcircled{4}$ 情报学领域。随着人工智能技术的发展，智能算法在情报工作中得以广泛应用，但追求情报分析结果精准性的同时还要兼顾可靠性和稳定性，因此对情报分析算法风险的研究理应受到情报学学者的重视，在情报学领域的研究成果逐渐增多，相关学者从智能情报分析算法风险[20]、智能化情报手段对大国战略稳定的影响评估[21]、国家安全和情报分析中的认知偏见[22]等方面进行研究。尤其进入2023年，更是出现了算法素养内涵与范畴[23]；社交平台算法风险[24]、网络信息服务中的算法安全[25]等研究。由于情报工作服务于国家安全、发展、创新和治理体系等方面的重大决策，因此突出情报领域话语权的算法风险研究成果显得尤为重要。"
  },
  "2.2研究覆盖主题多": {
    "context1": "算法风险是数智时代社会发展的产物，算法风险既有技术自身层面的，也有在涉及技术应用之后，对个体以及对经济社会发展所带来的负面影响[26]，因此从影响国家政治安全与社会稳定方面划分为算法黑箱、算法操控、算法共谋、算法歧视、算法偏见、算法异化等主题。",
    "context2": "2.2.1政治经济风险算法的应用扩张了人的能力，产生了新的权利[27]，算法操控左右舆论导向，从而影响政治进程，这对国家政治与经济发展带来了新的挑战。 $\\textcircled{1}$ 算法操控。算法操控是指算法被人类控制以获取政治上或经济上的利益为目标。其中 2016\\~2018年间剑桥分析公司在美国大选、英国脱欧等事件中利用精准营销影响选民政治态度使其名声大噪。在美国大选中，剑桥分析公司对选民进行数据画像，准确判断不同人群的心理，从而影响目标人群的认知和态度。因为只有算法才可以区分不同偏向的人群，把相同偏向的个体集中在“信息茧房\"或\"回音壁\"中，才能实现特定个性化信息推送，事实上这是一种通过算法达到对目标人群人为支配和控制的行为。在此过程中选民用户并未认识到算法所带来的潜在风险，但事实上剑桥分析公司依据选民性格和认知特点，利用对算法的操控向用户精准投放政治营销广告、制造水军账户发文传播相关政治理念，直接影响到了选民政治态度与投票结果，剑桥分析公司为了经济利益对算法操控的行为危及了社会稳定乃至国家安全。 $\\textcircled{2}$ 算法共谋。数字经济的发展带来了竞争法视角下的算法共谋问题。合谋是一种常见的反竞争行为，算法使用增加了市场的透明度和效率，但它使更容易串通。具体而言，算法通过自动交换信息、监控和调整增加了串通的可能性，使潜在竞争者难以进入市场。伴随数字经济发展，算法共谋作为一个随着智能算法的兴起而形成的新概念，越来越受到国内外经济、法律领域相关学者的高度重视。",
    "context3": "2.2.2社会伦理风险算法在伦理道德层面的风险，最直接体现在由算法控制的机器与人交互的安全风险，一旦算法拥有记忆，所带来的风险更可怕。人工智能作为新技术，其开发与应用都有一定门槛，这将会加剧收入分配的不平等，进而演化为社会的不平等。被人工智能所放大的这种技术不平等所带来的社会不平等，会引起社会伦理风险。算法歧视、算法偏见、算法异化都属于社会伦理风险范畴。算法歧视到算法偏见再到算法异化是一个演进过程，尤其是算法歧视、算法偏见后可能会导致算法异化现象出现，算法异化一旦出现将操控人类的行为，而被算法操控行为的人类又无法识别，这种不可预知的后果可能会打开危害全世界和平的\"潘多拉魔盒”。 $\\textcircled{1}$ 算法歧视。算法歧视是指自动决策算法通过过滤种族、性别、宗教等显性特征，对条件相同的人实施差别待遇，以避免明目张胆的现实歧视[28]。2016 年9月“Nature”发表题为“More Accountability for Big Data Algorithms”的社论文章指出，大数据算法有可能增加偏见或成见，并会复制或加剧人类犯错[29]。算法歧视给社会各行业带来了巨大的安全风险。 $\\textcircled{2}$ 算法偏见。从算法歧视到算法偏见是交互演进、相互作用的。所谓算法偏见就是在机器学习过程中，由于初始算法、样本数据或其他原因所形成的思维处理惯性，而导致人工智能系统在真实运行过程中出现有偏向性的举措或选择[30]。 $\\textcircled{3}$ 算法异化。当前算法的飞速发展和自我进化已初步验证了埃鲁尔在其《技术社会》中提出的\"技术的发展通常会脱离人类的控制\"的预言[31]。算法异化原则上属于算法缺陷的一种，只不过算法异化后可能会给社会带来更严重的后果。算法异化往往由多种风险演进而来，尤其是当算法具有人类智慧时，可能会引发更为严重的后果。",
    "context4": "2.2.3算法风险实际应用场景国内外部分学者通过实际应用场景剖析试图破解算法风险。例如，Hwang 等探讨COMPAS 案例中算法的可解释性，并建议将逆向工程技术作为一种促进算法问责制的方法[32]。吴椒军等通过对欧盟相关法规算法黑箱治理条款研究，从技术角度、法律角度与伦理角度对算法黑箱进行法治化管理，以实现算法黑箱法治化治理层面的合法性与最佳性耦合[33]。S.Mukhopadhyay 基于金融部门、生物医学研究、营销活动和刑事司法系统的真实数据示例实证信息论学习框架（可接受的机器学习）和算法风险管理工具的可信性[34]。郝志斌以算法行政风险场景为例，认为其法律规制需要以“算法法权”的科学配置为核心，建构法律、伦理、技术与自我规制一体化的规制体系[35]。"
  },
  "2.3 治理工具多元化": {
    "context1": "推进国家治理体系和治理能力现代化就是要不断创新治理体系和提升治理能力，算法风险治理是国家创新治理体系和提升治理能力的重要组成部分[36]。对算法风险进行有效治理，才能使算法应用创造出更大的社会价值，从治理工具角度出发，涉及“事前一事中一事后”的多元化算法风险治理。 $\\textcircled{1}$ 事前环节。主要包括算法风险防范、算法可解释性、算法风险评估。算法风险防范是有效防范算法所带来的技术性风险是算法风险治理的必要条件和基本前提。算法风险防范国内研究居多，主要从智能投顾、意识形态、智能政府等领域提出；算法可解释性是其本身存在欠缺或不够完备使算法风险程度升高，其中算法黑箱是较为典型的为提升算法精准度而出现的风险。算法可解释性研究是破解算法黑箱的重要手段；算法风险评估是指由特定主体根据已确定的标准对算法自动化决策系统的设计、应用和数据处理等内容进行全面评估，并据此确定该自动化系统对特定区域内的个人或群体所产生的影响程度和风险等级，进而寻求减缓和消除负面影响和风险之应对方案和措施的算法治理活动。国外算法风险评估的研究较早，由于国外法律断案中多采用智能算法，因此要针对算法风险进行评估以确保量刑的公平。 $\\textcircled{2}$ 事中环节。主要包括算法监管，算法公开一直被认为是监管体系中的重要一环，即通过提高算法的透明度，打开算法黑箱以达到监管算法的目的。自《互联网信息服务算法推荐管理规定》正式施行，我国互联网信息服务算法推荐管理有\"规\"可依了。而ChatGPT出现后，我国快速响应，在2023年7月就率先发布了《生成式人工智能服务管理暂行办法》，针对生成式AI进行规制，学界也持续针对算法监管进行深入研究。 $\\textcircled{3}$ 算法问责制度作为一种规制途径，可以从事后问责的角度解决算法引发的问题。算法时代的来临引发一系列危机，算法价值目标的缺失、算法歧视等问题使得公众对算法技术产生担忧与不信任，深刻影响着信息时代的发展进程。"
  },
  "2.4治理措施多样化": {
    "context1": "算法风险治理是一个复杂的、系统的过程，通常需要多样化的措施对算法进行治理。因此将现有研究划分为治理体系、治理路径、治理框架、治理机制等。 $\\textcircled{1}$ 治理体系。当前学者从不同角度对算法风险治理体系进行研究。例如，张吉豫提出算法分级分类的敏捷治理思路，以形成具有中国特色并在世界范围内推广的算法治理体系[37];许可提出引入“算法发展\"平衡算法安全，引入“权利公平\"补充算法公平，引入“私人自主\"调和算法向善，以铸就彰显中国风格、体现中国智慧的算法规制体系[38]。当前国内算法风险治理体系构建更为突出中国特色、中国风格、本土化等。 $\\textcircled{2}$ 治理路径。国内学者从算法风险治理内容层面和应用层面对算法治理路径的研究较多且较集中。内容层面：算法风险法律规制路径[39]、算法伦理治理路径[40]、从算法危及算法信任的本土化路径[41]、算法决策风险防范路径[42]、算法歧视治理路径[43]；应用层面：算法共谋反垄断治理路径[44]、算法应用的公共妨害治理路径[45]、职场领域算法技术风险法律规制路径[46]、档案应用算法风险治理路径[47]，此外还有部分学者针对美国算法治理路径进行研究[48]。 $\\textcircled{3}$ 治理框架与机制。国内外学者在算法风险治理框架和治理机制方面也有研究。例如，T.Lysaght 等采用了健康大数据伦理框架的审慎平衡方法确定相关价值，以确保更高效的医疗保健与人工智能伦理相平衡[49]；K.Rhum以Facebook 的政治微目标为例，阐述了信息信托框架[50]；王燃认为应注意大数据司法监督中的数据风险和算法风险[51]；黎梦兵认为决策过程中容易引发隐私泄露风险、算法决策错误风险、算法偏见风险和声誉风险等，使用户面临不确定的算法决策环境，提出构建算法决策的社会信任机制[52]；J.Vassilopoulou 等基于叙述性审查，提出了检查HR 算法偏见的框架[53]。"
  },
  "3算法风险特征分析": {
    "context1": "基于对国内外文献研究框架的分析，算法风险呈现出学科的交叉性、复杂的交织性、突出的人为性、泛化的不确定性等特征[54]。而对算法风险特征分析有助于准确识别风险，并能够实现对算法风险防范、评估、监管、问责等精准治理措施，如图3所示。",
    "context2": "![](images/8540453a5c371d1504fb3cad87f46beb4c250577ebf953dad9ccbeed4d29bb82.jpg)  \n图3国内外算法风险特征分析框架图  \nFig.3 Framework for analyzing characteristics of algorithmic risk at home and abroad",
    "context3": "1）学科的交叉性。针对算法风险的研究已经深入各领域，研究具有典型的交叉学科特征，主要体现在以下方面。第一，学科领域交叉。法学、新闻传播学、哲学、金融学、教育学等学科均对算法风险问题进行详细研究，研究体现了较强学科交叉性。例如，人工智能算法给各个学科带来的安全风险是不同的，而且各学科对算法风险的认知差异也较大，因此防范与化解算法风险多通过学科交叉研究来规制。第二，研究主题交叉。算法风险即是法学问题又是哲学问题，还是公共管理学问题，因此算法风险内容本身就具有较强的学科交叉性。例如，算法黑箱会直接导致出现算法操控、算法共谋、算法歧视，甚至是算法异化，需要各学科相互协同来解决。第三，治理工具交叉。一般来说算法风险治理要从防范、评估、监管、问责等角度来进行，而算法可解释性研究是风险治理的关键，对该问题研究除计算机领域外，还涉及法学、哲学、公共管理学等领域从伦理、法律、政策等方面进行有效规制。",
    "context4": "2）复杂的交织性。算法风险具有复杂的交织关系，主要体现在以下方面：第一，算法风险复杂性。由于技术的快速发展，算法风险存在形式的多样性，以多种形式展现其影响力，而算法风险往往存在滞后性，这也增加了算法风险识别的复杂性，加之决策能力等多重因素的影响，风险存在于政治、经济、伦理、科技以及人类感知能力等各个方面，关乎社会稳定与国家安全，算法风险诱发因素复杂多变，尤其是深度学习中神经网络算法所具有的多神经元、分布式并行计算、多层深度反馈调整等特点，这也使算法风险具有较高的复杂程度。第二，算法风险交织性。算法黑箱是导致系列风险出现的根源，往往在算法应用过程中，由算法黑箱导致的算法共谋、算法操控、算法歧视、算法偏见等多因素的复杂耦合作用也是各类安全事件诱发过程中的强大动力，并使得安全风险的广度和深度在各领域不断蔓延。当前，算法风险问题往往与政治、经济、社会、科技等领域问题相互混杂、交叉、关联、融会在一起，并带来了一系列连锁反应，这就使得算法风险的构成和后果变得高度复合化，人们对风险的识别、防范与治理的难度也大大提升。",
    "context5": "3）突出的人为性。由于算法是由设计人员根据实际需求而编写的代码，程序员在编写算法程序时存在欠缺或不够完备的地方，而导致的算法风险一般多归类于人为因素。算法风险人为性主要体现在非主观人为因素和主观人为因素两个方面：第一，非主观人为因素。随着技术的不断发展，人类可以通过提高自身的适应能力和发展科学技术的方法来化解该类风险，非主观性人为因素所带来的算法风险发生的概率在逐渐下降。第二，主观人为因素。吉登斯认为随着经济的发展，风险的\"人化\"程度不断提高，风险\"内生\"特点越来越明显，伴随着人类的决策与行为，各种利益共同作用导致了风险的\"人化\"结果[55]。算法操控是较为典型由于利益因素人类主观对算法实施有目的的操控行为，这具有突出的人为因素特征。在2016年美国大选事件中，剑桥分析凭借心理绘图技术，通过建立数据模型预测选民行为模式并诱导选民投票，为此帮助特朗普获得更多的选票，这也成了算法风险有人为因素的典型案例。",
    "context6": "4）泛化的不确定性。算法风险具有泛化的不确定性，主题体现在以下方面。第一，算法风险发生规律的不确定性。由于算法风险责任主体的不确定性，加之智能算法自身复杂性的特征，人们往往无法确定风险的发展、转化与演变规律。由此，部分算法风险具有突发性特点，规模大小和影响深度、广度难以准确预测。第二，算法风险治理的不确定性。算法风险的形成是由多种因素、多种主体所引发的，风险社会中各类风险形成的原因既有外部因素又有人为因素，算法风险诱因复杂且交织，无法准确界定谁应该对风险负责，因此算法风险治理也具有不确定性。第三，算法风险产生后果的不确定性。当算法无法实现可解释性，就可能会出现算法控制人类的严重安全风险，这对社会的直接影响是无法具体估量的，其间接影响和后果更是难以衡量。以卢米斯案为例，即使COMPAS的研发者自愿公开其评估工具的技术手段，但作为一款人工智能系统，其断案结果也存在不确定性风险，法官和被告人不但难以知晓智能算法的确切决策过程，即使研发公司也未必能够确切描述其分析和决策过程。"
  },
  "4结论与展望": {
    "context1": "现有文献围绕算法风险诸多方面展开了广泛讨论，本研究初步构建了基于“学科领域—研究主题一治理工具一治理措施”的算法风险研究框架。在学科领域方面，法学、新闻传播学、哲学、教育学等领域研究较多，具有典型的交叉学科特征。在研究主题方面，近年来从算法黑箱、算法操控、算法共谋、算法歧视、算法偏见再到算法异化等较为全面地对算法风险进行研究，使算法风险具有复杂的交织性和突出的人为性。在治理工具方面，形成了从算法风险识别到算法风险评估，从算法监管到算法问责形成了全方位的治理思路。在治理措施方面，从治理体系、治理路径、治理框架到治理机制将各领域算法风险研究主题运用算法治理工具进行融合，算法风险具有泛在的不确定性，尤其是算法风险后果可能存在着无法具体估量的安全风险，因此算法风险研究在政府决策中发挥重要的指导作用。算法风险发展历史较短，当前研究尽管取得了积极进展，但在算法风险研究角度未来尚存以下拓展空间。",
    "context2": "1)加强情报学学科对算法风险的研究。当前针对算法风险的研究成果已经覆盖了法学、新闻传播学、哲学、金融学、教育学等学科，而\"信息资源管理\"学科更名后，学科包容性更强，有更多的学者从情报学角度针对算法风险进行研究，由于算法风险具有典型的交叉学科特征，对其研究应该是多领域、多维度的。情报分析是情报学研究的重点内容，近年来，智能算法在情报分析中得到广泛运用并发挥了重要作用，与此同时其所带来的安全风险更具隐蔽性，而且算法风险是数智时代情报分析所特有的，其显现出的自我学习、自我完善、黑箱特性、人为性操控等风险往往是最难以识别并监管的。因此，算法风险即要从理论方法角度来研究，又要从应用实践来研究，尤其深度学习算法广泛应用于情报分析时，更应重点关注算法的可靠性和稳定性。而目前情报学领域一直关注国家重大安全风险防范与化解，因此情报学学科对算法风险研究应从两个视角发挥情报学学科的作用，一是将情报学理论、方法与应用紧密融合，形成既能为管理决策精准服务，又能形成直接服务于国家安全与发展的应用型成果；二是从情报学学科视角加强对情报分析算法事前风险识别与评估，事中风险防范与监管，事后风险回溯与问责的研究[56]，这符合总体国家安全发展战略需求与战略导向，并",
    "context3": "具有重要研究意义。",
    "context4": "2）加强对人工智能算法可解释性研究。算法黑箱是算法风险产生的根源，而在算法歧视、算法偏见、算法异化等问题中，我们无法忽视的一个问题就是以深度学习算法为代表的人工智能算法可解释性研究，该问题是算法风险防范与化解的关键点。未来从3个方面进行展望：一是建模前的可解释性研究，通过数据可视化使开发者全面地了解数据分布的特征，从而最大限度发现问题并选择一种最合理的模型；二是建立本身具备可解释性的模型，通过基于规则的模型、基于单个特征的方法、基于稀疏性的方法等实现模型本身的可解释性；三是使用可解释性方法对模型做出解释，通过隐层分析方法、敏感性分析方法对具有黑箱性质的深度学习模型进行解释性研究。",
    "context5": "3）加强算法应用向善和算法服务从善的研究。近年来算法出现了一些偏离正轨、不怀好意的“算计”备受社会质疑。面对与算法如影随形的社会风险问题，尤其是ChatGPT 出现后，算法不再一味地强调中立，如何使算法应用“向善”，如何驾驭算法服务“从善”，日益成为政府、社会和学术界所关注的重要问题。对算法风险的治理不应只局限于算法本身，而需要将算法嵌入整个社会体系中评估，并形成体系化的算法服务向善和算法应用从善的研究成果。一是算法应用向善。以善为主导的伦理道德是人类社会公认的社会伦理道德体系，算法审查标准不但要合法，而且要通过组建道德评审委员会、判断社会影响、论述算法正当性等方式，确保算法传播正能量，形成算法向善的价值观。二是算法服务从善。尤其是生成式人工智能的快速发展，各类算法服务呈现出野蛮生长之势，如何使算法从善是社会各界需要仔细思考的问题，只有使算法有法度，有正确的导向，推荐正能量的信息，服务才能从善，从而使民众心态从善、社会从善。",
    "context6": "4）加强对全球算法风险治理中国智慧与构想的研究。全球算法风险治理逐渐呈现出实质化、严格化、细致化的特征。一是治理实质化。基于国内外算法风险治理研究及近年来全球各国发布的算法风险法规政策，使算法风险治理向更具实质性的监管落地。二是治理严格化。美国《算法责任法案》、欧盟《人工智能法案》、中国《互联网信息服务算法推荐管理规定》等代表性法案的颁布呈现出全球算法风险严格治理的趋势。三是治理细致化。国内外对算法风险的研究聚焦于自动驾驶、智慧医疗等典型场景，未来，将抽象的算法伦理原则、法律规范转化为具体实践，落实到服务与应用中将是研究的重点内容。2022 年我国颁布的《互联网信息服务算法推荐管理规定》是全球第一部系统性规制算法的法律文件，而 2023年我国为应对生成式AI快速响应，发布了《生成式人工智能服务管理暂行办法》，这些都说明了我国逐步在全球算法风险治理中体现中国智慧和中国构想。□"
  },
  "参考文献": {
    "context1": "[1]李明,曹海军.中国央地政府人工智能政策比较研究—一一个三维分析框架[J].情报杂 志,2020,39(6):96-103， 53. (LI Ming, CAO Haijun. A comparative study of artificial intelligence policies of China's centraland local governments: a three-dimensional frame[J].Journal of Intelligence,2020,39(6):96-103， 53.)   \n[2]郑戈.算法的法律与法律的算法[J].中国法律评论,2018(2):66-85.（ZHENG Ge.Algorithm of law and law of algorithm[J].China Law Review,2018(2):66-85.)   \n[3]丁晓东.论算法的法律规制[J].中国社会科学,2020(12):138-159，203.（DING Xiaodong.On the legal regulation of algorithms[J].Social Sciences in China,2020(12):138-159，203.)   \n[4]李训虎.刑事司法人工智能的包容性规制[J].中国社会科学,2021(2):42-62，205.（LI Xunhu. Inclusive regulation of artificial intelligence in criminal justice[J].Social Sciencesin China,2021(2):42-62，205.)   \n[5]张超.新闻生产中的算法风险:成因、类型与对策[J].中国出版,2018(13):38-42.（ZHANG Chao. Algorithmic risks in news production: causes， types， and countermeasures[J].China Publishing Journal,2018(13):38-42.)   \n[6]高兆明,高昊.信息安全风险防范与算法法则的价值原则——自动驾驶汽车研发的两个实 践哲学问题[J].哲学动态,2017(9):77-83.（GAO Zhaoming,GAO Hao.Information security risk prevention and the value principle of algorithm rules: two practical philosophical problems in the research and development of autonomous vehicle[J].Philosophical Trends,2017(9):77-83.) [7]张林.智能算法推荐的意识形态风险及其治理[J].探索,2021(1):176-188.（ZHANG Lin.The ideological risk of intelligent algorithm recommendation and its governance[J].Probe,2021(1):176-188.)   \n[8]于淼.数字经济视域下算法权力的风险及法律规制[J].社会科学战线,2022(2):275-280.（YU Miao.The risk and legal regulation of algorithm power in the perspective of digital economy[J].Social Science Front,2022(2):275-280.)   \n[9]施春风.定价算法在网络交易中的反垄断法律规制[J].河北法学,2018,36(11):111-119.（SHI Chunfeng. Antitrust law regulation of pricing algorithm in online transactions[J].Hebei Law Science,2018,36(11):111-119.)   \n[10]袁康.社会监管理念下金融科技算法黑箱的制度因应[J].华中科技大学学报(社会科学 版),2020,34(1):102-110.(YUAN Kang. System Response on algorithm black-box of fintech under thesocialsupervision concept[J].Journal ofHuazhong UniversityofScienceand Technology(Social Science Edition),2020,34(1):102-110.)   \n[11]丁晓东.算法与歧视从美国教育平权案看算法伦理与法律解释[J].中外法 学,2017,29(6):1609-1623.(DING Xiaodong. Algorithm and discrimination rethinking algorithmic ethics and legal interpretation by studying American affirmative action cases[J].Peking University Law Journal,2017,29(6):1609-1623.)   \n[12]HACKER P. Teaching fairness to artificial intelligence: existing and novel strategies against algorithmic discrimination under EU law[J]. Common Market Law Review, 2018, 55(4):1143-1185.   \n[13]肖凤翔,张双志.算法教育治理：技术逻辑、风险挑战与公共政策[J].中国电化教 育,2020(1):76-84.(XIAO Fengxiang, ZHANG Shuangzhi. Algorithm education governance: logic, challenge and public policy[J].China Educational Technology,2020(1):76-84.)   \n[14]MARACHI R, QUILL L. The case of canvas: longitudinal datafication through learning management systems[J]. Teaching in Higher Education, 2020, 25(4): 418-434.   \n[15]张庆玲,胡建华.大学评价中的\"计算主义\"倾向分析[J].现代大学教育,2021,37(4):56-65， 112.(ZHANG Qingling, HU Jianhua. Quantitativism in university evaluation:a critique[J].Modern University Education,2021,37(4):56-65， 112.)   \n[16]BAKER R S, HAWN A. Algorithmic bias in education[J]. International Journal of Artificial Intelligence in Education, 2021: 1-41.   \n[17]王佑镁,王旦,梁炜怡，等.ChatGPT 教育应用的伦理风险与规避进路[J].开放教育研 究,2023,29(2):26-35.(WANG Youmei,WANG Dan, LIANG Weiyi, et al. Ethical risks and avoidancestrategiesofChatGPTeducationalapplications[J].OpenEducation Research,2023,29(2):26-35.)   \n[18]李书琴,刘旭.算法嵌入课堂教学：机遇、风险及其防范[J].当代教育科学,2023(7):43-54. (LI Shuqin, LIU Xu. Algorithmic embedding in classroom teaching:opportunity,risk and its prevention[J].Contemporary Education Sciences,2023(7):43-54.)   \n[19]贾德辉,卢瑞瑞.迈向“算法学术”：高校网络思想政治教育的算法塑造风险及其化解[J]. 湖北社会科学,2023(8):148-155.（JIA Dehui, LU Ruirui. Towards\"algorithmic science\":the risks and solutions of the algorithmic shaping in colleges and universities network political and ideological education[J].Hubei Social Sciences,2023(8):148-155.)   \n[20]张涛,马海群.智能情报分析中数据与算法风险识别模型构建研究[J].情报学 报,2022,41(8):832-844. (ZHANG Tao, MA Haiqun. Research on the construction of data and algorithm risk identification model in intelligent intelligence analysis[J].Journal of the China Society for Scientific and Technical Information,2022,41(8):832-844.)   \n[21]陈曦,葛腾飞,宋道青.智能化情报手段对大国战略稳定的影响评估[J].情报杂 志,2021,40(6):10-16,9. (CHEN Xi, GE Tengfei, SONG Daoqing. An assessment of the impact of inteligent intelligence meanson thestrategicstabilityof great powers[J].Journalof Intelligence,2021,40(6):10-16，9.)   \n[22]SANCLEMENTE G L. Reliability: understanding cognitive human bias inartificial intellgence for national security and intelligence analysis[J]. Security Journal, 2022, 35(4): 1328-1348.   \n[23]夏苏迪,邓胜利,付少雄，等.数智时代的算法素养：内涵、范畴及未来展望[J].图书情报知 识,2023,40(1):23-34.（XIA Sudi, DENG Shengli, FU Shaoxiong, et al. Algorithm literacy in"
  }
}