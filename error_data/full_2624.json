{
  "original_filename": "full_2624.md",
  "命名实体消歧研究进展综述 \\*": {
    "context1": "温萍梅」叶志炜」丁文健」刘　颖² 徐健11（中山大学资讯管理学院广州 510006)2（中山大学图书馆广州 510275)",
    "context2": "摘要：【目的】调研近年来命名实体消歧领域的相关研究和资源,重点介绍命名实体消歧方法研究进展。【文献范围】使用知网数据库、万方数据知识服务平台和EBSCO外文期刊平台检索命名实体消歧相关文献，共选择57篇代表性文献和电子资源【方法】从实体显著性、上下文相似度、实体关联度、深度学习和特殊标识资源5个角度对命名实体消歧的方法和思路进行归纳总结,并对可用的辅助知识库和开源工具以及国际评测会议进行梳理。【结果】传统的方法经典易用,而近年来出现的深度学习等新方法,则明显地提升了消歧效果。有效的消歧模型往往整合了不同类型方法,以期达到最优消歧效果。【局限】基于已有文献对各种方法的对比分析尚存在一定的主观性。【结论】现有的命名实体消歧方法仍然处在发展阶段,未来可利用人工智能方法和领域资源进一步提升实体消歧效果。",
    "context3": "关键词：命名实体消歧知识库实体链接聚类分类号：TP393G250DOI: 10.11925/infotech.2096-3467.2020.0382",
    "context4": "引用本文：温萍梅，叶志炜，丁文健等.命名实体消歧研究进展综述[J].数据分析与知识发现,2020,4(9)： 15-25.(Wen Pingmei, Ye Zhiwei, Ding Wenjian,et al. Developments of Named Entity Disambiguation[J]. Data Analysis and Knowledge Discovery, 2020, 4(9): 15-25.)"
  },
  "1引言": {
    "context1": "命名实体消歧（Named Entity Disambiguation,NED)是自然语言处理领域的一项基础性研究,已经成为知识库构建、信息检索、机器翻译,以及话题发现与追踪等研究领域的重要支撑技术。在知识图谱构建过程中,命名实体消歧结果越准确,才越能保证实体之间语义关系的正确性，从而有助于提升知识图谱的利用效果。在机器翻译系统中，待翻译语句中命名实体的准确消歧,能够帮助翻译系统选择更为可靠的候选译项,提升机器翻译的性能;在用户推荐系统中，用户的浏览历史或检索文本中含有大量歧义词,准确分析语义并对其进行消歧,能够进行更精确的用户兴趣建模[1]。命名实体消歧在各种领域都发挥了关键作用，对其进行各项研究具有重要的意义。本文使用知网数据库、万方数据知识服务平台和EBSCO外文期刊平台检索命名实体消歧相关文献，共选择57篇代表性文献和电子资源，并对其进行归纳总结。",
    "context2": "实体的歧义现象可以概括为多样性和歧义性两类,即多名现象(Synonymy)和重名现象(Polysemy)[2]。多名现象指一个实体可能会有多种命名，如全名、缩写、别名等。解决多名问题的主要途径是建立同义词词典,使其尽可能多地收录同义词条[3],通过目标文本与同义词词典匹配的方式实现多名间的映射。此外,模糊字符串匹配[4方法也常被用来进行目标文本中多名实体的合并。因此,多名问题解决效果主要与词典和模糊匹配算法有关[5]。重名现象指多个实体拥有相同的命名，即一词多义现象。例如，\"MichaelJordan\"既有可能指一位NBA球星，也可能指美国加州大学伯克利分校的一名教授，而在问题“著名篮球运动员Michael Jordan的生日是什么时候?\"中,需要将\"MichaelJordan\"消歧为该名字的篮球运动员，实现从数据库中获得唯一正确的出生日期。",
    "context3": "近年来，命名实体消歧技术取得了较大进展。从文献全文等长文本到推特、微博、查询语句等短文本，再到专业领域语料,学者们针对不同语料特点提出相应的命名实体消歧方法。然而,相比命名实体识别技术,命名实体消歧技术仍存在较大提升空间。本文对近年来出现的命名实体消歧算法进行梳理，总结归纳命名实体消歧相关资源的情况，以期为命名实体消歧在各领域的应用实施提供参考借鉴。"
  },
  "2主要思路及方法": {
    "context1": "按命名实体消歧算法所依据的特征类型,本文将典型命名实体消歧算法归纳为以下5类：基于实体显著性的命名实体消歧、基于上下文相似度的命名实体消歧、基于实体关联度的命名实体消歧、基于深度学习算法的命名实体消歧、以及基于特殊标识资源的命名实体消歧。"
  },
  "2.1实体显著性": {
    "context1": "基于实体显著性的命名实体消歧基本原理是：在候选实体列表中选出显著性最高的候选实体作为歧义实体的消歧结果。最简单直接的显著性特征是字符串相似度（String Similarity）。该方法不考虑实体指称的上下文、实体属性或语义信息,而是直接比较指称表层形式(SurfaceForm)与候选实体名称字符上的相似度,例如,待消歧实体\"Philosophy\"与已消歧实体\"Philosophy\"的字符串相似度高于类似\"Psychology\"这样的已消歧实体,则可将\"Philosophy”消歧为\"Philosophy”。该方法可用于生成候选实体列表，即通过计算编辑距离(EditDistance)[6、汉明距离(HammingDistance）[4]等指标得到相似度,选取相似度较高的候选实体，减小候选实体集的规模。显然,这种方法的作用有限,在重名和别名的情况下无法准确得到唯一消歧结果。",
    "context2": "另一个常用的显著性特征是流行度(Popularity)。如从查询语句、推特、微博等短文本中提取的实体，可以根据维基百科(Wikipedia)上的页面浏览量或者查询点击量，赋予候选实体一定的权重。当实体相关的文本信息较少时，流行度起到一定作用。例如,用户在搜索引擎中输入的搜索词具有歧义性，而搜索引擎返回相关搜索结果时，往往按照热度排序。流行度特征在推荐系统中得到较为广泛的应用，但这种特征存在一定的适用局限性,特别是在处理冷门实体时,流行度甚至起到反作用。例如,用户想要了解击剑运动员“李娜\"的信息，系统会返回大量流行度更高的网球运动员“李娜\"的信息。计算该指标需要有大量的浏览和点击数据作为前提，而这些数据集不一定可获得。此外,可能还面临\"冷启动\"问题,即当新的实体指称出现时，并没有足够的数据量进行流行度的有效计算。",
    "context3": "共性(Commonness)指从标注语料集中实体的义项分布计算出的实体的先验概率,近年来也被用作有效的显著性特征。在含有链接的知识库(例如Wikipedia)中,实体的先验概率如公式(1)所示。",
    "context4": "$$\np \\left( \\boldsymbol { e } _ { i } \\right) = \\frac { c _ { i } } { \\sum _ { i = 1 } ^ { n } c _ { i } }\n$$",
    "context5": "其中， $e _ { i }$ 表示该指称项所指的某个实体， $c _ { i }$ 表示实体 $e _ { i }$ 在知识库中的链接次数， $\\sum { _ { i = 1 } ^ { n } c _ { i } }$ 表示知识库中的总链接次数。通常情况下，目标实体在知识库中有较高的先验概率,而那些先验概率低的实体，成为目标实体的可能性也比较低。因此,通过设置先验概率筛选实体，将那些知名度较低，即先验概率较低的实体直接舍去,可以有效排除非目标实体[8]。",
    "context6": "事实上，许多研究并不直接利用实体显著性得到消歧结果，而是将基于实体显著性的方法用于候选实体列表的生成步骤中[1.8-9],旨在提高候选实体列表覆盖率的同时降低候选实体数目，提高消歧效率。"
  },
  "2.2上下文相似度": {
    "context1": "基于上下文相似度的命名实体消歧方法通过比较实体指称上下文和候选实体上下文的相似度，将相似度最高的候选实体作为消歧结果。上下文特征粒度有大有小，可以是整篇文本，也可以是部分名词、实体[10]等。Elmacioglu等[1]的研究表明上下文中的命名实体是有效的消歧特征，同时也可结合专有名词、人名、地名、机构名、职业名等,构成代表实"
  },
  "16 数据分析与知识发现": {
    "context1": "体语义的文本特征。相似度比较方式可分为两类，分别是：",
    "context2": "(1)待消歧文本集中命名实体之间的比较，如出自不同文章相同名称的实体之间的相似度比较;",
    "context3": "(2)待消歧文本中实体与外部知识库中候选实体之间的比较,如来自待消歧文本中的命名实体与维基百科中相同名称的实体的相似度比较。两种比较方式的区别在于是否使用外部知识库作为知识辅助来源。",
    "context4": "提取消歧特征后，可利用各种相似度算法计算实体间的相似度。最简单的方法是基于词袋(BOW)的相似度算法[12]。该方法将实体所在的文本用词集合表示，用词交集的大小表示相似度大小。另一种方法是构建特征项的向量空间模型,通常以TF-IDF值作为特征项权重，以点积(Dot-Product）、余弦相似度(Cosine Similarity)等指标作为相似度计算方法。",
    "context5": "为提高基于上下文相似度的消歧准确率，许多有效的算法模型被相继提出,包括分类、聚类、基于主题、概率语言模型方法。",
    "context6": "(1)基于分类的方法。该方法将相似度排序问题转化为分类问题[13],利用训练出的分类器去标记实体指称-候选实体对的真假，当有多个指称-实体对标记为真时,再通过计算词袋和共现等特征,以相似度最高的指称-实体对作为消歧结果。对于分类器无法唯一分类的实体,需要应用其他技术协助选",
    "context7": "择候选实体。",
    "context8": "(2)基于聚类的方法。该方法将具有相同指向的命名指称聚为一类。由于知识库中的实体表示相对独立的含义，因此一般以知识库中的实体作为聚类代表节点。当知识库中没有收录相对应的候选实体时，可通过聚类的方式,将代表同一种实体的不同实体指称聚为一类，以弥补知识库规模的不足[14-15]",
    "context9": "(3)基于主题的方法。该方法认为同一个文档中的实体应当具有相似的主题分布。怀宝兴等[据此使用标注训练集训练出eLDA语义建模模型，利用该模型得到文档在主题空间的分布,并将该主题分布作为文档中实体的主题分布。通过计算每个实体与候选实体之间主题分布的余弦相似度,以获得主题距离最小的候选实体，并将其作为消歧结果。",
    "context10": "(4)概率语言模型方法。概率语言模型[17-18]通常被应用在文本建模的过程中，在该模型中指称和候选实体都有一个固定大小的窗口的上下文，上下文由许多词语组成,通过比较指称上下文中的词语在不同候选实体上下文中出现的概率进行排序，概率最高的候选实体则为消歧结果。",
    "context11": "基于知识库和文本相似度进行命名实体消歧的一般思路如图1所示。以待消歧文本和知识库作为初始输入，不同研究使用不同的算法模型进行建模，使用各类指标计算指称与候选实体的相似度,排序后相似度高的候选实体作为消歧结果。",
    "context12": "![](images/450483808b972bce8a12088d9e2d4e01179008c92ac7b9463396864596e226cd.jpg)  \n图1基于知识库和文本相似度的命名实体消歧结果[19]  \nFig.1Named Entity Disambiguation Results Based on Knowledge Base and Text Similarity",
    "context13": "可以看到,文本中识别出\"Jordan\"这一实体，但它的候选实体有两个，将文本与候选实体的知识库文本作为输入，经过建模输出计算机可计算的实体向量，并计算出指称向量与两个候选实体的相似度分别为0.9和0.1，则认为相似度为0.9的候选实体更有可能与指称指向同一实体，因此原文中的“Jordan\"消歧结果为“Michael Jeffrey Jordan”。"
  },
  "2.3实体关联度": {
    "context1": "在上述基于实体显著性和文本相似度的算法中，一次只对文本中的一个实体指称进行消歧[20],而同一文本中实体之间的语义联系却经常被忽略。由于同一文本中共现的实体往往属于同一个主题或具有某种相关性，一些学者尝试利用这种联系对实体指称进行协同消歧。用来计算实体关联度的语义特征有很多，包括文本描述和文本分类信息、实体注释、实体共现、实体分布、实体关联图等。根据这些语义特征,最早由Cucerzan[21提出采用协同消歧的方法，使用不同实体指称的候选实体之间的语义相关度衡量候选实体的内聚性。而Alhelbawy等[22]使用隐马尔科夫模型来建模实体指称的候选实体之间的依赖性。",
    "context2": "现有协同消歧方法一般分为聚类和图关系推理两种。线岩团等[10采用聚类的方法，以TF-IDF值作为特征项权重，计算特征项重叠度，用近邻传播聚类算法协同考虑多个待消歧实体间的关联度和相互作用，一般以知识库中的实体作为聚类代表节点。另一类基于图的方法在协同消歧中较为常用,将文档中的实体指称与其候选实体建立图关系，并利用实体间的关联关系对边加权，以此为基础进行协同推理。Han等[23]构造了两类图：一类是实体指称-候选实体图，以实体指称和候选实体的局部文本相似度作为边的权重;另一类是候选实体-候选实体图，以候选实体之间的语义相关度作为边的权重。Phan等[24]提出基于最小生成树的协同消歧,考虑实体对之间的关系，而不是所有实体的关系,该方法在准确率和速度上都有很大的提升。协同消歧的方法也应用在作者重名消歧任务中，如Niu等[25认为，由于作者合作团队往往相对稳定，两个同名作者所拥有的相同合作作者越多，则越有可能指向同一作者实体。这一特征应当作为实体关联特征运用到作者消歧中。因此提出以同名作者对作为节点,将作者合作关系转化为边,以作者文本属性相似度为初始输入,通过迭代计算,同名作者对的相似度达到一定阈值时则认为这两个指称指向同一个作者实体，实现消歧。",
    "context3": "基于图的方法的优势在于：当查询文档包含大量实体且具有较多关联关系时，该方法消歧效果较好。反之,其劣势体现在：当查询文档较短、缺乏关联关系时，消歧的效果会受到负面影响。"
  },
  "2.4深度学习": {
    "context1": "近年来词嵌入和神经网络的蓬勃发展为命名实体消歧任务提供了一种新的解决思路。其基本原理是：利用具有语义特征的分布式向量代表消歧任务中的指称、文本和实体,并将该向量用于深度学习模型中,通过改变神经网络参数等方式训练模型，从而获得有效的命名实体消歧模型。Mikolov等[26提出词向量概念，并开发用于训练词向量的软件工具Word2Vec。它是基于语言模型的假设：一个词的含义可以由其上下文推断得出。根据此假设,Mikolov等设计了Skip-gram 和CBOW 两种模型:Skip-gram模型通过目标单词预测其上下文中的单词，而CBOW通过目标单词上下文中的单词预测目标单词。Pennington等[27-28]提出另一种较有影响力的词向量生成模型GloVe。",
    "context2": "通过上述方法获得词向量后,可以选择不同的神经网络模型进行消歧训练。已有研究显示LSTM(Long Short-Term Memory)[19,29]、CNNs(ConvolutionalNeuralNetworks)[30-31]等训练模型效果较好,能有效地将命名指称和实体在空间向量上表示出来。通过比较训练出来的向量表示的相似度,获得消歧结果。训练模型所用的训练数据可以是人工标注的语料集[29],也可以是从Wikipedia中获得的大量实例数据[19]。目前已提出的神经网络常用的模型架构超过25种,学者可以根据各模型的优缺点,加以完善或融合,选择性地应用到命名实体消歧任务中。"
  },
  "2.5特殊标识资源": {
    "context1": "某些领域内存在通用的标识资源，可充分利用这些标识资源的语义辅助开展消歧工作。如国际专利分类(International Patent Classification,IPC)是目前国际上唯一通用的专利文献分类和检索工具，是一个复杂的层次结构分类系统,分为部、大类、小类、主组和分组5个层次[32],每一篇专利文献被赋予一个包含分类信息的编号,以该编号的分解作为特征，可将专利实体所在的文档特征进行降维处理，从而得到能够表达词语领域标识性的特征向量。因此,"
  },
  "18 数据分析与知识发现": {
    "context1": "充分利用实体标识资源是在命名实体消歧任务中提高消歧质量、降低消歧难度的一种方法。",
    "context2": "随着命名实体消歧问题越来越受到关注，学者们普遍认为从发布信息的源头来进行实体唯一标识,或通过实体相关方对所属实体进行自行认领,其消歧效果远比事后控制要更有效。如在作者重名歧义的消歧任务中，一些机构在作者注册时产生的ID,如谷歌学术、ORCID和汤森路透的ResearcherID可对作者进行唯一识别[33]。通过作者参与识别他们自己的出版物，可以精准便捷地对大量作者进行消歧。以ORCID[34]为例,2012年推出，是目前使用最广且永久持有的“国际学术身份证”,诸多期刊在投稿时已要求作者必须提供ORCID。由于ORCID的唯一标识性,有ORCID的作者不具备歧义性，因此即使只能获取部分作者的ORCID,也能辅助降低消歧难度。"
  },
  "2.6不同方法间的对比分析": {
    "context1": "从消歧特征、特征来源、消歧方法以及消歧思路对各种类型的命名实体消歧方法进行对比分析，如表1所示。",
    "context2": "表1利用不同消歧特征的方法对比分析  \nTable 1Comparative Analysis Based on Different Disambiguation Characteristics",
    "context3": "<table><tr><td>消歧特征</td><td>特征来源</td><td>消歧方法</td><td>消歧思路</td></tr><tr><td>实体显著性</td><td>字符串、流行度、共性</td><td>规则匹配、先验概率</td><td>计算实体显著性,将候选实体列表中显著性最高的候选实体作为歧 义实体的消歧结果</td></tr><tr><td></td><td>上下文相似度 整篇文本、部分名词、实体</td><td>分类、聚类、基于主题、 概率语言模型</td><td>比较实体指称上下文和候选实体上下文的相似度,并将相似度最高 的候选实体作为消歧结果,比较过程可选择借助外部知识库</td></tr><tr><td>实体关联度</td><td>文本描述和文本分类信息、 实体注释与实体共现和实体 分布、实体关联图</td><td>聚类、图关系推理</td><td>同一文本中共现的实体往往属于同一个主题或具有某种相关性，利 用同一文本中实体之间的语义联系进行协同消歧</td></tr><tr><td>深度学习</td><td>词向量</td><td>神经网络模型</td><td>用具有语义特征的分布式向量代表消歧任务中的指称、文本和实 体,并将该向量用于深度学习模型中,通过向量相似度完成消歧</td></tr><tr><td>特殊标识资源 IPC、ORCID</td><td></td><td></td><td>特殊标识、唯一标识符通过领域内通用标识资源,降低消歧难度</td></tr></table>",
    "context4": "从表1可知,基于实体显著性的消歧方法利用字符串匹配度、先验概率等指标,可以简便快速地筛选出一批候选实体,形成候选实体列表。其他消歧方法往往也会采用此方法作为基础处理,以提高消歧效率。基于上下文相似度的消歧方法利用文本相似度特征,通过待消歧实体上下文之间的比较或待消歧实体上下文与外部知识库中无歧义实体的上下文之间的比较进行消歧。该类方法经过多年的发展,已经提出多种具体算法模型,从最初的词袋等简单模型,到分类、聚类、基于主题、概率语言模型等，消歧准确率得到有效提升。基于实体关联度的消歧方法关注同一文本内实体之间的语义关联，一次对多个实体进行协同消歧。当文本中包含的实体数量较大且关联度高时，消歧效果较好;反之，建议结合其他消歧方法以获得更好的效果。将深度学习算法应用于消歧问题的解决是近年来的发展趋势。它用神经网络训练出来的词向量表示实体以及其语义关系，用可直接比较的词向量进行消歧。特殊标识资源也是命名实体消歧一种重要的资源,不同于以上通用的消歧方法,需要相应领域资源的支持,若运用得当将会是一条消歧\"捷径”。"
  },
  "3命名实体消歧相关资源": "",
  "3.1常用知识库": {
    "context1": "命名实体消歧可利用的知识主要有两类，一是实体指称的上下文信息,如实体指称周围的词语、实体等；二是外部知识库[10],如Wikipedia、DBpedia[35]、Freebase[36]、YAGO[37]。因此,知识库的发展在一定程度上推动了命名实体消歧的发展。而Wikipedia已经成为命名实体消歧任务的重要资源，大多数现有的知识库(DBpedia、Freebase等)都从Wikipedia中的词条中取出结构化信息[2]。英文Wikipedia页面可分为4类[21]：",
    "context2": "(1)条目页面：包含单个实体的描述信息，比如一个人、一个地点、一个领域等。Wikipedia上美国篮球运动员“MichaelJordan\"的条目页面如图2所示，除了介绍该人物的基本信息以外,还包含蓝色的锚文本链接,可提供丰富的链接结构。",
    "context3": "![](images/a90ac5883f097af456796ed402d685ab58ee9ab4033121e095d742dba75b736e.jpg)  \n图2条目页面Fig.2Entity Page",
    "context4": "(2)重定向页面：当一个实体有多种名称，或者某些页面已经废弃不用时,需要通过重定向页面指向其它表示它们的页面。",
    "context5": "(3)消歧页面：一个名称有多种含义，消歧页面列出名称可能表示的所有实体。“MichaelJordan\"的命名实体消歧页面如图3所示。这类页面的特点是在该页面标题后会跟一个括号标明这是消歧页面，页面的主体部分列出候选实体，并且每个候选实体都是锚文本，可链接到实体介绍页。",
    "context6": "![](images/71466536bbbe498908a0b2308cdbbcea42f09adc48030823e03ed6d514be09b4.jpg)  \n图3消歧页面  \nFig.3Disambiguation Page",
    "context7": "(4)类别页面：Wikipedia中每一个条目都分属于多个类别,类别页面聚集同种类型的实体,可以获得一些词向量无法表达的上位词信息和语义信息。",
    "context8": "除了Wikipedia外,命名实体消歧任务中还可用其他常用的知识库[38作为知识支撑。常在命名实体消歧过程中被利用的4个知识库如表2所示。",
    "context9": "表2部分通用知识库  \nTable 2Examples of General Knowledge Bases",
    "context10": "<table><tr><td>知识库</td><td>研发机构</td><td>实体数量</td><td>知识源</td><td>介绍</td></tr><tr><td></td><td>DBpedia[35]德国莱比锡大学与曼海姆大学</td><td>458万Wikipedia</td><td></td><td>大规模跨语言的知识库,支持多达125种语言,包括人物、地 点、唱片、游戏、组织、疾病、物种等领域</td></tr><tr><td></td><td>Freebase[36]MetaWeb公司,后被谷歌收购</td><td>6800万</td><td>Wikipedia、 IMDB、Flickr</td><td>大规模开放结构数据库,包含三层结构:Domain、Type、Topic</td></tr><tr><td>YAGO[37]</td><td>德国马普研究所</td><td>1000万</td><td>Wikipedia、WordNet、 GeoNames</td><td>大规模跨语言的语义知识库,包含人物、组织、城市等领域</td></tr><tr><td>WordNet[39]普林斯顿大学</td><td></td><td></td><td>15万专家人工构建</td><td>人工编辑,英文词典,按词义组织,名词同义词集合及上下位 为消歧提供帮助</td></tr></table>",
    "context11": "DBpedia是一个多语言的综合型知识库,包含百科全书式的领域的实体信息，其类别结构并不复杂，但实例的属性较多，且事实三元组的数量巨大。Freebase中的数据来自于Wikipedia、IMDB、Flickr等众多网站或数据集，由计算机和人共同维护,通过非常严格的增加或修改过程，使得数据质量较高。YAGO构建了一个复杂的类别层次结构体系，其类别的数量超过36万条，但实体数量和事实三元组条目相对较少。WordNet由专家人工构建,是一个范围覆盖广泛的英语词汇语义网,包括一义多词、一词多义、类别归属等概念。"
  },
  "3.2实体链接服务": {
    "context1": "目前已有一些公司提供实体链接服务，包括实体识别以及将命名实体链接到知识库（一般为",
    "context2": "Wikipedia或DBpedia)两部分。微软提供了非开源的文本分析工具TextAnalytics[40],在线输入文本后可以输出识别到的命名实体,并且链接到Wikipedia相应的词条，界面十分简洁，如图4所示。在文本框中输入一段文本，即可获得文本分析结果,包括关键词、情感、实体识别和实体链接。该工具还提供了API接口。AGDISTIS[41]是一个开源的命名实体消歧框架[42],将命名实体链接到DBpedia,从而实现消歧。TAGME[43]与AGDISTIS类似,将命名实体链接到Wikipedia的无歧义页面。FEL[4445]是雅虎公司推出的开源轻量级多语言实体链接工具包，同样将命名实体链接到Wikipedia。通过在代码中调用API或工具包，即可使用这些实体链接服务。但除了这些已发布的服务之外，有研究者意识到虽然已有许多命名实体消歧算法发布在文献等出版物上,但只有极少部分会发布源代码或API接口，这导致不同的算法之间难以进行比较。因此,研究者开发出开源的实体链接框架(例如Dexter[46-47]）,提供平台以便进行消歧算法性能对比。相关实体链接服务信息汇总如表3所示。",
    "context3": "![](images/4c2855f61a42e2cc2939ebb50eff404338edc5d61d060c5741358f3eb636b61a.jpg)  \n图4TextAnalytics网页界面  \nFig.4Web Interface of Text Analytics",
    "context4": "表3部分实体链接服务  \nTable 3Examples of Entity Linking Service",
    "context5": "<table><tr><td>服务</td><td>研发机构</td><td>是否开源</td><td>链接源</td><td>说明</td></tr><tr><td>Text Analytics[40]</td><td>微软</td><td>提供API</td><td>Wikipedia</td><td>该API提供情感分析、关键词提取、命名实体识别等功能</td></tr><tr><td>AGDISTIS[41,48]</td><td>莱比锡大学</td><td>开源</td><td>DBpedia</td><td>开源实体链接框架</td></tr><tr><td>TAGME[43]</td><td>比萨大学</td><td>开源API</td><td>Wikipedia</td><td>开源实体链接和注释工具</td></tr><tr><td>FEL[44]</td><td>雅虎</td><td>开源工具包</td><td>Wikipedia</td><td>多语言轻量级实体链接工具包</td></tr></table>"
  },
  "3.3命名实体消歧评测": {
    "context1": "一些国际评测会议提出了命名实体消歧任务，其所提供的实验数据为客观评测命名实体消歧效果提供了依据。在英文评测方面主要有TACKBP[49-50]的Entity Linking 评 测和 WePS[51-53]（Web PeopleSearch)评测，WePS要求在没有命名实体知识库的情况下，将具有相同指称的命名实体聚集到一起。与WePS不同,KBP提供一个从Wikipedia中抽取出来的关于实体的知识库,知识库中同一个名字通常都会给出多个实体的定义，该任务需要将某个实体链接到知识库的相应定义，并将无链接关系的实体进行聚类。TACKBP的官网[54提供开放下载的训练语料集。在中文方面有 $\\mathrm { C L P - } 2 0 1 2 ^ { \\left[ 5 5 - 5 6 \\right] }$ 汉语命名实体识别与歧义消解和NLP&CC中文微博实体链接评测。CLP-2012在有知识库的前提下，判定命名实体是否在知识库中定义以及是其中的哪一条定义；对于不属于其中定义的名字进行聚类,将有相同指称的名字聚为一类。NLP&CC中文微博实体链接评测[57要求将微博中出现的实体与百科条目相链接，是对TACKBP任务的延伸。命名实体消歧评测会议给出明确定义的问题、指定数据集、评测指标等，让各消歧算法具有可比较性,也为学者提供交流平台，一定程度上推动了命名实体消歧研究的发展。上述命名实体消歧测评会议的相关特征如表4所示。",
    "context2": "表4命名实体消歧国际测评会议  \nTable 4International Conference on Named Entity Disambiguation",
    "context3": "<table><tr><td>测评会议</td><td>测评语言</td><td>消歧要求</td><td>链接源</td><td>说明</td></tr><tr><td>TAC KBP[49-50]</td><td>英文</td><td>链接并聚类</td><td>Wikipedia抽取的知识库</td><td>官网提供开放训练语料集</td></tr><tr><td>WePS[51-53]</td><td>英文</td><td>聚类</td><td>无</td><td>无命名实体知识库</td></tr><tr><td>CLP-2012[55-56]</td><td>中文</td><td>链接并聚类</td><td>知识库</td><td>链接到知识库中的定义</td></tr><tr><td>NLP&amp;CC[57]</td><td>中文</td><td>链接</td><td>百科知识库</td><td>实现短文本实体的链接</td></tr></table>"
  },
  "4结语": {
    "context1": "命名实体消歧在自然语言处理、信息检索、知识图谱等领域中有着重要的潜在价值，目前正处于高速发展阶段，取得了一定成果,但仍有大量问题亟待解决。命名实体消歧的发展经历了从简单规则匹配到统计、再到深度学习的过程。早期的规则方法仍被运用在候选实体生成步骤，以降低候选实体集大小;基于文本相似度的研究相对成熟,取得了较好结果,但孤立地考虑每一个实体指称,忽略了指称之间的关联;协同消歧方法考虑了实体之间的关联度，但关联度的计算多基于词序、共现等特征,还较为模糊；深度学习是近年来命名实体消歧的新热潮，随着训练模型的改进和完善，命名实体消歧的效果也将更优。在改进算法本身的同时，学者们还可关注特殊知识资源对消歧任务的帮助。",
    "context2": "本文对命名实体消歧任务的方法思路、辅助资源、消歧工具、会议评测等进行总结。依据命名实体消歧算法所依据的特征类型，将消歧任务分为基于实体显著性、基于上下文相似度、基于实体关联度、基于深度学习算法以及基于特殊标识资源的命名实体消歧5大类。传统的方法经典易用,而近年来出现的深度学习等新方法,则明显地提升了消歧效果。有效的消歧模型往往整合了不同类型方法,以期达到最优消歧效果。此外,本文还对已有的相关消歧资源进行总结和梳理。命名实体消歧发展多年，但由于数据集、评价指标各不相同,多数算法并未提供开源代码或Web服务，造成不同算法之间难以进行性能比较。实体评测会议营造了一个可比较的环境,但也仅限于提出统一的消歧问题。",
    "context3": "分析近年来相关研究发现,命名实体消歧研究还不够完善。展望未来，存在以下三个发展方向：",
    "context4": "(1)大数据环境下，应用以深度学习为代表的人工智能方法解决消歧问题将会是行之有效的途径，可从模型优化、特征选择、语料规模扩大等角度进一步提升实体消歧效果。",
    "context5": "(2)随着各领域网络资源的不断丰富和完善，基于领域内通用标识资源等已有知识资源进行高效消歧将会得到更为广泛的应用。",
    "context6": "(3)由于目前相关研究所采用的测试集存在差异，不同消歧算法的真实效果难以进行客观对比。相关组织机构可从评价框架、评测会议的角度提供规范的评测平台供学者交流,进一步推动命名实体消歧研究的良性发展。"
  },
  "参考文献：": {
    "context1": "[1]赵军.命名实体识别、排歧和跨语言关联[J].中文信息学报, 2009,23(2):3-17.(Zhao Jun.A Survey on Named Entity Recognition，Disambiguation and Cross-Lingual Coreference Resolution[J]. Journal of Chinese Information Processing,2009, 23(2): 3-17.)   \n[2] 高艳红,李爱萍,段利国.面向实体链接的多特征图模型实体 消歧方法[J].计算机应用研究,2017,34(10):2909-2914.(Gao Yanhong,Li Aiping,Duan Liguo.Entity Disambiguation Method Based on Multi-Feature Fusion Graph Model for Entity Linking [J].Application Research of Computers,2017,34(10):2909- 2914.)   \n[3] Shen W,Wang J,Han J.Entity Linking with a Knowledge Base: Issues,Techniques,and Solutions[J].IEEE Transactionson Knowledge and Data Engineering,2015,27(2): 443-460.   \n[4] Dredze M,McNamee P,Rao D,et al. Entity Disambiguation for Knowledge Base Population[C]// Proceedings of the 23rd International Conference on Computational Linguistics.2010: 277-285.   \n[5] Zhu G,Iglesias C A.Exploiting Semantic Similarity for Named Entity Disambiguation in Knowledge Graphs[J]. Expert Systems with Applications,2018,101: 8-24.   \n[6] 左乃彻.基于维基百科的中英文命名实体消歧[D].北京:北京 邮电大学,2015.(Zuo Naiche.Named Entity Disambiguation Based on Chinese and English Wikipedia Knowledge Base[D. Beijing:Beijing University of Posts and Telecommunications, 2015.)   \n[7] Gatani A,Lamba D S,Garera N,et al．Entity Extraction, Linking， Classification，and Tagging for Social Media:A Wikipedia-basedApproach[J].Proceedingsof the VLDB Endowment, 2013,6(11): 1126-1137.   \n[8] 王静,谭绍峰,贺东东,等.基于上下文特征的领域文献实体消 歧算法[J].北京生物医学工程,2018,37(4):398-402,409. (Wang Jing，Tan Shaofeng，He Dongdong，et al.Entity Disambiguation Algorithm for Domain Document Based on Context Feature[J]. Beijing Biomedical Engineering,2018,37(4): 398-402,409.)   \n[9] Guo S,Chang MW,Kiciman E.To Link or Not to Link?A Study on End-to-End Tweet Entity Linking[C]// Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.2013: 1020-1030.   \n[10] 线岩团,余正涛,洪旭东,等.基于特征加权重叠度的中文实体 协同消歧方法[J].中文信息学报,2017,31(2):36-41.(Xian Yantuan,Yu Zhengtao,Hong Xudong,et al. Collaborative Entity Disambiguation Method Based on Weighted Feature Overlap Relatedness for Chinese[J]. Journal of Chinese Information Processing,2017,31(2): 36-41.)   \n[11]Elmacioglu E,Tan Y, Yan S,et al.PSNUS:Web People Name Disambiguation by Simple Clustering with Rich Features[C]/ Procedings of the 4th International Workshop on Semantic Evaluations. 2007: 268-271.   \n[12]Hofart J, Yosef MA, Bordino I,et al.Robust Disambiguation of Named Entities in Text[C]/ Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. 2011: 782-792.   \n[13] Zhang W,Su J, Tan C L,et al. Entity Linking Leveraging: Automatically Generated Annotation[C]// Proceedings of the 23rd International Conference on Computational Linguistics. 2010:1290-1298.   \n[14]李广一,王厚峰.基于多步聚类的汉语命名实体识别和歧义消 解[J].中文信息学报,2013,27(5):29-34,42.(LiGuangyi, Wang Houfeng. Chinese Named Entity Recognition and Disambiguation BasedonMulti-Stage Clustering[J].Journal of Chinese Information Processing,2013,27(5): 29-34,42.)   \n[15] 谭咏梅,杨雪.结合实体链接与实体聚类的命名实体消歧[J]. 北京邮电大学学报,2014,37(5):36-40.(Tan Yongmei, Yang Xue.An Named Entity Disambiguation Algorithm Combining Entity Linking and Entity Clustering[J]. Journal of Beijing University of Posts and Telecommunications,2014,37(5): 36-40.)   \n[16] 怀宝兴,宝腾飞,祝恒书,等.一种基于概率主题模型的命名实 体链接方法[J].软件学报，2014,25(9):2076-2087.(Huai Baoxing，Bao Tengfei, Zhu Hengshu,etal. Topic Modeling Approach to Named Entity Linking[J]. Journal of Software, 2014,25(9): 2076-2087.)   \n[17]Han X,Sun L. A Generative Entity-Mention Model for Linking Entities with Knowledge Base[C]// Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. 2011: 945-954.   \n[18]Meij E,Bron M,Hollink L,et al.Mapping Queries to the Linking Open Data Cloud: A Case Study Using DBpedia[J]. Journal of Web Semantics,2011,9(4): 418-433.   \n[19] Sun Y,Ji Z,Lin L，et al.Entity Disambiguation with DecomposableNeuralNetworks[J].WileyInterdisciplinary Reviews:Data Mining and Knowledge Discovery,2017,7(5): e1215.   \n[20] 杨光,刘秉权,刘铭.基于图方法的命名实体消歧[J].智能计算 机与应用,2015,5(5): 52-55.(Yang Guang,Liu Bingquan,Liu Ming. Graph-based Method for Named Entity Disambiguation[J]. Intelligent Computer and Applications,2015,5(5): 52-55.)   \n[21] Cucerzan S.Large-Scale Named Entity Disambiguation Based on Wikipedia Data[C]// Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,Prague, Czech Republic.DBLP,2007: 708-716.   \n[22]Alhelbawy A,Gaizauskas R.Named Entity Disambiguation Using HMMs[C]// Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferenceson Web Intelligenceand Intelligent Agent Technologies.IEEE Computer Society,2013: 159-162.   \n[23]Han X, Sun L, Zhao J. Collective Entity Linking in Web Text: A Graph-Based Method[C]// Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2011: 765-774.   \n[24]Phan M C,Sun A,Tay Y, et al. Pair-Linking for Collective Entity Disambiguation:Two Could be Better than All[J].IEEE Transactions on Knowledge and Data Engineering,2018,31(7): 1383-1396.   \n[25]Niu L,Wu J,Shi Y. Entity Disambiguation with Textual and Connection Information[J]. Procedia Computer Science, 2012,9: 1249-1255.   \n[26]Mikolov T, Chen K,Corrado G,et al.Eficient Estimation of Word Representations in Vector SpacelCl//Proceedings of the 1st International Conference on Learning Representations. 2013.   \n[27]Pennington J, Socher R,Manning C.GloVe: Global Vectors for Word Representation (Code and Pre-trained Data)[EB/OL] [2019- 12-21]. https://nlp.stanford.edu/projects/glove/.   \n[28]Pennington J,Socher R,Manning C.GloVe:Global Vectors for Word Representation[C]//Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. 2014.   \n[29] Zuheros C,Tabik S,Valdivia A,et al.Deep Recurrent Neural Network for Geographical Entities Disambiguation on Social Media Data[J]. Knowledge-Based Systems,2019,173: 117-127.   \n[30] He Z, Liu S,Li M,et al. Learning Entity Representation for Entity Disambiguation[C]//Proceedingsof the 51st Annual Meeting of the Association for Computational Linguistics. 2013.   \n[31]Francis-Landau M,Durrett G,Klein D.Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks[C]/Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.   \n[32] 王琰炎,王裴岩,蔡东风,等.一种用于专利实体的实体消歧方 法[J].沈阳航空航天大学学报,2015,32(1):77-83.(Wang Yanyan，WangPeiyan，Cai Dongfeng,et al.AnEntity Disambiguation Method forPatent Entity[J]. Journalof Shenyang Aerospace University,2015,32(1): 77-83.)   \n[33]Lerchenmuellr MJ,Olav S.Author Disambiguation in PubMed: Evidence on the Precision and Recall of Authority Among NIHFunded Scientists[J]. PLoS ONE,2016,11(7): e0158731.   \n[34] Haak L L,Fenner M,Paglione L,et al.ORCID:A System to Uniquely Identify Researchers[J].Learned Publishing,2012,25 (4): 259-264.   \n[35]Auer S,Bizer C,Kobilarov G,et al. DBpedia: A Nucleus for a Web of Open Data[A]//Aberer K,Choi K,Noy N,et al. The Semantic Web[M]. Springer Berlin Heidelberg,2007: 722-735.   \n[36] Bollacker K,Evans C,Paritosh P,et al．Freebase:A Collaboratively Created Graph Database for Structuring Human Knowledge[C]//Proceedingsof the 2008ACM SIGMOD International Conference on Management of Data.ACM,2008: 1247-1250.   \n[37] Suchanek F M,Kasneci G,Weikum G.YAGO:A Core of Semantic Knowledge Unifying WordNet and Wikipedia[C]// Proceedings of the 16th International World Wide Web Conference.2007: 697-706.   \n[38] 黄恒琪,于娟,廖晓,等.知识图谱研究综述[J].计算机系统应 用,2019,28(6):1-12.(Huang Hengqi, Yu Juan,Liao Xiao,et al. Reviewon Knowledge Graphs[J]. ComputerSystems& Applications,2019,28(6): 1-12.)   \n[39]Millr G A.WordNet: A Lexical Database for English[J]. Communications of the ACM,1995,38(11): 39-41.   \n[40]Microsoft Azure.Text Analytics: Detect Sentiment, Key Phrases, Named Entities and Language from Your Text[EB/OL].[2019-12- 21.https://azure. microsoft.com/en-us/services/cognitive-services/ text-analytics/.   \n[41]Usbeck R,Ngomo A C N,Auer S,et al. AGDISTIS-Agnostic Disambiguation of Named Entities Using Linked Open Data[C]// Proceedings of the l2th International Semantic Web Conference, Sydney, Australia. 2013.   \n[42] AGDISTIS.Agnostic Disambiguation of Named Entities Using Linked Open Data[EB/OL].[2019-12-21]. http://ksw.org/Projects/ AGDISTIS.html.   \n[43]Ferragina P, Scaiella U. TAGME[EB/OL].[2019-12-21].https:// tagme.d4science.org/tagme/.   \n[44]Blanco R,Pappu A. FEL GitHub[DB/OL]. [2019-12-21]. https:// github.com/yahoo/FEL.   \n[45]Blanco R,Ottaviano G,Meij E.Fast and Space-Efficient Entity Linking in Queries[C]// Proceedings of the 8th ACM International Conference on Web Search and Data Mining.2015:179-188.   \n[46] Dexter. Dexter,an Open Source Framework for Entity Linking [EB/OL].[2019-12-21]. http://dexter.isti.cnr.it/.   \n[47] Ceccarelli D,Lucchese C,Orlando S,et al. Dexter: An Open Source Framework for Entity Linking[C]//Proceedings of the 6th International Workshop on Exploiting Semantic Annotations in Information Retrieval. 2013.   \n[48]AGDISTIS.AGDISTIS-Agnostic Named Entity Disambiguation [DB/OL].[2019-12-21]. htps://github.com/dice-group/AGDISTIS.   \n[49]Ji H,Grishman R,Dang H T,et al. Overview of the TAC 2010 Knowledge Base Population Track[C]//Proceedings of the 3rd Text Analysis Conference.2010.   \n[50] Ji H,Grishman R,Dang H T.Overview of the TAC 2011 Knowledge Base Population Track[C]/Proceedings of the 4th Text Analysis Conference.2011.   \n[51]Artiles J,Gonzalo J，Sekie S.The SemEval-2007 WePS Evaluation: Establishing a Benchmark for the Web People Search Task[C]//Proceedings of the 4th International Workshop on Semantic Evaluations.2007: 64-69.   \n[52] Artiles J, Gonzalo J,Sekine S. WePS 2 Evaluation Campaign: Overview of the Web People Search Clustering Task[C]// Proceedings of the 2nd Web People Search Evaluation Workshop. 2009.   \n[53]Artiles J,Borthwick A,Gonzalo J,et al.WePS-3 Evaluation Campaign: Overview of the Web People Search Clustering and Attribute Extraction Tasks[C]//Proceedings of the 2010 CLEF LABs & Workshops.DBLP,2010.   \n[54]TAC. Past TAC Data[DB/OL]. [2019-12-21]. https://tac.nist.gov/ data/index.html.   \n[55]He Z,Wang H,Li S.The Task 2 of CIPS-SIGHAN 2012 Named Entity Recognition and Disambiguation in Chinese Bakeoff[C]// Proceedings of the 2nd CIPS-SIGHAN Joint Conference on"
  }
}