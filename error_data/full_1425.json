{
  "original_filename": "full_1425.md",
  "人工智能生成内容研究综述：应用、风险与治理\\*": "",
  "李旭光¹ 胡奕¹ 王曼¹ 陆颖颖¹ 冯瑄²": {
    "context1": "山东理工大学信息管理学院淄博255000  \n²南开大学商学院信息资源管理系天津300071",
    "context2": "摘要：［目的／意义]对人工智能生成内容（artificial intellgence generated content,AIGC）应用、风险及治理的研究，有助于把握人工智能未来的发展方向，为新兴主题研究提供参考与借鉴。「方法／过程]以中国知网、万方数据知识服务平台和Webof Science核心合集、ProQuest、ScienceDirect 数据库为数据源，收集人工智能生成内容相关文献，分析AIGC在不同领域的应用现状及其风险，并提出AIGC的治理目标。[结果/结论]AIGC 主要在医疗、新闻、学术、教育与艺术等领域取得一定成果，同时面临具有关联关系的来自技术、个人和社会3个层面的风险。本文通过构建“以人为本”的AIGC服务体系模型，从内部循环共生层面提出技术控制和个人提升的具体治理措施，从外部控制引导层面提出政策法规和社会引导具体措施，以指导生成式人工智能的设计、应用与发展。",
    "context3": "关键词：人工智能生成内容 生成式人工智能 以人为中心的人工智能 人机协同 治理目标  \n分类号：G203  \nDOI: 10.13266/j.issn.0252-3116.2024.17.011",
    "context4": "引用本文：李旭光，胡奕，王曼，等.人工智能生成内容研究综述：应用、风险与治理[J].图书情报工作,2024,68(17) 136-149. (Citation: Li Xuguang,Hu Yi, Wang Man, etal. AReviewofA-generated Content Research: Aplications,Risks,anc Governance[J]. Library and Information Service, 2024, 68(17): 136-149.)"
  },
  "1引言 /Introduction": {
    "context1": "人工智能生成内容（artificial intelligence generatedcontent，AIGC）的出现最早可追溯到1950年的“图灵实验”，即判定机器是否具有智能的实验方法[]。随着人工智能算法和模型上的进步，AIGC 相继取得突破性进展。一方面，生成对抗网络[2、强化学习[]、流模型[4、扩散模型[5等技术的发展与成熟推动AIGC扩展多场景应用，从而实现多个领域的技术突破。另一方面，不同于以往缺乏泛化能力的生成模型，AIGC在无监督机器学习与数据生成能力方面实现了新突破，可以模仿人类的创造过程，将人工智能从“赋能者”提升为“协作者”[。Gartner估计到 2025 年超 $10 \\%$ 的数据将由“生成式AI”创造，麦肯锡报告估算 AIGC每年能为全球经济增加4.4万亿美元收人。AIGC具有推动经济发展和社会变革的巨大潜力，因此，加强对AIGC 的研究和应用，具有十分重要的现实意义。",
    "context2": "目前，学术界对于AIGC 的概念定义没有达成完全的统一，争议在于AIGC 是指 AI技术生成的内容，还是具有生成和创造能力的技术。从“AI生成内容”的视角出发，AIGC 是伴随着网络形态演化和人工智能技术变革产生的一种新的生成式网络信息内容[7]，是继专业生成内容（professionally-generatedcontent，PGC）、用户生成内容（user-generated con-tent，UGC）后由人主导的AI生成内容[8；从“AI生成技术”的视角出发，AIGC是利用生成对抗网络（generative adversarial network，GAN）、扩散模型（diffusion model）、神经辐射场（neural radiancefields，NeRF）、自然语言处理模型等对规模化数据集进行训练、学习和优化，从而自动生成相关内容的技术[9]，其可以像人类一样抓取、分析、创造信息。兼顾两种视角，AIGC 既是指从内容生产者视角进行分类的一类内容，又是一种内容生产方式，还是用于内容自动化生成的一类技术集合[10]。该定义兼具综合性与专业性，能够涵盖更多研究领域与问题，对理论研究和行业应用具有广泛的指导意义，所以本文讨论的 AIGC 定义兼顾两种视角，既指由AI技术生成的内容，也指具有生成创造能力的AI技术。",
    "context3": "技术变革带来社会变革，技术的高速发展推动AIGC 进入多个领域的应用阶段，然而，AIGC的相关法律法规尚未完善，围绕公平、责任、安全的争议日益增多，引发了一系列亟待解决的问题，需要探讨新技术如何塑造和影响社会以及如何规范其应用、应对其风险。基于此，笔者通过对AIGC相关文献的统计与分析，从应用、风险和治理3个方面展开讨论。具体而言，首先基于AIGC各应用领域的文献统计，揭示其应用的分布规律，选取主要领域阐述AIGC 的应用与影响；然后，基于对主要应用领域的分析，从技术、个人、社会3个层面提炼 AIGC引发的风险，并分析3个层面风险产生的根源与联系，揭示风险产生的本质；最后，提出治理目标，即构建“以人为本”的 AIGC服务体系模型，在目标的指引下从两个层面提出兼具针对性和综合性的治理措施，助力风险的预防与控制，促进人机协同的优化，推动AIGC提供更加智能和人性化的服务。"
  },
  "研究数据与文献分析/Research dataand literature analysis": {
    "context1": "选取中国知网（CNKI）、万方数据知识服务平台和Web of Science 核心合集（含 SSCI和 SCI）、ProQuest、ScienceDirect数据库作为本研究的数据源，以“人工智能生成内容／人工智能生成物／人工智能生成作品／人工智能生成成果／人工智能生成技术方案／人工智能生成数据／人工智能创作物／生成式人工智能”和“AIGC/ChatGPT/Generative ArtificialIntelligence/Artificial Intelligence Generated Content/",
    "context2": "Generative AI/AIGenerated Content”为关键词进行主题检索，不限制检索起始时间，截止时间设定为2023年12月31日。文献检索与筛选流程如图1所示：",
    "context3": "![](images/85bdd171e808cc6c46d704f0e0e8b22f37c8164ebd41ac67f38b5cd382a9461e.jpg)  \n图1文献检索与筛选过程  \nFigure 1 Literature retrieval and screening process",
    "context4": "AIGC应用研究的文献数量年度分布见图2,AIGC 应用研究在总体上呈递增态势，其中，2023年出现爆炸式增长趋势，这与生成式人工智能在技术上的突破有很大关系。",
    "context5": "![](images/52fd32ba4caece5497852fc22ce17f880318066f6a830a0d9916776bdb795b3b.jpg)  \n图2AIGC应用研究的主要年份及发文量Figure 2 Distribution of publication years and publicationvolume of AIGC application research",
    "context6": "AIGC应用领域分布见图3，可以看出AIGC应用领域极为广泛，学术界对于AIGC在医疗保健、教育教学、新闻传媒、学术研究、艺术创作5大领域研究最多，占比约 $70 \\%$ ，分布结果大致符合“二八定律”[I]，即少数领域占据了大部分的 AIGC 应用研究。由于资源有限和市场需求的差异，只有少数热门AIGC应用能够得到充分的资源支持和市场推广，而大量冷门AIGC应用则无法得到足够的资源支持和市场推广，更多分散的、个性化的应用领域被忽视。因此，AIGC的实际应用情况符合“长尾效应”，即出现了大量未被开发的长尾数据[12]。",
    "context7": "![](images/b051e53ee97111fcfa3503c0d50e348c2fd0e984cea7d6bf2a54aeb1dd2cfca5.jpg)  \n图3AIGC应用领域分布及发文量  \nFigure 3AIGC application fields and publication volume"
  },
  "3 AIGC 的应用领域 /Application fieldsof AIGC": "",
  "3.1医疗保健领域": {
    "context1": "笔者从疾病检测与诊断、辅助治疗、健康管理3方面来探究AIGC在医疗领域的应用。",
    "context2": "首先，在疾病检测与诊断方面，一是可以通过对话式人工智能与患者进行智能问答，实现临时自助诊断[13]；二是基于AIGC 的算法、模型进行医疗图像合成、增强、分析辅助医疗专家诊断[14]；三是基于临床数据分析辅助诊断，利用ChatGPT分析病例、诊断病情、制订治疗方案[15]。其次，在辅助治疗方面，AIGC可以准确估计个体化治疗效果并确定最佳治疗方案，实现精准化和个性化治疗；还可以通过文献检索、数据挖掘和知识图谱构建等技术，更快地整理和分析医学信息，提高医疗服务的质量和效率[16]；AIGC 也可以作为癌症和其他重大疾病患者的长期治疗管理工具[15]，通过提取患者的诊断信息和既往治疗等，以实现治疗的延续性。最后，在健康管理方面，AIGC可以为患者提供个性化健康管理指导，同时作为医疗助手协助医疗人员管理患者信息以及为患者提供服务（专业答疑、提醒检查和服用药物等）[17]。",
    "context3": "虽然AIGC在医疗保健领域有广阔的应用前景，但不可否认AIGC在医疗领域的应用也存在隐患。一方面，由于病理细节的复杂性、输入的医疗数据不全面等问题，导致生成的预测结果不可靠[18]，从而影响患者的治疗效果；另一方面，AIGC 难以解释其预测结果的原因，降低医疗专业人员对其信任度，从而限制其在临床实践的应用。此外，患者也会担心隐私泄露以及预测结果的安全性，从而降低他们对医疗服务的接受度。这些问题亟待解决以确保AIGC充分发挥潜力，使患者和医疗专业人员受益。"
  },
  "3.2　新闻传媒领域": {
    "context1": "从专业新闻机构生产内容、用户生产内容，到",
    "context2": "AI直接生成新闻内容，新闻传媒的生产方式朝着更智能、高效的方向发展。笔者从新闻产生的3个阶段分析AIGC在新闻传媒领域的应用情况。",
    "context3": "首先，信息采集上，AIGC可爬取网站收集信息，通过快速生成摘要帮助媒体工作者高效获取关键信息[19]；还可用于跨语言间的文本数据翻译，分析来自不同国家和地区的资料[20]；此外，人工智能算法还能剔除假信息，提高采集信息的质量和准确性[21]。其次，信息加工上，AI机器人可以在信息结构化较强的财经、体育、突发灾害等领域以效率倍增于人工的信息组合能力，自动化地生成新闻内容[22]，还能根据受众偏好定制生产不同风格的新闻内容[20]。最后，信息传播上，从媒体的角度而言，AIGC可以给出新闻报道个性化的融合分发策略，辅助媒体做出分发决策[23]；从用户的层面出发，利用大数据采集与分析、用户智能画像、智能分发推荐等技术将新闻报道的不同内容定向、精准传播至合适的用户[24]；从新闻自身的价值来说，个性化推送促使小众、冷门的信息得到关注，实现它们的新闻价值，使闲置的社会资源得以利用[25]。",
    "context4": "人工智能生成技术的迅猛发展改变了新闻行业的生产与传播流程，为新闻工作者带来了发展机遇与挑战。但AIGC 输出内容机械呆板，无法满足深度化、人性化的报道要求；AIGC还存在偏见和捏造的可能[26]，影响到新闻内容的准确性和专业性。此外，AIGC可能被恶意操纵来传播虚假、违法信息进而攫取不当利益[27]。因此，如何在新闻领域实现好、利用好、发展好人工智能生成技术，是未来研究的重点之一。"
  },
  "3.3学术研究领域": {
    "context1": "以ChatGPT为代表的AIGC具有惊人的内容创作能力，但也有不少学者极力反对AIGC介入学术研究中。笔者围绕学术研究的4个模块阐述AIGC的应用。",
    "context2": "首先，学术生产中使用AIGC 进行科学论文的辅助写作，最基本的功能是拼写和语法的修正[28]；还可以作为有效的学术搜索引擎进行文献检索，提供选题方向、论文大纲、自动化文献综述[29]；以及赋能多模态写作（如文本、图像、音频、视频等），促进学者构建多模态文本[30]。其次，学术评价中，AIGC借助大数据和大算力改善人工评价的耗时、主观性和不一致性等弊端。例如，Grammarly 和ChatGPT不仅可以评估用户生成文本并提出替代方案，还能帮助用户通过更高质量的审查[31。再者，学术出版中AIGC 促进流程优化、降本增效，推动学术期刊出版更加智能化。AIGC可以应用于文本格式编辑、元数据信息分类和归一化、稿件数据分析和理解、出版物内容分析等[32]；以及根据各种期刊投稿指南构建论文、编写研究结果[33]；还可以进行稿件状态跟踪，把控整个论文投稿周期，促进学术成果的发表[34]。最后，学术传播中AIGC可以实现快速传播及定向传播。AIGC可以通过创建元数据、索引和研究结果摘要以及语言翻译来支持研究成果的快速扩散；还可以将高度复杂的技术研究转化为一般公众更容易理解的信息，甚至可以针对特定受众定制并展示信息，实现学术信息的广泛传播和定向传播[35]。",
    "context3": "AIGC在学术研究各个环节帮助提高工作效率和工作质量，助力学术研究的持续发展。但也存在人工智能生成内容质量不佳（如遗漏、错误与虚构）[36]、研究者牵涉学术诚信问题（如数据捏造、抄袭与剽窃）[37]，以及由此引发的道德与法律风险,给学术生态和社会秩序带来消极影响。所以如何使AIGC在学术研究中发挥其优势的同时最大限度地避免风险至关重要。"
  },
  "3.4²教育教学领域": {
    "context1": "生成式人工智能改变了教育模式，实现了多主体交互的对话教学和多元化教学场景，推动了个性化教学和创新型人才的培养[38]。随着智能系统的迅速发展，未来教育模式将由传统的“师一生”模式转变为“师一机一生”三角状态[39]。教师可以为学生提供多样化的学习体验，学生也可以根据自己的需求选择个性化学习方式。",
    "context2": "对于教师来说，生成式人工智能可以帮助他们创建课程、制定教学计划、准备教学材料、审查和批改作业，并给予学生个性化评估与反馈[40]，提高了教师的教学效率与效果。但仍然有不少教师拒绝将其纳入教学实践，或者由于AIGC 的便利性而对其过度依赖[41]。对于学生而言，生成式人工智能可以增加自主学习的机会、打造积极的学习体验、增强数字环境中的适应性和交互性[40]。创新思维、人工智能素养等将会成为未来学生培养更重要的目标。但同时也会出现学生因信息泄露风险而导致的不完全利用、过度依赖AI而导致的学习技能衰退[42]，以及将生成作品冒充自己原创作品的诚信问题等，这都对学生的创新力产生了消极影响。",
    "context3": "可以看出，对于教师和学生，尽管 AIGC带来了诸多潜力，随之而来的也有诸多担忧与隐患，技术的不稳定性与不安全性可能导致个人信息泄露、财产损失等问题，使人难以完全信赖。用户相关认知和能力的缺乏也会导致信息的误解和误用，更是影响了使用的机会和效果。所以在推动教育发展的同时应该关注如何规避这些问题，促使传统的教学模式迅速走上智能化的道路。"
  },
  "3.5艺术创作领域": {
    "context1": "2022年10月，StableDiffusion 的出现引爆了Al作画领域，标志着人工智能开始向艺术创作领域渗透。AIGC在艺术创作领域的研究主要集中于4个方面：绘画创作领域、音乐创作领域、文学创作领域和影视创作领域。",
    "context2": "在绘画创作领域，AIGC可以模拟著名画家的绘画风格、生成指定类型和风格的画作和图像[43]，还能进行物理绘画、模拟人类性情来绘制肖像、独立完成原创作品[44]，以及通过提供思路来激发画家的创造性思维并与其进行实时的流畅协作[45]。在音乐创作领域，AIGC一方面可以辅助作词作曲，为艺术家提供创作灵感[46；另一方面可以模仿人类音乐家的演奏形式、演奏风格[47]，生成逼真的音乐演奏与团队表演。在文学创作领域AIGC可以学习人类作家的写作方式和写作风格，生成带有文学价值的剧本、小说和散文等，还可以仿写特定朝代、特定类型、指定诗人词人的作品，传承这种艺术表达形式[48]。在影视创作领域，AIGC不仅可以辅助影视内容创作，自动生成动画角色的表情、语言和动作以及特效画面[49]，还可以主导制作一部完整的电影[46]。",
    "context3": "AIGC不仅可以提高艺术家的创作效率和创作质量，还可以帮助艺术家发掘新的艺术形式和风格，让更多人参与到艺术创作中来，实现艺术的大众化、平民化。不过，仍然有学者发现问题，例如艺术家的不当使用（如滥用与禁用）、创造性和艺术高度可能达不到标准[50]、观众的算法厌恶[51]，以及由此产生的一系列社会、伦理问题。这些问题不容忽视,亟待解决。"
  },
  "4 AIGC 存在的风险 /Risks of AIGC": {
    "context1": "AIGC 潜力巨大，但在其渗透到各领域的过程中带来了风险。通过对AIGC在5个应用领域的分析,提炼出技术、个人和社会3个层面的风险。其中，技术作为AIGC发展的底层逻辑，是个人和社会层面风险产生的根源；个人层面的风险可能会演化为社会风险，因为个体效应的积累和扩大会造成更大规模的社会影响；而社会层面的风险亦会对技术发展和个人进步产生约束。三者紧密关联且相互作用，共同影响着AIGC的应用与发展，因此，笔者从技术、个人和社会3个层面分析AIGC造成的风险，进而揭示AIGC风险产生的本质。"
  },
  "4.1技术层面": {
    "context1": "AIGC在技术层面上的风险是个人和社会层面风险的根源。AIGC的运作核心主要是通过算法对训练数据集进行加工和生成输出，在机器学习运行过程中需经过“数据输入、模型处理、内容输出与数据存储”4个阶段，涉及数据质量问题、算法黑箱问题、数据滥用与数据泄露风险。",
    "context2": "（1）数据质量问题。生成式人工智能模型的质量很大程度上取决于训练数据的质量[52]。然而，训练数据质量难以保证，数据真实性、准确性、完整性、客观性受到多方面影响。一方面，AIGC的训练数据中存在误导信息、虚假信息和有害信息，还会因“数据投毒”，即训练数据中混入污染数据（如错误样本或恶意样本）而降低数据质量，从而影响模型决策。另一方面，由于训练数据中由人类生成的数据本身带有偏见；收集的数据分布在低密度数据区域[53],代表性和多样性不足[54]；大语言模型采用投人类所好的“人类反馈强化学习”（reinforcement learningwith human feedback，RLHF）方法等原因[55]，AIGC模型认知不足，生成的结果缺乏客观性和全面性，造成偏见与偏差。",
    "context3": "（2）算法黑箱问题。算法黑箱问题是指算法和模型缺乏可解释性和透明度，这意味着无法了解算法和模型如何得出结果进而引发用户难以解释和理解 AIGC输出的结果、难以发现输出结果中的潜在错误[56]。AIGC 算法黑箱问题可能是由于其复杂的底层技术架构。例如，ChatGPT所依托的深度学习模型Transformer在前馈神经网络中引入自注意力机制（self-attention mechanism）是经典的黑箱算法[57]。同时，算法不透明造成信息不对称，又会加剧算法黑箱问题，但是算法开源后，会使头部企业的技术优势随之丧失，使其成本回收与利益分配问题难以调和[54]。",
    "context4": "（3）数据滥用风险。数据滥用是指数据的不正当使用，包括在未征得数据主体知情同意的情况下，以其所不知的方式使用其个人信息或数据。例如，以ChatGPT为代表的大型语言模型从互联网上抓取的信息包括未经同意获得的个人信息、商业数据等。同时，由于受数据价值的利益驱动，在数据资源利用过程中，出现了数据超权限使用、超协定分析，甚至产生了非法数据交易的“黑灰产”利益链，对个人隐私、商业秘密及国家安全造成了极大侵害[58]。",
    "context5": "（4）数据泄露风险。数据泄露存在于大模型开发和应用的全过程，包括迭代训练导致的数据泄漏、网络攻击和漏洞导致的泄露[59]、数据储存不当导致的泄露、数据流动与共享导致的泄露。这些可能是由于大语言模型学习能力强大以及交互方式相对自由、敏感信息处理不当、数据存储缺乏安全性、数据安全保护程度无法与数据的规模和重要性相匹配、接触训练数据的主体多等原因。泄露的数据类型包括用户个人隐私信息、企业内部商业机密及国家秘密等，造成隐私侵权、不正当竞争和国家安全问题。"
  },
  "4.2个人层面": {
    "context1": "随着生成式人工智能产品进入市场及生成式人工智能技术在各个领域的应用，个人将在不同程度上经历AIGC技术层面风险的影响，但也有一些风险是通过AIGC直接影响个人而产生的。个人层面的风险包括个人隐私泄露风险、过度依赖问题和个人职业影响。",
    "context2": "（1）个人隐私泄露风险。个人隐私泄露的根源是AIGC在技术层面的数据泄露与数据滥用问题。数据泄露是以一种直接的方式造成个人隐私泄露风险，而数据滥用下的个人隐私泄露是更为隐秘的，因为多数情况下，个人并不知情或并未授权。此外，数据滥用下的“深度伪造”，即通过分析个人数据来生成高度逼真的虚拟形象，以生成的虚假内容来进行身份盗窃，从而造成了隐私侵犯[60]。隐私泄露与侵犯进一步引发了用户控制个人数据使用方式、网络自由表达的权利以及数据被遗忘的权利等问题[61]。",
    "context3": "（2）过度依赖问题。AIGC表面上的方便和强大可能会导致个人的过度依赖，过度依赖会影响个人的认知和能力。在认知方面，过度依赖导致个人认知萎缩，以及因习惯性接受AIGC建议而产生人类自动化偏见[62]；此外，还有因技术层面中数据质量问题而输出的错误、偏见信息导致的认知误导，从而影响个人的正确判断和决策[63]。在能力方面，AIGC 会影响创造力、批判性思维和解决问题等技能以及独立思考能力和社交能力[64]。",
    "context4": "（3）个人职业影响。AIGC将影响个人职业现状。",
    "context5": "由于AIGC在从事重复性事项处理、模式化文本生成等任务方面拥有快速度、低成本的特点，以及其对薪资和福利待遇等方面的零要求，不仅会挤压在岗位职责和专业技能上与其相重合、交叉的劳动者的就业空间[65]，甚至取代从事低技能工作的个人[6]，进而导致结构性失业人数的增加，造成社会层面的就业风险。美国OpenAI公司调研发现，将有超过 $80 \\%$ 美国人的工作会受到AIGC 的影响[]。"
  },
  "4.3社会层面": {
    "context1": "技术层面和个人层面的风险通过转移和积累及影响范围和影响程度的扩大，引发了社会层面的风险，同时，社会层面的风险也会制约技术和个人发展。社会层面的风险具体包括因隐私泄露、偏见与歧视、透明度、算法操纵等对社会稳定造成的影响，以及知识产权争议、技术垄断问题和能源消耗问题。",
    "context2": "（1）社会稳定问题。AIGC可能通过隐私泄露、偏见与歧视、透明度、算法操纵等造成社会不稳定。隐私泄露、偏见与歧视、透明度问题是由技术层面的数据和算法问题所导致，其中，社会层面的隐私泄露包括规模、范围扩大的个人隐私泄露，企业和组织的商业机密和内部机密的泄露以及涉及国家安全的数据泄露[68]。偏见与歧视的根本原因是数据偏见和算法歧视，事实上，AIGC在实际应用中已经出现了基于种族、性别或性取向的偏见与歧视，这更加强化了现有的不公平的社会结构[61]。AIGC 的算法黑箱问题导致其可解释性和透明度问题，引发了AIGC使用的文化障碍（culturalbarriers）[61]，即如果用户难以理解结果的产生过程，这将会影响用户对结果的信任程度，同时也会对相关机构在生成式人工智能缺陷分配责任和问责方面造成困难[69]。",
    "context3": "AIGC 算法的恶意操纵可能会引发社会恐慌甚至是政治冲突[70]，因为 AIGC 能在非常短的时间内生成虚假内容并用于传播[71]，还可能通过创造“社交环境回声室”产生情绪感染，以及利用心理弱点进行恶意操纵[72]。而且，一旦AIGC被用于国家级的认知作战，将很有可能产生颠覆政权的现实风险[73]。此外，不法分子可能通过算法操纵进行违法犯罪活动，如利用ChatGPT开发恶意工具，用于盗取信息和建立暗网市场等[74]。算法操纵导致网络安全问题与犯罪加剧，继而导致监管机构的崩溃，因为庞大的运营规模使他们面临着难以克服的执法挑战[75]。",
    "context4": "（2）知识产权争议。由AIGC引发的知识产权争议体现在生成式人工智能主体性、生成内容属性、生成内容归属的争议和生成内容侵权问题4个方面。主体性的争议主要是指生成式人工智能是否具备主体资格，即是否可将其称之为“作者”，从现行法律出发，对其主体资格的判定集中于是否能将其作为法人作者[7；生成内容属性争议的关键在于人工智能生成内容是否具有独创性[77]，判断标准有“以作者为中心”的主观标准和“以作品和读者为中心”的客观标准[78]；生成内容归属争议是由于AIGC上下游和前后端存在多主体参与，其权利、责任归属难以划分；侵权问题主要是指因数据滥用造成的侵权，因为生成式人工智能通过文本与数据挖掘（text anddatamining，TDM）获取的资料包括任何不受著作权保护或受著作权法保护的材料[79]。",
    "context5": "（3）技术垄断问题。部署生成式人工智能需要巨大的投资和丰富的资源，如大规模的计算基础设施和训练数据，中小企业无法承担进入AIGC 赛道的高额成本[80]，从而构筑数据壁垒、算力壁垒和专业知识壁垒，形成资本驱动的技术垄断[8I]。此外，还存在由于不正当竞争造成的技术垄断，如以非控股的方式实行的合谋垄断[82]。技术垄断导致资本无序扩张，挤压其他主体的生长空间，不利于AIGC 技术的可持续发展和应用。",
    "context6": "（4）能源消耗。AIGC的成功在很大程度上依靠庞大的参数量和训练数据实现。训练大规模的模型需要巨大算力和电力的不断投入，这就会产生巨额的环保负担[83]。且由于模型训练的复杂性和计算资源的有限性，往往需要进行大量的试错和调整，导致计算资源的浪费。从AIGC 发展的总体趋势看，其模型的参数量、文本训练量都呈现出了不断递增的态势[84]。相对ChatGPT-3 投入使用前所运算的1 750亿个参数，GPT-4的参数量已达到百万亿级。尤其是在ChatGPT爆火之后，国内外的大型科技企业纷纷开创自己的大模型[82]，这些模型需要花费数百万美元来训练和运行，并消耗巨大的能量。",
    "context7": "综上所述，3个层面相互联系与作用（见图4），具体表现在：技术层面风险是个人和社会层面风险的根源，对两个层面均有影响；个人层面的风险受技术层面风险影响的同时还作用于社会层面，个人层面风险的范围扩大和影响加剧造成了社会层面的风险；社会层面的风险也制约着技术和个人的发展。3个层面相互交织与作用共同影响技术、个人、社会甚至是国家的发展。究其原因，AIGC风险产生的根源是技术问题,本质是技术发展忽视了人的需求和价值观[69]。因为AIGC设计时更关注AI目标函数的最大化，而不是人类和社会福祉[85]。未遵循以人为中心的原则使得AIGC不能更好地满足人的需求、违背人类伦理、引发社会问题。所以需要设计以人为中心的治理框架，强调人类在技术发展中的核心地位，将人类的需求、利益和价值观置于首要位置，考虑人类情感、伦理与社会、文化因素助推技术的可持续发展，使技术能够更好地服务于人类。",
    "context8": "![](images/a16ecd6773fdd5a23dfdcfd26ec63c9f4f69aa02c08c46fbece3fb6a99f3ef65.jpg)  \n图4AIGC三个层面的风险与联系"
  },
  "5 AIGC的治理目标与措施/Governance objective and measures of AIGC": {
    "context1": "基于上述3个层面风险的分析与风险本质的揭示，笔者围绕“以人为中心”原则设立AIGC风险治理目标、构建治理框架、提出治理措施，致力于推动AIGC更加智能和人性化，满足人类的生产、生活需求。"
  },
  "5.1治理目标一一建立“以人为本”的AIGC 服务体系": {
    "context1": "以人为本的人工智能设计策略有助于减轻潜在危害与实际风险[72]。笔者深刻考虑人类需求和价值观，通过构建“以人为本”的AIGC服务体系指导生成式人工智能的设计、应用与发展。该体系建立在“以人为中心的人工智能”（Human-centered AI,HCAI）的人机协同系统基础上，基于智能技术转化为系统和产品过程中的3种机制[8，提炼出“技术”“用户”和“环境”3个因素，然后补充国家政策与法规，社会价值观与伦理道德两大外部环境因素，如图5所示：",
    "context2": "![](images/4f6f853782f3e616f02bbf8bed68e4b54ac0d13c5d4fb26477736d023d17ce4e.jpg)  \nFigure 4 Risks and connections of AIGC at three levels   \n图5 “以人为本”的 AIGC 服务体系模型Figure 5 \"Human-centered” AIGC service system model",
    "context3": "该体系以“以人为中心的人工智能”（HCAI)为内核展开。HCAI结合了人工智能算法和以人为中心的设计思维，强调技术赋予人权力而非取代人的机会[87]。HCAI要求人工智能系统的设计应以人的价值观和需求为指导，并在开发过程中嵌人政策法规、社会价值观与伦理道德来应对法律和伦理风险[87]。该设计一方面通过更快地了解用户需求来生成用户想要的结果，另一方面在政策法规滞后或失效时通过社会价值观与伦理道德来弥补，从而实现满足人类需求的最终目标[69]。“以人为本”的AIGC 服务体系通过内部循环共生与外部控制引导两个层面实现。",
    "context4": "首先，通过用户需求的认识与表达以及基于用户反馈下HCAI的改进二者循环促进，实现第一层“以人为本”的AIGC 服务体系。用户认识和表达自身需求是起点，用户通过与系统交互表达需求，生成式人工智能根据指令产生内容，这个过程对用户的人工智能素养提出了要求。用户再根据生成式人工智能服务结果进行评价和反馈，反馈信息会促使生成式人工智能进行算法优化、模型更新、数据增加等改进，以提高用户服务的质量和准确性。在双向反馈的过程中，用户可以不断审视自身需求表达是否清晰、合理和规范，“以人为中心”的生成式人工智能也会不断改进和迭代，最终实现循环发展。",
    "context5": "其次，在建立第二层“以人为本”的AIGC 服务体系时，还应强调外部环境的政策与法规要素和社会价值观与伦理道德要素。政策与法规是“以人为本”",
    "context6": "的AIGC服务体系运行的基本原则，通常以强制执行为主，用以保障用户的隐私和安全、规范AIGC 的技术研发和应用运行。社会价值观与伦理道德要素是“以人为本”的AIGC 服务体系运行的理想目标，具有柔性的牵引作用，引导AIGC 服务商更加关注用户的需求和福祉，推动AIGC 服务体系朝着更加人性化和社会化的方向发展。外部环境因素的影响使得“以人为本”的AIGC 服务体系在内部循环共生的基础上更加符合社会需求和价值取向，可以实现更加健康和可持续的发展。"
  },
  "5.2　治理措施": {
    "context1": "要想实现“以人为本”的AIGC 服务体系，需要从内部循环共生与外部控制引导两个层面入手，通过关键角色与要素治理，优化各个环节，解决技术、个人和社会3方面的风险。基于治理目标，从技术控制、个人提升、政策法规和社会引导4个层面治理AIGC风险，治理措施间相互补充和完善，治理效果相互促进与作用，形成AIGC治理体系，如图6所示：",
    "context2": "![](images/4a88f8aef9f8d142df9b1d07b974ee704fb0f94cee8308aca0ba3069e107b917.jpg)  \n图6AIGC风险治理措施及影响路径 Figure 6Risk governance measures and impact pathways of AIGC"
  },
  "5.2.1内部循环共生层面": {
    "context1": "从内部循环共生的角度来看，综合技术控制和个人能力提升是实现“以人为本”的AIGC 服务体系的重要手段。基于用户反馈下HCAI技术的改进，不断提高AIGC 服务的质量和准确性，使其更好地满足用户需求。同时，用户在与系统的交互中不断提升个人能力，可以更好地理解和利用AIGC 服务，从而形成良性循环。",
    "context2": "（1）技术控制先行。在整个治理过程中，技术控制起到了基础性的作用，帮助监督和管理人工智能系统的运行，确保其符合人类价值观和伦理标准。相关治理从数据处理与算法优化、系统维护与多模态优化、用户使用辅助和失效补救机制入手。",
    "context3": "数据处理包括模型内部的数据预处理和后处理[88]，可以改善模型对低密度数据的认知不足问题。还可以通过主动学习启发方法来提高生成模型的性能，即改变模型的内部表示与学习重点，经过不断的动态调整提高数据的认知能力[53]。算法方面，可以使用联合学习（federatedlearning，FL）算法促进有效的机器学习（machine learning，ML）模型创建[89]。联合学习算法能够使多个组织在数据利用和模型训练方面进行协作，同时遵守用户隐私保护、数据安全的要求。",
    "context4": "系统维护方面，可以采用人工智能预测性维护（predictivemaintenance，PdM）。基于对ProdAI和CarAI的案例研究发现PdM可以基于对系统运行条件的持续分析，智能地安排维护活动，综合考虑技术和社会风险[90]。此外，多模态也可以有效改进人工智能模型[91]，当其增加处理图像的功能时增强了与用户沟通的能力。谷歌的广义多模态智能网络接口模型（GeminiAI）能够将用户发布的任务以不同的模式产生输出，生成了更加符合用户需求的内容。",
    "context5": "用户使用辅助分为产品使用辅助和内容使用辅助。一方面，开发AI提示模型，帮助用户高效使用AIGC，同时指导人工智能生成高质量内容[92]；另一方面，企业可以通过建立技术机制（如水印系统），确保用户正确判断AI生成信息，减少数据不当使用风险。例如谷歌将“元数据”功能附加到AI创建的图片上，以便用户了解图片来源和背景信息。最后，失效补救机制必不可少。美国《人工智能权利法案蓝图》提出在自动化系统失效或出现程序故障时，通过人工后备系统提供及时的人工帮助。",
    "context6": "技术控制措施可以提高数据质量、减少算法的误差和偏见、降低个人隐私泄露和社会偏见与歧视等风险。同时，相关技术措施可以使用户对人工智能生成技术与内容的理解加深，减少个人对算法决策的过度依赖，从而降低个人职业影响和社会算法操纵风险。通过降低技术风险和对个人的负面影响，进一步降低了生成式人工智能对整个社会的消极影响。因此，技术控制的治理措施在3个层面上的影响是层层递进的。",
    "context7": "（2）个人能力提升。通过提升人工智能素养，个人能够更好地理解和应对人工智能技术带来的挑战和机遇，更大程度地参与到人工智能的发展和应用中。人工智能素养既包括认知的能力，也包括使用的能力[93]。 。",
    "context8": "一方面，个人应不断增进对AIGC技术和风险的认识，增强使用警惕性和批判性思维，学会辨别和评估生成内容的可信度和可靠性；提升版权意识以减少使用生成式人工智能的法律风险；另一方面，个人可以提高数据分析及可视化能力以更好地分析人工智能生成的结果，建立跨学科团队合作从而多角度理解人工智能[61]，不断学习AIGC 各情景操作方式以在任何环境中实现与它们的高效协作，最终促进用户以合乎道德和负责任的方式来使用人工智能[94]。",
    "context9": "用户人工智能素养的提升有利于减少过度依赖风险和个人职业危机。而通过提高用户对生成式人工智能技术的认知和应用能力，其可以更好地理解和利用这些技术，同时提供更高质量的反馈和数据，帮助优化算法模型，减少技术本身的风险。随着技术的不断优化以及个人层面的风险得到缓解，社会也将更加理性地应对人工智能技术带来的挑战和风险。"
  },
  "5.2.2外部控制引导层面": {
    "context1": "从外部控制引导的角度来看，政策法规保障和社会引导助力是实现“以人为本”的AIGC服务体系的关键支撑。政策法规的制定和执行可以保障用户的隐私和安全，规范AI的使用和运行，从而确保用户权益得到保护。同时，社会价值观与伦理道德的引导促使AIGC 服务商更加关注用户的需求和福祉，推动AIGC服务体系朝着更加人性化和社会化的方向发展。",
    "context2": "（1）政策法规保障。通过建立健全的政策法规框架，可以规范人工智能技术的发展和应用，保护个人隐私和数据安全，防止滥用人工智能技术带来的风险。政策法规方面的措施包括政策的调整与支持、制定明确的法律框架以及构建全方位的监督机制。",
    "context3": "一是政策的调整与支持。国家层面出台的政策对于AIGC问题的治理起着决定性作用，通过产业政策和竞争政策助力其技术难题的攻克和垄断问题的解决。首先，产业政策方面，财政通过加大对科技创新的投入，给予科技企业更多的补贴或退税减免政策，攻克当前AIGC的技术自限性风险。其次，竞争政策方面，监管机构应确保生成式AI系统的设计和使用遵循竞争法和基本性原则[95]。还需要进一步完善现有的竞争政策，包括反竞争行为的认定和规制、建构竞争精神与原则、治理数字平台封闭结构[]。",
    "context4": "二是制定明确的法律框架。一方面可以基于现有法律规范进行完善，如借鉴欧盟的《人工智能法案》中分级立法监管的措施，定义不同风险等级的人工智能系统并提供相应监管要求，以及为AIGC开发商定义“安全港”以尽可能使用具有定量阈值的最新措施和指标[97]；借鉴美国产品责任法中的风险效用测试来保障AIGC产品安全，在产品投放前进行测试以降低事故风险。",
    "context5": "另一方面对于各主体要及时立法，落实权责。例如，考虑赋予生成式人工智能以特定的法律地位，发展“负责任的人工智能”[7I]。针对人工智能的相关主体，优先展开生成式预训练大模型生成内容责任主体划分的探索。同时考虑采用责任上限、中小企业保险补贴、对“不正当伤害”案件的限制等措施，减轻创新型和成长型公司的负担[97]。",
    "context6": "三是构建全方位监督机制。首先，国家可设立专门监管机构来监督AIGC 的开发、使用和运营，授予其为AI大模型颁发和撤销许可的权利，并建立全面问责制。另外，还可以集中有限的规制资源对市场内部的监督者进行再监督，并依此做出法规和政策上的调整[98]。其次，互联网企业应加大人员和技术投入，建立审核机构来监督内容，强化个人账户审核[99],并组建特设的道德GenAI委员会，监督公司对设立的AI模型标准和合格评定的遵守情况[100]。此外，人工智能风险管理可以整合并纳入更广泛的企业风险管理战略和流程，将人工智能风险与其他关键风险（如网络安全和隐私）一起处理，提高组织效率。",
    "context7": "最后，政府和企业还应呼呼广大用户乃至社会公众监督互联网企业及人工智能产品，采用外部审计程序提升透明度（如可解释性与可追溯性）与技术稳健性[91]。",
    "context8": "政策法规措施一方面规范了技术研发和应用的过程，降低了技术本身风险；另一方面保护了个人数据隐私和权益，防止个人信息被滥用或泄露。与此同时，技术研发和应用过程的规范可以有效缓解技术垄断和能源消耗问题，并保护知识产权，促进技术创新和竞争，从而维护了市场的公平竞争环境，有利于社会稳定。",
    "context9": "（2）社会引导助力。对整个社会层面进行教育与引导将会助力AIGC 的风险治理，可以从意识形态、信息素养、道德共建、自律机制4个方面制定相关措施。",
    "context10": "首先，社会应加强对AIGC潜在风险的宣传和教育，引导公众思想、价值观念，防范意识形态风险[82]。其次，各行业应普及信息素养教育，提升全民算法素养、数据素养以及综合素质[65]，尤其是教育教学过程中对学生素养的提升，例如，南佛罗里达大学将有关专业AIGC工具集的信息纳入教学内容[101]。此外,人工智能利益相关者应遵循共生共存的原则，共同承担道德责任,制定详细的道德责任分配方案[102]。最后,社会组织和行业协会可以建立自律机制，制定行业准则和伦理规范。例如，增设人工智能伦理委员会来评估训练数据和算法的道德性，以及围绕数据管理政策对团队进行培训和测试[92]，从而引导相关主体高道德、严标准地使用AIGC。",
    "context11": "通过意识形态防控和道德共建措施，减少生成式人工智能的恶意使用、降低技术风险。同时，信息素养教育和自律机制可以提高开发者对人工智能的认识和控制能力，减少技术风险的发生。其次，用户也能更加理性地对待人工智能生成内容，减少个人受到负面影响的可能性。最后，积极的社会引导建立起对生成式人工智能的共识和价值观，减少社会分歧和冲突，降低社会风险。"
  },
  "6 结语/Conclusion": {
    "context1": "AIGC 在医疗、新闻、学术、教育与艺术等领域取得了一定的成果，但是在各个领域的应用也面临着技术、个人和社会3个层面的风险。本文基于AIGC应用归纳出AIGC产生的风险，并揭示了风险产生的根源是技术自限，本质是AIGC的设计与开发缺乏“以人为本”的理念。以此为基础，提出建立“以人为本”的AIGC 服务体系的目标，在目标的指导下提出具体的治理措施，推动实现人机协同的可持续发展，让AIGC更好地服务于人。",
    "context2": "未来有关AIGC 的研究，应进一步丰富理论基础和研究视角，包括以下4个方面： $\\textcircled{1}$ 聚焦AIGC技术的完善，包括强化标准化技术手段，促进高质量数据集发展；研究大模型的可解释性问题，构建大模型参数修正技术，提升模型和人类知识与价值观的对齐，研发可信赖的生成式人工智能[103]。 $\\textcircled{2}$ 应用场景的拓展，AIGC未来发展有望突破单一个体、单一场景以及现实世界，实现不同个体间交互创作、多场景交互融合以及AIGC 与元宇宙相结合[10]。 $\\textcircled{3}$ 风险识别方法研究，如通过定量方法和大数据挖掘的技术去识别风险之间的组合关系、传导路径、勾稽关系和风险之间的权重，从而更精准地治理。 $\\textcircled{4}$ 强化人与AIGC的交互性研究，包括在不同功能背景下AIGC 的有效性研究[104]、交互过程中用户行为研究以及交互效果评价研究。"
  },
  "参考文献 /References:": {
    "context1": "[1]郭全中,张金熠. $\\mathrm { A I ^ { + } }$ 人文：AIGC 的发展与趋势[J].新闻爱",
    "context2": "好者,2023(3): 8-14. (GUO Q Z, ZHANG J Y AI+ humanities: development and trends of AIGC[J]. Journalism lover,2023(3): 8-14.)   \n[2] GOODFELLOWI,POUGET-ABADIE J,MIRZA M,et al. Generative adversarial nets[J].Advances in neural information processing systems,2014,27: 2672-2680.   \n[3] GANIN Y, KULKARNI T, BABUSCHKIN I, et al.Synthesizing programs for images using reinforced adversarial learning[C]// International Conference on Machine Learning. Stockholm Sweden: PMLR,2018: 1666-1675.   \n[4] REZENDE D,MOHAMED S.Variational inference with normalizing flows[C]// Proceedings of the 32nd International conference on machine learning.Lille,France:PMLR,2015: 1530-1538.   \n[5] HO J,JAIN A,ABBEEL P.Denoising diffusion probabilistic models[J].Advances in neural information processing systems, 2020,33: 6840-6851.   \n[6] PAN Z, YU W, YI X, et al. Recent progress on generative adversarial networks (GANs): a survey[J]. IEEE access, 2019,7: 36322-36333.   \n[7] 李白杨，白云,詹希旎,等．人工智能生成内容(AIGC)的 技术特征与形态演进[J].图书情报知识,2023,40(1):66- 74.(LIBY,BAI Y, ZHAN XN,et al. The technical features and aromorphosis of artificial intelligence generated content (AIGC)[J]. Documentation,information & knowledge,2023,40(1): 66-74.)   \n[8] 翟尤，李娟.AIGC 发展路径思考：大模型工具化普及迎来新 机遇[J].互联网天地,2022(11):22-27.(ZHANY,LIJ.AIGC development path thinking: new opportunities for popularization of large-scale model tools[J]. China Internet,2022(11): 22-27.)   \n[9] LEWIS D, MOORKENS J. A rights-based approach to trustworthy AI in social media[J]. Social media+ society, 2020, 6(3): 1-13.   \n[10]中国信息通信研究院，京东探索研究院．人工智能生成内容 (AIGC)白皮书 [R/OL]. [2024-06-16]. htp: //www.caict.ac.cn/ sytj/202209/P02022091358075 2910299.pdf. (China Academy of Information and Communications Technology, JD Exploration Research Institute.White paper on artificial intelligence generated content (AIGC)[R/OL]. [2024-06-16]. htp://www. caict.ac.cn/sytj/202209/P020220913580752910299.pdf.)   \n[11]ERRIDGE P. The Pareto principle[J]. British dental journal, 2006,201(7): 419-419.   \n[12]杨平,田野.长尾数据共享研究进展[J].图书情报工作,2014, 58(8): 133-138. (YANG P, TIAN Y. Research process of long tail data sharing[J].Library and information service,2014,58(8): 133-138.)   \n[13]BALAS M,ING E B.Conversational AI models for ophthalmic diagnosis: comparison of ChatGPT and the Isabel pro differential diagnosis generator[J]. JFO open ophthalmology, 2023,1: 100005.   \n[14]DEDICATORIA M, KLAUS S,CASE R, et al.AI detection of M. Tuberculosis pathogens using generative adversarial network (GAN) analyses[J]. European journal of public health,2020, 30(supplement 5): ckaal65.320."
  }
}