{
  "original_filename": "full_4474.md",
  "《数据分析与知识发现》网络首发论文": {
    "context1": "题目：  \n作者：  \n网络首发日期：  \n引用格式：  \n基于大语言模型的文献综述智能生成与循证研究  \n宋梦鹏，白海燕  \n2024-12-09  \n宋梦鹏，白海燕．基于大语言模型的文献综述智能生成与循证研究[J/OL]．数  \n据分析与知识发现.https://ink.cnki.net/urlid/10.1478.G2.20241209.1524.012",
    "context2": "网络首发：在编辑部工作流程中，稿件从录用到出版要经历录用定稿、排版定稿、整期汇编定稿等阶段。录用定稿指内容已经确定，且通过同行评议、主编终审同意刊用的稿件。排版定稿指录用定稿按照期刊特定版式（包括网络呈现版式）排版后的稿件，可暂不确定出版年、卷、期和页码。整期汇编定稿指出版年、卷、期、页码均已确定的印刷或数字出版的整期汇编稿件。录用定稿网络首发稿件内容必须符合《出版管理条例》和《期刊出版管理规定》的有关规定；学术研究成果具有创新性、科学性和先进性，符合编辑部对刊文的录用要求，不存在学术不端行为及其他侵权行为；稿件内容应基本符合国家有关书刊编辑、出版的技术标准，正确使用和统一规范语言文字、符号、数字、外文字母、法定计量单位及地图标注等。为确保录用定稿网络首发的严肃性，录用定稿一经发布，不得修改论文题目、作者、机构名称和学术内容，只可基于编辑规范进行少量文字的修改。",
    "context3": "出版确认：纸质期刊编辑部通过与《中国学术期刊（光盘版)》电子杂志社有限公司签约，在《中国学术期刊（网络版)》出版传播平台上创办与纸质期刊内容一致的网络版，以单篇或整期出版形式，在印刷出版之前刊发论文的录用定稿、排版定稿、整期汇编定稿。因为《中国学术期刊（网络版)》是国家新闻出版广电总局批准的网络连续型出版物（ISSN2096-4188，CN11-6037/Z)，所以签约期刊的网络版上网络首发论文视为正式出版。"
  },
  "基于大语言模型的文献综述智能生成与循证研究": {
    "context1": "宋梦鹏，白海燕",
    "context2": "(中国科学技术信息研究所 北京100038)",
    "context3": "摘要：[目的]自动生成带参考文献的结构化综述，辅助科研用户快速了解某一领域科研知识。[方法]选取NSTL平台7万篇论文，对摘要进行语步识别，构建语料库。通过大模型生成与人工修改构建3千条综述数据，对GLM3-6B模型微调训练。通过将语料库转换成高维向量、利用索引存储向量、再向量检索实现LangChain 外挂知识库。为弥补专有名词检索不佳，再混合BM25检索并重排序，提高检索精度。[结果]通过微调训练模型和混合检索框架构建综述生成系统，BLEU和ROUGE 得分提高了 $1 0 9 . 6 3 \\%$ 和 $4 0 . 2 1 \\%$ ，人工评估真实性得分提高$6 2 . 1 7 \\%$ 。[局限]受计算资源限制，本地模型参数规模较小，生成能力有待继续提高。[结论]利用检索增强生成技术发挥大模型的优势，不仅可以生成高质量的文献综述，也为生成内容提供循证溯源，辅助科研人员智能阅读。",
    "context4": "关键词：大语言模型；自动综述；检索增强生成  \n分类号:G356.7  \nDOI:"
  },
  "Research on Intelligent Generation and Evidence Based of Literature Review Based on Large Language Model": {
    "context1": "Song Mengpeng, Bai Haiyan (Institute of Scientific and Technical Information of China, Beijing 10oo38, China)",
    "context2": "Abstract: [Objective]Automatically generates structured literature reviews with references to assist research users in quickly understanding a particular area of scientific knowledge.[Methods]A corpus was constructed by selecting 70,OoO papers from the NSTL platform and identifying moves in the abstracts.The GLM3-6B model was fine-tuned for training by constructing 3,OOO reviews of data through large language model generation and manual revision.By converting the corpus into high-dimensional vectors, utilizing index storage for vectors,and then retrieving vectors to implement LangChain's external knowledge base.To solve the problem of poor retrieval of proper nouns,hybrid search with BM25 is used and reordered to improve retrieval accuracy.[Results]Constructing the literature review generation system by fine-tuning and hybrid retrieval framework the model improved the BLEU and ROUGE scores by $1 0 9 . 6 3 \\%$ and $4 0 . 2 1 \\%$ , and the authenticity score of manual evaluation by $6 2 . 1 7 \\%$ .[Limitations] Due to the limitation of computational resources, the scale of local model parameters is small, and the generation ability needs to be continued to improve.[Conclusions]Utilizing retrieval-augmented generation technique to take advantage of large language models not only generates high-quality literature reviews, but also provides evidence-based traceability for the generated content and assists researchers in intelligent reading.",
    "context3": "Keywords: Large language model; Automatic review; Retrieval-augmented generation"
  },
  "1引言": {
    "context1": "学术文献作为知识密度极高的载体，一直备受研究人员的关注。大数据时代科学研究成果不断涌现，科技文献资源总量呈爆炸性增长。中国科学技术信息研究所对2022年中国的论文发表情况进行了统计，其中主要反映基础研究状况的SCI收录的中国科技论文73.56万篇，反映工程科学研究情况的EI收录中国科技论文46.10万篇[1]。更有研究发现，论文数量每九年就会翻一番[2]，这使得研究人员面临着巨大的信息获取和处理压力。",
    "context2": "海量的文献资源在提供了丰富的知识来源的同时，也带来了一系列挑战：研究人员需要花费大量时间和精力从庞大的文献库中检索、阅读和整理所需的信息。这个过程不仅有较高的时间成本，还需要大量精力投入。因此，如何高效地进行科技文献知识组织与服务，以更好地满足科研工作者的需求，已经成为当前研究领域的热点问题。",
    "context3": "本研究的应用场景是自动综述智能辅助阅读。是指借助文本自动生成技术，特别是借助大语言模型及其相关技术，对大量学术文本进行自动化处理，以满足用户在阅读过程中消化吸收和理解信息的需求。在智能辅助阅读中，系统通过精确检索相关文献内容，对文档进行分析、归纳和总结，生成具有清晰结构的综述性文本，帮助用户快速了解某一领域的专业知识，而非直接替代研究人员者进行正式文献综述的撰写。",
    "context4": "由于面向学术文献领域，对综述内容的准确度要求较高。目前大型语言模型与其他文本生成技术都存在着一系列挑战，如信息的“幻觉”以及生成内容的解释性不足等问题。因此，除了致力于实现自动综述生成的高效性，确保生成内容的可信度也成为研究中的关键问题。",
    "context5": "本研究将聚焦于文献综述生成内容的循证溯源，基于开源大语言模型结合学术文献摘要数据集微调，构建面向学术文献的自动综述生成模型，通过检索增强技术提高结果的准确性、一致性和相关性。本文将结合国内外相关研究，在分析学术文献摘要数据的特征后，对开源的大语言模型进行微调，构建自动综述结构化生成方法及模型，做好信息信息检索、循证溯源等工作，更好地实现机器智能生成和机器辅助阅读。"
  },
  "2相关研究": "",
  "2.1自动摘要": {
    "context1": "文本自动摘要是指依据原始文本内容，创建包含重要句子或相关重要信息的，能够表达及还原原文意图的概括性摘要文本[3]。自动文摘技术在上世纪五十年代末，Luhn[4首次提出，经过几十年的迭代与发展，领域概念树庞大，内容形式复杂，其分类5如表1所示。",
    "context2": "表1文本自动摘要系统分类及代表文献简介  \nTablel Classification of Automatic Text Summarization Systems and Brief description of   \nRepresentative Literature",
    "context3": "<table><tr><td>分类依据</td><td>类型</td><td>代表文献简介</td></tr><tr><td>基于文本输入大小</td><td>单文档摘要</td><td>基于特征的对文本最重要的内容进行压缩，选取得分最高的若干 句子生成摘要[4]</td></tr><tr><td rowspan=\"2\"></td><td rowspan=\"2\">多文档摘要</td><td>基于图模型和聚类算法从一组文档中提取摘要[6]</td></tr><tr><td colspan=\"1\">将任一篇文章转换为一个信息提取框架实体，再由文摘生成器产</td></tr><tr><td rowspan=\"4\">基于输出摘要类型</td><td>一般摘要</td><td>生文摘[7]</td></tr><tr><td></td><td colspan=\"1\">基于查询的摘要 识别文档主题，并根据用户的查询提取相关的句子来生成摘要[8]</td></tr><tr><td></td><td colspan=\"1\">有监督算法提取文档特征，设计可训练的机器学习算法的自动摘要应用[9]</td></tr><tr><td>无监督算法</td><td colspan=\"1\">通过无监督深度神经网络技术与词嵌入方法相结合来提高自动文</td></tr><tr><td></td><td></td><td>本摘要的质量[10] 只包含关于源文档的一般想法，其目的是给用户一个想法，即是</td></tr><tr><td rowspan=\"2\">基于摘要内容</td><td>指示性摘要</td><td>否要阅读这个原始文档[]</td></tr><tr><td>报道性摘要</td><td colspan=\"1\">包含有关原始文档的所有主要主题</td></tr><tr><td rowspan=\"2\">基于摘要所属领域</td><td>适用领域</td><td>摘要系统适用于所有文本，无特定结构</td></tr><tr><td>特定领域</td><td colspan=\"1\">基于法律文档和主题的架构，设计针对法律文件的摘要系统[12]</td></tr><tr><td rowspan=\"3\">基于摘要方法</td><td>抽取式</td><td>使用从给定语料库的摘要中抽取词汇和概念进行生成[13]</td></tr><tr><td>生成式</td><td colspan=\"1\">利用 seq2seq模型改写语料库并生成新句子[14]</td></tr><tr><td>混合式</td><td colspan=\"1\">从给定语料库提取压缩文本再生成高质量语句[15]</td></tr><tr><td rowspan=\"4\">基于摘要语言</td><td>单语言</td><td>专门针对土耳其语言文本进行摘要研究[16]</td></tr><tr><td>多语言</td><td colspan=\"1\">从三个不同语种的多文档新闻文本中有效地摘出摘要[17]</td></tr><tr><td>跨语言</td><td colspan=\"1\">在跨语言文本摘要器中，输入文档是一种语言(例如英语)，输出摘</td></tr><tr><td></td><td colspan=\"1\">要是另一种语言(例如印地语)[18]</td></tr><tr><td rowspan=\"4\">基于摘要类型</td><td>简明标题</td><td>识别相似信息的短语和统计生成常见短语，融合成关键句子[19]</td></tr><tr><td>句子级摘要</td><td colspan=\"1\">在评论性文本中识别信息量最大的句子最为摘要[20]</td></tr><tr><td>突出强调</td><td colspan=\"1\"></td></tr><tr><td>完整总结</td><td colspan=\"1\">从源文档中选取内容按照组织结构和要点组装到模板中[21] 根据用户压缩率或用户要求对所有文章生成完整摘要[22]</td></tr></table>",
    "context4": "根据文档数目的不同，自动摘要可分为单文档自动摘要和多文档自动摘要。其中，多文档摘要是将同一主题或同一领域内多篇待总结文本进行浓缩、提炼为一个较短文本[23]。多文档摘要常用于优化学术检索等场景，例如基于多篇科技文献自动生成综述[24]任务，或是Cao[25]等提出的面向学术查询的多文档摘要模型，该模型通过注意力机制同时解决查询相关性排序和句子显著性排序的任务。",
    "context5": "部分研究也不局限于单一的技术方法，采用多种技术混合来提高多文档摘要的质量。如郑义[26等基于统计方法，围绕段落的语义相关性，进行文本分段、聚类、类排序、抽取代表段，从而实现多文档摘要。唐晓波[27等面向学术文献提出了一种将机器学习、聚类以及图排序相结合的方法，尝试解决多文档摘要冗余度高和信息不够全面的问题。",
    "context6": "在多文档摘要的基础上，研究人员面向学术场景不断优化相关工作生成方向。早在1999 年，Nanba[28]等提出通过文献之间的引用关系及引用术语等信息进行同一领域的相关工作生成。Alamo[29]等借助LDA 主题模型和主题层次凝聚聚类方法共同确定主题个数，为每个簇抽取句子单元，经过压缩、排序后生成描述相关工作的综述性文本。Mohammad[30]等应用无监督摘要方法，如LexRank[31],生成相关工作的技术调查。Agarwal[32]等提出了基于聚类的共被引论文摘要生成方法。但是，这些方法实质上仅使用几十个精简摘要进行拼接，而不是高质量的文献综述。",
    "context7": "本研究的文献综述自动生成本质上属于多文档摘要研究，可以看作是多文档自动摘要更高层次的任务。区别于简单总结相关工作，自动综述对生成内容的质量要求更高，要求上下文连贯，具有一篇综述的前后逻辑。并标引生成内容的参考文献，可以追溯源文档，对生成内容进行循证。比起现有的相关工作生成中的简单罗列和拼接内容，本研究的自动综述要求综述结构清晰，例如按照清晰的语步结构进行生成，同时梳理归纳不同的观点。"
  },
  "2.2大型语言模型与自动综述任务": {
    "context1": "大型语言模型（Large Language Model，LLM）如GPT-3 等是具有几十亿甚至百亿参数的Transformer语言模型，GPT-3和它的后继产品在自然语言处理任务中达成显著的结果[33]。事实上，最近的研究[34]已经证实，即使没有明确的训练，GPT-3在标准的总结任务上也比完全监督的模型表现更好。",
    "context2": "文献综述作为一项困难的文本任务，其子任务主要包括文献检索与评估、文献分类组织、综合论述撰写等[35]，在全过程中事实的准确性非常重要。Taylor等人[36提出了GALACTICA，这是一个对4800万篇科学论文进行训练的大规模语言模型。GALACTICA公开对外展示了它在文献综述生成方面的潜力，然而由于幻觉问题，它在几天内被关闭，这一事件突显了在将大语言模型引入文献综述领域时所面临的挑战。",
    "context3": "虽然接受过“开放领域”内容训练的LLM已显示出在跨领域表现良好的能力[37]，但大量研究[38]表明，通过继续“领域内”的预训练，使LLM专业化可以进一步提高表现。于是现有研究逐渐把重点放在先构建数据集、再重新建构模型上，如Big Bird[39]和 Fusion-in-Decoder[40]。Kasanishi[41]等基于事先构建的文献综述大规模数据集，评估了其他基于Transformer 的文献综述生成任务的摘要模型，并提出了基于查询加权的融合解码器（Queryweighted Fusion-In-Decoder,QFID）,通过机器和人工评估，结果显示提出的模型在关注与查询相关的内容方面优于其他模型，甚至有 $3 0 \\%$ 的章节完全优于人工专家撰写的文献综述，为该领域的研究指出了新的方向。但问题仍然存在，研究[42]表明， $8 \\%$ 至 $3 0 \\%$ 的系统生成的自动摘要存在事实错误。"
  },
  "2.3检索增强生成": {
    "context1": "LLM在自然语言处理任务上展现显著的能力的同时，也面临着诸如幻觉[43]、知识过时、不透明、无法追踪的推理过程等挑战[44]，这些限制促使了检索增强生成（Retrieval-Augmented Generation，RAG）的发展，该技术整合了来自外部数据库的知识，以提高模型的准确性和可信度。RAG技术由Meta AI[45]于 2020年所提出，检索方法特指向量检索，RAG技术利用文本嵌入模型和生成模型之间的协同作用，利用嵌入模型将输入问题向量化，然后结合知识向量数据库以及高效、准确的搜索算法进行搜索，将相关检索结果与用户提问共同输入给LLM,以期获得更为准确的文本生成结果。",
    "context2": "有学者[46通过实验发现，提供高质量的辅助文档时，LLM性能更佳且更加自信，LLM倾向于依赖所提供的辅助文档生成反馈。辅助文档与问题的相关性越强，LLM越自信，也更加依赖辅助文档。由此也可以论证，利用LLM生成摘要的时候，如果有外接知识库提供辅助文档，生成内容会更可信。",
    "context3": "此外，对比从零开始生成文本，基于RAG的文本生成以检索得到的文档作为参考依据，LLM在训练后能生成带引用标记的文本[47]，利于循证溯源。许多商业化的检索系统都采用了检索增强生成的方式，并附加引用标记，例如NewBing 和 perplexity.ai参考网页内容回答用户的问题，并在生成的答案中附上引用的网站。但NewBing 等主要尝试商业搜索引擎和闭源代码模型，这使得其结果难以评估。",
    "context4": "赵浜[48]等在情报领域典型任务实验过后得出结论，LLM目前是无法保证其内部检索质量的。Dhuliawala[49]等也探索了检索增强生成来提高事实的正确性，其思想是利用检索机制来获取需要引用的现有论文的相关列表，为基于LLM的生成提供了相关的上下文知识。这也引入了RAG的另一个优点，利用LLM结合外部工具，允许持续更新知识和集成特定领域的信息，不仅解决幻觉问题，还能限制过时知识的影响。"
  },
  "3研究设计与数据来源": "",
  "3.1综述生成系统架构设计": {
    "context1": "本研究面向学术文献领域，通过抽取国家科技图书文献中心（National Scienceand TechnologyLibrary，NSTL）平台上的高质量学术文献，构建摘要数据集、预训练数据集、知识向量库，并选取了ChatGLM3-6B作为实验基础模型，部署后首先进行基于Lora 的大语言模型微调，再将微调后的模型接入LangChain 框架，使用设计好的多重Prompt进行检索、重排序、内容生成。",
    "context2": "当用户提出问题时，生成相应的查询向量，利用Faiss 这一快速相似性搜索库进行高效的检索，获取前top_k条相关记录。再将这些记录组合到一个提示模板中，交由LLM生成答案并反馈给用户。如图1所示。",
    "context3": "![](images/da50608d81be32b7740d3fb966f4adb1f946ee6ff39d6c9ea0c582917dbe68d3.jpg)  \n图1基于GLM-Lora 的学术文献综述生成框架",
    "context4": "Fig.1 Framework for Literature Review Generation Systems Based on GLM-Lora",
    "context5": "在实际的文献检索平台应用中，并不是所有的文献都有全文数据。摘要是对文献内容的简短陈述，能够获得文献的必要信息，因此，从实际工程应用的角度出发，基于文献原始文摘进行压缩归纳进而生成综述，既能保留文本的主要内容信息，且更符合实际数据特点，支撑后续的实际应用。而为了区别简单的多文档摘要，按照语步生成结构化综述需要进一步从摘要数据中识别并提取语步。LLM输入输出实际应用中存在限制，一次性输出一篇文献综述在实际应用中效果不佳，因此不仅逐次输入语步信息，在内容生成时也需要先多次调用LLM生成不同部分的综述性文本，再由系统整合输出。"
  },
  "3.2数据来源及处理": {
    "context1": "本研究数据来源于NSTL平台，对中英文期刊进行筛选，以核心期刊收录为质量判断，其中中文期刊选自NSTL数据库中的北大核心期刊目录，共525 本；英文期刊是数据库中的 SCI期刊目录，共4398本。从这些期刊中筛选出1998年至 2023年内具有结构化摘要的中文文献和所有英文文献，剔除不完整的无效文件数据后，共74564篇，提取其摘要。中文期刊提取出的数据，由于本身就是结构化摘要，基于结构化的关键词及表达用词，采取正则表达式的方法进行结构化摘要语步要素的自动提取。从结构化摘要中切割的语步字段包括：结论、方法、目的、结果、背景、局限、创新、数据。对于英文期刊中存在非结构化的摘要，本研究采取基于BERT深度学习模型进行语步识别。",
    "context2": "经过调研分析后，本研究选取 $\\mathrm { Y u } ^ { [ 5 0 ] }$ 等提出的基于BERT的掩藏句子模型(Masked SentenceModel，MSM)的语步自动识别方法。在相同数据集上，MSM比同样基于BERT的 SciBERT在F1得分上高 $4 . 3 4 \\%$ ，可以通过对训练数据中的摘要句子进行上下文特征的学习，提高语步识别的精度，在现有语步识别研究中具有较为突出的效果与通用性，因此本研究选取MSM进行语步识别。最终从原摘要中直接抽取到的语步字段包括：结论、方法、目的、结果、背景、设计、对象、测定项目、数据、处理、意义、应用。",
    "context3": "提取的语步数据中，例如局限、数据等语步要素占比较少。目前语步识别研究中，大多数研究包括本研究使用的MSM模型，最终采用的语步要素均为以下5个语步要素：“背景”、“目的”、“方法”、“结果”、“结论”，这五个语步要素基本涵盖了一篇论文的主要信息。因此本研究在后续的实验中计划按照背景、目的、方法、结果、结论五个语步进行综述的生成。区别于现有的搜索引擎等应用提供的多文档摘要，这样的综述结构不仅完整，也能清晰的展现主题领域丰富的综合信息。"
  },
  "3.3微调数据集生成": {
    "context1": "实验对模型进行微调处理的目的是，使得模型能够适应学术文献领域生成综述性文本的任务，重点在于希望结合检索增强使得大语言模型在生成综述性文本时会依据提供的文本生成引用标识符，为用户循证溯源提供文献。",
    "context2": "首先针对原有文献数据集中关键词最常出现的主题词进行排序，提取前 625个主题词，依据该主题词，在向量数据库中分不同语步进行检索，检索结果限制在5篇论文以内，得到背景、目的、方法、结果、结论不同语步对应的五篇论文的语步部分。整理后原625条数据扩充到3125条数据，每个主题词对应了五个语步检索结果，每份检索结果中有最相关的五篇论文的摘要内容。再使用GLM-130B的API接口调用性能最优的在线大模型，同一主题词下不同的语步使用不同的提示词进行综述性文本的生成。",
    "context3": "不同于问答任务，问答任务仅需要模型根据相应的文本提取片段来生成答案，但是本研究仅在于让模型根据大量文本进行总结和归纳。依据五个语步部分对应的不同特点要求模型进行生成。提示词包括文本结构、应有内容、语言风格、引用要求等，涵盖了综述性文本常见的内容。",
    "context4": "对生成内容进行审查，过滤不合格数据后，再由人工审查筛选质量，对综述性文本进行合理修改，确保引用合理真实，最后得到3084条数据。参照用于LLM微调的“prompt-input-output”格式，设计的数据集如下所示，其中 instruction 字段指的是文献综述自动生成的描述性指令，input字段指的是文献综述主题和围绕该主题的五篇语步级学术文献摘要，output字段指的是依据提供的五篇摘要生成的带有引用标识符的综述性文本。数据集生成时，训练集、验证集以及测试集划分为8：1：1。"
  },
  "4模型训练与系统实现": "",
  "4.1实验环境与参数设置": {
    "context1": "本实验环境配置为：CPU,12 vCPU Intel(R) Xeon(R) Platinum 8163 CPU $@$ 2.50GHz; GPU,1 \\* NVIDIA V100Tesla V100-SXM2-16GB;显存：16GB。Cuda 版本12.1，python 版本3.10.14。实验参数上，早有其他实验指出，ChatGLM模型微调训练轮数不宜过多，否则容易出现灾难遗忘问题[51l，故实验将超参数设置为5轮。其他实验超参数如表2所示。",
    "context2": "表2模型微调训练中主要的超参数设置  \nTable2 Main Hyperparameter Settings in Model Fine-tuning Training",
    "context3": "<table><tr><td>超参数</td><td>中文解释</td><td>参数值</td></tr><tr><td>max_target_length</td><td>最大输出序列长度</td><td>8192</td></tr><tr><td>learning_rate</td><td>学习率</td><td>1e-4</td></tr><tr><td>per_device_train_batch_size 每批次训练数据量</td><td></td><td></td></tr><tr><td>gradient_accumulation_steps loraplus_lr_ratio</td><td>梯度累计步数 学习率倍数</td><td>2 16</td></tr></table>"
  },
  "4.2模型训练": {
    "context1": "本地部署ChatGLM3-6B，在借助LlamaFactory 高效微调框架，使用Lora 微调方法进行微调训练，为区别于基础模型，本研究将经过微调后的模型称为GLM-Lora。LLaMA-Factory 是一个支持多种开源大语言模型和训练方法的微调框架，可以方便地实现有监督微调、Lora微调、预训练微调等。该框架支持LLaMA、Mistral、Qwen、ChatGLM等多种模型使用多种集成方法在多种精度上进行微调。使用LLaMA-Factory最大的优势就是用户能够在有限算力资源下更加高效地开展微调训练。",
    "context2": "![](images/f2482cfff9e6038319e16d3d196c6deaac8e0a5073935b08f5fc958f545db217.jpg)  \n图2模型训练样本（左）与验证样本（右）损失曲线  \nFig.2 Model Training Loss and Evaluation Loss Plots",
    "context3": "有监督微调阶段中训练样本、验证样本的损失变化曲线如图2所示。训练集损失曲线显示，模型预测结果与实际标签差异逐渐减小，损失值下降速率较快，最终基本降至0.8左右，表明模型在训练集上具有良好的拟合效果，能有效学习数据内在规律。同时本研究随机抽取微调数据集中 $1 0 \\%$ 数据作为验证集，以每一百步为一次检查点，进行验证集的效果评估。验证集损失曲线趋势与训练集损失曲线方向一致，说明模型没有出现过拟合现象，在没有训练的验证集上表现出良好的泛化能力。"
  },
  "4.3模型评估指标": {
    "context1": "为评估模型效果，本研究采用指标评估与大模型评估结合的方式，对后续系统生成文献综述的质量与真实性进行自动化评估提供依据，以下是本研究采用的评估方法。",
    "context2": "词频-逆文档频率[52] (Term Frequency-Inverse Document Frequency,TF-IDF)通常用于评估短语对一个语料库的重要程度，计算方法如公式（1）。TF-IDF 加权余弦相似度通过考虑每个词的频率和其在文档中的重要性以衡量生成回答与标准答案之间的内容相似度。",
    "context3": "$$\nT F - I D F ( x ) = { \\frac { n x , j } { \\sum _ { k } n k , j } } \\times \\log { \\frac { N + 1 } { N ( x ) + 1 } }\n$$",
    "context4": "BLEU[53]（Bilingual Evaluation Understudy）是一种常用的用于评估机器翻译质量的指标，它通过计算文本间的 $\\mathbf { n }$ -gram 重叠，精确度量各类模型生成文本与参考回答间的符合程度。BLEU的计算方法如公式（2）所示。",
    "context5": "$$\nB L E U = \\frac { \\displaystyle { \\sum _ { C \\in \\{ C a n d i d a t e \\} } \\sum _ { n - g r a m e C } C o u n t . c l i p ( n - g r a m ) } } { \\displaystyle { \\sum _ { C ^ { \\prime } \\in \\{ C a n d i d a t e \\} } \\sum _ { n - g r a m \\in C ^ { \\prime } } C o u n t ( n - g r a m ^ { \\prime } ) } }\n$$",
    "context6": "但因 BLEU较少关注文本的覆盖范围与流畅性，本研究生成的是综述性文本，故本研究还引入了ROUGE-L指标作为补充，该指标通过比对最长公共子序列，更全面地评估生成文本在信息完整性与连贯性方面的表现",
    "context7": "ROUGE[54]（Recall-Oriented Understudy for Gisting Evaluation）是常用于评估自动摘要和文本生成模型性能的指标。ROUGE 分为ROUGE-N、ROUGE-L等多种指标，ROUGE-L使用最长公共子序列，计算方法如公式（3）所示。",
    "context8": "$$\nR O U G E - L = \\frac { ( 1 + \\beta ^ { 2 } ) R _ { l c s } P _ { l c s } } { R _ { l c s } + \\beta ^ { 2 } P _ { l c s } }\n$$",
    "context9": "在传统的指标评估方法之外，本研究引入基于大模型的自动化评估方法，分别使用高性能的Gemini-Pro、GPT-4对输出的综述性文本进行质量评估，使用GPT-4进行真实性评估。",
    "context10": "谷歌推出了基于Gemini-Pro 的大模型评估[55]，针对摘要、问答、工具使用、常规文本生成四大任务进行评估，本研究适配于摘要生成任务，Gemini-Pro 通过利用其强大的推理分析能力综合考虑是否按照指令生成、是否以事实为依据、是否综合全面、是否简要清晰来进行自动评估。",
    "context11": "GPT-4模型对综述文本的质量评故则通过调用其API实现，使用提示词指令，令其针对文本质量、贴近答案、内容全面三个标准进行打分。",
    "context12": "除了对综述性文本的质量进行评估外，本研究作为自动综述，对文本生成内容的真实性也有高要求。为了辅助验证检索到的数据是否正确并有效地使用，以确保模型响应与用户查询相关性及生成内容真实性，利用GPT-4模型对综述内容的真实性进行评分。主要关注是否严格依据参考文献进行内容生成，尽可能降低\"幻觉”，具体 prompt 如表3所示。",
    "context13": "表3调用GPT-4 评估真实性的 Prompt  \nTable3 GPT-4 Prompt for Evaluation of the Authenticity",
    "context14": "<table><tr><td>真实性评估 prompt 你是一名学术专家，负责对文献综述真实性进行评估和评分。文献综述的参考文献是</td></tr><tr><td>容是否全部引用到文献综述中，二是参考文献内容与综述中引用内容是否高度相关，三 是答案是生成了参考文献中没有提供的虚假信息。请根据这三个标准对答案进行科学评 分，评分标准为0.0000-10.0000，浮动。不用解释原因，直接给出最后得分，精确到小 数点后4位。请您对综述性文本进行打分。</td></tr></table>"
  },
  "4.4检索及重排序模块": {
    "context1": "向量检索（VectorRetrieval）对语义理解更强，能有效处理模糊或间接的查询，能识别不同词汇的相同意义，在语义搜索情景中具有明显优势。尤其是在构建完成向量数据库后，向量检索速度非常快。但是在搜索专有名词、缩写词、带ID 的词语时效果不佳，这些缺点恰恰是传统关键词搜索的优势所在。传统关键词检索（BM25）更擅长精确匹配（如专有名词），通过少量字符进行向量检索时效果往往降低，但在实际应用场景中，用户习惯只输入几个关键词。向量检索和关键词检索方法各有优劣，因此结合二者，平衡检索速度与精确度的混合检索更具优势。当完成混合检索后，对多路召回的结果进行重排序，重新排序召回文本的顺序，将能够输出最佳的检索效果。",
    "context2": "![](images/dd15605ebb97eeed234671b796a77e417710b3de0a13b08c691fba964c5ac4b9.jpg)  \n图3文献综述生成系统的混合检索框架",
    "context3": "Fig.3 Ensemble Search Framework of Literature Review Generation System"
  },
  "（1）向量检索": {
    "context1": "向量检索首先需要对用户Query 和本地七万余条文献语料库进行文本嵌入，研究选用的Embedding 模型为bge-base-zh-v1.5模型，为每段文本生成向量表示。"
  }
}