{
  "original_filename": "full_2859.md",
  "国内外专利挖掘研究进展与前瞻 \\*": "",
  "■陈亮¹ 陈利利‘ 许海云² 魏超¹ 苏娜°尚玮姣4": {
    "context1": "1中国科学技术信息研究所北京100038  \n²山东理工大学管理学院淄博255000  \n中国科学院科技战略咨询研究院北京100190  \n4中国林业科学研究院林业科技信息研究所北京100091",
    "context2": "摘要：「目的／意义]专利挖掘是获取技术情报的重要途径，在近年来智能技术快速发展的驱动下，专利挖掘不仅在方法自动化、智能化和挖掘深度、精确度上取得了长足进步，而且展露出数据与算法紧密融合的发展新范式，亟需通过综述形成对其研究现状和未来发展趋势的全面认识。「方法/过程]将文献调研活动的主要环节连成闭环“检索 筛选 梳理 查漏 拓展和再次检索”并持续更新、反复迭代，调研范围包括国内外专利挖掘的相关论文、专利、数据集、算法竞赛评测活动、专利信息服务平台乃至代码托管网站和模型托管网站，并在叙述内容中穿插专家访谈、竞赛选手交流会以及笔者学术成果评审意见中获得的相关信息，最终完成对专利挖掘的系统综述。[结果/结论]专利基础资源的种类和数量较之前增长较快，专利挖掘方法的训练和性能评测逐步具有数据基准和统一测度标准；专利挖掘前沿方法紧跟智能技术发展步伐以实现技术升级和性能提升，而统计学习、人工规则、软件工具等传统方法也在学习成本、实践成本和方法效果的平衡中得到优化和发展；专利挖掘的研究范围实现了从数据处理、规范化到专利基础服务和技术情报分析的全面覆盖，并开启了专利智慧法律的探索。",
    "context3": "关键词：专利挖掘基础资源建设深度学习信息抽取 专利检索  \n分类号：G25  \nDOI: 10.13266/j.issn.0252-3116.2024.02.010"
  },
  "1引言": {
    "context1": "专利是一项社会契约，它通过公开一项发明的技术内容，换取发明拥有者在有限时间段内对该项发明的完全专有权，从而在保障创新者权益、激励创新行为的同时，推动该项发明的社会效益在专利期满后得到广泛传播[。相比其他科技信息，专利具有题录丰富、内容详尽、格式规范、分类科学、时效性强、覆盖面广等优点，据统计，专利覆盖了世界上最新技术信息的 $90 \\%$ ，其中 $80 \\%$ 的技术信息不会以其他形式发布[2]。专利挖掘是从专利数据中获取技术情报的重要方式，该概念起源自A.Porter与 S.Cunningham[3]所提的技术挖掘（techmining），即利用文本挖掘技术从科学、技术和创新（ST&I）信息记录集合中获取技术情报，当将技术挖掘目标限定到专利分析时，就是专利挖掘。随着智能信息技术的快速发展和情报分析方法的长足进步，专利挖掘的内涵和外延也在不断深化和拓展，为跟踪这些变化，胡正银等[4]、屈鹏等[5]、L.Zhang等[分别于 2014—2015 年连续撰文对专利挖掘研究进展进行综述。其中胡正银团队延续 A.Porter与S.Cunningham的定义，从文本挖掘角度汇总相关成果，屈鹏等[5]将专利挖掘的研究范围拓展到文本挖掘和数据挖掘，L.Zhang 等[更是进一步整理了专利挖掘的定义，即利用机器学习、自然语言处理、机器翻译、信息检索、信息可视化等技术手段，来协助专利分析人员进行专利文献调研、处理和深入分析，进而支持一系列重要的技术情报任务，这也成为本文所秉承的专利挖掘定义。近年来有国内知识产权从业者使用“专利挖掘”来表达专利申请者“有意识地对创新成果进行创造性的剖析和甄选，进而从最合理的权利保护角度确定用以申请专利的技术创新点和技术方案的过程”[7]，但该定义无论实现手段还是达成目标都与前述定义相去甚远，故不在本文探讨范围之内。",
    "context2": "经过20年的发展，专利挖掘已经形成了较大的方法家族，但从其具体内容来看，这些方法更多是各项信息技术在不同专利场景上的应用研究，不成体系且缺乏理论指导。虽然胡正银等[4]、屈鹏等[5]、L.Zhang等[从各自角度对这一领域的研究成果进行了梳理和总结，并指出未来的挑战存在于如何建立能够准确揭示技术发明关键信息的专利内容表示方法，如何让智能算法充分利用专利数据特点，更加全面、精准地完成专利挖掘任务，如何将专利与产品、诉讼等其他信息相结合，使专利挖掘的技术边界触达专利实务的核心问题，如专利侵权分析、专利新颖性识别以及应对所有这些挑战的前提- -如何推动学术社区在统一训练数据和评测标准下开展专利挖掘研究，以便不同技术方案之间的横向对比并产生可复现、可信赖的评测结果，让真正优秀的研究成果脱颖而出。但这些综述距今时隔已久，经历了近年来大数据和人工智能的长足发展后，先前作为专利挖掘技术基础的统计机器学习逐步显现出被深度神经网络、预训练模型乃至大语言模型替代的趋势。而在新形势下算法和数据结合的密切程度前未所有，这不仅体现在高质量数据基准（benchmark）带来智能计算技术出现爆发性增长的案例屡见不鲜，更体现在研究者在训练文本和微调指令上训练、微调预训练模型和大语言模型，并将所产生的词嵌人向量和检查点（checkpoint）文件分享出来供后续学者直接加载和重复使用。因此当再次对专利挖掘展开综述时，除全面梳理国内外专利挖掘技术的最新进展外，本文也对专利公开数据和模型文件现状展开综述，从而在数据、算法密切结合的智能技术研究新范式下帮助读者建立对专利挖掘研究现状和未来发展趋势的全面认识。"
  },
  "2文献材料获取和内容综述方法简介": {
    "context1": "本文对近年来专利挖掘领域出现的技术方法、标注数据乃至预训练模型、大语言模型所产生的词向量词典、模型检查点文件进行了全面调研，具体如表1所示："
  },
  "表1文献材料来源汇总": {
    "context1": "Table1 Summary of sources for documents and other resources",
    "context2": "<table><tr><td>来源类型</td><td>来源名称</td><td>网址</td></tr><tr><td>论文数据库</td><td>科睿唯安科学网</td><td>https://www.webofscience.com</td></tr><tr><td rowspan=\"7\">专利数据库</td><td>谷歌学术检索</td><td>https://scholar.google.com</td></tr><tr><td>万方数据知识服务平台</td><td>https://www.wanfangdata.com.cn/</td></tr><tr><td>计算机科学文献库</td><td>https://dblp.org/</td></tr><tr><td>美国计算机学会数据库</td><td>https://dl.acm.org</td></tr><tr><td>在线科学预印本存储库</td><td>https://arxiv.org/</td></tr><tr><td>全球专利统计数据库</td><td>https://www.epo.org/searching-for-patents/business/patstat.html</td></tr><tr><td>世界知识产权局专利检索平台</td><td>https://www.wipo.int/patentscope/en/</td></tr><tr><td></td><td>智慧芽专利数据库</td><td>https://www.zhihuiya.com/</td></tr><tr><td>代码托管网站</td><td>Github</td><td>https://github.com</td></tr><tr><td>模型托管网站</td><td>Huggingface</td><td>https://huggingface.co/</td></tr></table>",
    "context3": "由于调研对象类型繁多、内容庞杂，采用构造检索式、文献检索筛选、阅读汇总这种惯常的文献调研方法容易失之偏颇、挂一漏万，因此本文将上述环节连成闭环持续更新、反复迭代，并在该过程中融合了调研文献的前向引用和后向引用，文献数据库平台提供的推荐文章列表，专家访谈、数据竞赛选手交流会以及笔者撰写论文、专著、申请项目的评审意见所提供的文献、数据等，最终完成对专利挖掘的系统综述，其具体流程包括：",
    "context4": "（1）在前期学术工作中形成对专利挖掘发展现状及其代表性学术成果的总体认识，这里的学术工作主要指笔者撰写综述类文章，或者撰写方法类文章、专著、项目申请书的研究现状综述部分时，对专利挖掘相关内容所做的多轮检索和梳理汇总。",
    "context5": "（2）以上一步骤所识别的代表性学术成果作为种子，通过前向引用、同一作者或团队发表文献以及文献数据库平台所提供的推荐功能等方式拓展出更多文献，根据这些文献的发表时间、期刊或会议的层次、被引次数等对文献质量进行初步筛选，之后阅读文章以确定其研究对象、学术水平、创新性等是否符合准入标注，若符合则将其纳入调研文献集合。",
    "context6": "（3）以该调研文献集合作为基础数据集，梳理专利挖掘的知识体系，在这一步骤中会发现诸多逻辑断裂或者知识空白之处，需要总结、提炼关键词并进行文献检索，以确认这些断裂点、空白点是真实存在还是被之前文献调研所漏检。",
    "context7": "（4）由于专利挖掘受智能技术发展驱动效应十分明显，笔者也重点跟踪了人工智能前沿热点、国际计算机顶级会议中与专利相关的研究成果连同团队参加算法竞赛、学术研讨会获得的知识经验，并将其与现有专利挖掘知识体系建立关联，如果在关联过程中发现逻辑断裂点或者知识空白点，那么就对该部分总结归纳、提炼关键词并进行文献检索，以确认这些断裂点、空白点是真实存在还是被之前文献调研所漏检。",
    "context8": "按照专利信息服务中的数据流转顺序，本文将这些调研材料划分为基础资源建设、数据处理和规范化以及面向专利信息服务的智能算法研究3个模块，具体如图1所示：",
    "context9": "![](images/72b1ae1afc2f39c1e1053a1d077c034d292481024b534bccd6858da1169c0108.jpg)  \n图1专利挖掘研究成果汇总  \nFigure 1Summary of research achievements in patent mining field",
    "context10": "其中基础资源建设既包括构建无标注或标注数据集来为智能算法的训练提供原材料，也包括创建词向量文件和模型检查点文件为后继研究者提供模型基础；数据处理和规范化指从专利文献中抽取关键信息并对其加以规范整合和结构化，以消除专利中固有的模糊性和二义性，并使其中的技术核心要素凸显出来，来支撑上层专利应用服务；面向专利应用服务的智能方法研究以前两个模块为基础来构建算法模型，为终端用户的实际需求提供解决方案。",
    "context11": "本文其余部分安排如下：第三节对基础资源建设情况进行汇总梳理，第四节对数据处理和规范化方法相关成果进行阐述，第五节为面向专利信息服务的智能算法研究，最后在总结当前专利挖掘研究不足和挑战的基础上，对可能的解决之道和未来发展前景进行探讨。值得注意的是，专利挖掘横跨人工智能和知识产权两大领域，尤其方法研究部分更是纷繁庞杂、水平不一，因此在第四、五节选取其中代表性较强的研究方向重点介绍。"
  },
  "3 基础资源建设": {
    "context1": "相比其他科技文献，专利原始数据的获取非常便利，例如美国专利商标局、中国国家知识产权局均以FTP站点或API接口形式提供了最新专利数据的官方下载通道（详见 https://developer.uspto.gov/data 和 http://patdatal.cnipa.gov.cn/），欧洲专利局提供1978年以来专利申请和授权全文的批量下载（详见 https://www.epo.org/searching-for-patents/data/bulk-data-sets/data.html）。这为基础资源建设提供了得天独厚的优势。丰富的字段信息使得专利原始数据具有标注和无标注数据的双重属性：专利的技术分类标签，以及不同国家专利局之间用于数据交换的多语种专利文本，使得专利文献是天然的类别标注数据集和平行语料库；但对于其他专利挖掘任务，如命名实体识别、语义关系抽取来说，专利则是无标注数据，需要人工标注后才能训练相关模型。为避免混淆，在本文中将标注特指为在专利原始数据基础上继续展开的人工标注活动，而将人工标注后的专利数据称为标注数据资源、将专利原始数据称为无标注数据资源。"
  },
  "3.1无标注数据资源": {
    "context1": "受益于专利数据本身丰富的字段信息及其易获取性，将专利原始数据转化为规范化数据资源的过程相对简单、自动化程度较高，这也使得此类数据集数量较多且每个数据集通常体量较大，例如美国国家经济研究局（National Bureau ofEconomic Research,NBER）发布的NBER数据集中包含约300万条专利题录信息和1600万条专利引文信息[8]，美国专利商标局最新版专利审查研究数据集PatEx中包含了超过1250万份公开的临时和非临时专利申请以及超过",
    "context2": "100万份专利合作条约（PCT）申请的详细信息[9]，更多数据资源详见表2。由于专利本身包含丰富的题录字段，即便未对这些数据资源做进一步的人工标注，它们也可以作为类别标注数据集、平行语料库、自动摘要数据集来支持专利分类、专利翻译、专利自动生成摘要等任务；不仅如此，还有无标注数据甚至可以支持专利文本的重写，比如为避免专利原文内容晦涩、给用户带来理解障碍,德温特创新索引（Derwentinnovations index）的摘要字段系由领域专家对原始专利摘要改写而成，这些摘要信息可以和专利原文摘要以及权利要求项、专利说明书等字段相结合形成微调指令，帮助大语言模型（如GPT-2）学习如何提升专利文本的可读性[10]。",
    "context3": "表2无标注数据资源汇总  \nTable 2 Summary of unlabeled data resources",
    "context4": "<table><tr><td>数据集名称</td><td>数据来源</td><td>数据集内容</td><td>数据集规模及语种</td></tr><tr><td>NBER dataset[8]</td><td>美国专利商标局</td><td>专利题录和引文数据</td><td>300 万条专利题录，英文；1600万条专利引文</td></tr><tr><td>PatEx2021[9]</td><td>美国专利商标局</td><td>专利申请题录数据、审查员 ID及 其审查小组、专利交易历史数据</td><td>超过1250万份专利申请记录和超过100万份PCT 专利申请记录，英文</td></tr><tr><td>USPTO-2M[11]</td><td>美国专利商标局</td><td>专利题录数据</td><td>200 万条专利记录，英文</td></tr><tr><td></td><td>发明专利数据 V2[12]中国国家知识产权局</td><td>专利题录数据</td><td>277万条专利记录，中文</td></tr><tr><td></td><td>NTCIR-7PATMT[13]美国专利商标局和日本专利局</td><td>专利题录和全文数据</td><td>130万条美国专利记录，英文；350万条日本专利记录， 日文</td></tr><tr><td></td><td>NTCIR-8 PATMT[14]美国专利商标局和日本专利局</td><td>专利题录和全文数据</td><td>210万条美国专利记录，英文；525万条日本专利记录， 日文</td></tr><tr><td>BigPatent[15]</td><td>美国专利商标局</td><td>专利全文</td><td>130 万件专利，英文</td></tr><tr><td>MAREC[16]</td><td>欧洲专利局、世界知识产权组织、专利题录和部分全文数据 美国专利商标局、日本专利局</td><td></td><td>1900 万条专利记录，将近一半专利具有全文数据， 语种以英语、德语、法语为主</td></tr><tr><td>PTAB[17]</td><td>美国专利商标局</td><td>专利诉讼卷宗</td><td>截至2023年11月28日共16.5万条记录，目前还在 更新中，英语</td></tr></table>"
  },
  "3.2标注数据资源": {
    "context1": "依据J.Zhu等[18]定义，标注是对未处理的初级数据，包括语音、图片、文本、视频等进行加工处理，并转换为机器可识别信息的过程。数据标注是大部分人工智能算法得以有效运行的关键环节，数据标注越准确、标注的数据量越大，算法的性能就越好[9]。当前专利挖掘领域的数据标注工作主要面向专利检索、信息抽取以及其他任务展开，相关数据资源如表3所示。",
    "context2": "由于专利检索本身在行业中的重要地位以及专利检索多样性（例如可专利性检索、有效性检索、侵权检索、确权检索、现有技术状况检索、专利全景检索等[38]）所带来较高的研究价值，专利检索标注资源构建一直是信息检索和专利分析领域的重要工作内容。自2011年起，NTCIR[39]、CLEF[40]、TREC-CHEM[41]、SIGIR[42]先后举办了15次技术评测，并形成多种类型的专利检索标注数据集，内容涉及普通专利检索、篇章级专利有效性检索、段落级专利有效性检索、跨语种专利检索、基于图片检索的专利有效性检索以及在先技术检索和现有技术状况检索。这些数据资源一般以专利参考文献作为检索任务的目标文献，并辅以人工标注、清洗和审核工作，实现大规模标注数据资源的构建。一般来说每条专利标注数据包含3部分内容，即检索式（或检索主题）、专利文献编号以及对应的相关性等级标签。",
    "context3": "信息抽取旨在解决一个长期困扰专利分析的基础问题，即如何高效、准确地从海量专利数据中识别技术及其属性、功能、效果、相关产品等，并实现这些信息之间的语义关联和规范化。由于专利文献中信息抽取标注可以借力的内容极少，该类资源建设所需人工劳动高度密集。但即便如此，也涌现出不少相关数据资源，内容涵盖命名实体识别、语义关系抽取、"
  },
  "表3　标注数据资源汇总": {
    "context1": "Table3 Summary of labeled data resources",
    "context2": "<table><tr><td>任务大类</td><td>任务类别细分</td><td>数据资源名称</td></tr><tr><td rowspan=\"7\">专利检索</td><td>一般专利检索</td><td>NTCIR-3 PATENT[20]</td></tr><tr><td>篇章级专利有效性检索</td><td>NTCIR-4 PATENT[20]、NTCIR-5 PATENT[20]、CLEF-IP-2009[21]、CLEF-IP-2010[22]</td></tr><tr><td>段落级专利有效性检索</td><td>NTCIR-5 PATENT[20]、CLEF-IP-2012[23]</td></tr><tr><td>跨语种专利检索</td><td>CLEF-IP-2009[21]、CLEF-IP-2010[22</td></tr><tr><td>基于图片的专利有效性检索</td><td>CLEF-IP-2011[24]</td></tr><tr><td>在先技术和技术现状检索</td><td>TREC-CHEM-2009[25]、TREC-CHEM-2010[26]、TREC-CHEM-2011[27]</td></tr><tr><td>专利信息 命名实体识别</td><td>NTCIR-8 PATMN[28]、THF-2020[29]、CHEMDNER-patents[30]、CPC-2014[31]、ChEMU 2020[32]、ChEMU 2021[33]</td></tr><tr><td rowspan=\"6\">其他</td><td>语义关系抽取</td><td>THF-2020[29]、ChEMU 2021[33]</td></tr><tr><td>事件抽取</td><td>ChEMU 2020[32]、ChEMU 2021[33]</td></tr><tr><td>专利插图的化学结构、处理流程抽取</td><td>CLEF-IP-2012[23]、CLEF-IP-2013[34]、TREC-CHEM-2011[27]</td></tr><tr><td>专利文本和插图之间的跨模态实体链接（</td><td>CLEF-IP-2013[34]</td></tr><tr><td>专利术语匹配</td><td>PhraseMatching[35]</td></tr><tr><td>专利图片分类</td><td>CLEF-IP-2011[24]</td></tr><tr><td></td><td>专利诉讼</td><td>PatentMatch[36]</td></tr><tr><td>医学研究</td><td></td><td>Cancer Moonshot Patent Data[37]</td></tr></table>",
    "context3": "事件抽取乃至专利插图中的化学结构和处理流程识别等；同时专利信息提供商也从专利行业需求出发，将专利文献中高价值的技术要素提炼出来，例如科睿唯安的德温特专利创新索引将专利新颖性、先进性和用途抽取出来并作为改写后摘要的组成部分，智慧芽专利数据库也对专利要解决的技术问题及其功能效果进行了标注。",
    "context4": "本文也发现专利标注数据资源建设在信息类型上向跨模态方式拓展，在研究目标上向智慧法律方向迈进。早在 2011年，CLEF-IP-2011[43]就将专利图片划分为9种类型，包括摘要图、流程图、基因序列、符号、程序列表等，并形成包含38087张图片的训练集和1000 张图片的测试集；2013年，CLEF-$\\mathrm { I P - } 2 0 1 3 ^ { [ 4 4 ] }$ 进一步举办了旨在关联文本和插图之间语义信息的跨模态实体链接测评；2022年，谷歌以合作专利分类号（cooperative patent classification）作为专利术语的语境信息，发布了包含约5万个术语对的专利术语匹配数据集PhraseMatching[35]，为跨语境术语语义匹配研究奠定了必要基础，德国波茨坦大学J.Risch等[28]更是在世界知识产权组织提供的专利检索报告中萃取600万条句子级别的专利无效记录，并形成专利诉讼数据集PatentMatch供并形成专利诉讼数据集PatentMatch供开展智慧法律研究使用使用。"
  },
  "3.3词嵌入向量词典和模型检查点": {
    "context1": "词嵌入向量词典和模型检查点是两种不同于专利文献数据的新型数据资源，是应用深度神经网络、预训练模型乃至大语言模型开展专利挖掘的基础条件。其中词嵌入向量词典由深度神经网络在语料库上运行产生，用于将用户输入的词汇或句子转化为向量或矩阵，从而为深度学习模型提供可执行的输入信息，模型检查点则是预训练模型或大语言模型训练完毕后存储下来的模型快照。由于创建这两类资源尤其是模型检查点对训练语料的体量和计算资源的规格要求不菲，当前主流范式是由技术能力较强、数据与算力充沛的企业或高校训练这两类资源并公开发布到模型托管网站，如Huggingface、魔搭社区（https://modelscope.cn），其他研究者和普通用户只需要将这些资源下载本地并加载起来，就可以实现词嵌入向量词典、预训练模型以及大语言模型的本地运行，从而避免重复训练所带来的资源浪费。对于专利挖掘来说，虽然这些模型托管网站提供了诸多基于通用语料库，如谷歌新闻数据集[45]、维基百科或网页数据集common crawl（https://commoncrawl.org/）所训练的词嵌入向量提供开放下载，然而J.Risch等[46]发现，由于专利在句法结构和表达内容上显著迥异于通用语料，基于通用语料和专利语料训练的词嵌入向量在专利挖掘任务表现上差异明显，因此他们在USPTO-5M的540万美国专利全文数据上（目前该数据集下载链接已经被官方取消）上使用fastTEXT算法训练出100维、200维、300维共3种向量长度的词嵌入向量词典并提供公开下载（https://hpi.de/naumann/projects/web-science/paar-patent-analysis-and-retrieval/patent-classification.html），其中30o 维词嵌入向量在专利分类任务上的平准准确率较同样维度的通用",
    "context2": "词嵌入向量提升了 $1 7 \\%$ 。",
    "context3": "预训练模型和大语言模型的专利挖掘性能同样会受到通用训练语料和专利挖掘任务之间领域不匹配的影响。有两种策略可以缓解甚至消除这一影响，其一是继承原有通用模型的词表和参数权重，但使用专利语料继续训练，以增加模型的领域适应性；其二是丢弃原有通用模型的词表和参数权重，利用专利语料重新构建词表并从头训练模型。第一种策略适合专利语料有限、不足以充分训练模型的情况，这种条件下两阶段混合训练策略往往能取得更好的效果。谷歌公司采用第二种策略，它从美国及其他国家采集超过1亿份专利文献的全文（包括摘要、权利要求项和说明书字段）并训练出可供开放下载的BERT-for-Patents[47]，在陈亮等[48]参加2022年中国计算机学会大数据与计算智能大赛专利分类赛题的方案尝试中，谷歌公司的模型较通用版本BERT在专利分类效果上提升了 $8 \\%$ （使用weighted-average F1指标评价），显示出强大的性能。同样使用第二种策略，J.S.Lee[49]基于1976年至 2021年间共计731G专利全文数据，在GPT-3的开源替代大语言模型GPT-J-6B上配置和重新训练，最终形成参数量为60亿、16亿、4.56亿、2.79亿、1.91亿、1.28亿、1.15亿的7个模型检查点，其中最大4个模型检查点已经上传Huggingface 网站并提供公开下载（下载链接https://huggingface.co/patent）。"
  },
  "3.4小结": {
    "context1": "当前专利挖掘领域建设的基础资源类型较多、分布广泛，一方面由于专利自身丰富的题录和全文信息，外加各大专利局在专利业务和数据资源上的多年积累，使得从中衍生出的无标注数据资源，以及可以从专利原始数据中借力产生的标注数据资源数量较多、规模庞大；但另一方面，对于完全依赖人工标注建设的标注数据资源来说，还存在诸多问题，比如数据资源数量不足、规模也远逊于通用领域的相应数据资源，且存在领域偏好问题，即相当数量的标注数据出现在信息资源建设较为完备的生物、医学领域，而在同属技术前沿的电子、信息、智能制造等领域中标注数据却非常匮乏，而专利数据显著的领域依赖（domain-dependent）特点，即不同技术领域的标注数据难以跨领域使用，使得这些问题更加严峻。当然,也有值得欣喜的一面：基础资源建设的目标逐步从辅助数据处理、支持专利分类等常规业务迈向攻关专利信息服务核心难题，如跨语境术语匹配和专利无效宣告判定，同时研究者们也紧跟智能技术前沿步伐，积极投人预训练和大语言模型的数据资源建设，为全面升级专利挖掘的研究和应用提供必要基础。"
  },
  "4专利信息处理和规范化": {
    "context1": "专利信息处理和规范化一直是传统专利数据加工建设的核心业务，在专利挖掘范畴下，其研究内容被从常规流程性工作中抽离出来，聚焦于从专利题录、文本中抽取关键信息并将其规范化、结构化以消除专利数据中存在的模糊性和歧义性，为计算机理解专利内容并支持上层的专利应用服务奠定基础。由于专利信息处理和规范化技术细节较多、内容涵盖较为广泛，本文选择其中代表性较强的术语抽取、命名实体识别、语义关系抽取、跨篇章共指消解等方向展开陈述。"
  },
  "4.1术语抽取": {
    "context1": "术语是对特定科学技术概念的文字表述，可以是词或者词组，而术语抽取即使用计算机方法将术语从文本中提取出来并捕获其内在含义[50]。自上世纪 80年代出现术语自动识别系统以来[51],大量学者对术语相关领域展开了广泛的研究，形成了成员众多的术语抽取方法家族，如表4所示："
  },
  "表4术语抽取方法分类[52]": {
    "context1": "Table 4Categories of terminology extraction methodsl5:",
    "context2": "<table><tr><td>术语抽取 方法分类</td><td>详细类别</td><td>内容</td></tr><tr><td rowspan=\"6\">基础语言 信息类</td><td>基于语言学的方法</td><td>词形特征，语义特征，词法特征</td></tr><tr><td>基于统计学的方法</td><td>词频特征</td></tr><tr><td>混合方法</td><td>语义特征，词法特征，词频特征， 等等</td></tr><tr><td>基于外部知识的方法</td><td>候选词在特定领域与其在通用领域 的对比特征</td></tr><tr><td>基于机器学习的方法</td><td>语义特征，词法特征，词频特征， 外部资源特征，分布式特征，等等</td></tr><tr><td>基于深度学习的方法分布式特征</td><td></td></tr><tr><td rowspan=\"4\">关系结构 信息类</td><td>基于语义相关的方法</td><td>候选词之间的相似性</td></tr><tr><td>基于图的方法</td><td>候选词之间的关系特征：共现关系、</td></tr><tr><td></td><td>语义相似，等等</td></tr><tr><td></td><td>基于主题模型的方法候选词在主题上的分布特征</td></tr></table>",
    "context3": "较早出现的术语抽取方法包括基于语言学的方法、基于统计学的方法以及混合方法。基于语言学的方法利用句法解析软件从专利文本中获取词性、句法依存关系等特征，并在此基础上制定相关规则以获取术语，例如 S.Dewulf认为专利文本中动词表示功能型术语而形容词表示属性型术语；J.Yoon等[54]将这些规则进一步细化为“动词 $^ +$ 名词”表示功能型术语，而“形容词 $^ +$ 名词”表示属性型术语，同时他们使用了5种StanfordCoreNLP所定义的句法依存关系类型，并将其所关联词汇的词性拼装起来以识别术语。相比传统专利分析中所使用的题录数据，这些从专利文本中识别出来的术语包含着专利的原理、组成、功能效果、新颖性、先进性等核心内容，因此可以更好反映出行业创新方向[53]、技术发展趋势[54]以及可能的技术机会[55]。",
    "context4": "然而使用常规语料训练出的句法解析器在专利这种长句、难句俯拾皆是的文本上面临着处理速度和准确率同时跌落的事实，同时专利文本典型的领域依赖（domain-specific）属性使得人工规则的可移植性较差。对此，研究者提出了基于统计学的术语抽取方法以及两者的混合方法，如D.A.Evans和R.G.Lefferts[5]利用TF-IDF 进行术语抽取；K.Frantzi等[57]在词性组合规则的基础上，利用术语及其内嵌子术语的统计学特征,提出了C-value 方法；不仅如此，他们注意到术语与其上下文环境的密切关系，进一步提出了将候选术语的C-value 得分与其上下文相结合的NC-value方法，为细粒度的技术结构识别[58]、技术路线图绘制[59]和技术演化分析[50]等应用服务奠定了良好基础。",
    "context5": "随着自然语言处理技术的进步和开放获取知识库的日益丰富，研究者逐渐将外部知识、语义信息、图结构、主题模型及深度学习等技术应用到术语抽取任务中。例如J.Vivaldi等[51]使用维基百科类别的层次结构对候选术语进行有效性验证以提升术语抽取效果；与之不同，W.Wu等[60]将维基百科的词条作为节点、词条之间的超链接作为边形成图结构，通过随机游走算法对所选概念赋权重来判断其是否是某技术领域中的术语；A.Judea 等[61 提出一种大规模、无监督的高质量标注数据产生方法，用以训练专利术语抽取模型，并基于候选术语分类器和条件随机场的实证分析证明，这种方法不仅能够保持高准确率，同时还可以大幅提高召回率；主题模型用于术语抽取并不新鲜，E.Bolshakova等[62]利用经典主题模型LDA（latent Dirichlet allocation）对特定领域术语进行抽取;虽然深度学习近年来横扫几乎自然语言处理领域的所有方向，但将其应用于术语抽取的研究并不多见，R.Wang等[63]针对目前利用机器学习方法进行术语抽取时遇到的两个困境，即繁琐耗时的特征工程和特征选择以及标注数据的缺失，提出一种利用两个深度学习分类器实现的弱监督、自提升术语抽取方法，由于该方法旨在解决通用领域和专业领域面临的共同问题，其在有限标注数据上的良好表现预示着这一研究方向的良好前景。"
  },
  "4.2命名实体识别": {
    "context1": "命名实体识别相比术语抽取更进一步，它不仅需要从文本中识别具有特定意义的词或者词组，而且需要给出其类型判断。在自然语言处理技术通常面临的文本如新闻、评论等，惯常定义的实体类型包括地址、人物、机构、货币、百分数、日期、时间等[6465]。然而专利文本中包含着对发明创新及其技术背景、实现细节和权利要求等内容的描述，其所定义的实体类型截然不同：S.Y.Yang等[从工艺流程出发，将实体类型划分为方法、步骤、方式、属性、实体、值，将实体之间关系划分为动作、包含、前置，实体和关系可进一步细分为实际类型（real）、辅助类型（auxiliary）、领域依赖、领域无关等；S.Choi等[]侧重实体的句法特征和保存状态，将实体分为概念、主语概念、宾语概念、事实类型、部分事实类型、效果事实类型、概念状态、固体、气体、液体、场等；薛池等[8受到 TRIZ思想影响[69]，使用一种更加系统全面的概念模型，该模型将机械产品专利中的关系划分为层次关系、属性关系和功能关系，将实体划分为技术系统、流、属性，技术系统分为系统、零部件，流分为物流、能量流、信息流，属性分为性状、位置、方向、数量、几何、材料等；I.Bergmann 等[70] 建立一套针对DNA芯片技术的细致的实体类型定义。",
    "context2": "除了类型定义，在命名实体抽取方法上，自然语言处理和专利挖掘领域同样各具特点。前者经历了基于规则的方法、基于无监督聚类或弱监督自提升的方法、基于特征的有监督的方法以及深度学习方法4个阶段[71，目前研究已经比较成熟，命名实体识别的效果超过 $90 \\%$ （F1值）也屡见不鲜。然而达成这一效果通常需要充足的标注数据且标注语料和目标语料来自同一领域或者近似领域。但专利数据是典型的领域特定数据，不同技术领域的专利文本之间内容、特点迥异，这使某一技术领域的标注语料并不适用于其他技术领域命名实体识别模型的训练，且目前可公开获取的信息抽取标注语料库最大规模仅为3万条[72]。因此，长期以来专利中命名实体识别选择了更实际和高效的做法，即在通用句法解析工具对专利文本进行句法解析和词性标注的基础上，使用规则匹配来识别命名实体的边界和类型。",
    "context3": "当然，随着深度学习技术的溢出效应，将其应用于专利命名实体识别的工作逐渐开始出现，如F.",
    "context4": "Saad[73]设计了一种基于BiLSTM改进的循环神经网络，从生物医药专利文本中抽取蛋白质、基因等实体;Z.Zhai等[74]以BiLSTM-CNN-CRF为例，对生物医药专利数据集和化学专利数据集中进行命名实体识别，为提升识别效果和方便对比分析，他们使用来自相同领域的专利数据集训练出一套常规的Word2Vec词嵌入向量和一套能够感知上下文环境的ELMo 词嵌入向量，其中后者在命名实体识别效果上较前者有明显改善；L.Chen 等[29]同样证实了训练自相同领域专利语料库的词嵌人向量会对该领域上自然语言处理任务（命名实体识别、语义关系抽取）的效果带来",
    "context5": "改善。"
  },
  "4.3 语义关系抽取": {
    "context1": "语义关系抽取旨在判断两个实体之间所存在的语义关系及其类型，按照语义关系的抽取对象范围不同，可分为句子级语义关系抽取、文档级语义关系抽取（或称句间语义关系抽取）以及语料库级语义关系抽取[75]。目前专利挖掘中的语义关系抽取以句子级语义关系抽取为主，即从给定句子中识别实体之间的语义关系。由于这些方法以面向专利分析实际应用为主，具体方法多以流程形式呈现，内容较为繁碎，主要流程可概括如图2所示：",
    "context2": "![](images/34802912a0046d49f08919bdf0560b981256b2760e16bd077b7794d2c9c43c11.jpg)  \n图2专利语义关系抽取流程  \nFigure 2 Procedure of semantic relation extraction from patents",
    "context3": "步骤 $\\textcircled{1}$ 和 $\\textcircled{2}$ 与专利命名实体抽取类似，即首先建立专利信息概念模型，确定下语义关系的类型；之后使用句法解析工具获取句子中词汇的词性和句法依存关系，并在步骤 $\\textcircled{3}$ 中使用人工规则筛选出其中可能的语义关系并采用结构化的方式表示。当前主要的结构化表示形式有 SAO三元组和功能一属性对。所谓SAO，即句子中的主语（subject）、谓语（cction）、宾语（object）成分，可组成三元组形式来表示文本中的实体语义关系。而在功能一属性对中，功能指系统可提供的有用行为，属性指系统或其子系统具有的某种性质[25]。相比较而言，功能—属性对的优势在于其本身即是TRIZ 的重要组成部分，因而可以作为 TRIZ的计算机实现手段来指导真实场景下的创新实践；而 SAO三元组当初是为弥补向量空间模型的元素间缺乏语义关联而产生[4，旨在发现专利之间的联系和区别。当然，随着研究的推进，这两种表示方式之间界限逐渐模糊，比如文献[76-77]等认为部分AO 反映了技术所提供的功能，因而可以在SAO 的基础上识别功能、属性。",
    "context4": "由于专利语义关系抽取是建立在既定概念模式上的封闭关系抽取，所以步骤 $\\textcircled{4}$ 的语义关系加工提炼需要将类型繁多的候选实体语义关系对应到固定有限的关系种类集合中，当前主流做法有规则方法和知识库方法。所谓规则方法，即总结归纳一套规则以实现从语义关系表示形式向语义关系的转化，S.Choi等[78]建立了一套用词汇来判别S、O以及AO实体类型的规则，并根据判断所得实体类型将它们分配到包含产品、技术、功能3个层次的实体框架；J.Yoon等[55]将AO分为产品可完成的任务、产品可改变的属性和产品结构3类，并给出各自的词构成规则和代表性词汇，来协助新 SAO 的类别判定并以此为基础来提炼语义关系；J.Yoon 等[54] 先采用句法分析将包含创新概念的候选语义关系汇集起来，之后建立一套功能一属性融合规则来归并具有相同含义的语义关系。知识库方法通过对齐知识库中关系实例与专利中的候选语义关系，来完成语义关系的提炼，S.Choi等[7]提出一种面向事实的本体方法来处理 SAO，他们先将原始的 SAO 结构对应到由Wordnet中的词汇所组成的泛化SAO 结构上，之后利用Wordnet中的概念层级关系将泛化SAO结构进一步抽象到专利信息概念模型上；在专利知识库构建上，S.Dewulf]、J.Yoon 等[54]建立了以功能、属性为核心的知识库；J.Yoon 等[55]、X.Wang等[79]、J.Yoon 等[80]、S.Choi等[81]从 SAO 结构中抽取出产品、功能、技术信息并将其作为实体类型构建出类型不同的知识库，也有研究者尝试将Wordnet 和产品设计语言Functional Basis相结合，以求在一个既定框架创建出具有明确规范限制的知识库[82]。",
    "context5": "相比术语抽取和命名实体识别，面向专利文本的语义关系抽取从关注单一事物转向探索事物之间的相互联系，从而使研究者以知识库的形式来呈现专利文本中零部件、原材料、科学概念、功能效果等技术要素之间及其与产品、市场的相互关系，从而更好地支持产品核心技术识别、技术转移转化、技术路线图构建、技术趋势分析等应用服务。然而，从上述综述来看该方向的研究探索并不充分，语义关系抽取中所存在的词汇和语法歧义问题没能得到很好解决;同时这些专利关系抽取方法在执行成本、效率以及可移植性、可扩展性上均存在种种不足。实际上近年来自然语言处理领域在该方向的技术进展尤其是深度学习方法对专利语义关系抽取具有很大的启发性。以2019年语言与智能竞赛为例，冠军团队在关系抽取任务上取得的F1值达到 $8 9 . 3 \\% ^ { [ 8 3 ] }$ ，这在之前难以想象的。背后有两个关键因素，一是大规模预训练模型的使用，二是高达21万条标注数据的支持。然而，这两个因素都需要巨大的人力、算力投入，即便谷歌提供了基于专利文献的BERT-for-Patents预训练模型，如何高效、低成本地生成大规模专利标注数据集，如何在同等标注工作量下优化关系抽取效果，以及如何在关系抽取建模时合理利用专利文本的特殊性仍然面临着巨大的挑战。L.Chen 等[84]在这方面做了一些探索性工作，他们发现专利文本相比普通文本包含更多词组型命名实体，且这些命名实体之间存在稠密的共词关系，利用图神经网络对这些共词关系建模以产生额外信息可以有效提升常规语义关系分类模型的效果。"
  },
  "4.4跨篇章实体共指消解": {
    "context1": "为增加专利文本的理解难度、避免发明被竞争者发现、理解和复现[85]，专利撰写者会使用一系列文字技巧，例如同义词、近义词、模糊术语、上下位概念替换、对等词等，使专利文本晦涩难懂、描述用语极为模糊，比如真空吸尘器被描述为“龙卷风产生装置”[86]，文件扫描仪被描述为“光线扫描装置”[87],而如何将出现在不同文献中指向相同实体的一组对等实体指称识别出来，即跨篇章实体共指消解[88],则凸显出其超越单篇专利内部数据处理的重要价值。",
    "context2": "该类方法的惯用特征包括词法特征、句法特征、基于知识库的特征以及实体之间的字符串匹配程度等。专利文本的特点会使这些特征在跨篇章实体共指消解中的效力大大减弱，需要研究者通过常识和领域知识加以弥补,而这些方面的研究成果还非常稀缺[89],更多的实体共指消解研究聚焦于同一文档内部[90],或者通过将实体指称映射到知识库的对应实体上，即实体链接[91]，来达成跨篇章实体共指消解的目的。抛开知识库相关方法后（目前此类方法所基于的通用知识库的内容对专利实体来说仍然过于宽泛），跨篇章实体共指消解方法仍然停留在传统机器学习方法阶段，主要依赖实体指称本身及其上下文的特征提取和相似度计算，对不同实体指称之间的关系进行度量，进而使用聚类算法将实体指称划归到指向不同实体的聚簇中[88]。近三年来，已有学者尝试引人深度学习来完成这一任务，S.Barhom等[90]受到H.Lee等[92]的联合模型的启发，在事件参数（即实体指称）共指消解和事件本身共指消解在模型学习过程中相互激励的假设基础上，利用联合神经网络实现这一过程并分别在实体共指消解和事件共指消解上较独立神经网络提升 $1 . 2 \\%$ 和 $1 \\%$ （ $\\mathrm { p } { < } 0 . 0 0 1$ ）；2021年，A.Cattan 等[93]提出了第一个从纯文本中进行跨文档共指消解的端到端模型；同年，A.Caciularu 等[94]采用定制化预训练语言模型的方式来支持跨篇章实体共指消解，具体来说，他们基于Longformer模型将多个相关文档拼接起来作为模型输入并通过跨文档遮掩（cross-documentmasking）使模型学到长距离和跨文档关系，新模型在大幅减少训练参数的同时，其所产生的词嵌入在跨篇章实体共指消解和事件共指消解、论文引文推荐、文章剽窃探测等任务上均取得了新的最佳成绩，这些研究成果为解决跨篇章实体共指消解问题面临的普遍问题，可以直接用于专利文本或者对专利文本中开展此类工作具有重要启发作用。"
  },
  "4.5小结": {
    "context1": "本类专利挖掘任务的目标比较明确，即处理专利数据以支持下游的应用需求，而专利数据处理方法本身并不直接提供业务服务能力。在技术实现上，此类任务一般可以转换为对应的机器学习或者自然语言处理任务，但由于专利数据和通用数据之间的显著差别，会导致这些机器学习或者自然语言处理任务在专利数据上存在一定的性能下降，而如何量化专利特点并在此基础上建模以提升效果，成为专利挖掘的重要研究方向；同时由于专利数据的领域特定属性，不同技术领域的专利标注数据难以跨领域使用，这使得研究者们更加青睐以句法解析工具和人工规则方式进行免标注的数据处理，例如基于SAO结构和功能一属性对的关系抽取方法，但这些方法存在人工规则难以复用且抽取精度较低的问题，而如何低成本、大规模、高质量生成标注数据，以及在无标注或少标注前提下如何提升专利数据处理的效果，成为当前亟",
    "context2": "待解决的问题。"
  },
  "面向专利信息服务的智能算法研究": {
    "context1": "当前面向专利信息服务的智能算法研究可以分为3类，如图1下半部分所示：其一是发展时间较长、成熟度较高、可以集成到软件平台并为常规专利业务开展提供基础服务的算法类型，比如案源分配、专利检索、专利翻译、信息可视化等；其二是利用信息技术实现专利分析服务自动化、智能化的算法类型，例如技术脉络识别、技术机会发现、合作伙伴推荐、技术热点探测等；其三是探索专利核心问题智能化解决方案的算法类型，包括专利无效判断、专利侵权诉讼、专利自动撰写、专利新颖性识别等。下文分别从这3类算法中挑选若干具有代表性的研究方向，对其发展脉络和重要成果进行梳理和阐述。"
  },
  "5.1 案源分配": {
    "context1": "当专利申请文件到达专利局后，需要对其所属技术类别进行标注以便分配给相应的审查员，这一环节被称为案源分配。由于科学技术的快速发展、社会各界知识产权保护意识的增强以及相关政策支持等多种原因，专利申请量屡创新高，以中国国家知识产权局为例，仅2020年上半年全国发明专利申请量就高达68.3万件。巨量的专利申请极大加重了审查员的工作负担，对专利审查的质量和效率提出了严峻的挑战。如何将机器学习技术引入案源分配、实现专利审查的提质增效成为一个亟待解决的重要问题。",
    "context2": "案源分配中的技术分类体系，如IPC、CPC、USPC 等均为层次分类体系。以IPC为例，它从上到下共分部、大类、小类、大组、小组5个层级，粒度从上到下逐步细化，具体如图3实例所示；IPC 每年1月份更新一次,2021版IPC中包含了8个部、131个大类、646个小类、7523个大组和68 899个小组[95]。进行案源分配时，由于发明创新往往涉及多个技术类别，导致一个专利申请会被分配多个技术类别，从而使案源分配天然对应到自然语言处理领域的多标签文本分类任务，外加专利数据本身字段丰富、内容详尽、体量巨大，是合适的训练数据，使得针对这一任务的研究工作早在20世纪90年代已经出现[9]。早期案源分配方法采用词袋（bag-of-word）和空间向量模型（spacevectormodel）来表示专利文本内容，通过忽略词汇顺序来降低模型复杂度和算力需求，采用的分类模型包括支持向量机[97]、K近邻[9]、朴素贝叶斯方法[9]、Winnow算法[98]等；也有研究从案源分配的特殊性上出发，从专利数据或者技术分类体系上优化特征或者分类算法，比如J.H.Kim 等[99]在专利文本表示中融入词汇之间的语义信息，并在日本专利分类任务上取得了 $74 \\%$ 的效果提升，L.Cai和T.Hofmann[0]着眼于技术分类体系的层次结构，基于支持向量机拓展出一种层次分类方法，这种思路同样被D.Tikk等沿用[1oI]，他们将技术分类体系融入在线分类器并在WIPO-alpha 和Espace A/B 数据集上取得了良好效果。",
    "context3": "![](images/4ea931810482925311fe06877ba42c493d6395db70cb83bc76a759cb8b068c37.jpg)  \n图3IPC 实例 Figure 3 IPC sample",
    "context4": "近年来深度学习方法的突飞猛进为案源分配带来了新思路，即通过深度神经网络学习到的低维、稠密向量，来表示词汇、短语、句子、段落乃至整个篇章，进而将文档分类纳入深度学习的解决范围之内。吕璐成等[102]系统汇总了卷积神经网络（convolution-al neural network,CNN）、循环神经网络（recurrentneural network,RNN）、注意力机制等常见深度神经网络结构或数据特征权重分配方法，并结合词嵌入生成技术Word2Vec[103] 组配出7种文本分类模型用于测评其在中文专利案源分配上的效果，他们发现上下文特征和双向语序特征能有效提升案源分配效果，而注意力机制对关键数据特征的强化作用同样有助于判定专利类别。然而此类案源分类方法所基于的静态词嵌入技术（例如Word2Vec）将单一词汇恒定地对应到一个数值型向量上面而无法随上下文语境动态变化，并不符合自然语言中一词多意的特点，对此研究人员提出了一系列能够根据上下文语境动态变化的动态词嵌入向量生成技术及其模型框架，例如BERT[104]、ELM0[105] $\\mathrm { G P T } ^ { [ 1 0 6 ] }$ 等，进而通过“预训练模型 $^ +$ 微调”的模式把案源分配效果提升到新的高度，所谓微调（fine-tuning）即在原有模型参数权重的基础上使用特定任务数据集继续训练，以“轻微调整”模型参数权重的方式使其适应该任务并具备较强的任务完成能力。最早通过微调进行案源分配的模型是"
  }
}