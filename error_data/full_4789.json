{
  "original_filename": "full_4789.md",
  "多文档自动摘要方法的进展研究": {
    "context1": "黄文彬，倪少康(北京大学信息管理系，北京100871)",
    "context2": "摘要：【目的/意义】多文档自动摘要技术的目的是从一组文档中精炼出重要信息摘要,减轻用户从文档中获取与理解信息的负担，是自然语言理解领域的重要研究方向之一【方法/过程】本文提取十五年内的多文档自动摘要研究文献并筛选出至少50篇关键影响文章,梳理多文档自动摘要的概念与研究进展，揭示了最新的技术实现与实践情况【结果/结论】基于不同技术方法对单词、句子或段落作为主要数据处理对象,找出多文档自动摘要的技术特征与难点，明确该领域的发展趋势，为未来的研究奠定了基础。",
    "context3": "关键词：自动摘要；多文档处理；自然语言处理中图分类号：G254 文献标识码：A 文章编号:1007-7634(2017)04-160-06",
    "context4": "DOI:10.13833/j.cnki.is.2017.04.029"
  },
  "Study of the Development of Multi-document Automatic Summarization": {
    "context1": "HUANG Wen-bin, NI Shao-kang",
    "context2": "Department of Information Management,Peking University, Beijing 10o871,China,",
    "context3": "Abstract:【Purpose/significance】Multi-document automatic summarization (MDS) extracts the most essential information fromagroupof documents and provides users tounderstand and exploit information easilyandquickly.MDS has been one of the most important studiesof natural language understanding recently.【Purpose/significance】More than 5O papers selectedfrom key journalsandconferencesbetween 20Oand2015arereviewed,nd theconcepts,state-of-the-artmethodologies,mprovementsof MDSaredisplayedandconcluded inthisarticle.Result/conclusion】Featuresanddificultiesof MDS methodsareseparatedandanalyzed inword-level,sentence-level,andparagraph-level toshowits trendforfurther researches.",
    "context4": "Keywords : document automatic summarization; multi-document processing; natural language processing",
    "context5": "信息资源暴增背景下，用户获取与理解信息的要求与困难与日俱增。文档自动摘要(document automatic summariza-tion)技术通过计算机为用户进行文本总结和精炼,提供文本的概括性信息。用户只需简短阅读摘要就可以初步窥探全文的重点内容，大幅提升了用户获取或理解信息的效率。单文档自动摘要是计算机通过算法自动生成一篇文档主要内容的摘要，自1958年Luhn提出文档自动生成摘要的方法以来，基于单文档自动摘要的研究便如火如茶地展开,使得单文档自动摘要的结果至目前为止达到普遍接受的程度。而多文档自动摘要（Multi-document summarization,MDS)是通过不同文档生成主要内容的综合性摘要。到目前为止，多文档自动摘要技术已经和人工智能科学与相关算法紧密结合起来,近年来更与演化算法和深度学习算法结合发展[2-4]。多文档自动摘要技术目前被广泛应用在网页应用与学术检索系统中。在网页应用（如GoogleNews和News-Blaster)中，系统先提取一组相似的新闻生成摘要(预先聚类),让读者能够迅速了解这一聚类下新闻的内容;而在学术检索系统的多文档自动摘要模块中，如美国密歇根大学的Radev等人开发的MEAD系统、哥伦比亚大学McKeown等人开发的基于片段聚类的MutiGen,系统将一组学术文章生成摘要,让用户快速确认该组文章的内容与其间的相关性。",
    "context6": "多文档自动摘要可以根据形成摘要的语句是否源自原文而被分为抽取式(Extractive)摘要和抽象式(Abstractive)摘要。抽取式摘要主要将原文档的语句进行重要性评估,再从中选取重点语句形成摘要。抽象式摘要主要从原文档中提取单词信息，然后组织单词串联语句形成摘要。",
    "context7": "表1 停用词的处理",
    "context8": "<table><tr><td>类别</td><td>方法</td><td>目的</td><td>主要应用</td></tr><tr><td rowspan=\"2\">去除停用词</td><td>语法词性</td><td>减少计算干扰</td><td>基于图的自动摘要方法[5]</td></tr><tr><td>经验判别</td><td>减少计算干扰</td><td>基于主题相关度对摘要句子排序[6]</td></tr><tr><td rowspan=\"2\">保留停用词</td><td>语法特性</td><td>明确篇章修辞结构</td><td>基于图的自动摘要方法[7]</td></tr><tr><td>经验判别</td><td>成为语句特征属性</td><td>基于语句特征的自动摘要方法[8]</td></tr></table>",
    "context9": "![](images/4ed7a3f43d089ce5186da2b46bd1fd6e29766b21aeb2d730b5ea2d65d1a3f25b.jpg)  \n图1多文档自动摘要研究框架",
    "context10": "多文档自动摘要技术的研究框架主要分成四个阶段（如图1所示),分别为数据选取、信息处理、形成摘要和摘要评估。多文档自动摘要研究首要考虑数据选取的问题,不同数据形态将影响算法的思路与评估方式，依据写作方式的不同可将目前研究的文档数据分成正式形态与非正式形态，主要区别在于语法语句的口语化程度。信息处理阶段包括预处理和提取特征信息,其主要目的是从文章中提取关键信息或单词,并且去除噪声。形成摘要阶段根据抽象式摘要和抽取式摘要分为生成语句筛选语句。生成语句通过前一阶段所获取的关键信息进行组织并生成语句，而筛选语句则根据句子特征、知识本体和句间关系从文档中选取语句。语句排序独立于二者，是有了摘要语句之后，将其按照一定的标准进行赋分，从而重新排序。最后，摘要评估阶段通过语料参照或自主评估两类方法对形成的摘要结果进行评估。本文将对研究框架的每个阶段按照如上顺序进行阐释与总结。"
  },
  "1数据选取": {
    "context1": "在选择输入数据的阶段，目前多文档自动摘要的研究主要利用特定领域的语料数据进行实证分析，数据可分成正式形态和非正式形态。正式形态文档具有完整的写作结构和正式书面用词的特性,例如学术文章和新闻稿件。非正式形态文档则主要属于交谈式、口语用语较多的会话数据，包含大量的缩写、简写等非书面用语,例如电子邮件。两类形态主要有三个区别：(1)非正式文档用语多含非书面用语，这可能对信息处理阶段的去除停用词造成影响;(2)非正式文档可能存在交流者之间的共同知识，比如代词所指对象可能不出现在原文中，而正式文档不会出现类似的情况;(3)非正式文档缺少必要的编辑修改步骤，可能存在拼写错误、语法错误与句子不完整等现象，正式文档在发布前已尽量避免类似问题,如新闻文章。"
  },
  "2信息处理": {
    "context1": "信息处理阶段包括预处理和特征词提取。预处理是指对语料进行停用词的处理和无意义短语的去除，而特征词提取则是从语料中选取特征词的信息以及去除词根词缀。"
  },
  "2.1预处理": "",
  "2.1.1 停用词处理": {
    "context1": "停用词通常包含虚词、介词等一系列无实际意义的词。停用词不仅在信息的表达上贡献极少，而且其存在还在特征词提取步骤中造成词频统计的误差。目前对停用词的处理方式主要有去除与保留两类，如表1所示。",
    "context2": "一般来说,除名词、动词、形容词和副词以外的词均被视作停用词。通过去除语句中的噪声(停用词),可以更精确地计算两个句子间的相似度。去除的方法主要有两种：一种是通过研究者自身所建构的停用词表进行停用词的去除(如基于主题相关度的自动摘要算法),但是这种方法具有一定的主观性;另一种方法是通过现有的词表工具(WordNet等)来决定停用词范围(如基于图的自动摘要方法)。相比而言，研究者使用自定义词表往往是出于简化步骤的目的根据经验判断来建立，该词表可能会出现遗漏的状况，而通过词性判别的工具会相对的严谨客观。",
    "context3": "保留的停用词主要作为筛选语句的特征之一或者作为合成语句时两关键词的连接信息。基于\"特征信息\"赋分的自动摘要方法将语句包含停用词的数量作为特征，含有大量停用词的语句可能因含有过多不重要的信息而无法体现出句子重要性，而该停用词多数依照研究者根据经验自定义的词表来判别,较主观且词性不唯一。基于图的自动摘要方法，从保留的停用词中选取合适的词来明确篇章修辞结构，例如句与句之间的转折关系等。由于该类停用词在语法特性上体现的较为明显，多数研究采用语法特性来筛选保留停用词。"
  },
  "2.1.2去除无意义短语": {
    "context1": "无意义的短语被视为无信息价值的噪声，去除无义短语可以减少分析的误差并增强生成摘要的连贯性。研究者采用预先定义的短语列表来实现对无意义短语的去除[。多数自动摘要方法会在词频统计之前去除信息量少的短语，以避免它们对词频分析造成误差。还有一部份的自动摘要方法会在草稿形成后，去除与时间相关或具有因果关系的短语,以此来消除由这些短语造成摘要不连贯的问题。这个方法多出现于注重解决摘要的连贯性问题时[]。",
    "context2": "表2关键信息提取的方法  \n表3句子生成方法分类",
    "context3": "<table><tr><td>类别</td><td>方法</td><td>步骤</td><td>关键信息形态</td></tr><tr><td>基于相似段落的信息提取[2]通过树结构的相似度来提取关键信息</td><td></td><td>(1)句子相似的判定 (2)相似的句子聚类 (3)句法结构和谓词参数分析 (4)子树相似的判定、提取</td><td>短语</td></tr><tr><td>基于预定结构的信息提取[13]符合预定义结构的语句才会被提取关键信息</td><td></td><td>(1)根据特定的话题建构本体 (2)定义信息类型(message type) (3)定义关系类型</td><td>信息</td></tr></table>",
    "context4": "<table><tr><td>类别</td><td>参数</td><td>使用工具</td></tr><tr><td>基于自定义信息成分</td><td>预定义的&quot;信息&quot;和&quot;关系类型”</td><td>般NLG工具[13]</td></tr><tr><td>基于语法成分</td><td>句法结果、语义标引结果</td><td>SimpleNLG[14]、FUF/SURGE[13]</td></tr></table>"
  },
  "2.2特征词提取": "",
  "2.2.1 去除词根词缀": {
    "context1": "由于许多自动摘要的研究多基于英语语料作为实证数据,而英语的词汇含有许多词根词缀，其中同根不同形的词汇会造成误差，例如提取词干的处理，名词的单复数形式会被视为两个不相同的词汇，而对词频产生影响。这方面的实现多数研究采用开源的工具,如Porter stemmer[]。"
  },
  "2.2.2 提取关键信息": {
    "context1": "从文档中提取关键信息是很重要的步骤，多文档自动摘要的方法通过所选取的信息或短语进行语句筛选或合成，并组织关键语句形成摘要。提取关键信息的方法分两种类型：基于相似段落和基于预定结构。基于相似段落的方法主要在一组文档中聚类出相似的语句,并对语句进行语法分析和谓词参数分析形成树结构，将树结构内相似的短语作为关键信息。基于预定结构的方法利用预先建构的本体来提供实体类型(Entity types）和特定事件下的角色(Event-specificroles）,并通过人工事先定义好的信息形态作为关键信息。",
    "context2": "相较之下，基于预定结构的方法较难实现，因为该方法需要较多的人工参与。同时,由于本体的建构限制较多,其适用题目范围也相对较窄，但该方法的摘要效果比较好，因为该方法从多文档中分析挖掘出可能的概念或描述,并提取概念实体、实体描述以及不同时期实体的变化关系，这些内容都以\"信息\"的形式存放。“信息\"可以有很多种，每种有特定的字段，比如实体、值、时间跨度等，可以理解为将信息提取出来并语义化的过程。基于相似段落的方法通过对不同文档的比对分析，只挖掘不同文章的同一事物，专注于词语的特征而非语句深层的意义。提取的短语都只能是词语概念上的相似(概念上可能完全不相似，如新闻中对地震的报道,当不同报道中的\"地震\"指同一次地震时,彼此的概念实体是同一个；当指的是不同的地震时，尽管报道中存在的都是\"地震”,但是概念实体不同),造成实际概念与摘要结果可能存在较大的误差。关键信息提取的方法见表2。"
  },
  "3形成摘要": {
    "context1": "形成摘要阶段中,抽象式摘要的方法主要通过生成语句来形成摘要,而抽取式摘要的方法通过\"筛选语句\"和\"语句排序\"来形成该组文档的摘要。其中\"语句排序\"是指通过“筛选语句\"从文档中选取语句后，对其进行排序使得摘要具有连贯性。"
  },
  "3.1生成语句": {
    "context1": "生成语句的过程可视为使用不同成分来组成新句子的过程。根据成分的不同,句子生成的方法可以分为\"基于自定义信息成分\"和\"基于语法成分\"(见表3)。“自定义信息成分\"是指句子的内容按照人工定义的类型进行划分，而其结果与领域高度相关，例如足球比赛报道中可定义“信息\"为“表现描述”、“球队满意描述\"等成分,该\"表现描述\"可以包含“球队”“球员”、“时间”、“表现\"等关系类型，该方法可使用一般的自然语言生成(Natural Language Generation,NLG)工具生成语句。基于语法成分\"是指使用句法分析结果、语义角色标引后的结果来生成语句。句法分析的目的在于识别句子中的主语、谓语和宾语,而语义角色标引可以识别出精确的分类，如主语下的代理人（Agent）、设备(Instru-ment)。该方法可使用 SimpleNLG[14]、FUF/SURGE[13]的工具生成语句。"
  },
  "3.2筛选语句": {
    "context1": "筛选语句主要是对文档中每个句子进行选择是否可选入摘要中,针对句子筛选的处理方式不同,筛选语句可分为“句内关联\"和\"句间关联\"两种方法。其中“句内关联\"是利用句子内的组件来评估句子的重要性,包括其单词构成、句子长度、所处位置和包含的概念实体等;而\"句间关联\"主要使用句子彼此之间的关系来评估该语句的重要性。"
  },
  "3.2.1 句内特征": {
    "context1": "句子内的特征包含所使用的单词、句子长度、句子所在位置、句子所指的概念实体等。依据这些特征所体现语义信息可以将其分为\"特征信息\"和\"知识信息\"两个层次。",
    "context2": "“特征信息\"指比较表层外在的信息，能够被机器所直接识别,例如句长、词频、位置等。特征信息\"与句子的语义没有必然联系，可分为\"形式特征\"和\"内容特征”，如表4所示。形式特征\"体现一个句子的外在表现,比如长度、词频信息等一般句子都能够拥有的特征;而\"内容特征\"涉及语义最浅的层面,只关注单词的形式，比如含有特定的名词,呈现出该名词所在的句子重要性，并非所有句子都有这样的特征。",
    "context3": "表4“特征信息”分类",
    "context4": "<table><tr><td>类别</td><td>属性</td><td>意义</td></tr><tr><td rowspan=\"6\">形式 特征</td><td>词频</td><td>单词出现的次数</td></tr><tr><td>TF*ISF</td><td>词频与逆句子频率的乘积</td></tr><tr><td>位置信息</td><td>单词出现的位置，如段首段尾等</td></tr><tr><td>句子长度</td><td>句子中包含单词的数量</td></tr><tr><td>字体特殊的词 的数量</td><td>字体突出的单词的数量,如加粗、斜 体等</td></tr><tr><td>暗示性的词</td><td>提示性用语,如&quot;significant”</td></tr><tr><td rowspan=\"2\">内容 特征</td><td>特定的名词</td><td>由预先制定的词表决定，通常为有</td></tr><tr><td>标题中的词</td><td>重要意义的名词 出现在标题中的单词</td></tr></table>",
    "context5": "“知识信息\"指的是比较深层的信息,机器无法直接识别,需要借助其他背景知识协助处理,例如本体。本体的建构是将概念视为节点，两个概念间的关系可以通过所属节点间连线的距离、位置与方式来决定。“知识信息\"主要通过预定义的本体来获取,能将蕴含在单词形式中的信息联系起来，比如\"bike\"和\"bicycle”,两个单词被视作不同的表现特征。计算机在本体的协助下可识别出这两个词的概念实体是相同的,进而将包含这两单词的句子联系起来。由于多领域的本体复杂度高，多数研究仅能通过单一特定领域的本体进行实证,如体育比赛的小型本体库,亦可使用已经存在的本体库(例如DBpedia[5]或UMLS[)。基于句内特征的筛选语句过程首先选取特征,根据特征属性来计算句子重要性，并根据重要性来选取。表5比较了几种基于句内特征筛选句子的方法。筛选语句的方法主要分为基于“特征信息\"以及基于“知识信息\"的方法。基于“特征信息\"的筛选方法针对每个句子提取表4内的特征属性，并根据选定的函数加权计算这些特征属性值，将其定义为该句在文章中的重要性，再依据这个重要性排序选取句子。基于\"知识信息\"的筛选方法通过句子中概念的数量和句子对应的概念在本体结构中的位置来决定计算句子的重要性。有检索式的自动摘要依据用户感兴趣的领域、话题和词语来自动生成文档的摘要，而基于\"特征信息\"的方法对有无检索式一般无限制，只需要找出具有与检索词相关特征的句子。基于\"知识信息”的方法将根据选取的特征对应有检索式或无检索式的摘要类型，以句子的概念节点是否属于检索词为根节点的子树来评估选取摘要语句。"
  },
  "3.2.2句间关系": {
    "context1": "基于句间关系的筛选方法可分为基于图和基于聚类的方法。基于图的方法利用句子间的相似度得到句子的相互联系,利用社会网络分析的思想挑选句子的重要度。基于聚类的方法利用句子间的相似度进行聚类，越能够代表该类的语句就越重要。两类方法的句子表示模型可分为集合模型和向量空间模型。集合模型是把句子视作单词的集合,集合间交集的模的大小体现出句间相似度,由于长度长的句子包含的单词数量较多，在同等情况下更容易和其他句子有较高相似度,常使用句子长度为特征进行修正，如将共有的单词数量除以两个句子长度和或除以两句中长度较小的。另外还有基于标准谷歌距离(Normalized Google Distance,NGD)定义句子间的相异度(与相似度相对),主要是当两个词出现在同一句子中，判定二词有相似语义，并以每句中所包含单词的相异度之和作为句间相似度的衡量。向量空间模型是将句子视为向量,向量的维度与值由句内单词(或者概念)及其TF\\*IDF(词频\\*逆文档频率)来定义，因此该模型表示复杂、计算量大,但是比较精确[2]。基于句间关联的方法比较见表6。",
    "context2": "基于图方法的核心思想大多是使用PageRank算法来评估句子的重要性，即首先给定每个句子默认初始值,接着计算两两句间的相似度,并以此为权重进行投票,最后各个句子的值会收敛到一个值，即句子的重要程度[27]。相似度的度量方法根据表示模型的不同而有差异。例如向量空间模型使用余弦相似度来计算句子间的相似度。集合模型使用句子长度修正后的共同含有单词的数量来表示其相似度。该类方法新的发展出现在相似度的度量上，文档层面的关系还可以被更加深入地利用,根据文档间的关系来修正句子间的相似关系,例如根据句子是否属于同一篇文档来修正二者之间的相似度[28]。",
    "context3": "表5基于句内关联的筛选语句方法比较",
    "context4": "<table><tr><td>类别</td><td>选取的特征</td><td>语句重要性的计算方法</td><td>适用类型</td></tr><tr><td>特征</td><td>标题中的词、句子长度、TF*ISF、句子位置、特定的名 词[1</td><td>使用特征的加权平均值来衡量句子的重要性</td><td>无检索式</td></tr><tr><td>信息</td><td>特定的名词、句子与检索式的余弦相似度[18]</td><td>使用特征的加权平均值来衡量句子的重要性</td><td>有检索式</td></tr><tr><td>知识</td><td>句子对应的概念在本体结构中的位置[19]</td><td>根据句子对应的概念是否出现在以检索式所对应的节点为根 节点的子树上来评估其重要性</td><td>有检索式</td></tr><tr><td>信息</td><td>句子所包含的概念的数量[20]</td><td>根据句子包含的出现在本题中的概念的多少来评估其重要性</td><td>无检索式</td></tr></table>",
    "context5": "表6基于句间关联的方法比较",
    "context6": "<table><tr><td>类别</td><td>举例</td><td>表示模型</td><td>相似度计算方式</td><td>重要性评估方法</td></tr><tr><td rowspan=\"2\">图</td><td>LexRank[22]</td><td>向量空间模型</td><td>余弦相似度</td><td>PageRank</td></tr><tr><td>TextRank[23]</td><td>集合模型</td><td>共同含有的单词数量除以句子长度之和</td><td>PageRank</td></tr><tr><td rowspan=\"3\">聚类</td><td>借助&quot;质心&quot;的摘要方法[24]</td><td>向量空间模型</td><td>余弦相似度</td><td>句子与质心的相似度</td></tr><tr><td>利用单文档聚类的多文档摘要方法[25]</td><td>集合模型</td><td>共同含有的单词数量除以较短句子的长度</td><td>句子与质心的相似度</td></tr><tr><td>基于聚类和PSO的摘要方法[26]</td><td>集合模型</td><td>标准谷歌距离(NGD)</td><td>句子对分类的贡献度</td></tr></table>",
    "context7": "基于聚类的方法根据句子对整个类的重要性来确定句子的重要性。评估方法主要有两种,一种是句子与质心的相似度,另一种是句子对分类的贡献度。通过句子与质心相似程度来评估重要性是指句子与质心越相似则对整个类就越重要。采用向量空间模型时,使用余弦相似度来表示句子之间的相似度。使用集合模型时,利用修正后的句子长度含有共同的单词数量来定义其相似度。而使用句子对分类的贡献度来评估句子重要性的方法是将聚类过程看作优化过程，定义一个函数来体现分类质量，每个句子所属分类为变量，通过优化使函数取得极值来确定分类"
  },
  "3.3语句排序": {
    "context1": "句子排序是指根据句子赋分结果重新排序的过程。句子的赋分依据给定不同权重的某些特征值,如表7所示。选取方法共有两类,第一类是根据已有摘要人工总结出来的方法，而另一类是通过机器学习所训练出来的权重。句子排序是为了解决摘要的连贯性问题，而多数抽取式摘要研究的重点是怎样找出包含信息量大的句子,故连贯性尚未成为研究重点，因此目前关于句子排序的研究数量还不多。",
    "context2": "表7句子排序方法分类",
    "context3": "<table><tr><td>权重的选取方法</td><td>句子的特征值选取</td></tr><tr><td>机器学习</td><td>时间顺序、主题相似度、优先度、继承关系[]</td></tr><tr><td>人工赋予</td><td>重要程度、查询式与句子的重合度、是否文档的 首句或者尾句、长度临界值[0]</td></tr></table>"
  },
  "4摘要评价": {
    "context1": "现有自动摘要质量的评价主要区别在\"评价语料\"和\"评价方法\"两个方面。语料主要有两大类，一是公测语料，如DUC或TREC会议提供的语料，专注在摘要方法的研究主要利用这类语料作为实证数据;另一是自制语料,如媒体的新闻或论文等,多是研究者根据研究项目的领域需要收集整理的数据。如表8所示，评价方法分成\"有参照\"和\"无参照\"两大类。有参照\"方法有两个参照摘要的来源，语料自带的摘要(如学术论文)以及研究者组织人工写出的摘要。该类方法可以是\"自定指标\"和\"ROUGE\"两种，后者是学术会议指定的评价指标，更有普遍性和说服力，同时该类方法将机器生成的摘要和参照摘要比对相似程度并评价质量。“无参照”的评价方法则包含了“分步测试\"与\"用户反馈\"两种。“分步测试\"是指将实现的方法分解成若干步骤，根据每一步骤不同的目的设置不同的测试。因为抽象式摘要方法无法使用通用的评价方法，所以多使用这类方法。“用户反馈\"则是通过询问用户直接获取相关的反馈，属于面向摘要功能和摘要质量层面上的评价。",
    "context2": "表8评估语料和方法",
    "context3": "<table><tr><td>类别</td><td>评价方法</td><td>研究案例</td><td>使用语料</td></tr><tr><td rowspan=\"3\">有参 照</td><td>自定指标与 人工摘要结</td><td>基于质心的多文档摘 要241</td><td>Usenet[24](新闻数据)</td></tr><tr><td>果比对</td><td>SUMMA[29]</td><td>DUC[29](新闻数据)</td></tr><tr><td>ROUGE-1, ROUGE-SU4</td><td>问答系统[0]</td><td>TREC[o]（生物医学 数据)</td></tr><tr><td rowspan=\"2\">无参 照</td><td>分步测试</td><td>基于概念的多文档摘 要30]</td><td>论文[30](学术数据)</td></tr><tr><td>用户反馈</td><td>交互式多文档摘要[25]</td><td>新闻[25](新闻数据)</td></tr></table>"
  },
  "5结语": {
    "context1": "多文档自动摘要的本质是利用计算机自动生成多篇文章的摘要，大大减少用户的阅读量，增加其利用信息的效率。本文通过国内外相关文献系统梳理与归纳,将多文档自动摘要方法总结出\"数据形态”、“信息处理”、“形成摘要\"和“摘要评估\"四个部分。通过这四个部分，我们可以看出目前在句子层面的处理方法较为丰富,而单词层面与段落层面上的处理相对较少。抽取式自动摘要在对句子重要性计算得益于机器学习等领域的发展,大量吸取深度学习理论来对已有的方式进行改进[31-33]。在抽象式自动摘要方面,由于目前的机器对于自然语言的理解程度不足,使得摘要的逻辑连贯性差以及需要较多的人工参与，造成发展改进较慢,也有很大的改进空间。"
  },
  "参考文献": {
    "context1": "1 Luhn HP.The Automatic Creation ofLiterature Abstracts[J]. IBM Journal of Research & Development, 1958,2(2):159-165.   \n2 秦兵,刘挺,李生.多文档自动文摘综述[J].中文 信息学报,2005,(6):15-22,58.   \n3 Zhong S H,Liu Y,Li B,et al. Query-oriented unsupervised multi-document summarization via deep learning model[J].Expert Systems with Applications, 2015,42(21):8146-8155.   \n4 刘德喜,何炎祥,姬东鸿,杨华.一种基于演化算法进行 句子抽取的多文档自动摘要系统SBGA[J].中文信息学 报,2006,(6):46-53.   \n5 Zhao L,Wu L,Huang X.Using query expansion in graph-based approach for query-focused multi-document summarization[J].Information Processing & Management,2009,45(1):35-41.   \n6Bollegala D,Okazaki N,Ishizuka M.A bottom-up approach to sentence ordering for multi-document summarization[C]// International Conferenceon Computational Linguistics and the,Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,2006:89-109.   \n7 徐永东,徐志明,王晓龙.基于信息融合的多文档自动文 摘技术[J].计算机学报,2007,30(11):2048-2054.   \n8 Ouyang Y,Li W, Li S,et al. Applying regression models to query-focused multi-document summarization[J]. Information Processing & Management, 2011, 47(2):227-237.   \n9 Bollegala D,Okazaki N, Ishizuka M. A preference learningapproachtosentenceorderingfor multi-document summarization[J]. Information Sciences,2012,217(24):78-95.   \n10 Shi Z, Meli G, Wang Y,et al. Question answering summarization of multiple biomedical documents[J].Advances in Artificial Intelligence,2007,71(10):284-295.   \n11Wan X, Yang J, Xiao J. Manifold-ranking based topic-focused multi-document summarization[C]// Proceedings of the 2Oth international joint conference on Artificial intelligence. Morgan Kaufmann Publishers Inc., 2007:2903-2908.   \n12McKeown KR,Klavans JL,Hatzivassiloglou V,et al. Towardsmultidocument summarization by reformulation: progress and prospects[C]// Sixteenth National Conference on Artificial Inteligence and the Eleventh Innovative Applications of Artficial Intelligence Conference Inovative Applications of Artificial Intelligence．American Association for Artificial Intelligence,20oO:453-460.   \n13 Afantenos S D,Doura I, Kapellou E,et al.Exploiting CrossDocument Relations for Multi-document Evolving Summarization[J].Lecture Notes in Computer Science,2004, (3025):410-419.   \n14Khan A, Salim N,Kumar Y J.A framework for multi-document abstractive summarization based on semantic role labelling[J]. Applied Soft Computing, 2015, (30):737-747.   \n15 DBPedia [EB\\OL].http://wiki.dbpedia.org/,2015-12-06.   \n16 Kogilavani A A,Balasubramanie P.Ontology Enhanced Clu stering Based Summarization of Medical Documents[J]. International Journal of Recent Trends in Engineering,2009, 1(1):546-549.   \n17Suanmali L,Salim N, Binwahlan M S. Fuzzy Logic Based Method for Improving Text Summarization[J]. International Journal of Computer Science & Information Security, 2009,2(1):arXiv:0906.4690.   \n18 Li J, Li S. A novel feature-based Bayesian model for query focused multi-document summarization[J]. Transactions of the Association for Computational Linguistics,2O13,(1):89- 98.   \n19Li L，Wang D，Shen C，et al.Ontology-enriched Multi-Document Summarization in Disaster Management [C]// SIGIR 2O1O: Proceedings of the 33rd Annual International ACM SIGIR Conference on Research Development in Information Retrieval. Association for Computing Machinery.,2010:819-820.   \n20 Verma R,Chen P,Lu W.A semantic free-text summarization system using ontology knowledge[C]//Proceedings of Document Understanding Conference,Salt Lake City,2007.   \n21 宋宣辰.基于统计与语义分析的多文档自动摘要研究[D]. 安徽：中国科学技术大学,2009.   \n22Erkan G,Radev DR. LexRank: Graph-based Lexical Centrality as Salience in Text Summarization[]. Journal of Qiqihar Junior Teachers College,2010,(22):2004.   \n23 Mihalcea R, Tarau P. TextRank: Bringing Order into Texts D]. Unt Scholarly Works,2004,(9):404-411.   \n24 Radev D R, Jing H, Sty M, et al. Centroid-based summarization of multiple documents[J]. Information Processing & Management, 2004, 40(6):919-938.   \n25Stein G C, Strzalkowski T,Wise G B.Interactive,Text-Bas ed Summarization of Multiple Documents[J]. Computational Intelligence,2000,16(4):606 - 613.   \n26Aliguliyev R M. Clustering Techniques and Discrete Particle Swarm Optimization Algorithm for Multi - Document Summarization[J]. Computational Intelligence,2O1O,26(4):   \n420-448.   \n27Wan X, YangJ. Improved Affinity Graph Based Multi-Doc ument Summarization.[C]// Proceedings of the human language technology conference of the NAACL.Association for Computational Linguistics.,2006:181-184.   \n28 Wei F,Li W,Lu Q,et al. A document-senOO73itive graph model for multi-document summarization[J]. Knowledge & Information Systems,2010,22(2):245-259.   \n29 Moens M F,Angheluta R,Dumortier J. Generic technologies for single- and multi-document summarization[J]. Information Processing & Management, 2005, 41(3):569-586.   \n30 Ou S,Khoo S G,Goh D H. Design and development of a concept-based multi-document summarization system for research abstracts[J]. Journal of Information Science,2008,   \n34(3):308-326.   \n31 Yang G. Using Contextual Topic Model for a Query-Focused Multi-Document Summarizer[J]. International Journal on Artificial Intelligence Tools,2016,25(1):1660002.   \n32 Zhong S, Liu Y, Li B, et al. Query-oriented unsupervised multi-document summarization via deep learning model[J]. Expert Systems with Applications,2015,42(21): 8146-8155.   \n33Fattah MA.A hybrid machine learning model for multi-do cument summarization[J].Applied intellgence,2014,40(4):   \n592-600.",
    "context2": "(责任编辑：赵红颖)"
  }
}