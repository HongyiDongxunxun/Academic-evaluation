{
  "original_filename": "full_5110.md",
  "属性约简方法研究综述\\*": {
    "context1": "马 捷²葛 岩³蒲泓宇",
    "context2": "1（吉林大学管理学院长春130022）  \n2（吉林大学信息资源研究中心长春130022)  \n3（北华大学计算机科学技术学院 吉林132021)",
    "context3": "摘要：【目的】探讨属性约简方法的发展趋势及应用领域,为该领域的系统研究提供借鉴。【文献范围】在Web of Science和CNKI中分别以检索词\"Atribute Reduction\"和\"属性约简\"进行文献检索,再结合主题筛选，精读并使用追溯法获得属性约简研究的代表性文献共142篇【方法】介绍属性约简的基本方法,对属性约简方法的主要研究内容进行归类总结。【结果】属性约简方法的热点研究集中在利用粗糙集、粒计算和形式概念分析等基本方法,其发展趋势与数据的动态性、智能算法之间的相互融合密切相关。【局限】仅针对属性约简算法之间的融合发展进行简要论述，未对其进行更深人探讨。【结论】多种属性约简算法的融合研究是属性约简算法的发展趋势。",
    "context4": "关键词：粗糙集粒计算形式概念分析分类号：TP393DOI: 10.11925/infotech.2096-3467.2018.1278",
    "context5": "引用本文：马捷，葛岩，蒲泓宇.属性约简方法研究综述[J].数据分析与知识发现，2020,4(1)：40-50.(MaJie,Ge Yan,Pu Hongyu. Survey of Atribute Reduction Methods[J]. Data Analysis and Knowledge Discovery,2020,4(1): 40-50.)"
  },
  "1引言": {
    "context1": "属性约简被用于数据挖掘的预处理环节，是重要的特征选取方法之一[],指在保持系统分类不变的前提下，删除冗余属性[2],得到有效规则库，从而辅助决策,其数学描述为：设 ${ \\sf K } = ( { \\sf U } , { \\sf R } )$ 为一个知识库,在非空有限论域U上，R为等价关系集合，K中所定义的所有等价关系的族记作IND(K)。若$\\mathrm { ~ P ~subseteq ~ R ~ }$ 是满足 $\\mathrm { I N D } \\left( \\mathrm { K } \\right) = \\mathrm { I N D } \\left( \\mathrm { R } \\right)$ 的极小属性子集，则称P为R的属性约简。大数据时代,众多应用领域的数据量急剧增加,数据分析前需降低属性维数，属性约简方法便成为一项重要的基础性工作。Wong等已经证明寻找最小约简是NP-Hard问题[3],说明属性约简仍然是具有挑战性的研究议题。因此，本研究结合属性约简方法相关文献的关键词词频分析结果,梳理属性约简的基本方法，总结属性约简方法的未来发展趋势。"
  },
  "2关键词分析": {
    "context1": "以\"属性约简”、“AttributeReduction\"为关键词,分别在CNKI及Webof Science数据库中检索2010年-2018年的文献共计1341篇，其中中文文献1113篇,英文文献228篇，以上述文献的关键词作为本研究的基础数据，并精读属性约简研究的代表性文献142篇，进而总结研究热点与发展趋势。",
    "context2": "关键词是文献内容的精髓，是对文献内容的高度凝练和总结。高频关键词在一定程度上能反映该领域研究热点和发展趋势。因此关键词词频分析对研究文章内容具有十分重要的作用，是研究某一领域热点的重要依据[4]。利用CiteSpace软件统计关键词词频，将词频大于3的86个关键词作为类别划分的依据,结果如表1所示。",
    "context3": "表1关键词类别划分  \nTable 1 Classification of Keywords",
    "context4": "<table><tr><td>类别</td><td>关键词</td><td>类型定义</td></tr><tr><td>1</td><td>粗糙集、差别矩阵、粗糙集理论、信息熵、邻域粗糙集、条件熵、模糊粗糙集、区分矩阵、决策粗糙集、不完备决策表、 正区域、变精度粗糙集、正域、辨识矩阵、算法复杂度、启发式算法、序信息系统、互信息、信息量、布尔矩阵、分辨矩 阵、依赖度、模糊集、区间值信息系统、相似关系、粗集、邻域关系、条件信息熵、相似度、覆盖粗糙集</td><td>基于粗糙集的属性 约简方法</td></tr><tr><td>2</td><td>属性重要度、约简、优势关系、属性重要性、粒计算、知识粒度、约简核、多粒度、容差关系、相容关系、属性约简算基于粒计算的属性 法、粒子群、属性核、冲突域、模糊等价关系、多粒度粗糙集</td><td>约简方法</td></tr><tr><td>3</td><td>决策表、不完备信息系统、概念格、形式背景、决策系统、属性依赖度、决策规则、决策树、邻域、决策形式背景、不完 基于形式概念分析 备形式背景、不完备决策系统、属性、区分能力、不可约元 遗传算法、信息系统、数据挖掘、故障诊断、支持向量机、规则提取、集值信息系统、属性特征、蚁群算法、增量式学</td><td>的属性约简方法</td></tr><tr><td>4</td><td>习、MapReduce、算法、增量学习、蚁群优化、规则获取、增量式、神经网络、分布约简、不一致决策表、包含度、二叉 树、依赖空间</td><td>基于智能算法的属 性约简方法</td></tr></table>",
    "context5": "第一类关键词涉及信息熵、条件熵、差别矩阵与正区域等，因此将其归纳为基于粗糙集的属性约简方法。第二类关键词以粒计算、知识粒度、多粒度为主,因此定义为基于粒计算的属性约简方法。第三类关键词围绕形式背景、概念格、决策形式背景等方面，故定义为基于形式概念分析的属性约简方法。第四类关键词有遗传算法、支持向量机、蚁群优化、神经网络等，主要围绕相关算法，故定义为基于智能算法的属性约简方法。"
  },
  "3相关概念": "",
  "3.1粗糙集": {
    "context1": "粗糙集理论由波兰数学家Pawlak于1982年提出[5],能够分析不确定、不完备数据,被应用于机器学习、模式识别、决策分析与知识发现等领域,其主要特点是在不改变分类能力的情况下，通过剔除冗余信息获得知识的属性约简，进而导出问题的决策规则。",
    "context2": "设 $I S = \\{ U , A , V , f \\}$ 为信息系统，其中， $U =$ $\\{ x _ { 1 } , x _ { 2 } , . . . , x _ { n } \\}$ 是对象集， $X \\subseteq U , U | A$ 是 $U$ 的一个划分， $X$ 的粗糙下、上近似分别定义如公式(1)和公式（2）所示[。",
    "context3": "$$\n\\underline { { A } } \\ : X = U \\ : \\{ Y \\in U | A \\colon Y \\subseteq X \\} \n$$",
    "context4": "$$\n\\overline { { A } } X = U \\\\\\{ Y \\in U | A \\colon Y \\bigcap X \\neq \\phi \\}\n$$",
    "context5": "相应的序对 $< \\underline { { A } } \\ : X , \\overline { { A } } \\ : X >$ 被称为粗糙集。"
  },
  "3.2粒计算": {
    "context1": "Zadeh 首次提出粒计算（Granular Computing）的概念[7],学界普遍认为粒计算是一种看待客观世界的世界观和方法论[8],采用粒度思想,将复杂问题转化为简单问题的求解方法[9],其数学描述：在空间 $X$ 上的粒 $A$ 可表示为空间的映射：",
    "context2": "$$\nA \\colon X \\longrightarrow G ( X )\n$$",
    "context3": "其中， $X$ 表示为某空间， $G$ 表示粒 $A$ 的形式框架。"
  },
  "3.3形式概念分析": {
    "context1": "形式概念分析是德国数学家Wille提出的数据分析和规则提取方法[10],形式背景 $K = ( U , A , I )$ ,其中 $U = \\{ \\ : x _ { 1 } , x _ { 2 } , . . . , x _ { n } \\}$ 是对象集， $A = \\left\\{ \\begin{array} { l l }  a _ { 1 } , a _ { 2 } , . . . , a _ { m } \\right\\} \\end{array}$ 是属性集， $I$ 是 $U \\times A$ 上的二元关系,通过概念格所展现出的概念之间的泛化与特化关系，描述对象与属性之间的依赖关系。此外，从决策信息系统T诱导出决策形式背景 $\\Pi = ( U , A , I , D , J )$ ,其中 $U , A , D$ 定义如公式(4)-公式(6)所示。核心概念为形式背景、形式概念与概念格。",
    "context2": "$$\nU = \\{ \\ : x _ { 1 } , x _ { 2 } , . . . , x _ { n } \\}\n$$",
    "context3": "$$\n\\begin{array} { c } { { A = \\left\\{ a _ { 1 } \\left( \\nu _ { 1 } ^ { 1 } \\right) , . . . , a _ { 1 } \\left( \\nu _ { 1 m 1 } ^ { 1 } \\right) , a _ { 2 } \\left( \\nu _ { 1 } ^ { 2 } \\right) , . . . , a _ { 2 } \\left( \\nu _ { 1 m 2 } ^ { 2 } \\right) , \\right. } } \\\\ { { \\left. . . , a _ { n } \\left( \\nu _ { 1 } ^ { n } \\right) , . . . , a _ { n } \\left( \\nu _ { 1 m _ { n } } ^ { n } \\right) \\right\\} } } \\\\ { { D = \\left\\{ d \\left( \\nu _ { 1 } ^ { d } \\right) , d \\left( \\nu _ { 2 } ^ { d } \\right) . . . , d \\left( \\nu _ { m _ { d } } ^ { d } \\right) \\right\\} } } \\end{array}\n$$"
  },
  "3.4三者的联系与区别": {
    "context1": "粗糙集理论与形式概念分析是两种不同的数学方法,但都是在分类基础上，从不同的侧面研究和表示数据中隐含的知识。粗糙集利用等价关系对数据表进行分类，而概念格是利用序理论对数据表进行概念分层讨论[]。粗糙集理论是在不可分辨关系基础上进行论域的划分,该划分是一些信息粒的合集，故粗糙集方法是在单粒度空间进行的概念近似逼近,被称为单粒度粗糙集。而在概念格理论中，粒子的表述就是一个概念，包括概念的内涵与外延。",
    "context2": "粗糙集、粒计算与形式概念分析三者之间的联系与区别如表2所示。从基本组成来看，粗糙集理论是在不可分辨关系基础上,得到论域的一个划分，由上近似集和下近似集组成[12]。而粒计算由粒子、粒层与粒结构组成;形式概念分析利用序理论对数据表进行概念分层,由属性集和对象集组成。",
    "context3": "粗糙集理论通常先对连续型数据进行离散化处理,这必将造成信息损失。粒计算能够在不同粒层之间相互转化,能够高效地实现复杂问题求解。形式概念分析用概念格展现对象与属性之间的二元层次关系[13]。",
    "context4": "表2粗糙集、粒计算与形式概念分析三者之间的联系与区别  \nTable 2Relations and Differences Among Rough Set, Granular Computing and Formal Concept Analysis",
    "context5": "<table><tr><td>方法</td><td>信息表示</td><td>处理变量</td><td>基本组成</td><td>划分问题</td><td>数据分类的依据</td><td>特点</td></tr><tr><td></td><td>粗糙集一个子集名义型变量</td><td></td><td>上近似集、 下近似集</td><td>通过属性的增加 或删减来控制</td><td>等价关系</td><td>研究离散的对象集,针对属性值的差异对对象进 行分类,从而形成集合的上、下近似,而对象之间</td></tr><tr><td>粒计算粒子</td><td></td><td>数值型数据</td><td>粒子、粒层、 粒结构</td><td>在不同粒层之间 基于等价关系、</td><td></td><td>没有结构关系或拓扑关系。 粒计算是通用的结构化问题求解方法。</td></tr><tr><td>形式概</td><td>一个概念</td><td>名义型变量、 数值型数据</td><td></td><td>相互转化 对象集、属性集改变概念的内涵序理论、格理论对概念进行分层处理。</td><td>基于模糊集等</td><td></td></tr></table>"
  },
  "4属性约简的基本方法": "",
  "4.1基于粗糙集的属性约简方法": {
    "context1": "经典粗糙集理论主要处理完备信息系统数据，学者们纷纷对经典粗糙集理论模型进行改进,将等价关系扩充为容差关系或非对称相似关系等，使其适用于不完备数据的处理,如覆盖粗糙集[14]、概率粗糙集[9]、变精度粗糙集[15]、领域粗糙集[16]、决策粗糙集[17]等,上述模型均可以与属性约简方法相结合。经过归纳总结,典型属性约简算法包括：基于信息熵的属性约简[18] 基于差别矩阵的属性约简[19]和基于正区域的属性约简[20]。",
    "context2": "（1）基于信息熵的属性约简方法$\\textcircled{1}$ 信息熵的基本概念",
    "context3": "信息熵是对事件的不确定程度的度量。假设一个总体包含 $m$ 个随机变量 $X _ { i } , i { = } 1 , 2 , \\cdots , m$ ，则信息熵为：",
    "context4": "$$\nH \\left( X \\right) = - \\sum _ { i \\mathrm { ~ = ~ 1 ~ } } ^ { m } P \\left( x _ { i } \\right) \\log \\left( x _ { i } \\right)\n$$"
  },
  "$\\textcircled{2}$ 基本思路及研究进展": {
    "context1": "基于信息熵的属性约简的基本思路为：根据属性重要度或属性关联度,依次剔除无关属性，直到所得的属性集与原信息系统的分类能力相同为止。",
    "context2": "从信息的角度，苗夺谦等提出粗糙集中概念的信息表示，充分利用信息熵度量不确定性数据的优势,将信息熵作为启发式信息,提出高效的属性约简方法[17]。但当条件属性较多时,时间复杂度会相应增加[21]。Wang等提出以条件信息熵为启发条件的约简算法[22],利用条件信息熵度量属性集之间依赖程度。而后，陈媛等将条件信息熵和属性重要度相结合,以决策表的相对核为起点,逐步添加引起互信息量变化大的属性，加快了决策表的运行速度[23]。针对数据集的特异性问题,马斌斌提出基于奇异值分解熵的属性约简算法，以时间序列数据为例,与条件信息熵对比,该方法在约简结果和识别精度方面具有一定优势[24]。",
    "context3": "从属性区分能力角度，陶午沙等扩展基于信息熵的度量方法，提出不完备信息系统中的不确定性"
  },
  "42 数据分析与知识发现": {
    "context1": "度量方法 $\\alpha$ 信息熵，其仅针对等价关系和容差关系进行分析，缺乏对可调参数的解释[25];在此基础上，滕书华考虑到数据集中样本权重的不同，提出加权$\\alpha$ 信息熵的属性约简算法，融入主观偏好和先验知识,实验结果证明该算法提高了属性约简结果的分类能力[26]。",
    "context2": "（2）基于差别矩阵的属性约简方法"
  },
  "$\\textcircled{1}$ 差别矩阵的基本概念": {
    "context1": "在决策系统 $T = ( U , A , V , f )$ 中， $U =$ $\\{ x _ { 1 } , x _ { 2 } , . . . , x _ { n } \\}$ 为对象集， $A = C \\cup D$ ， $C =$ $\\{ c _ { 1 } , c _ { 2 } , . . . , c _ { m } \\}$ 为条件属性， $D = \\{ d \\}$ 为决策属性，依据决策属性 $D$ 将对象全集 $U$ 划分为不同的类，即$\\{ x _ { 1 } , x _ { 2 } , . . . , x _ { n } \\}$ ,则条件属性 $C$ 的差别矩阵为 $M \\left( C \\right) =$ $| m _ { i j } | _ { n \\times n }$ 定义如公式(8)所示。",
    "context2": "$$\nm _ { i j } = \\left\\{ \\begin{array} { l } { { \\left\\{ c \\in C \\right\\} , c \\left( x _ { i } \\right) \\neq c \\left( x _ { j } \\right) \\mathrm { a n d } d \\left( x _ { i } \\right) \\neq d \\left( x _ { j } \\right) } } \\\\ { { - 1 , c \\left( x _ { i } \\right) = c \\left( x _ { j } \\right) a n d d \\left( x _ { i } \\right) = d \\left( x _ { j } \\right) } } \\\\ { { \\phi , d \\left( x _ { i } \\right) = d \\left( x _ { j } \\right) } } \\end{array} \\right.\n$$",
    "context3": "因此,差别矩阵中元素 $m _ { i j }$ 能够区分对象 $x _ { i }$ 与 $x _ { j }$ 的所有属性构成的集合。当 $d \\left( x _ { i } \\right) = d \\left( x _ { j } \\right)$ 时， $m _ { i j }$ 的值为空集 $\\phi$ 。",
    "context4": "$\\textcircled{2}$ 研究进展",
    "context5": "基于差别矩阵属性约简的基本思路[19]为利用差别矩阵导出区分函数，然后求解区分函数的析取范式,其中每一个析取项即为系统的一个约简。在此方法基础上,有学者提出众多改进算法，如Felix等提出基于二进制的差别矩阵,该差别矩阵元素由0和1组成,使存储空间减少一半[27];杨传健等改变存储策略，提出将垂直分解的二进制差别矩阵存储于外部介质中，仅将所需运算的二进制属性列调入内存[28] 。"
  },
  "（3）基于正区域的属性约简方法": {
    "context1": "基于正区域的属性约简主要是对等价类进行划分,不需要建立差别矩阵，降低了时间和空间复杂度。吴守领等通过优化终止条件，使其能够适应较大数据集的属性约简[29]。邓大勇等提出可变正区域约简,允许正区域在一定的范围内发生变化,从而提高泛化能力[30]。徐章艳等利用基数排序算法改进传统等价类划分算法，采用快速缩小搜索空间的思想计算属性重要度,实验证明该算法能处理大型决策表[31]。在此基础上,葛浩等分析上述算法的局限性,以核属性为初始约简集,将重要性大的属性依次加入其中[32],优化等价类划分和正区域求解过程。",
    "context2": "综上所述,三种方法的优缺点和适用范围如表3所示。",
    "context3": "表3信息熵、差别矩阵、正区域三种方法的比较  \nTable3Comparison of Three Methods of Information Entropy,Difference Matrix and Positive Region",
    "context4": "<table><tr><td>方法</td><td>优点</td><td>缺点</td><td>适用范围</td></tr><tr><td>信息熵</td><td>信息熵度量不确定性数据</td><td>条件属性较多时,时间复杂度高</td><td>适用于存在较多不确定因素的数据集</td></tr><tr><td></td><td>差别矩阵 方法简单、解释性良好</td><td>差别矩阵中可能出现重复元素</td><td>适用于较小数据集</td></tr><tr><td>正区域</td><td>复杂度</td><td>对等价类进行划分，降低了时间和空间等价类划分需要依据相应方法，否则分类 的准确性不高</td><td>适用于包含少量条件属性的相对属性约简</td></tr></table>"
  },
  "4.2基于粒计算的属性约简方法": {
    "context1": "基于粗糙集的属性约简算法普遍效率低,不能对不完备信息系统进行直接处理。与形式概念分析与粗糙集理论相比,粒计算更强调方法性与思想性,其实质是在条件属性集中寻找一个粒度最粗的属性子集[33],以约简核为基础,计算剩余属性的重要性来获取约简集。众多学者提出很多新的模型，如基于商空间的粒计算模型[34]、基于划分的粒计算模型[35]基于覆盖的粒计算模型[36]、基于概念格的粒计算模型[37]和基于相容关系的粒计算模型[38]。"
  },
  "4.3基于形式概念分析的属性约简方法": {
    "context1": "Ganter等通过运用可约对象和可约属性[39]，提出了一种形式背景属性约简方法。张文修等提出基于概念格的属性约简方法,即寻找极小属性子集,使其能确定形式背景上的概念及其层次结构[40]。李进金等引入形式背景中概念格的交可约元概念[13]并进一步提出形式背景中概念格属性约简方法[41]。在形式背景概念的基础上，张文修等提出决策形式背景概念[42],将其定义为具有一组条件属性和一组目标属性的形式背景，由这两组属性分别形成两个概念格。随后不少学者深入研究决策形式背景的属性约简[43-44],如魏玲等提出决策形式背景的概念格属性约简理论[45]。而后,有学者结合模糊理论,提出模糊概念格理论[46],但随着数据规模的增加,模糊形式背景下生成的概念数急剧增加，其相应的格结构更复杂,这使得对概念格的分析不能有效运行。"
  },
  "5属性约简方法的发展趋势及应用分析": "",
  "5.1动态属性约简算法": {
    "context1": "现实世界存在着大量不断变化的数据，如果每获得一批数据，都对数据集重新进行属性约简计算，必将造成不必要资源损耗[47]。针对动态数据中数据对象增加、属性增加、属性值变化三种情形,产生了很多算法。"
  },
  "（1）数据对象动态增加": {
    "context1": "针对此类数据，很多学者提出基于Skowron区分矩阵的增量算法[48-49],但不能处理不协调决策表。有学者认为在更新差别矩阵时，仅须插入某一行及某一列,或删除某一行并修改相应的列,Liang等通过分析增加一组数据后样本集上数据分布的变化，提出使用信息熵的增量机制来确定属性重要度的方法[50]。当同时增加多个数据对象时,Shu等提出基于正区域的增量属性约简方法[51],而Jing等提出基于知识粒度的增量式约简方法[52]。当新增数据对象与原约简集完全矛盾时，申雪芬找到区分新增数据对象和矛盾对象的属性,进而转化为新增属性问题[53]。"
  },
  "（2）数据维度动态增长": {
    "context1": "许多真实数据集不仅对象在增加，而且属性维度也在动态变化。以医疗诊断决策系统为例，已经存在不同的临床特征，如头疼、温度、血压等数据信息，新的临床特征会逐步被添加，即属性维度会增加。针对此类数据,维度增量属性约简算法被提出。Shu针对不完备决策系统中添加和删除属性集时，提出正区域的属性约简算法[51]。Wang等提出基于信息熵的维度增量属性约简算法[54]。景运革探讨当多个对象的属性值发生变化后，引入知识粒度增量机制[55]。"
  },
  "（3）属性值变化": {
    "context1": "Wang等分析对象的属性值发生变化时，在互补熵、组合熵和香农熵的基础上,提出一种属性值动态变化增量属性约简算法[56]。王磊等针对属性值发生粗化、细化变化情况下,设计概念近似集增量式更新的矩阵算法[57]。同样,针对此种情况,季晓岚等提出优势关系下决策信息系统近似集增量更新算法[58]。"
  },
  "5.2大数据环境下属性约简方法": {
    "context1": "（1）数据集分解方法",
    "context2": "传统的属性约简方法将整个数据集一次性装入内存，很难处理大规模数据。Kusiak采取数据集分解的方法，减少每次处理的数据量，提高属性约简算法计算效率[59]。国内外学者提出了一些数据集分解的思想和方法,包括基于抽样技术的分解、基于属性重要度的分解、基于属性依赖关系的分解等。",
    "context3": "有学者利用分层抽样思想,将原始大数据集拆分为多个样本子集，在每个子集上，运用属性的区分能力进行属性约简，将各子集约简结果进行加权融合,得到原始大数据集的属性约简结果,实验表明该算法适用于海量数据集6]。Yang等利用MapReduce技术进行数据集分解，对小数据集进行属性约简[61]。此外,也有学者依据粗糙集理论中属性重要度对对象集进行分解，减少了数据分析的复杂度,提高规则提取的速度[62]。有学者通过属性依赖关系对条件属性进行聚类,将依赖程度高的属性聚为一类,依据时间复杂度与分类准确率,对属性约简效果进行评价。"
  },
  "（2）并行属性约简方法": {
    "context1": "传统的并行属性约简利用任务并行计算属性约简，因此,有学者融入并行计算的思想,将属性约简任务分配到多个中央处理器中同时进行，从而提高属性约简的效率[63]。此外,Deng等提出并行约简思想,将大规模数据分解为多个子决策表，分别对各个子决策表计算正区域个数,选择一个最优候选属性，重复此过程,直到获取一个约简[64]；而Liang等分别计算子决策表上的每一个约简，然后融合各个约简，得到最终约简结果[6]。上述两种方法,当针对不一致决策表时,在各个子决策表上计算约简时,并不交换信息，故只能得到一个近似约简。",
    "context2": "随着大数据平台的迅速发展，并行计算编程模式MapReduce逐渐成熟[6],大数据环境下属性约简算法研究不断涌现。学者们纷纷使用Hadoop平台和MapReduce分布式计算框架,对粗糙集属性约简"
  },
  "44 数据分析与知识发现": {
    "context1": "在云环境下进行分析实现[67-69]。"
  },
  "5.3应用分析": {
    "context1": "随着各种算法逐渐成熟，属性约简方法的应用范围也逐渐拓宽,涵盖医学领域、商业领域、教育领域、应急管理领域和评价问题等。部分属性约简的应用案例如表4所示，这更进一步说明，当人们面对大量冗余数据时,通常将实际问题的属性集约简，得到符合实际问题的较优解。",
    "context2": "表4属性约简的应用案例  \nTable 4 Application Cases of Attribute Reduction",
    "context3": "<table><tr><td colspan=\"2\">应用领域</td></tr><tr><td>医学领域</td><td>目的 处理海量电子病历[70-71]</td></tr><tr><td>商业领域</td><td>提取销售规则[72-73]</td></tr><tr><td>教育领域</td><td>教学质量评价[74]、图书馆信息资源评价[75]</td></tr><tr><td>应急管理领域</td><td>获取突发事件的关联规则[76]、辅助救援调度决 策[7-78]</td></tr><tr><td>评价问题</td><td>矿井火灾风险评价[79]、云计算安全风险评估[80]、 企业竞争力指标体系构建[81]</td></tr></table>"
  },
  "6结语": {
    "context1": "属性约简是数据挖掘、知识发现等领域中的重要研究议题,研究者们不断努力改进算法，但当前属性约简研究的数据源多以少量数据进行实验，属性约简结果评价指标和方式单一，基本上都是先约简属性,然后以分类结果的F1值或时间和空间复杂度作为评价指标。随着数据呈现海量、高维及动态等特征，属性约简方法遇到了前所未有的挑战。",
    "context2": "(1)处理海量数据需要高效的属性约简算法",
    "context3": "目前，大数据环境下属性约简还不够成熟，例如对于海量数据、混合型数据、数据缺失及不协调问题,尚缺乏高效的启发式算法,需要关注算法中的数据结构以及内存管理问题,如何根据实际情况融合多种智能算法,与其他处理不确定知识的方法相结合，提高属性约简算法的效率,是今后主要的研究方向之一。",
    "context4": "(2)与大数据相关技术结合，提出更多分布式属性约简算法",
    "context5": "随着大数据技术和分布式数据存储技术的成熟,数据集分解方法日趋完善，但各数据子集之间存在差异，构建分布式环境进行数据子集的并行处理，采取合适的属性加权方法，提出分布式属性约简算法,是有待于进一步研究的问题。",
    "context6": "(3)提出更多增量式属性约简算法",
    "context7": "针对属性、对象和属性值变化的动态属性约简算法已取得较多成果,但随着数据量的增加、准确性要求的提高，如何寻求改进的动态属性约简算法，是亟需解决的重要议题。"
  },
  "(4)算法之间的融合发展": {
    "context1": "粗糙集属性约简通常先对连续型数据进行离散化处理,必将造成信息损失。模糊集理论则关注信息系统中知识的模糊性。因此可将粗糙集与模糊集相结合对连续型数据表示的对象进行聚类划分，将属性的模糊性转化为对象的模糊性[82]。粗糙集理论定义的分类边界过于简单,产生的决策规则不太稳定,而且分类精确性不高。基于神经网络的属性约简因为属性众多，数据规模庞大，存在网络结构复杂、约简速度慢等问题,两者结合可以很好地弥补各自的缺点。总之,随着各种算法的改进，基于粗糙集、粒计算、形式概念分析的属性约简方法将与遗传算法[83-85]、聚类算法[8、蚁群算法[87-89融合，以逐步优化属性约简问题。"
  },
  "参考文献：": {
    "context1": "[1]Lin K C, Zhang K Y, Huang YH,et al. Feature Selection Based on an Improved Cat Swarm Optimization Algorithm for Big Data Classification[J]. Journal of Supercomputing,2016,72(8): 3210- 3221.   \n[2] Yao Y, Zhao Y.Attribute Reduction in Decision-Theoretic Rough Set Models[J].Information Sciences,2008,178(17):3356-3373.   \n[3] Wong SKM, Ziarko W. On Optimal Decision Rules in Decision Tables[J].Bulletin of the Polish Academyof Sciences Mathematics,1985,33(11-12):693-696.   \n[4] 谭章禄,彭胜男,王兆刚.基于聚类分析的国内文本挖掘热点与 趋势研究[J].情报学报,2019,38(6):578-585.(Tan Zhanglu,Peng Shengnan,Wang Zhaogang. Research on Hotspots and Trends of Domestic Text Mining Based on Cluster Analysis[J].Journal of the China Society for Scientific and Technical Information,2019, 38(6):578-585.)   \n[5] Abdolrazzagh-Nezhad M.Enhanced Cultural Algorithm to Solve Multi-objective Attribute Reduction Based on Rough Set Theory [J].Mathematics and Computers in Simulation,2020,170: 332-350.   \n[6] Yao Y.Three-Way Decision: An Interpretation of Rules in Rough SetTheory[C]//Proceedingsofthe2Oo9International Conference on Rough Sets and Knowledge Technology. Springer Berlin Heidelberg,2009:642-649.   \n[7] Zadeh L A. Toward a Theory of Fuzzy Information Granulation and Its Centrality in Human Reasoning and Fuzzy Logic[J]. Fuzzy Sets & Systems,1997,90:111-127.   \n[8] Li J,Huang C,Qi J，et al. Three-Way Cognitive Concept Learning via Multi-Granularity[J]. Information Sciences,2017, 378: 244-263.   \n[9] 姚一豫,祁建军,魏玲.基于三支决策的形式概念分析、粗糙集 与粒计算[J].西北大学学报:自然科学版,2018,48(4):477-487. (Yao Yiyu,Qi Jianjun，Wei Ling.Formal Concept Analysis, Rough Set Analysis and Granular Computing Based on ThreeWay Decisions[J]. Journal of Northwest University: Natural Science Edition,2018,48(4):477-487.)   \n[10]Ganter B,Godin R. Formal Concept Analysis[M].Springer Berlin Heidelberg,1999.   \n[11]王虹,张文修.形式概念分析与粗糙集的比较研究[J].计算机工 程,2006,32(8):42-44.(Wang Hong, Zhang Wenxiu. Comparative Study on Formal Concept Analysis and Rough Set Theory[J]. Computer Engineering,2006,32(8): 42-44.)   \n[12] Pawlak Z.Rough Sets: Theoretical Aspects of Reasoning About Data[M].London:Kluwer Academic Publishers,1991.   \n[13] 李进金,张燕兰,吴伟志,等.形式背景与协调决策形式背景属性 约简与概念格生成[J].计算机学报,2014,37(8):1768-1774.(Li Jinjin,Zhang Yanlan,Wu Weizhi,et al.Attribute Reduction for Formal Context and Consistent Decision Formal Context and Concept Lattice Generation[J]. Chinese Journal of Computers, 2014,37(8):1768-1774.)   \n[14]Chen D,Wang C, Hu Q.A New Approach to Attribute Reduction of Consistent and Inconsistent Covering Decision Systems with Covering Rough Sets[J]. Information Sciences,2007,177(17): 3500-3518.   \n[15]Katzberg JD, Ziarko W. Variable Precision Extension of Rough Sets [J]. Fundamenta Informaticae,1996,27(2-3):155-168.   \n[16]Lin TY. Granular Computing on Binary Relations I: Data Mining and Neighborhood Systems[J].Rough Setsin Knowledge Discovery,1998,1: 107-121.   \n[17]Jia X, Liao W, Tang Z,et al. Minimum Cost Attribute Reduction inDecision-Theoretic Rough Set Models[J]. Information Sciences,2013,219(1):151-167.   \n[18] 苗夺谦,王理.粗糙集理论中概念与运算的信息表示[J].软件学 报，1999,10(2):113-116.（Miao Duoqian，Wang Jue．An Information Representation of the Concepts and Operations in Rough Set Theory[J].Journal of Software,1999,10(2):113-116.)   \n[19] Skowron A，Rauszer C.The Discernibility Matricesand Functions in Information Systems[A]// Intelligent Decision Support.Theory and Decision Library[M].Springer,1992,11: 331-362.   \n[20]Pawlak Z.Rough Sets[J].International Journal of Computer and Information Science,1982,11(5): 341-356.   \n[21]吴尚智,苟平章.粗糙集和信息熵的属性约简算法及其应用[J]. 计算机工程,2011,37(7):56-58.(Wu Shangzhi, Gou Pingzhang. Attribute Reduction Algorithm on Rough Set and Information Entropy and Its Application[J].Computer Engineering,2011,37 (7):56-58.)   \n[22] Wang G Y, Zhao J,AnJJ,et al. Theoretical Study on Attribute Reduction of Rough Set Theory: Comparison of Algebra and Information Views[C]// Proceedings of the IEEE International Conference on Cognitive Informatics.IEEE,2004:148-155.   \n[23] 陈媛,杨栋.基于信息熵的属性约简算法及应用[J].重庆理工大 学学报:自然科学,2013,27(1):42-46.(Chen Yuan,Yang Dong. Attribute Reduction Algorithm Based on Information Entropy and Its Application[J]. Journal of Chongqing University of Technology:Natural Science,2013,27(1):42-46.)   \n[24]马斌斌.基于多重奇异值分解熵的属性约简方法研究及应用 [D].合肥:安徽大学,2017.(Ma Binbin.Research on Attribute Reduction Based on Multi-scales Singular Value Decomposition Entropy and Its Application[D].Hefei: Anhui University,2017.)   \n[25] 陶午沙,滕书华,孙即祥,等.基于一般二元关系的不确定性度量 方法研究[J].国防科技大学学报,2011,33(2):63-67.(Tao Wusha,Teng Shuhua, Sun Jixiang,et al.Study on Uncertainty Measure Based on General Binary Relation[J].Journal of National University of Defense Technology,2011,33(2): 63-67.)   \n[26] 滕书华,鲁敏,杨阿锋,等.基于一般二元关系的粗糙集加权不确 定性度量[J].计算机学报,2014,37(3):649-665.(Teng Shuhua,Lu Min,Yang Afeng,et al.A Weighted Uncertainty Measure of Rough Sets Based on General Binary Relation[J].Chinese Journal of Computers,2014,37(3):649-665.)   \n[27]Felix R, Ushio T. Rough Sets-Based Machine Learning Using a BinaryDiscernibility Matrix[C]//Proceedingsof the 2nd International ConferenceonIntelligentProcessingand Manufacturing ofMaterials.IEEE,1999,1:299-305.   \n[28] 杨传健,葛浩,李龙澍.垂直划分二进制可分辨矩阵的属性约简 [J].控制与决策,2013,28(4):563-568.(Yang Chuanjian,Ge Hao, Li Longshu. Attribute Reduction of Vertically Partitioned Binary Discernible Matrix[J]. Control and Decision,2013,28(4): 563-568.)   \n[29] 吴守领,杨颖,杨磊,等.基于粗糙集的决策表属性约简方法的研 究[J].计算机技术与发展,2012,22(1):32-35.（Wu Shouling,Yang Ying,Yang Lei,et al.Study of Decision Table Attribute Reduction MethodsBased on Rough Set[J].Computer Technology and Development, 2012,22 (1): 32-35.)   \n[30] 邓大勇,李亚楠,薛欢欢.基于粗糙集的可变正区域约简[J].浙江 师范大学学报:自然科学版,2016,39(3):294-297.(Deng Dayong, Li Ya'nan,Xue Huanhuan.Attribute Reduction of Various Positive Region Basedon Rough Sets[J]. Journal of Zhejiang Normal University: Natural Sciences,2016,39(3):294-297.)   \n[31] 徐章艳,刘作鹏,杨炳儒,等.一个复杂度为 $\\operatorname* { m a x } ( \\mathrm { O } ( | \\mathrm { C } | | \\mathrm { U } | ) , \\mathrm { O } ( | \\mathrm { C } |$ 2[U/CI))的快速属性约简算法[J].计算机学报,2006,29(3):391- 399.（Xu Zhangyan,Liu Zuopeng,Yang Bingru, et al. A Quick Attribute Reduction Algorithm with Complexity of max(O (IC||U),O(C|2|U/C))[J].Chinese Journal of Computers,2006,29 (3):391-399.)   \n[32] 葛浩,李龙澍,杨传健.改进的快速属性约简算法[J].小型微型计 算机系统,2009,30(2): 308-312.（Ge Hao,Li Longshu,Yang Chuanjian.Improvement to Quick Attribution Reduction Algorithm[J].Journal of Chinese Computer Systems,2009,30(2): 308-312.)   \n[33] 陈志恩,马旭.基于粒计算的信息系统规则提取方法[J].西北师 范大学学报:自然科学版,2018,54(4):11-15.(Chen Zhien, Ma Xu.Rules Extraction Method of Information System Based on GranularComputing[J].JournalofNorthwestNormal University: Natural Science,2018,54(4):11-15.)   \n[34]杨正华.基于商空间的粒计算模型研究[D].长沙:中南大学, 2012.(Yang Zhenghua .Research on Granular Computing Model Based on Quotient Space [D].Changsha:Central South University, 2012.)   \n[35]Yao Y Y.A Partition Model of Granular Computing[A]// Transactions on Rough Sets I. Lecture Notes in Computer Science[M]. Springer,2004.   \n[36]折延宏,王国俊.粒计算的一种覆盖模型[J].软件学报,2010,21 (11): 2782-2789. (Zhe Yanhong，Wang Guojun. A Coverage Model for Granular Computing[J]. Journal of Software,2010,21 (11): 2782-2789.)   \n[37] 仇国芳,陈劲.概念知识系统与概念信息粒格[J].工程数学学报, 2005(6):17-23.(Qiu Guofang，Chen Jin. Concept Knowledge System and Concept Information Lattice [J].Journal of Engineering Mathematics,2005 (6):17-23.)   \n[38] 孟军.相容粒计算模型及其数据挖掘研究[D].大连:大连理工 大学,2012.(Meng Jun ．Research on Compatible Granular Computing Model and Data Mining [D]. Dalian $:$ Dalian University of Technology,2012.)   \n[39] Ganter B.Formal Concept Analysis: Mathematical Foundations [M]. Springer-Verlag,1999.   \n[40] 张文修,魏玲,祁建军.概念格的属性约简理论与方法[J].中国科 学E辑:信息科学,2005,35(6):628-639.(ZhangWenxiu,Wei Ling,Qi Jianjun.Attribute Reduction Theory and Method of Concept Lattice[J]. Science in China: Series E,2005,35(6): 628-639.)   \n[41] Zhang W, WeiL, Qi J. Attribute Reduction Theory and Approach to Concept Lattice[J]. Science in China Series F:Information Sciences,2005,48(6):713-726.   \n[42]张文修,仇国芳.基于粗糙集的不确定决策[M].北京;清华大学 出版社,2005.（Zhang Wenxiu,Qiu Guofang. Uncertain Decision Making Based on Rough Set[M].Beijing: Tsinghua University Press,2005.)   \n[43]Li J,Mei C,Lv Y.Knowledge Reduction in Decision Formal Contexts[J]. Knowledge-Based Systems,2011,24(5):709-715.   \n[44] Wang H, Zhang W X. Approaches to Knowledge Reduction in GeneralizedConsistent DecisionFormal Context[J]. Mathematical & Computer Modelling,2008,48(11-12): 1677- 1684.   \n[45]魏玲,祁建军,张文修.决策形式背景的概念格属性约简[J].中国 科学E辑:信息科学,2008,38(2):195-208.(WeiLing,Qi Jianjun, Zhang Wenxiu. Conceptual Lattice Attribute Reduction of Decision-Making Formal Background[J].Science in China: Series E,2008,38(2):195-208.)   \n[46]Belohlavek R, Vychodil V. Reducing the Size of Fuzzy Concept Latticesby Hedges[C]//Proceedingsof the 14th IEEE International Conference on Fuzzy Systems.IEEE,2005: 663-668.   \n[47]丁棉卫.基于二进制区分矩阵的增量式知识约简算法研究[D]. 南京：南京邮电大学,2017.（Ding Mianwei.Research on Incremental Knowledge Reduction Algorithm Based on Binary Discernibility Matrix[D]. Nanjing:Nanjing University of Posts and Telecommunications,2017.)   \n[48] Wei W,Wu X,Liang J,et al. Discernibility Matrix Based Incremental AttributeReductionforDynamicData[J]. Knowledge-Based Systems,2018,140:142-157.   \n[49] Wang J, Wang J. Reduction Algorithms Based on Discernibility Matrix:The Ordered Atributes Method[J].Journal of Computer Science and Technology,2001,16(6):489-504.   \n[50] Liang J, Wang F, Dang C,et al. A Group Incremental Approach to Feature Selection Applying Rough Set Technique[J]. IEEE Transaction on Knowledge and Data Engineering,2014,26(2): 294-308.   \n[51]Shu W, Qian W.An Incremental Approach to Atribute Reduction from Dynamic Incomplete Decision Systems in Rough Set Theory[J].Data & Knowledge Engineering,2015,100:116-132.   \n[52]Jing Y,Li T,Fujita H,et al. An Incremental Attribute Reduction Approach Based on Knowledge Granularity with a MultiGranulation View[J]. Information Sciences,2017,411: 23-38.   \n[53] 申雪芬.基于邻域粗糙集的增量学习算法研究及其在客户分类 上的应用[D].太原:太原理工大学,2014.（Shen Xuefen.The Research on Incremental Learning Algorithm Basedon Neighborhood Rough Setsand Application in Customer Clasification[D]. Taiyuan:Taiyuan Universityof Technology, 2014.）   \n[54]Wang F,Liang J,Qian Y. Attribute Reduction: A Dimension Incremental Strategy[J]. Knowledge-Based Systems,2013,39(2): 95-108.   \n[55] 景运革.基于知识粒度的动态属性约简算法研究[D].成都：西 南交通大学,2017.（Jing Yunge.Research on Approaches of Dynamic Attribute Reduction Based on Knowledge Granularity [D]. Chengdu: Southwest Jiaotong University,2017.)   \n[56]Wang F, Liang J, Dang C.Attribute Reduction for Dynamic Data Sets[J]. Applied Soft Computing,2013,13(1):676-689.   \n[57]王磊,洪志全,万旎.属性值变化时变精度粗糙集模型中近似集 动态更新的矩阵方法研究[J].计算机应用研究,2013,30(7): 2010-20l3.（Wang Lei,Hong Zhiquan,Wan Ni.Research on Matrix-Based Incremental Method for Updating Approximations Under Variation of Atribute Values in Variable Precision Rough Set[J].Application Research of Computers,2013,30(7): 2010- 2013.）   \n[58] 季晓岚,李天瑞,邹维丽,等.优势关系下属性值粗化细化时近似 集分析[J].计算机工程,2010,36(12):33-35,42.(Ji Xiaolan,Li Tianrui,Zou Weili,et al. Analysis of Approximations Under Dominance Relation During Attribute Values Coarsening and Refining[J]. Computer Engineering,2010,36(12): 33-35,42.)   \n[59]Kusiak A.Decomposition in Data Mining:An Industrial Case Study[J].IEEETransactionsonElectronicsPackaging Manufacturing,2000,23(4):345-353.   \n[60] 冀素琴,石洪波,吕亚丽.基于粒计算与区分能力的属性约简算 法[J].模式识别与人工智能,2015,28(4):327-334.(Ji Suqin,Shi Hongbo,Lv Yali.An Attribute Reduction Algorithm Based on Granular Computing and Discernibility[J]. Pattern Recognition and Artificial Intelligence,2015,28(4): 327-334.)   \n[61]Yang Y, Chen Z, Liang Z, et al.Attribute Reduction for Massive Data Based on Rough Set Theory and MapReduce[C]/ Proceedings of the 2O10 International Conference on Rough Set and Knowledge Technology. Springer Berlin Heidelberg,2010: 672-678.   \n[62] 刘柳明.基于粗糙集的决策信息系统分解研究[D].长沙：中南 大 学，2007.(Liu Liuming.Research on Decomposition of Decision Information System Based on Rough Set Theory[D]. Changsha: Central South University,2007.)   \n[63] 肖大伟,王国胤,胡峰.一种基于粗糙集理论的快速并行属性约 简算法[J].计算机科学,2009,36(3):208-211.(Xiao Dawei, Wang Guoyin,Hu Feng.Fast Parallel Attribute Reduction Algorithm Based on Rough Set Theory[J].Computer Science,2009,36(3): 208-211.)   \n[64]Deng D Y,Wang JY,Li X J.Paralel Reducts in a Series of Decision Subsystems[C]// Proceedings of the 2009 International Joint Conference on Computational Sciences and Optimization. IEEE,2009,2:377-380.   \n[65]Liang J,Wang F,Dang C,et al.An Efficient Rough Feature SelectionAlgorithmwithaMulti-GranulationView[J]. International Journal of Approximate Reasoning,2012,53(6): 912-926.   \n[66] Dean J, Ghemawat S. MapReduce: Simplified Data Processng on Large Clusters[J]. Communications of the ACM,2008,51(1): 107-113.   \n[67] 李朋.基于云计算的粗糙集属性约简的研究[D].沈阳:沈阳师 范大学,2015.(Li Peng. Study on the Attribute Reduction of Rough Set Based on Cloud Computing[D]. Shenyang: Shenyang Normal University,2015.)   \n[68]吴健阳.基于典型相关性分析的粗糙集属性约简研究及其并行 化实现[D].南京：南京大学,2014.（Wu Jianyang.Rough Set Attribute Reduction Research Based on Canonical Correlation Analysis Algorithm and the Paralelization[D]. Nanjing:Nanjing University,2014.)   \n[69]Hu Q, Zhang L, Zhou Y,et al. Large-Scale Multi-Modality Attribute Reduction with Multi-Kernel Fuzzy Rough Sets[J]. IEEE Transactions on Fuzzy Systems,2017,26(1):226-238.   \n[70]周威光.粗糙集理论处理海量电子病历的研究与应用[D].杭 州：浙江理工大学,2017.（Zhou Weiguang.Research and Application of Rough Set Theory in Dealing with Massive Electronic Medical Records[D]. Hangzhou: Zhejiang Sci-Tech University,2017.)   \n[71]齐晨虹.基于属性简约的乳腺疾病数据分类技术及应用研究 [D].兰州：兰州交通大学,2015.（Qi Chenhong.Research on Classification Technology of Breast Disease Dataand Application Based on Atribute Reduction[D]. Lanzhou: Lanzhou Jiaotong University,2015.)   \n[72] 饶泓,夏叶娟,李姆竹.基于分辨矩阵和属性重要度的规则提取 算法[J].计算机工程与应用,2008,44(23):163-165.（Rao Hong, Xia Yejuan,Li Meizhu.Algorithm for Rule Extraction Based on Discernibility Matrix and Atribute Significance[J].Computer Engineering and Applications,2008,44(23): 163-165.)   \n[73] 曲朝阳,陈帅,杨帆,等.基于云计算技术的电力大数据预处理属 性约简方法[J].电力系统自动化,2014,38(8):67-71.(Qu Chaoyang, Chen Shuai, Yang Fan,et al. An Attribute Reducing Method for Electric Power Big Data Preprocessing Based on Cloud Computing Technology[J].Automation of Electric Power Systems,2014,38(8):67-71.)   \n[74]李萍.基于条件信息熵属性约简的教学质量评价体系研究[J]. 赤峰学院学报:自然科学版,2017,33(4):205-206.(Li Ping. Research on the Teaching Quality Evaluation System Based on Attribute Reduction of Conditional Information Entropy[J]. Journal of Chifeng University: Natural Science Edition, 2017,33 (4):205-206.)   \n[75]陈肠,左珊.基于粗糙集条件信息熵的图书馆信息资源评价研 究[J].现代情报,2014,34(3):47-50.(Chen Yang,Zuo Shan. Library Information Resources Evaluation Based on Rough Set ConditionalInformationEntropy[J].JournalofModern Information,2014,34(3):47-50.)   \n[76]高田,杜军平,王肃.基于粗糙集的旅游突发事件属性约简[J].东 南大学学报:自然科学版,2009,39(S1):163-167.(Gao Tian,Du Junping，Wang Su. Tourism Emergency Attribute Reduction Based on Rough Set[J]. Journal of Southeast University: Natural Science Edition,2009,39(S1): 163-167.)   \n[77] 吴雪莲,孙丙宇,李文波,等.基于粗糙集和CBR的救灾口粮需求 预测[J].计算机工程,2012,38(9):158-161.(Wu Xuelian,Sun Bingyu,Li Wenbo,et al. Relief Food Demand Forecast Based on Rough Set and Case-based Reasoning[J]. Computer Engineering, 2012,38(9):158-161.)   \n[78]仲秋雁,王然,曲毅.基于粗糙集的突发事件属性约简方法[J].运 筹与管理,2018,27(1):89-95.(Zhong Qiuyan,Wang Ran, Qu Yi. A Method of Attribute Reduction for Emergency Based on Rough Set[J]. Operations Research and Management Science, 2018,27(1):89-95.)   \n[79]邬云龙,刘丹龙,王浩然,等.基于粗糙集 Skowron差别矩阵的矿 井火灾风险评价指标约简[J].中国安全生产科学技术,2016,12 (5):60-65.（Wu Yunlong,Liu Danlong，Wang Haoran,et al. Reduction of Risk Assessment Indexes for Mine Fire Based on Skowron Discernibility Matrix of Rough Set Theory[J]. Journal of Safety Science and Technology,2016,12(5):60-65.)   \n[80] 陈旭,蒋朝惠.基于粗糙集差别矩阵的云安全评估指标约简[J]. 通信技 术,2018,51(4): 919-923.(Chen Xu,Jiang Chaohui. Reduction of Security Assessment Indexes for Cloud Computing Basedon Differential Matrix ofRough SetTheory[J]. Communications Technology,2018,51(4): 919-923.)   \n[81] 刘杰.基于信息粒度的属性约简改进算法在企业竞争力指标体 系构建中的应用[J].中国管理信息化,2008,11(15):98-100.(Liu Jie.The Application of Reduction Improvement Algorithm in Enterprise Competitive Power Indicator System Construction Based on Information Granulation[J]. China Management Informatization,2008,11(15):98-100.)   \n[82] 张敏.基于粗糙集理论的数值型决策表的属性约简方法研究 [D].北京:华北电力大学,2015.(Zhang Min.A Study of the Attribute Reduction in the Real Valued Decision Table Based on Rough Set Theory[D].Beijing:North China Electric Power University,2015.)   \n[83] 陈曦,雷健,傅明.基于改进遗传算法的粗糙集属性约简算法[J]. 计算机工程与设计,2010,31(3):602-604,608.(Chen Xi,Lei Jian,Fu Ming.Attribute Reduction Algorithm for Rough Set BasedonImprovingGeneticAlgorithm[J].Computer Engineering and Design,2010,31(3):602-604,608.)   \n[84] 李玉龙.张亚光.毕聪聪.一种基于改进遗传算法的粗糙集属性",
    "context2": "约简算法[J].计算机与数字工程,2014,42(10):1831-1834.(Li Yulong,Zhang Yaguang,Bi Congcong.An Attribute Reduction Algorithm for Rough Set Based on Improving Genetic Algorithm [J].Computer and Digital Engineering,2014,42(10):1831-1834.)   \n[85]Jia X,Liao W, Tang Z,et al. Minimum Cost Attribute Reduction inDecision-Theoretic Rough Set Models[J].Information Sciences,2013,219(1):151-167.   \n[86]陈晨.基于模糊聚类和粗糙集的连续值属性约简研究[D].北 京：首都经济贸易大学,2016.（Chen Chen.Research on ContinuousValue Attribute Reduction Based on Fuzzy Clustering and Rough Set[D].Beijing:Capital University of Economics and Business,2016.)   \n[87]Jensen R,Shen Q. Finding Rough Set Reducts with Ant Colony Optimization[C]// Proceedings of the 2003 UK Workshop on Computational Intelligence.2003.   \n[88] Chen Y,Miao D,Wang R.A Rough Set Approach to Feature Selection Based on Ant Colony Optimization[J].Pattern Recognition Letters,2010,31(3):226-233.   \n[89] 陈颖悦,陈玉明.基于信息熵与蚁群优化的属性约简算法[J].小 型微型计算机系统,2015,36(3):586-590.(Chen Yingyue,Chen Yuming.Attribute Reduction Algorithm Based on Information Entropy and Ant Colony Optimization[J].Journal of Chinese Computer Systems,2015,36(3):586-590.)"
  },
  "作者贡献声明：": {
    "context1": "马捷：设计论文框架,论文起草及修改;  \n葛岩：设计研究方案,分析文献,撰写论文;  \n蒲泓宇：收集、获取参考文献。"
  },
  "利益冲突声明：": {
    "context1": "所有作者声明不存在利益冲突关系。"
  },
  "支撑数据：": {
    "context1": "支撑数据由作者自存储,E-mail: geyanyan0314137@126.com。  \n[1]马捷,葛岩,蒲泓宇．data.xlsx.关键词类别划分统计数据.  \n[2]马捷,葛岩,蒲泓宇．originaldata.csv.关键词词频分析数据."
  }
}