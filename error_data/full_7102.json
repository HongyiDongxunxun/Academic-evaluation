{
  "original_filename": "full_7102.md",
  "文本内容新颖性探测研究综述": {
    "context1": "邢美凤12,过仕明",
    "context2": "(1.中国科学院 国家科学图书馆,北京100190;2.晋中学院 图书馆,山西晋中030600;3.哈尔滨师范大学 文理学院,哈尔滨 150301)",
    "context3": "摘要:如何为用户提供及时有用的新颖信息是一个亟待解决的研究内容。试图对文本内容新颖性探测的研究方法做一个梳理，从文本内容新颖性探测的研究起源、应用于这一研究的文本表示方法、相似性对比的方法以及内容新颖性探测过程等方面进行分析,以期对文本内容新颖性探测的研究有一个较全面的把握。",
    "context4": "关键词：文本;新颖性;探测;综述",
    "context5": "中图分类号：G350 文献标识码:A文章编号:1007-7634(2011)07-1098-06"
  },
  "Overview of Novelty Detection for Text Document": {
    "context1": "XING Mei-feng $^ { 1 , 2 }$ ,GUO Shi-ming (1.National Science Library of Chinese Academy of Sciences,Beijing 1Oo190,China; 2.Library of Jinzhong College ,Jinzhong O30600,China; 3.School of Arts and Sciences,Harbin Normal University,Harbin 150301,China)",
    "context2": "Abstract: How to provide users with useful and timely information is a new research content that should be solved quickly.This paper focuses on the origin of novelty detection for text document, text representation,similarity calculation and the process of novelty detection.The major purpose of this paper is providing a survey and comprehensive understanding of novelty detection for text document.",
    "context3": "Key words:text; novelty; detection; overview",
    "context4": "随着网络和信息技术的不断发展，在给定的主题当中发现相关的文献信息己不再是一件困难的事。在信息极大丰富的同时也带来了信息的冗余的问题,如何为用户提供及时新颖的有用信息，是一个亟待解决的研究内容。在这种情况下，文本内容新颖性探测的各种技术也应用而生。",
    "context5": "文本内容新颖性的研究可以追溯到1996年9月,由美国国防部发起的话题检测与跟踪(Topic De-tection and Tracking)项目[],其中有一个子项目为首次报道检测(First Story Detection 或New Event Detec-tion)：在数据流中检测首次讨论某个话题的报道。另外文本检索领域最权威的国际性评测会议TREC从 $2 0 0 2 ^ { [ 2 ] }$ 年开始增加了文本内容新颖性探测的测评。"
  },
  "1 文本新颖性的问题描述及文本的表示方式": {
    "context1": "文本新颖性的探测指按时间顺序在给定的一些相关文档集中，比较新到来的相关文本与己有文本之间内容的冗余度,确定新到来的文本内容是否新颖。这里研究的新颖性有两个特点，一是所研究文本在主题上是相关的,另外当前文本与己有文本相比较,携带了以前没有的新信息。",
    "context2": "目前文本的表示方式主要有三种：向量空间模型,概率模型和语言模型。向量空间模型和概率模型的表现形式类似,只是在每个词项的权重计算中,向量空间模型利用词频的方式,概率模型计算在相关文档和不相关文档中出现的概率值来估计。本文对概率模型和向量空间模型不做区分。",
    "context3": "(1)基于向量空间模型和概率模型的文本表示方法。基于向量空间模型和概率模型的文本表示方法包括以下三个要素：",
    "context4": "文档：为n维空间的一个向量。",
    "context5": "特征项：向量中的每一项是文档中不可分的语言单元,可以是字、词、词组和短语称为特征项。",
    "context6": "权重：每一个特征项都依据一定原则赋予数值，称为权重,表示该特征项在文档中的重要程度。",
    "context7": "(2)基于语言模型的文本表示方法。语言模型把文档看成词的序列,他们的出现与否及出现的次序可以看成是一种语言结合模式。常用的语言模型是N元语言模型,通常构建文档s的概率分布P(s),P(s)试图反映文档s作为一个文档出现的概率。实质上是统计的模型参数估计的方法。假设S代表了某个长度为K的文本： $\\mathrm { S } { = } ( \\mathrm { w } _ { 1 } { , } \\mathrm { w } _ { 2 } { , } ^ { \\ldots } { , } \\mathrm { w } _ { \\mathrm { k } } )$ ,n元语言模型将文本S看作是具有以下概率值的马尔科夫过程：$\\mathrm { P ( s ) } = \\prod _ { i = 1 } ^ { k } P ( w _ { i } ) | w _ { i - 1 } , w _ { i - 2 } , w _ { i - 3 } , . . . , w _ { - n + 1 i } \\circ$"
  },
  "2 基于向量空间模型的文本新颖性探测": "",
  "2.1基于向量空间模型的文本新颖性检测的一般步骤": {
    "context1": "停用词去除,有一些词在新颖度检测中不起作用,可以事先去除。",
    "context2": "词根和词缀处理,将单复数的形式和时态的变化可预先进行一致性处理。",
    "context3": "文本特征提取及权重赋值，利用最能表征文本内容的关键词组成文本的向量空间。",
    "context4": "利用给定方法进行文本新颖性的计算。"
  },
  "2.2基于向量空间模型的文本新颖性检测方法": {
    "context1": "2.2.1相似度计算的作用及度量方法",
    "context2": "在向量空间模型中,文本新颖性结论的得出经常依赖向量两两之间的相似度计算，自然语言处理中经常用到的相似度公式几乎都可用于文本内容新颖性的探测，有很多科研机构和人员利用这些方法进行了尝试。经常用到的相似度计算公式有：",
    "context3": "(1)基于几何距离的方法。几何距离用于向量相似性的计算主要有曼哈顿距离、欧氏距离和向量的余弦值等。近几年用的最多的是向量余弦值的方式[3-7]。利用向量余弦值进行度量时,将两个相比较的文本表示为相同维数的向量空间,权重赋值方法主要是文档词频和倒排文档频率[3],以及对词频和倒排文档频规格化处理[4]。向量夹角余弦值的公式如下：",
    "context4": "$$\n\\cos ( \\mathrm { d . d . } ) = \\frac { \\sum _ { k = 1 } ^ { n } w _ { k } ( d _ { t } ) \\cdot w _ { k } ( d _ { i } ) } { \\| d _ { t } \\| \\cdot \\| d _ { i } \\| }\n$$",
    "context5": "$\\mathrm { d } _ { \\mathrm { t } }$ 和 $\\mathrm { { d } _ { i } }$ 指进行比较的两篇文档所对应的向量， $\\mathrm { n }$ 表示向量维数。当前文本和以前的文本之间相似性值越大,则新颖性越小。在有些研究中，直接利用相似度给出计算新颖度的公式。Tsai5利用向量夹角余弦值的方差和均值的算术运算来计算新颖度。Zhang依据相似度给出的新颖度计算公式为：",
    "context6": "Novelty Score(d)=1-maxosit-cos(d)",
    "context7": "(2)基于Hellnger距离[8-10]。由Ernst Hellinger[8]引入的Hellinger距离是一种能够体现两个分布的观察值之间距离的度量。Brants[采用向量空间模型进行文本表示，权重计算方法采用改进的增量式tf-idf,在此基础上利用Hellinger距离匹配文本相关性。Brants利用Hellinger距离公式为：",
    "context8": "$\\sin ^ { \\mathrm { h } } , ( \\mathrm { d } , \\mathrm { q } ) = \\sum$ W $\\sqrt { w e i g h t _ { t } ( d , w ) \\cdot w e i g h t _ { t } ( q , w ) }$ ,其中， $\\mathrm { d , q }$ 代表相比较的文档。",
    "context9": "Zhang[10]利用Hellinger距离计算文本的相似性，并将时间参数引入距离公式。利用新提出的动态创建\"索引树\"聚类方法进行文本间的相似性对比。Zhang提出的Hellinger距离公式为：",
    "context10": "$$\n\\begin{array} { r } { \\mathrm { s i m ( d , d ^ { \\prime } , t ) } { = } \\sum _ { \\mathrm { w e d , d ^ { \\prime } } } \\sqrt { \\mathscr { w } e i g h t _ { t } ( d , t , w ) \\cdot \\mathscr { w } e i g h t _ { t } ( d ^ { \\prime } , t , w ) } } \\end{array}\n$$",
    "context11": "(3)基于句子在文献中出现位置的文本新颖性检测。基于句子在文献中的出现位置来度量文献与文献之间相似度的度量方法是：",
    "context12": "$$\n\\sin ( X _ { \\alpha } , Y _ { \\alpha } ) \\sum _ { i = 1 } ^ { n } \\ \\sum _ { k = 1 } ^ { m _ { i } } \\ { \\frac { 1 } { 2 \\ln { p _ { i _ { k } } } } }\n$$",
    "context13": "$\\boldsymbol { \\mathit { p } } _ { i _ { k } }$ 表示第i个特征词在第 $\\mathrm { k }$ 个文献中个句子中的第 $\\boldsymbol { \\mathit { p } } _ { i _ { k } }$ 个句子首次出现,假设认为核心的内容出现在标题或前面几个句子中。Makkonen[\"应用语义类进行话题检测与跟踪中使用上述公式进行，并利用实验和其它相似性度量公式进行了对比。",
    "context14": "(4)基于最大区间相关度的方法[12-13]。1998年由Carbonell[2]提出最大区间相关度(Maximum Margin-alRelevance)的概念,兼顾了当前文本、文本集中的所有文本、以及主题之间的相关度。其公式如下：",
    "context15": "$$\n\\begin{array} { r } { \\mathbf { M M R \\stackrel { \\mathrm { \\tiny ~ d e f } } { = } A r g m a x _ { \\mathrm { \\tiny ~ D i \\in ~ R / S } } } [ \\lambda ( \\mathrm { S i m _ { i } ( D _ { i } , Q ) - ( 1 - } \\lambda ) \\mathrm { m a x _ { \\mathrm { \\tiny ~ D i \\in ~ \\Omega } } } } \\\\ { \\mathrm { s S i m _ { i } ( D _ { i } , D _ { j } ) } ) ] } \\end{array}\n$$",
    "context16": "$\\mathrm { D } _ { \\mathrm { i } }$ 表示当前文本,Q表示主题，D表示以前文本的向量表示形式,S表示 $\\mathrm { D } _ { \\mathrm { i } }$ 文本之前的相关文本集合， $\\mathrm { { s i m } _ { 1 } }$ 为文本和主题相似度计算函数， $\\mathrm { s i m } _ { 2 }$ 为文本之间相似度计算函数， $\\mathrm { { s i m } _ { 1 } }$ 和 $\\mathrm { s i m } _ { 2 }$ 可以是信息检索中提到过的任一相似性度量方式，两者的度量方式可以相同，也可以不同。 $\\lambda$ 为两者之间的调节参数。 $\\mathrm { S u n } ^ { [ 1 3 ] }$ 将这一方法应用在句子级相关性度量中。",
    "context17": "(5)基于词重叠度的方法。这种方法的向量空间权重赋值为0或1,经常用到的词重叠度方法有：Dice系数 $\\mathrm { \\overline { { = } } O v e r l a p B _ { \\mathrm { A } } } \\mathrm { = } \\frac { \\mathrm { 2 } | A \\cap B | } { | A | + | B | }$ 和 Jaccard 系数 $=$ Overlap-$\\mathrm { B } _ { \\mathrm { A } } { = } \\frac { \\left| A \\cap B \\right| } { \\left| A \\cup B \\right| }$",
    "context18": "张[4提出度量词重叠度的标准计算公式为",
    "context19": "$$\n\\mathrm { O v e r l a p B } _ { \\mathrm { A } } { = } \\frac { A \\bigcap B } { | B }\n$$",
    "context20": "以上的公式中，A和B分别表示两篇文本对应的向量，重叠度越高越不新颖。给定一个阈值,与己有文本一一判断其文本内容是否新颖。"
  },
  "2.2.2 基于命名实体识别的文本新颖性检测": {
    "context1": "命名实体指具有特定意义的实体，主要包括人名、地名、机构名、日期,时间,货币等专有名词,近年来，很多机构和研究人员利用命名实体改进文本内容新颖性探测的尝试[15-22]。主要关注命名实体的两方面，一是各类命名实体在新颖性探测中的权重值[16-20],另一个是利用语义扩展命名实体的内涵[21-22]。",
    "context2": "Umass[16-17]认为相似的句子中新的人物,新的机构或新的地名出现往往意味着新的信息的出现。都柏林城市大学[18]根据词频和倒排文档频率区分这些命名实体能提供新颖信息的重要度;剑桥大学[19]利用一个命名实体识别器，使用分类器获得不同分类的权重，综合考虑这些权重值，分值在一个预先定义的范围内,被认为是新颖的句子。Yang[20]根据命名实体的不同类别为命名实体赋不同权值的方法来改进新颖性探测结果。",
    "context3": "Juha[2将抽取的术语分为四个语义类别，分别为时态类、专有名词类、地名类和普通名词类,利用文中提出的相似性度量方法抽取语义信息。 $\\mathrm { S u n } ^ { [ 1 3 ] }$ 将查询和文档向量利用wordnet进行扩展,然后利用重叠度对相关事件和新信息进行探测。IOWA[22大学计算句子中新的命名实体以及名词短词的数量，扩展名词短语中的同义词并进行词义消歧,利用扩展后的词进行文本新颖性的对比。"
  },
  "2.2.3基于聚类的新颖性检测": {
    "context1": "距离聚类的方法在数据集中生成若干个类簇，当一个新的数据点与所有的簇类距离都大于最大的训练距离时，这个数据点被认为是新颖数据。变量值聚类方法为每个聚类训练最大值和最小值，当一个新的数据点与所有聚类的最大值和最小值相比,都不在其范围内,则认为是新颖数据。有监督的聚类将训练数据聚成若干个簇，簇的个数根据具体的聚类算法而定，当新到来的文本与这些簇相比较，不属于其中的任一个簇时被认为是新颖文本。",
    "context2": "税[23]利用增量聚类算法区分样本集中的不同主题,利用 single pass聚类算法进行新颖主题探测的研究。 $\\mathrm { l a m } ^ { [ 2 4 ] }$ 为每个主题和所有的文本都建立了三种类型的元素，分别为概念特征向量,命名实体识别向量和主题特征向量。每个主题聚类的特征向量为这个主题下所有文本特征向量的平均值。先对首批出现的主题进行聚类,新到文本与现有主题进行相似性计算时，如果存在相似度高于阈值的聚类,将当前文本按原有算法嵌入该主题所对应的特征向量，否则该文本是新的主题。"
  },
  "2.2.4基于K近邻的新颖性检测": {
    "context1": "k近邻法的基本思想是在多维空间中找到与未知样本最近邻的k个点，并根据这k个点的类别来判断未知样本的类。这k个点就是未知样本的k近邻。在文本新颖性检测中,将可能有的分类情况利用样本集描述为k个类簇,新到来的文本与每个类簇的中心点相比较判断属于哪个类簇，然后再与这个类簇中距离最近的点进行比较,如果相似度小于给定阈值则认为新到来文本是新颖的。",
    "context2": "Yang[20]利用k近邻法进行新颖主题探测的实验研究。",
    "context3": "具体的做法是：将已有文档按主题分类，每个主题包含一个或多个文档;为每个主题识别命名实体并优化各自的权值;将新到来的文档与每个主题相比较,如果新到来文档与最近邻居的相似性度量值底于所给定的阈值,那么这个文档被认为是最近邻居所属这个主题的新事件。这个算法分为两步，新一步利用分类器决定新到来文档的主题;第二步利用新颖探测器决定新到来文本是这个主题的新事件还是旧事件的重复。"
  },
  "2.2.5 基于概率模型方法的新颖性检测": {
    "context1": "基于概率模型方法的文本新颖性检测,往往事先给出部分数据的结果,依据己知的结果去推测当前文本的新颖度。概率模型认为样本数据服从某个己知的分布,计算样本数据属于这一分布的概率密度值，利用概率密度值进行文本新颖性检测。",
    "context2": "Hansen [25]构建了基于潜在语义索引文档模式的通用高斯混合模型,高斯混合模型认为数据服从多个高斯分布的加权和,这一模型能够平滑地近似任意形状的密度分布。Hansen利用给定的样本集来构建密度函数，如果测试数据和训练样本有同样的分布,则认为这些数据不是新颖信息,否则认为是新颖的信息。"
  },
  "2.2.6 基于神经网络的方法": {
    "context1": "基于神经网络进行文本新颖性探测的方法主要是给定一段文本及其特征集,输入层神经元的个数设定为特征集的大小,输出层神经元指示输入文本内容是否新颖。神经网络应用于新颖性探测分两个阶段：网络学习阶段和网络应用阶段。训练时如果输入层的数据经过隐含层到达输出层后的结果与预计的结果不符,则这个误差归结为各连接层节点间的连接权重的错误,反向传播将误差分摊给各节点连接权,计算相应误差修正各连接权。通过不断的修正达到输出值与预计输出值之间的统一。如果训练集共有N篇文档，则这个神经网络学习的次数为N,每一次学习都经历两个阶段：向神经网络输入该文档的关键词,以获得输出神经元的一个当前输出；根据当前输出与神经网络理想输出之间的差值，沿着神经网络的输出到输入的方向，依次反向修改神经网络的权值。输入权值和、特征函数计算、阈值处理和权值调整在研究利用神经网络进行新颖性探测时都是不可缺少的。神经网络用于文本新颖性探测的一个优点是对于训练网络所使用的优化参数数量要求少。",
    "context2": "Markou[2基于理论层面综述了可用于新颖信息探测的各种神经网络方法。张3利用国际上通行的开放支持向量机源码系统SVMlight(Version5.00)进行新颖文本句子的探测。"
  },
  "3 基于语言模型的文本新颖性探测": {
    "context1": "基于语言模型的文本新颖性探测是有监督的新颖性探测方法。语言模型的目的是建立一个能够描述给定词序列在语言中出现的概率分布。文本的表示问题等价于文本语言模型的模型参数估计问题。每一篇文本都可以看成是语言模型抽样产生的一个样本。基于语言模型的文本相似性计算的问题就转换为计算两篇文本概率分布的差异程度。如果当前文本和己有文本之间的计算值都低于训练语料的概率值时，认为当前文本是新颖的。"
  },
  "3.1风险最小化框架模型": {
    "context1": "3.1.1 基于信息论的Kullback-leibler(KL)发散距离",
    "context2": "张[4基于信息理论的KL发散距离计算 $\\mathrm { K L } ( \\theta _ { 1 } | | \\theta$ ${ \\mathrm { \\Omega _ { 2 } ) = } } \\mathrm { { Z } } _ { \\mathrm { { w } } } { \\mathrm { | } } \\Theta _ { 1 } { \\mathrm { ) l o g } } \\ \\frac { P ( \\ w \\backslash \\theta _ { 1 } ) } { P ( \\ w | \\theta _ { 2 } ) }$ 句子的新颖度，具体的计算公式如下给出 $\\scriptstyle \\mathrm { K L N o v ( s _ { i } | s _ { 1 } , \\ldots , s _ { i - 1 } ) } = \\mathrm { K L } ( \\theta _ { \\mathrm { s i } } | | \\theta \\mathrm { s } _ { 1 } , \\ldots , \\mathrm { s } _ { \\mathrm { i } - 1 } ) =$",
    "context3": "$$\n\\Sigma _ { \\mathrm { w } } \\mathrm { P } ( \\mathrm { w } | \\Theta _ { \\mathrm { s i } } ) { \\log \\frac { P ( \\mathrm { w } | \\theta _ { s i } ) } { P ( \\mathrm { w } | s _ { 1 , \\dots , s i - 1 } ) } }\n$$",
    "context4": "同时，使用最大似然估计与插值平滑技术处理数据稀疏问题。经实验，语言模型的方法能够取得的性能与向量空间模型的相似度比较方法相当。",
    "context5": "Dragon 系统[利用Kullback-Leibler(KL)距离对语音报道进行相似性度量,将对比的两篇语音报道看作一个话题和一篇报道,计算报道产生于话题的概率,并通过调换两篇报道的角色分别从两个方向估计它们的产生概率,最终的相关性则依据这两种概率分布,综合得到,具体的计算公式如下： $scriptstyle \\mathrm { d } = \\sum _ { \\mathrm { \\scriptsize { n } } } ( \\mathbf { S } _ { \\mathrm { \\scriptsize { n } } } /$ $\\mathrm { S } ) { \\log { \\frac { s _ { n } / S } { ( c _ { n } + s _ { n } ) / ( C + S ) } } + \\sum _ { \\mathrm { n } } ( \\mathrm { c } _ { \\mathrm { n } } / \\mathrm { S } ) { \\log { \\frac { c _ { n } / S } { ( c _ { n } + s _ { n } ) / ( C + S ) } } } }$",
    "context6": "C 和S分别代表进行比对的两篇语音报道,当一篇语音报道和所有话题中的语音报道进行计算的概率值低于阈值，则认为此报道是新颖的报道。",
    "context7": "3.1.2基于信息论的Jensen-Shannon(JS)发散距 离",
    "context8": "Horwich[2]利用KL发散距离的一个对称变体Jensen-Shannon(JS)发散距离计算当前文本和给定的文本集之间的距离。具体的公式如下d为一篇文本,D为要比较的文档集。",
    "context9": "$\\mathrm { d i s t _ { j s } ( d | | D ) } = \\frac { K L ( d | | \\theta ) + K L ( D | | \\theta ) } { 2 }$ 其中 $\\scriptstyle \\theta = { \\frac { d + D } { 2 } }$",
    "context10": "利用迭代的方式给出一个新颖性排序的算法，对于按时间顺序送来的新闻稿件产生一组读者可能感兴趣的新稿件。"
  },
  "3.2隐马尔可夫模型": {
    "context1": "HMM[2方法假设文档集合S包含N个不同文本,HMM方法根据每一篇文本d和文档集合S构造包含两个状态的离散隐马尔可夫模型，这样得到N个不同的隐马尔可夫模型的集合。任一个离散隐马尔可夫模型由以下四组参数集合构成：文档d本身和文档集合S构成状态集合;状态间的转移概率集合 $\\mathrm { T } { = } \\{ \\mathrm { a } _ { 1 } , \\mathrm { a } _ { 2 } , \\cdots , \\mathrm { a } _ { \\mathrm { i } } \\}$ ;状态输出可见符号集合由文档集合中出现的所有词汇构成;而每个状态产生可见符号的概率集合通过以下最大似然估计得到：",
    "context2": "$$\n\\mathrm { P ( t e r m ` G E ) } \\frac { \\Sigma _ { k } { \\it t f } _ { t e r m } } { \\Sigma _ { k } | D _ { k } | } \\qquad \\mathrm { P ( t e r m ` D _ k ) } \\frac { t f _ { t e r m } } { | D _ { k } | }\n$$",
    "context3": "其中 $\\operatorname { t f } _ { \\operatorname { t e r m } }$ 代表词汇term在文档 $\\mathrm { D } _ { \\mathrm { k } }$ 中出现的次数， $| \\mathrm { D } _ { \\mathrm { k } } |$ 代表文档 $\\mathrm { D } _ { \\mathrm { k } }$ 包含的单词个数。给定一个训练过的HMM,HMM方法将计算当前文本和己有文本的相似性概率值,判断公式为： $\\operatorname { P } ( \\operatorname { Q } | D _ { k } ) \\prod _ { q \\in Q } { } ($ $\\mathrm { a _ { 0 } P }$ $\\left( { \\bf q } | \\mathrm { G E } \\right) + _ { \\bf a _ { 1 } } \\mathrm { P } \\left( { \\bf q } | \\mathrm { D } _ { \\bf k } \\right) ,$ )。这个概率值看作由上述的N个不同隐马尔可夫模型产生的可见符号序列的概率。生成概率越大,文本之间越相似,给定一个阈值,可以得出当前文本是否新颖的结论。"
  },
  "4 文本新颖性探测方法的评价标准": {
    "context1": "在TREC的评测方法中，召回率和准确率是最基本的评价标准。由人工选择的相关句子和新颖句子作为标准的正确答案。召回率反映了系统返回的正确结果在全部正确结果中的比率,公式为：Re-$\\mathrm { c a l l } { } = { \\frac { M } { A } }$ ，其中 $\\mathbf { M }$ 指系统和人工都认为是正确句子的数量，A指由人工方式选择的正确答案的数量;准确率反映了系统返回的结果中正确结果的比例,公式为：precision= $\\frac { M } { S }$ ,其中S指由系统返回的正确答案的数量。",
    "context2": "但召回率和准确率存在弊端：当人工给定的正确答案是很少，系统返回很多个答案时，召回率为往往很高,但准确率很小;反之，当正确答案是很多，但系统返回少数几个个答案时，召回率很小,但准确率为很高。另外一个极端的情况是系统没有返回结果,这时准确率不能计算。为了避免这些问题,提出了F测度的方法,联合考虑准确率和召回率,对召回率和准确率进行了权衡。具体的计算公式为： $\\mathrm { F } =$ $\\frac { \\mathrm { R e } \\operatorname { c a l } l \\times \\mathrm { P r } e c i s i o n \\times ( 1 + \\beta ^ { 2 } ) } { \\mathrm { R e } \\operatorname { c a l } l + \\mathrm { P r } e c i s i o n + \\beta ^ { 2 } ) }$ 其中, $\\beta$ 为引人的参数。当 $\\beta$ 取1时上面的公式等价于 $\\mathrm { F } { = } \\frac { 2 { \\times } M } { A { + } S }$ ,这样即使系统没有返回任何答案,F测度的计算数量不会溢出。",
    "context3": "在所有的主题上，TREC将以上这三个指标各自的平均值定义为系统的综合性能,设i为系统所有主题的个数,系统准确率、系统召回率、系统F测度分别为：",
    "context4": "系统准确率： ${ \\overline { { \\mathrm { R e } \\operatorname { c a l } { \\boldsymbol { l } } } } } = { \\frac { \\sum _ { i = 1 } ^ { n } \\mathrm { R e } \\operatorname { c a l } { \\boldsymbol { l } } ( i ) } { | N | } }$ 系统召回率： $\\overline { { { \\mathrm { P r } e c i s i o n } } } = \\frac { \\sum _ { i = 1 } ^ { n } \\mathrm { P r } e c i s i o n ( i ) } { | N | }$ 系统F测度： $\\overline { { F } } = \\frac { \\sum _ { i = 1 } ^ { n } F ( i ) } { | N | }$"
  },
  "5结论": {
    "context1": "文本内容新颖性探测技术是自然语言处理中的一项新的任务，涉及到了自然语言处理技术的诸多方面。在文档的表示、相关度计算的方式上与可以利用信息检索的相关技术;文本新颖性的探测又类似于根据用户需求,选择满足用户需求的信息过滤任务；判定相似性和新颖性的过程问题也可看成是二分类问题或单类分类问题;对于新到来的文本，提取文摘也是必要的过程。同时，利用自然语言处理和机器学习融合方法进行新颖性的探测研究还有必要进一步深入地研究。"
  },
  "参考文献": {
    "context1": "1 James Allan, Jaime Carbonell, George Doddington,et al. Topic detection and tracking pilot study: Final report. [EB/OL]. http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=35A2 B87655CC951F0355A1D61845E900?doi=10.1.1.21.6373&r ep=rep1&type=pdf.2010-11-20.   \n2 [EB/OL].http://comminfo.rutgers.edu/\\~muresan/IR/TREC/ Proceedings/t11_proceedings/papers/NOVELTY.OVER.pdf, 2010-10-30.   \n3Agus T.Kwee,Flora S. Tsai,Wenyin Tang,Sentence-level novelty detection in English and Malay.[J].Lecture Notes in Computer Science (LNCS),2009,(5476):40 - 51.   \n4 张华平 语言浅层分析与句子级新信息检测研究[D]北京： 中国科学院计算技术研究所,2005.   \n5[EB/OL]. http://comminfo.rutgers.edu/\\~muresan/IR/TREC/Proceedings/t13_proceedings/papers/ntu.novelty.pdf,2010-12- 20.   \n6 [EB/OL].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10 .1.1.3.5256&rep=rep1&type=pdf,2010-12-20.   \n7 [EB/OL]. http://portal.acm.org/ft_gateway.cfm?id=1699703&ty pe=pdf&CFID=29101377&CFTOKEN=90443107,2010-12- 20.   \n8 [EB/OL].http://en.wikipedia.org/wiki/Hellinger_distance,2010 -10-30.   \n9 [EB/OL].htp://portal.acm.org/ft_gateway.cfm?id=860495&type =pdf&CFID=27145084&CFTOKEN=11212665,2010-12-30.   \n10 [EB/OL].http://portal.acm.org/ft_gateway.cfm?id=1277780&t ype=pdf&CFID=27145084&CFTOKEN=11212665,2010-12 -30.   \n11[EB/OL]. http://citeseerx.ist.psu.edu/viewdoc/download?doi= 10.1.1.76.9196&rep=rep1&type=pdf,2010-12-30.   \n12 [EB/OL].htp://www.cs.cmu.edu/\\~jgc/publication/The_Use_M MR_Diversity_Based_LTMIR_1998.pdf.2010-12-30.   \n13[EB/OL]. http://citeseerx.ist.psu.edu/viewdoc/download?doi= 10.1.1.81.2673&rep=rep1&type=pdf,2010-12-30.   \n14[EB/OL].http://citeseerx.ist.psu.edu/viewdoc/download?doi= 10.1.1.143.8780&rep=rep1&type=pdf,2010-11-20.   \n15[EB/OL].http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4449883.2011-01-30.   \n16[EB/OL]. http://scholarworks.umass.edu/cgi/viewcontent.cgi? article=1185&context=cs_faculty_pubs,2010-11-20.   \n17[EB/OL]. http://citeseerx.ist.psu.edu/viewdoc/download?doi= 10.1.1.1.9552&rep=rep1&type=pdf,2010-11-20.   \n18 [EB/OL].http://citeseerx.ist.psu.edu/viewdoc/download?doi= 10.1.1.151.3006&rep=rep1&type=pdf.2010-11-20.   \n19 [EB/OL].http://citeseerx.ist.psu.edu/viewdoc/download?doi= 10.1.1.80.5384&rep=rep1&type=pdf.2010-11-20.   \n20 [EB/OL].http://www.google.com.hk/url?sa=t&source=web&cd =1&ved=0CB0QFjAA&url=htp%3A%2F%2Fciteseerx.ist.ps u.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.13.420% 26rep% 3Drep1% 26type% 3Dpdf&rct=j&q=Topic-conditioned% 20Novelty%20Detection&ei=Jyb7TfecIlisvgOH3ammAw&usg=AFQjCNECGPA31bFZ02MIijUGhXuT1ivjmg&ca d=rjt. 2010-10-20.",
    "context2": "21 [EB/OL]. http://www.google.com.hk/url?sa=t&source=web&cd",
    "context3": "=1&ved=0CCQQFjAA&url=http% 3A% 2F% 2Fciteseerx.ist. psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.76.919 6% 26rep% 3Drep1% 26type% 3Dpdf&rct=j&q=Applying% 20Semantic% 20Classes% 20in% 20Event% 20Detection% 20and%20Tracking&ei=Aif7Tdb3OIayvwP2svSlAw&usg= AFQjCNEH1uKfflp-sU8pghnbKp3sG_PeIQ&cad=rjt,2010- 10-20.   \n22[EB/OL]. http://trec.nist.gov/pubs/trec13/papers/uiowa.novelty.qa.geo.pdf.2010-10-20.   \n23 税仪冬,瞿有利,黄厚宽.周期分类和Single-Pass聚类相结 合的话题识别与跟踪方法[J].北京交通大学学报,2009,(5): 85-89.   \n24Lam W, Meng H, Wong K et al. Using econtextual analysis for news event detection.[J]. International Journal on Intelligent Systems,2001,16(4):525-546.   \n25 [EB/OL].http://ieexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=860154.2010-12-30.   \n26Markos Markou, Sameer Singh.2O03b.Novelty detection: A review-part 2: Neural network based approaches[J]. Sig. Proc,1983,(12):2499 - 2521.   \n27微软公司通过对信息新颖性和动态学的分析来个性化新 闻馈送的原理和方法[P]美国CN200810090700.9 2005-03-02.   \n28Markos Markou, Sameer Singh.2O03a. Novelty detection: A review-part 1: Statistical approaches[J]. Sig.Proc,1983,(12): 2481 - 2497.",
    "context4": "(责任编辑：刘凤琴)"
  },
  "（上接第974页）": {
    "context1": "Universities[EB/OL].http://www.webometrics.info/,2010-12",
    "context2": "-02.  \n2 吴茵茵.中美大学网络影响因子研究[J].情报科学,2008,26(7):1048-1055.  \n3 王建东,孙慧明.基于网站链接分析的\"211工程\"高校排名实证研究[J].现代图书情报技术,2008,(9):64-69.  \n4 王宏鑫.我国省级以上公共图书馆网站链接分析[J].中国图书馆学报,2005,(3):86-89,97  \n5Alfred Tat-Kei Ho.Reinventing Local Governments and theE-government Initiative[J]. Public Administration Review,2002，62(4):434-44.  \n6 U.S.News.Best Colleges 2011[EB/OL]. http://colleges.usnews.rankingsandreviews.com/best-colleges/national-universities-rankings,2010-12-02.  \n7中国大学排行榜[EB/OL].http://edu.sina.com.cn/gaokao/  \n2008-12-24/1548180776.shtml,2010-11-31.  \n8Han W.Park,Mike Thelwall.Hyperlink Analyses of theWorld Wide Web:A Review[J].Journal of Computer-Mediat-ed Communication,2003,8(4):88.  \n9 沙勇忠,欧阳霞.中国省级政府网站的影响力评价一网站链接分析及网络影响因子测度[J].情报资料,2004,(4):17-22.  \n10 谢奇,张晗.中国大学网站的网络计量学研究[J].现代图书情报技术,2005,(7):74-77.  \n11 邱均平,安珊.中文期刊影响因子与网络影响因子和外部链接数的关系研究[J].情报学报,2003,22(4):398-402.  \n12 杨木容.搜索引擎在网络链接分析中的应用研究[J].图书情报工作,2006,50(11):91-94.  \n13Yahoo! Site Explorer[EB/OL].http://siteexplorer.search.ya-hoo.com/,2010-12-02.  \n14 刘思峰,党耀国,方志耕.灰色系统理论及其应用[M].北京:科学出版社,2010:40-77.",
    "context3": "(责任编辑：赵立军)"
  }
}