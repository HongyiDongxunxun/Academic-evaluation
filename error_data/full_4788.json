{
  "original_filename": "full_4788.md",
  "多文档摘要研究综述\\*": "",
  "宝日彤’孙海春1,2": {
    "context1": "1（中国人民公安大学信息网络安全学院北京100038)  \n2(安全防范技术与风险评估公安部重点实验室 北京 100026)",
    "context2": "摘要：【目的】调研和梳理相关文献,总结多文档摘要研究框架和主流模型【文献范围】以\"Multi-DocumentSummarization”、“多文档摘要\"为检索词,分别在AI Open Index、Paper with Code 和CNKI数据库中进行检索,共筛选出76篇文献。【方法】归纳多文档摘要技术实现的主流框架,依据关键技术对近年最新模型和算法进行分类概述,并对未来研究提出展望【结果】对比阐述了多文档摘要最新模型与传统方法的优缺点，并对高质量多文档摘要数据集、现阶段评价指标进行总结。【局限】在实验结果对比部分，只讨论了Multi-News等数据集上部分应用较为广泛模型的评估结果,缺乏全部模型在同一数据集上的实验结果对比。【结论】多文档摘要任务仍存在很多亟待解决的问题,如生成摘要的事实性不高、摘要模型的通用性差等。",
    "context3": "关键词：多文档摘要文本摘要内容选择Transformer模型预训练模型  \n分类号：TP311 G350  \nDOI: 10.11925/infotech.2096-3467.2022.1245",
    "context4": "引用本文：宝日彤，孙海春.多文档摘要研究综述[J].数据分析与知识发现，2024，8(2)：17-32.(BaoRitong,Sun Haichun.An Overview of Research on Multi-Document Summarization[J]. Data Analysis andKnowledge Discovery, 2024, 8(2): 17-32.)"
  },
  "1引言": {
    "context1": "多文档摘要（Multi-Document Summarization,MDS）是自然语言处理（Natural LanguageProcessing，NLP）领域中文本摘要（TextSummarization,TS)任务的一个分支。文本摘要任务旨在保留原文主旨的情况下形成更简洁的文字描述，文本摘要技术广泛应用于长文章压缩、新闻标题自动生成和基于多文档的情感分析等场景。",
    "context2": "文本摘要通常分为单文档摘要（SingleDocument Summarization，SDS）和 多文档摘要（Multi-Document Summarization,MDS）两类任务。1958年,Luhn[首次利用计算机对长文本进行概括，拉开了文本摘要研究的序幕。之后，互联网中的信息量增长快速且内容冗余，利用多文档摘要技术过滤海量文本逐渐成为一种趋势。20世纪80年代，多文档摘要的概念被提出并应用于科技文献领域。自2001年起，美国国家标准与技术研究所(NationalInstitute of Standards and Technology,NIST)开始组织文本 理 解会议（DocumentUnderstandingConference,DUC)对多文档摘要系统进行年度评测。2016年,Nallapati等[2]通过修改每日邮报(DailyMail,DM)和有线电视新闻网(CableNewsNetwork,CNN)新闻文章相关的问答数据集,提出生成式摘要数据集CNN/DM。2018年,Zopf3以网页搜索返回的文档作为源文档、以维基百科导语作为摘要创建auto-hMDS数据集。之后,WikiSum[4]、Multi-News[5]等数据集也相继出现。以上评估算法、大规模数据集的相继出现极大地推动了该领域技术的发展。",
    "context3": "深度神经网络(Deep NeuralNetworks，DNN)的突破性发展对于多文档摘要任务起到了极大的推进作用,其中,序列到序列（Sequence to Sequence,Seq2Seq)模型被广泛应用于生成式文本摘要任务。2016年,文本摘要技术引入Copy机制[和Coverage机制[],解决了序列到序列架构存在未登录词(OutofVocabulary,OOV)和生成重复的问题。2017年，Yasunaga等[8]将摘要过程分解为句子显著性评估和摘要句选择两个模块，通过将句子中存在的实体和关系映射到句子图中，使模型更好地理解文档间更深层次的关系，提升生成摘要的质量。除了深度学习的方法,Paulus等[9在文本摘要任务中首次提出结合强化学习的方法，考虑了更多损失函数，提高生成摘要的可读性。",
    "context4": "相比于传统算法,深度学习通过捕捉数据之间的非线性关系，对具有不同特征和潜在关系的数据进行建模，“理解\"输入文本的含义,减少了人工特征提取方法和外部语言知识对摘要任务的限制。近年来,随着深度学习与多文档摘要技术的进一步融合，对多文档摘要领域的研究达到新高度,许多学者针对具体问题提出更为复杂的神经网络模型。例如，为解决输入文档内容高度冗余和训练数据短缺的问题,Cho等[10]利用胶囊网络结构对行列式点过程模型进行改进,有效建模句子对的相似性，降低生成摘要的冗余性。",
    "context5": "现有文献从不同角度对多文档摘要任务进行过综述，如黄文彬等[\"按照输入数据粒度的不同进行分类,总结了以单词、句子以及段落作为输入数据的三类的多文档摘要技术的特点与难点;李金鹏等[12]详细介绍抽取式摘要与生成式摘要的具体工作;Jalil等[13]总结并对比抽取式多文档摘要不同算法的优缺点。与现有综述不同,本文根据一般多文档摘要框架图对已有方法进行分类阐述,全面对比传统摘要方法和基于深度学习的摘要方法，主要工作如下：",
    "context6": "（1）本文以“Multi-Document Summarization”“多文档摘要”为检索词,分别在AIOpen Index、PaperwithCode和CNKI数据库中进行检索,共筛选出76篇文献，通过分析总结出实现多文档摘要算法",
    "context7": "的一般框架。",
    "context8": "(2)概括实现多文档摘要算法的一般框架,将实现过程划分为文档连接、文档预处理、摘要内容选择、组织排序、摘要生成5个模块。重点针对文档连接和摘要内容选择两个模块的相关算法进行综述，对每种重点技术以及在其基础上的改进、创新进行对比分析，总结每种方法的优势和不足。",
    "context9": "(3)对多文档摘要的技术难点、主要应用、数据集及评价指标进行综述,分析主流方法的特点、适用场景及其模型的主干网络。",
    "context10": "(4)提出多文档摘要技术面临的主要挑战和未来发展方向。"
  },
  "2多文档摘要技术与改进方法": "",
  "2.1单文档摘要与多文档摘要": {
    "context1": "单文档摘要通常通过关注句子间的关系评估句子的重要性,生成简洁且全面的摘要。多文档摘要既注意句子间的关系,也注意文档间的关系，实现过程更为复杂。在多文档摘要任务中，输入文档数量过多通常会增加模型负担，可能导致模型退化问题;不同文档信息之间可能存在冲突或重复，因此生成摘要过程中既要保证摘要的连贯性还要降低冗余性。两类任务常用的数据集、应用领域和技术难点如表1所示。"
  },
  "2.2多文档摘要实现一般框架": {
    "context1": "多文档摘要实现的一般框架如图1所示，通常可分为文档连接、文档预处理、摘要内容选择、组织排序、摘要生成5个模块。",
    "context2": "多文档摘要任务涉及文档数量庞大且文档间可能会存在冗余、矛盾或互相补充等情况。为完整捕捉跨文档文本单元之间的关系，一般需要在输入前对多个文档进行连接。然后,进行停止词删除、词干分析、特殊字符删除、分割、打标签等预处理,将完整的文本划分为段落、句子或者短语等文本单元。作为任务中最关键的一环,摘要内容选择首先生成文档内容表示、理解文档含义,然后根据特征规则或概率模型对句子进行权重分配,再根据权重选择句子或生成词语组成候选摘要。最后,组织候选摘要中的文本单元,增强摘要的连贯性,多数方法将句子按照其在源文档的原位置进行排序。",
    "context3": "表1单文档摘要与多文档摘要联系与区别  \nTable 1Relationship and Difference Between Single Document Summary and Multi-Document Summary",
    "context4": "<table><tr><td colspan=\"2\">常用数据集</td><td>开始年限</td><td>应用领域</td><td>技术难点</td></tr><tr><td rowspan=\"5\">单文档摘要</td><td rowspan=\"3\">Gigaword LCSTS[14] CNN/DM Newsroom[15]</td><td rowspan=\"3\">1958年</td><td>领域论文摘要自动生成</td><td></td></tr><tr><td></td><td>(1)模型大多具有普适性,但在细分 场景下生成摘要细节含量不足;</td></tr><tr><td>文献自动标引</td><td>(2)生成摘要可能存在事实性错误。</td></tr><tr><td rowspan=\"3\">Rotten Tomatoes DUC/TAC</td><td></td><td>新闻标题生成 新闻、产品评论等多种形式文档信息的总结</td><td>(1)跨文档句子间关系的建模;</td></tr><tr><td>WikiSum</td><td>智能机器人[17] 20世纪80年代</td><td></td></tr><tr><td>ScisummNet[18] Multi-News</td><td>临床试验干预的有效性预测[19]</td><td>(2)生成摘要冗余性高、覆盖细节信 息不全、可能存在事实性错误。</td></tr></table>",
    "context5": "![](images/dff4cc1d2459ae43c30d3a37048f126e92da98ad0e3a79a42aa426753e9b845a.jpg)  \n图1多文档摘要实现一般框架  \nFig.1General Framework Diagram of Multi-Document Summarization"
  },
  "2.3多文档摘要关键技术": {
    "context1": "(1)源文档连接",
    "context2": "按照连接层次的不同,源文档连接方式可分为平滑连接[4.20]和分层连接。平滑连接通常直接拼接多个文档,采用单文档摘要的思想进行处理。其中,突出长文档中的核心内容是摘要技术的难点。Zhao等[21提出在连接前根据文档中心性对源文档内容进行重要性排序的方法，降序选择内容拼接输入。分层连接通过建模语篇关系中的不同层次结构,保留跨文档关系,使模型获得更丰富的文档含义[22]。",
    "context3": "按照实现技术的不同,连接方式可以分为基于图结构的方法和基于聚类的方法。基于图结构的方法通常以相似图、主题图或语篇图等形式实现文本单元的连接,再通过合适的算法选取显著性高的句子。基于聚类的方法则是将具有特定关系的文本单元进行聚类,再从中选取显著性高的信息作为摘要。",
    "context4": "$\\textcircled{1}$ 基于图结构的文档连接方法",
    "context5": "传统基于图结构的多文档摘要方法通常基于句子相似性构建关系图,再利用图排序算法计算顶点权重值，最后选择权重较高的句子形成摘要。该方法无需标注数据集，只依赖于任意句子对间的相似性和迭代计算，具体流程如图2所示。传统方法只简单地对句子重要性进行建模,没有挖掘文档间的深层关系，生成的摘要冗余性偏高。",
    "context6": "基于图神经网络的方法可以更好地捕捉到图中句子间的语义语法关系,摘要效果远好于传统方法。Antognini等[23]使用预训练模型和长短期记忆（LongShort-TermMemory,LSTM)模型得到句子的通用嵌入和特定领域嵌入，通过图卷积网络(GraphConvolutionalNetwork,GCN)合并句子关系图和特定领域嵌入获得每个句子的高级表示，从而使模型更好地理解文档内容，捕捉跨文档关系。基于图神经网络的摘要流程如图3所示。",
    "context7": "![](images/8c26e6854ae776a3e2f08aa9f9332e9084dc357aa4aa62fc5166fd5eb263c791.jpg)  \n图2传统基于图结构的多文档摘要方法流程 Fig.2Traditional Graph-Based Multi-Document Summarization Algorithm Process Flow Chart",
    "context8": "![](images/ae9ea4cf4953d4ca49607beb9dd115ba057e1cfdca2966a2993af10286a5e2b2.jpg)  \n图3基于图神经网络的多文档摘要技术 Fig.3Multi-Document Summarization Technology Based on Graph Neural Network",
    "context9": "然而,基于神经网络的模型效果依赖于训练数据,而多文档摘要训练数据制作较为困难,无监督或半监督的多文档摘要技术因此成为研究热点。Zhao等[24提出一种基于句图压缩的无监督多文档摘要方法，该方法主要考虑句子间的语篇关系，以近似话语图为基础结合深度嵌入技术构建句子图,根据图中句子间的距离形成语义簇，然后使用压缩技术将每个簇压缩为一个代表显著内容的单句。但该方法过于依赖外部规则,容易出现错误传播。针对此问题，Wang等[25]将给定文档 $D$ 划分为更小的文本单元 $d =$ $\\{ d _ { 1 } , d _ { 2 } , . . . , d _ { n } \\}$ ，利用更小的文本单元构造异构图 $G =$ $( V , E )$ ,图中包括段落节点 $V _ { \\mathfrak { p } }$ 、词语节点 $\\boldsymbol { V } _ { \\boldsymbol { W } }$ 以及不同节点间的无向边 $E$ ,图中同类节点内部不存在边,有效抑制了错误传播问题。为减少计算量,Zhou等[26]使用实体节点代替词语节点，应用图注意网络实现节点之间的信息流动,并迭代更新节点表示。受异构图的启发,Cui等[27采用神经主题模型发现潜在主题,利用主题作为文本单元连接文档，并提供全局信息指导摘要的生成。",
    "context10": "为捕捉更丰富的跨文档信息，Li等[28]利用图注意机制将图表示融入编码过程中,并使用图结构指导解码过程。在此基础上,Hickmann等[29]对比分析以句子或段落两种粒度节点作为顶点的句子图指导生成的摘要质量，发现基于段落的方法性能更好。为保证摘要的覆盖率和连贯性，Chen等[30]将摘要任务抽象为子图选择问题,认为子图间具有相似节点代表摘要存在冗余，而带有不连通节点则表示摘要不连贯。上述分析了多种基于图的多文档摘要模型,具体内容如表2所示。",
    "context11": "表2基于图的多文档摘要模型  \nTable 2Multi-Document Summary Model Based on Graph",
    "context12": "<table><tr><td>模型</td><td>节点</td><td>边</td><td>边权重</td><td>方法</td></tr><tr><td>SemSentSum</td><td>句子</td><td>句子-句子</td><td>余弦相似度(边缘消除)</td><td>图卷积网络</td></tr><tr><td>SummPip</td><td>句子</td><td>句子-句子</td><td>近似话语图</td><td>无监督句子压缩</td></tr><tr><td>HeterSumGraph</td><td>单词、句子、文档</td><td>单词-句子 单词-文档</td><td>TF-IDF</td><td>图注意力网络</td></tr><tr><td>EMSum</td><td>段落、实体</td><td>段落-实体</td><td>TF-IDF</td><td>图注意力网络</td></tr><tr><td rowspan=\"2\">GraphSum</td><td rowspan=\"2\">段落</td><td rowspan=\"2\">段落-段落</td><td>TF-IDF相似图 基于LDA主题模型图</td><td rowspan=\"2\">分层图注意力网络</td></tr><tr><td>近似话语图</td></tr><tr><td rowspan=\"2\">SgSum</td><td rowspan=\"2\">句子</td><td rowspan=\"2\">句子-句子</td><td>TF-IDF相似图</td><td rowspan=\"2\">分层图注意力网络</td></tr><tr><td>基于LDA主题模型图 近似话语图</td></tr></table>",
    "context13": "图神经网络从句子图中学习句间关系和语义表示，可以拟合多个领域的数据,生成摘要质量较高但也存在自身问题。比如，已有基于图的方法一般综合考虑单词、句子或者段落之间的关系,很少考虑到文档级别。由于文档中句子和单词数量过多,因此基于图的方法在面对较长文本输入时可能会存在计算资源需求过大的问题。除此之外,部分图方法受限于大规模数据集的缺乏而难以适用于低资源领域。",
    "context14": "$\\textcircled{2}$ 基于聚类的文档连接方法",
    "context15": "传统基于聚类的摘要方法通常在无监督的情况下进行[31],通过计算给定文档集群 $D = \\{ d _ { 1 } , d _ { 2 } , . . . ,$ $d _ { \\mathbf { \\Gamma } _ { n } } \\}$ 中句子 $\\{ S _ { i , j } \\}$ 的相似度，构成聚类 $C =$ $\\{ c _ { 1 } , c _ { 2 } , . . . , c _ { n } \\}$ ,并在聚类中选择距离质心最近的句子作为摘要。聚类的数量、方式、类别以及粒度等条件决定了生成摘要的质量。Alambo等[32]构建了一个以主题为中心的无监督多文档摘要框架,通过文档间的相似性比较突显核心文档,将外围文档的语义单元通过相似性聚类到对应集群中，最后选择主题覆盖率最大的路径生成摘要。此外,输入文档多数是有固定结构的文本，而生活中则有大量有价值的非结构化信息,为有效利用这些信息,Saeed等[33]利用两级聚类技术生成多个加权节点的链接集，通过邻接图连接文档集群实现跨文档连接。一般的聚类方法专注于句子主题,很少考虑句子间存在不对齐的情况,为解决此问题,Ernst等[34]使用OpenIE在更细粒度的命题级别提取释义命题,避免对非对齐文本进行分组,然后微调跨语言模型并将命题二分类，在对命题进行聚类打分后，融合高分文本簇生成摘要。还有些研究侧重考虑句子位置、句子长度、聚类数量等影响摘要生成质量和覆盖范围的重要指标,提出多目标优化下的聚类方法。例如,Alqaisi等[35提出一种基于聚类的多目标优化方法,通过使用带有 Silhouette的K-Medoid聚类算法识别源文档的主要主题并确定聚类数量，采用NSGA-II算法同时最大化三个独立目标：覆盖率、相关性和多样性。",
    "context16": "在基于聚类方法生成的摘要中，每个句子都可以连接到生成该句子的一组主题或者命题,为输出提供了解释说明。这些解释可以扩展知识,为生成句子提供来自源文档中上下文的事实补充。但受限于聚类算法本身的缺点，在面临低资源数据集时，可能会产生不同类别下数据不平衡的情况，导致摘要句质量不均。"
  },
  "(2)摘要内容选择": {
    "context1": "摘要内容选择通常分为三个步骤：文本单元语义的理解与表示、句子重要性估计和候选摘要集的生成。",
    "context2": "$\\textcircled{1}$ 语义理解与表示技术",
    "context3": "1)基于Transformer模型的语义理解与表示方法",
    "context4": "生成式摘要最初依赖于卷积神经网络（ConvolutionalNeural Networks,CNN)和循环神经网络（Recurrent Neural Networks,RNN)的结构,捕获输入序列中包含的顺序关系和句法语义信息，但两种模型都存在自身的局限性。由于卷积核尺寸的限制，CNN只能通过增加层次并行处理更多文本信息,因此难以捕获远程信息,更难以跨文档建模语义单元的关系;过长的输入序列会导致RNN模型发生梯度爆炸或消失。多文档摘要任务多使用LSTM、Bi-LSTM或者门控循环单元(GatedRecurrent Unit,GRU)克服上述问题[36-37]。",
    "context5": "Transformer模型的非循环体系结构可以更有效地解决上述问题。Transformer模型由注意力机制组成，部分常见注意力机制如图4所示，其中每个方格为一个标记。",
    "context6": "输入序列过长增加了端到端架构的训练难度，为解决此问题,Liu等[4提出一种两阶段架构，利用抽取模型选择显著性高的段落,再通过Transformer模型生成摘要。该方法将多个输入文档视为单个文档,没有考虑文档间的层次结构和关系。针对此问题，Liu等39]提出分层编码方式，利用局部Transformer模型进行段落级编码,通过逻辑回归函数选择评分靠前的段落编码,进行多头池化操作后再利用全局Transformer模型使被选择段落可以从其他段落收集信息，捕获上下文关系。针对生成摘要存在的细节覆盖不足问题,Perez-Beltrachini等[40]利用行列式点过程引导Tranformer模型分配权重，提升生成摘要的多样性和主题相关性。为突显源文档中的重要信息,Liu等[41]为每个输入序列构建高亮矩阵,以表示关键短语在矩阵中的位置和重要性,引入单头和多头突出注意力机制,在编码环节赋予关键短语更大的权重。然而，简单的自我注意力机制和跨文档分享注意力机制并不能完全捕捉到文档间语义关系,Ma等[42]将依存分析与Transformer体系结构相结合，在编码部分引入外部解析器捕捉依存关系树，通过语言引导的多头注意力机制,将依赖解析信息和源文档结合起来,以互补的方式生成语义丰富的特征。",
    "context7": "![](images/ddc21469d47e4062586ac4be06132b712ba4d267fc5f93c39e3868fd606b6b4e.jpg)  \n图4不同注意力机制图示[38]  \nFig.4Overview of Various Attention Mechanisms",
    "context8": "Transformer模型采用自注意力机制捕捉输入序列中任意位置的依赖关系，因此它在处理不同位置的单词时并不改变它们之间的距离，这种特性使得Transformer模型可以更好地捕捉跨文档关系，准许更长的输入序列。虽然Transformer的结构解决了CNN和RNN不能并行计算的问题，但其捕捉局部细节信息能力较差，效率不高。除此之外，Transformer模型的位置编码在语义空间中并不具有可变换性,仅作为人为设计的一类索引,因此将位置编码与生成词向量相加不能很好地表征位置信息。本节对基于Transformer的编码器-解码器的结构和注意力机制的改进进行全面总结，如表3所示。",
    "context9": "表3基于Transformer模型的多文档摘要模型  \nTable 3Multi-Document Summary Model Based on Transformer Model",
    "context10": "<table><tr><td>模型</td><td>Transformer结构</td><td>注意力机制</td><td>文本单元</td></tr><tr><td>T-DMCA</td><td>仅含解码器 Transformer模型</td><td>自我注意力机制 记忆压缩注意力机制</td><td>词语</td></tr><tr><td>Hierarchical Transformer</td><td>分层 Transformer模型</td><td>段落间注意力机制 全局注意力机制</td><td>词语、段落</td></tr><tr><td>CopyTransformer+DPPs</td><td>普通 Transformer模型</td><td>基于行列式点过程分配注意力权重</td><td>词语、句子</td></tr><tr><td>Highlight-Transformer</td><td>普通 Transformer模型</td><td>单头突出注意力机制 多头突出注意力机制</td><td>关键短语</td></tr><tr><td>ParsingSum-Transformer</td><td>分层 Transformer模型 普通 Transformer模型</td><td>利用依存关系引导多头注意力机制</td><td>词语、句子</td></tr></table>",
    "context11": "2)基于预训练模型的语义理解与表示方法",
    "context12": "最近研究表明,迁移学习(TransferLearning)可以有效提升大多数自然语言处理任务的性能。当前,预训练模型也常见于摘要任务[43-45],但大多数都集中在训练数据丰富的单文档摘要任务中。为探索预训练模型在多文档摘要任务中的表现,Goodwin等[46]比较在Few-Shot 和 Zero-Shot 学习设置下BART[47] $\\mathrm { T } 5 ^ { [ 4 8 ] }$ 和PEGASUS[49]三种预训练模型在4种摘要数据集上生成摘要的质量，实验表明，在Few-Shot的学习设置下,三种模型的评估结果差别不大,证明预训练模型在多文档摘要任务中还存在改进空间。",
    "context13": "基于通用预训练模型方法：BART预训练模型是由Facebook提出的基于双向和自回归Transformer架构的预训练模型,相比于BERT模型更适用于序列生成任务。为处理更长的输入序列，Pasunuru等38]将包括本地和全局注意机制的Longformer[50]集成到BART模型中，在每个句子后加入全局注意力机制并探索各种尺寸的上下文局部注意机制窗口，使模型可以对更长文档进行编码。除此之外,还利用单独的图编码器将图编码集成到BART模型中，有效提升了模型的整体性能。输入文档过程中，直接通过线性模型进行连接可能导致信息与共享背景产生冲突，对生成摘要产生不良影响,为此,Moro等[51基于BERT语言模型进行三元组的训练,通过梯度下降使共享背景下源文档生成目标摘要的概率最大化,得到生成文档的潜在表示，为摘要生成部分消除噪音。除BART模型外，还有一些针对长序列输入的语言模型如T5模型和BigBird[52]模型也适用于多文档摘要任务。Guo等[53]在T5模型的注意力机制基础上，将PEGASUS模型中的预训练策略引入可伸缩的T5架构中，提出新的瞬时全局注意力机制，关注文档内部关系的同时有效地动态捕捉跨文档信息。",
    "context14": "基于特定任务预训练模型方法：PEGASUS模型是特定用于生成式文档摘要任务的预训练模型，遵循间隙句生成目标方法的思想，以自我监督的方法屏蔽重要句子,再通过解码过程按顺序恢复、连接句子并用作目标摘要训练模型生成最终摘要。受此启发,Xiao等[54]提出新的间隙句生成目标句子掩蔽策略，开发了用于多文档摘要任务的预训练模型PRIMERA。该模型使用通用高效的Longformer-Encoder-Decoder(LED)模型处理源文档,基于关键实体估计句子重要性,屏蔽文档中显著句子后训练模型根据上下文信息重构句子，使模型学会识别和聚合相关文档群中的显著信息，减少对大型数据集的依赖。由于PRIMERA模型根据实体选择重要句子,参考摘要由不同源位置的句子组成,导致其不连贯。Puduppully等[55]提出基于质心的摘要方法，在排除噪声文档后以信息量最大的文档作为参考摘要，将其余文档作为输入在NewSHead语料库对LED模型进行训练，生成摘要评估结果优于",
    "context15": "PRIMERA模型。",
    "context16": "综上，大多数方法偏向于在编码器中结合预训练语言模型捕获跨文档关系，但没能很好地解决输入特征过长和二次记忆增长的问题。由实验结果可知,通用预训练模型在多文档摘要任务中效果不够理想，而特定预训练语言模型还没有得到很好的探索。",
    "context17": "$\\textcircled{2}$ 候选摘要集的生成技术",
    "context18": "理解输入文档语义后，应根据权重选择相应的句子或生成新的单词组成摘要候选集。在文本单元的选择上，不应该仅考虑文本单元的权重，还应该考虑高权重文本单元之间的重复性等指标，避免生成摘要具有过高的冗余性。",
    "context19": "1)传统的摘要候选集生成方法",
    "context20": "在深度学习出现之前，文档摘要选择候选摘要集合通常采用基于最大边界相关（MaximalMarginalRelevance,MMR)算法、贪心算法、元启发式算法等传统算法。",
    "context21": "MMR算法[5]旨在在保证相关性的基础上降低摘要的冗余性，具体实现如公式1所示。",
    "context22": "$$\n{ \\cal M } { \\cal M } R { = } a r g m a x \\Biggl [ \\lambda S i m _ { 1 } ( S _ { i } , D ) { - } ( 1 { - } \\lambda ) \\operatorname * { m a x } _ { S _ { j } \\in S } S i m _ { 2 } ( S _ { i } , S _ { j } ) \\Biggr ]\n$$",
    "context23": "其中， $R$ 是候选句子的集合， $S$ 是已选择的句子的集合， $R \\backslash S$ 是未选择的句子的集合。 $S i m _ { 1 }$ 表示第 $i$ 句与文档的相似度, $S i m _ { 2 }$ 表示候选句子与已选句子的相似度,λ为可调参数。举例来说,Akhtar等[57]在选择摘要句的过程中，通过结合句子本身特征评分与MMR分数，引导模型选择分数较高且与已选摘要句相似度较低的句子作为最终摘要。",
    "context24": "贪心算法相当于MMR算法的一种变形，该算法在文本摘要中从相关度最高的句子开始选取,迭代地添加文本单元直到最大限度。在求解问题时，贪心算法并不考虑整体情况的最优解，而是考虑当前情况的最优解，因此,贪心策略的选择与生成摘要质量直接相关。",
    "context25": "元启发式算法不依赖算法组织结构,因此拥有更加通用的启发式策略,更有可能收敛到全局最优解。"
  },
  "2)基于指针生成网络模型的方法": {
    "context1": "一般的基于Seq2Seq架构的多文档摘要方法存在事实细节复现不准确、无法处理词汇表外单词以及生成摘要冗余性高的缺点。指针生成网络[58]作为带有Attention机制的编码器-解码器模型融合了指针网络、CopyNet与覆盖机制的功能,既可以通过指向从源文本中复制单词,也可以保留产生新单词的功能,具体结构如图5所示。",
    "context2": "![](images/08e3803f8727cc2fb83687873e8d3436289c75234cf8511168829e25f174f645.jpg)  \n图5指针生成网络结构[58]  \nFig.5Structure of Poniter-Generator-Network",
    "context3": "指针生成网络具有复制和生成的功能。模型通过编码和解码过程中的时序变量计算出某一时刻的生成概率 $p _ { g e n }$ ，利用 $p _ { g e n }$ 可以将词汇表中生成的单词和从原文中复制的单词结合起来。利用指针生成网络相当于构建扩展词汇表，既包含原有词汇表又包含句子中含有的单词,有效解决了词汇表中未登录词的问题。",
    "context4": "PG-MMR[59]和Hi-MAP[5]模型均使用MMR算法融合指针生成网络生成摘要的方法，但是MMR算法在其中的作用不同。PG-MMR模型通过考虑句子的长度、句子的绝对或相对位置、句子质量和句子文档相似性得到每个句子的重要性估计，将得分最高的句子输入指针网络生成新句子，再根据MMR算法迭代选择句子直到超过最大摘要长度限制。Hi-MAP模型则是先通过MMR算法对多文档摘要源句进行筛选,然后在生成摘要的过程中利用每个句子的MMR算法分数修改注意力权重，以平衡生成摘要的重要性和冗余性。由于源文档输入过长和结构稀疏的特点，从源文档中提取显著性信息是一项具有挑战性的任务。Chen等[6]通过构建事件语义图并利用图序列匹配进行主导事件检测，再使用引入事件语义权重的事件感知指针生成器对关键事件进行总结生成最终摘要，有效突出了源文档中的显著的事件信息。",
    "context5": "指针生成网络解决了生成摘要冗余性高和存在事实性错误的问题,提高了生成摘要的细节准确率，更适用于生成式多文档摘要。但指针生成网络架构较为复杂，训练过程相较于其他模型更加困难。"
  },
  "3)基于强化学习的方法": {
    "context1": "不同于元启发式算法输出最优解的结果,强化学习是求解一个最优策略的过程。如果经过一个策略时由从状态空间映射到动作空间得到的解是最优的，那么这个策略就叫做最优策略。强化学习融合了动态规划和马尔科夫决策过程的基本框架，将多文档摘要过程看作序列优化问题。为组合优化多文档生成摘要质量,Su等[6]提出一种新的基于强化学习的框架PoBRL，使用强化学习的方法单独优化子问题,最后利用PoBRL将每个学习到的策略混合在一起，生成简洁而完整的表示摘要。在PoBRL先提取后生成的摘要框架中，训练过程中抽取模块以最大似然估计为目标,选择与参考摘要具有高相似度的句子;而在测试过程中,抽取模块与生成模块相接，抽取的最终目标则是提供显著内容。为解决抽取模块目标在训练和测试时不一致的问题,Song等[62]提出一种测试时间目标优化的方法,依据信用意识自我批评学习进行微调,将奖励定义为选定句子S作为输入到生成模块输出句子的质量，基于探索行为的影响重新分配奖励，通过梯度下降获得最大预期奖励。一般方法普遍针对有限的参考摘要和简单的最大似然目标进行训练，为提升多文档摘要训练的效率,Parnell等[63]通过奖励平衡ROUGE评估参数和覆盖率，利用策略梯度的低方差和无偏的现代梯度估计器RELAX，以少量负对数似然(NegativeLogLikehood)方式微调预训练模型,有效地限制计算量并降低了参数飘移的风险。",
    "context2": "多文档摘要存在输入数据量大、冗余性高以及内容矛盾的情况，目前的基于强化学习的方法通常不需要显示模型，难以掌握动态环境，只能通过简单的试错不断探索，有可能导致采样效率低下。"
  },
  "3多文档摘要数据集及评价指标": "",
  "3.1多文档摘要数据集": {
    "context1": "受限于主题一致性和文档的数量，高质量大规模多文档数据集数量较少，每个数据集的创建方式和特点如下。",
    "context2": "DUC/TAC数据集：全部来自各个主题下的新闻领域,数据集样本量大约在百量级且含有人工注释的参考摘要，既适用于单文档摘要也适用于多文档摘要,但仅适用于摘要模型的测评。",
    "context3": "WikiSum数据集：通过将英文维基百科文章的生成视为一个基于有监督多文档摘要任务，输入由维基百科文章主题和该文章的非维基百科的参考文档集合组成,以生成维基百科文章为目标,获得大规模多文档摘要数据集WikiSum。文章大致被分为80/10/10个训练/开发/测试子集,分别得到1865 750、233252和232998个示例。WikiSum数据集的数据来源包含多个领域,更适用于生成式摘要任务的训练和评估。",
    "context4": "ScisummNet数据集:第一个大型人工注释科学论文语料库，源文档来源于ACL文集论文的引用网络和被引用次数最多的1000篇参考文献，参考摘要则是由CL/NLP专家人工撰写生成。",
    "context5": "Multi-News数据集：第一个大规模多文档摘要新闻数据集，源文档数据由newser.com网站上的新闻文章组成,参考摘要由专业编辑撰写，除此之外该数据集中还包含引用的原始文章的链接。Multi-News数据集规模庞大、来源广泛，其中超过1500个网站作为源文档来源达到5次及以上，适用于多文档摘要神经模型的训练。",
    "context6": "Multi-XScience数据集[64]：通过搜集arXiv论文,使用微软学术图构建多文献对和参考摘要。Multi-XScience数据集的训练/开发/测试的文章数为$3 0 ~ 3 6 9 / 5 ~ 0 6 6 / 5 ~ 0 9 3$ ,源文档数量较短,与其他通用数据集相比包含更少的位置和提取偏差，因此更适用于具有高度文本抽象性的摘要模型。",
    "context7": "WCEP数据集[65]：以WCEP中的新闻源文章和在Common CrawlNews 数据库中搜索类似文章作为源文档，以新闻事件在WCEP中的摘要作为参考摘要构建数据集。在应用方面，WCEP数据集与现实世界用例有更好的一致性。",
    "context8": "HowSumm数据集[66]：多文档摘要包含一种特殊的面向查询的多文档摘要[7-68]（Query-focusedMulti-document Summarization）,旨在从多个文档中抽取相关信息，并生成与用户查询相关的简洁摘要。面向查询的多文档摘要除了要对源文档进行总结，生成的摘要还需要与查询问题密切相关。HowSumm数据集就是以查询为中心的多文档摘要数据集。创建者通过在wikihow.com网站上搜集具有特殊结构的\"how-to\"文章,以wikiHow文章的引用文章作为源文档,将标题定义为查询问题。\"how-to\"文章的主要内容根据主标题分为如何做某件事的步骤与每件步骤的次级标题。按照查询标题层级的不同分为步骤询问和方法询问,拼接不同文章中相应的回答内容得到参考摘要。HowSumm数据集包含11121个长摘要和84348个短摘要,适用于教育、工业和清洁领域。"
  },
  "3.2常用评价方法": {
    "context1": "多文档摘要的评价方法通常分为人工评价和自动评价的方法。人工评价从摘要内容、可读性和流畅性三个方面进行打分，自动评价通过计算生成摘要与参考摘要的相似性判断摘要质量。"
  },
  "(1)人工评价": {
    "context1": "人工评价方法是通过取若干专家根据标准摘要对生成摘要评分的均值进行评定的方法。从评价方式上来看，摘要评价受到专家主观性的影响，因此常在评价部分引用金字塔(Pyramid)[9方法降低人工差异性对分数的影响。该方法定义摘要内容单元（SummaryContentUnits)作为参考摘要的基本单元。摘要内容单元是受语义影响的含有完整主谓成分的从句，其权重与单元在摘要中出现的频率相关。最终评分由全部单元在生成摘要中的权重和与其在每个参考摘要权重和的比值组成。人工评价方法的效率受多文档摘要数据规模影响,因此目前研究通常使用自动评价方法。"
  },
  "(2)自动评价": {
    "context1": "相比人工方法，自动评价方法可以节省大量的时间和人力，但更注重生成摘要与参考摘要间的相似性，忽视了生成摘要的可读性和流畅性，因此其精准程度低于人工评价方法。自动评价算法可以大致分为ROUGE[70]算法和基本元素法[71]。"
  },
  "$\\textcircled{1}$ ROUGE算法": {
    "context1": "受BLEU/NIST算法评价机器翻译[72]的启发，Lin等[70提出计算在摘要对中共同出现的一元模型数量进行评估的方法。ROUGE是评估生成摘要的一组指标，通过计算生成摘要与参考摘要的单元重叠度得到摘要对的相似性进行评估。",
    "context2": "ROUGE-N ( $( \\mathrm { N } { = } 1 , 2 , 3 , 4 )$ 的值为每个n－gram在摘要对中共同出现的最大频数和与参考摘要中每个n-gram出现的频数和的比值,如公式(2)",
    "context3": "所示。",
    "context4": "$$\nR O U G E - N =\n$$",
    "context5": "$$\n\\frac { \\sum _ { S \\in \\{ R E F S u m m a r i e s \\} } \\sum _ { n - g r a m e S } C o u n t ( n - g a r m ) _ { _ { S i m } } } { \\sum _ { S \\in \\{ R E F S u m m a r i e s \\} } \\sum _ { n - g r a m e S } C o u n t ( n - g a r m ) }\n$$",
    "context6": "其中， $n \\mathrm { ~ - ~ } g r a m$ 表示 $n$ 元词，{REFSummaries表示参考摘要集合， $S$ 表示一个参考摘要， $C o u n t ( n \\mathrm { ~ - ~ }$ garm），表示生成摘要和参考摘要中同时存在的 $n \\mathrm { ~ - ~ }$ gram数量, $C o u n t ( n - g a r m )$ 表示参考摘要中存在的n-gram数量。",
    "context7": "$\\textcircled{2}$ 基本元素法",
    "context8": "基本元素法基于语义依存分析（SemanticDependencyParsing,SDP）,其定义由计算机自动抽取的最小语义单元作为评价生成摘要的基本单元。在对摘要对进行基本元素抽取之后，以特定方式对基本元素进行变换,保证基本元素形式一致，最后根据摘要对中基本元素的重叠程度对自动摘要进行打分。由于构建的依存关系树可能存在误差，该方法的评分结果可能会受到影响。",
    "context9": "作为最常见的摘要评估方法，除了以上两种评估算法外，还存在多种形式的多文档摘要自动评估指标。Gao等[73]提出一种无监督的多文档摘要评价指标 SUPERT,用于比较生成摘要与伪参考摘要之间的语义相似性。SUPERT利用上下文向量嵌入和软标记对齐技术从输入文档中选择重要信息以评估摘要质量。Wolhandler等[74]提出一种用于评估摘要“分散\"程度即覆盖其内容所需的源文档数量的评估方法。该方法对源文档的一个给定子集定义覆盖率评分，再通过增加最小文档数提升覆盖率得分至最高，最后通过测量所有规模子集下汇总信息数量得到相应的覆盖率曲线。",
    "context10": "除上述评价方法外，摘要评估还可以在没有参考摘要的情况下进行。通过利用生成摘要代替源文档作为其他的自然语言处理子任务如机器问答、文本分类等的输入数据,以子任务完成的质量间接体现摘要质量，这种评价方法一般被称为外部测评。但该方法也有一定的缺陷，如不存在统一的评价标准,耗时长且更加依赖于任务应用的场景。综上，人工评价方法更加全面,但是随着多文档摘要数据集规模增大,摘要对间的比对需要耗费的时间和人力"
  }
}