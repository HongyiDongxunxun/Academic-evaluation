{
  "original_filename": "full_4752.md",
  "处理流程视角下的大数据技术发展现状与趋势": {
    "context1": "陆泉12张良韬1",
    "context2": "1.武汉大学信息管理学院，武汉，430072；2.武汉大学信息资源研究中心，武汉，430072][摘要]随着大数据研究的蓬勃发展，其相关技术产品也日趋多样复杂。本文首先归纳了由数据采集、数据预处理、数据存储与管理、数据分析与数据展示构成的大数据一般处理流程，进而从流程中各阶段角度梳理了现有大数据技术，对主要技术产品进行归类与分析，并对各阶段所面临的问题与未来的发展趋势进行讨论与总结，以建立处理流程视角下的大数据技术全景视图，为大数据技术的研究与应用发展提供指导。",
    "context3": "［关键词］大数据处理流程技术产品开源人工智能隐私安全",
    "context4": "[中图分类号］TP311;TP391[文献标识码]A[文章编号］2095-2171(2017)04-0017-12   \nDOI:10.13365/j.jirm.2017.04.017",
    "context5": "Evolutive Status and Trends of Big Data Technology from the Perspective of Process Flow",
    "context6": "Lu Quan1,2Zhang Liangtao1",
    "context7": "(1.School of Information Management，Wuhan University，Wuhan，430072; 2.Center for Studies of Information Resources of Wuhan University,Wuhan,430072)",
    "context8": "[Abstract]With the vigorous development of big data researches，the related technology products are becoming more and more complicated.This paper first summarizes the general processng flow of large data composed of data acquisition，data preprocessing，data storage and management，data analysis and data display，and then combs the existing big data technology from various stages of the process，classifies and analyses the primary technical products.Besides，we also discuss and summarize the problems and future development trends of each stage to establish a big data technology panorama view from the perspective of process flow，and provide guidance for the development and application of big data technology.",
    "context9": "[Key words]Big dataProcessing flowTechnology product Open source Arificial intelligencePrivacy security"
  },
  "1引言": {
    "context1": "当前，随着互联网的高速发展、云计算技术的成熟以及移动终端和数据感应器的出现和普及，人们在生活中产生的数据量呈现指数级的增长。截至2014年6月底，中国互联网基础数据显示网民数量达到6.32亿，手机网民数量达到5.27亿，网站数达到 $2 7 3 \\ \\overline { { \\mathcal { F } } } ^ { [ 1 ] }$ ,这导致海量数据的产生。而根据国际数据公司",
    "context2": "IDC 检测，人类产生的数据量大约每2年翻一番，由此可知大数据的发展已经势不可挡。",
    "context3": "大数据目前还未有一个确切的定义，各行各业有着自己的见解，但总体而言，其关键在于从数量庞大、种类繁多的数据中提取出有用的信息。大数据主要具有以下四个方面的典型特征：规模性（Volume）、多样性（Varity）、高速性（Velocity）和价值性（Value），即所谓的“4V\"特性[2]。IBM的资深大数据专家Jeff Jo-nas提出要让数据“说话”，从而发现和理解信息内容及信息与信息之间的关系[3]。大数据的出现也转变了人类分析数据的态度，主要体现在以下三个方面：要全体而不是抽样，即利用所有的数据而不是仅仅依靠一小部分数据；要效率不要精确，即更加追求数据的分析效率而不是追求精确度；要相关不要因果，即只需要知道数据结果会是这样而不需要知道为什么会是这样。",
    "context4": "大数据已成为一个新兴产业，其相关技术的运用可以帮助人们实现多个领域如科研教学、环境保护、金融经济、工程技术、生物医疗等的突破，如何将海量数据进行有效分析并加以利用，是大数据最重要的研发意义所在，目前许多公司都推出了自己的大数据相关技术产品，如 IBM的DB2、CognOs与 SPSS,惠普的Vertica 分析平台以及 Haven 大数据平台，Google的Big Query等等，在各个领域都得到了广泛的应用。本文主要基于大数据处理流程视角梳理分析大数据技术产品与相关研究，有利于帮助人们了解现有大数据技术工具，对利用大数据进行管理及应用设计有着较大的作用。"
  },
  "2基于大数据处理流程的主流技术工具分析": {
    "context1": "目前，人们对于大数据处理流程的认识都比较统一，基本可以划分为数据采集、数据预处理、数据存储与管理、数据分析与数据展示5个阶段，即利用Flume、Splunk 等工具从数据源采集数据，用DataStage等进行预处理，为后继流程提供统一的高质量的数据集，然后将这些数据使用SQL、NoSQL等数据库技术进行集成和存储，分门别类地进行放置，再用合适的技术对其进行分析挖掘，并将最终的结果利用可视化技术如Tableau、Qlik 等展现给用户，这就是整个大数据处理的流程，图1为大数据技术框架示意。",
    "context2": "![](images/9798e9bd4562b4b9be67432d0d9fed427de49adaba5ae4b448c4f6780f362ae7.jpg)  \n图1大数据技术框架"
  },
  "2.1数据采集": {
    "context1": "数据采集连接了计算机与外部物理世界，是大数据处理流程中最基础的一步，Kwon 等人从数据质量管理和数据使用经验层次解释了大数据分析中的数据采集意图[4]，阐述了有效的数据采集方案对于大数据研究具有重要意义。随着大数据越来越被重视，数据采集的挑战变得尤为突出，因此本节比较了几种流行的数据采集工具，它们大多抽象出了输入、输出和中间缓冲的架构，利用分布式的网络连接，实现一定程度的扩展性和可靠性。本节从扩展性、系统架构、系统特点方面对典型大数据采集工具进行了比较，如表1所示。",
    "context2": "表1数据采集工具对比表",
    "context3": "<table><tr><td rowspan=1 colspan=1>软件工具</td><td rowspan=1 colspan=1>扩展性</td><td rowspan=1 colspan=1>系统架构</td><td rowspan=1 colspan=1>系统特点</td></tr><tr><td rowspan=1 colspan=1>Flume[5]</td><td rowspan=1 colspan=1>高扩展性，采用多Master的方式，拥有丰富的自带插件</td><td rowspan=1 colspan=1>分布式管道架构</td><td rowspan=1 colspan=1>主要处理流数据事件，其使用JRuby来构建，依赖于Ja-va运行环境</td></tr><tr><td rowspan=1 colspan=1>Fluent[6]</td><td rowspan=1 colspan=1>高扩展性，客户可以自己定制（Ruby）In-put/Buffer/Output</td><td rowspan=1 colspan=1>可插拔架构</td><td rowspan=1 colspan=1>使用C/Ruby开发，采用JSON统一数据/日志格式，专为处理数据流设计，不支持Windows平台</td></tr><tr><td rowspan=1 colspan=1>Splunk[7]</td><td rowspan=1 colspan=1>可扩展性较低，可以通过开发Input和Modular Input的方式来获取特定的数据</td><td rowspan=1 colspan=1>分布式机</td><td rowspan=1 colspan=1>商业化大数据平台产品，提供很多具体化应用，多平台支持，具有日志聚合功能；搜索功能；提取意义；可视化功能；电子邮件提醒功能等等</td></tr></table>",
    "context4": "在数据采集相关研究中，如何更好更快地采集数据一直是其中的热点，刘富源等人结合Fluentd和HDFS，设计了一个分布式日志收集系统，可以从多种异构平台和应用收集日志，并将日志存储于 HDFS上[8]。付华峥等人提出了一种基于标签树节点权重的正文提取算法，并应用于分布式大数据采集系统，从而能够高效获取网络数据[9]。在大数据背景下，解决数据采集过程中的数据量、实时性、传输速率等问题，是研究者更进一步研究的重点。"
  },
  "2.2数据预处理": {
    "context1": "大数据通过获取、处理和分析大规模异构数据得到有价值的信息，然而获取和处理数据的规模、速度以及格式均会影响数据质量，给大数据分析带来困难。数据质量已经成为大数据处理流程中的难题，数据预处理主要包含了数据清理、数据集成、数据变换和数据归约等基本功能，有助于解决数据质量问题。常用ETL(extract、transform、load)工具负责处理各类分布的结构化、半结构化以及非结构化数据，对其进行清洗、转换、集成以及管理。Ban-sal提出了一种语义ETL框架，使用语义技术集成和发布来自于各个源的开放链接数据，创建语义数据模型，为数据可视化分析和语义查询提供了便利[10]。本节对主流ETL工具进行简单介绍。",
    "context2": "目前市场上主流的 ETL工具有IBM公司的DataStage[11]、Informatica 公司的 Informati-caPowercenter[12]、免费 ETL工具Kettle[13]等，均以图形化界面配置完成作业设计和任务设计，实现快速地开发和部署，并且提供了丰富的数据映射和转换函数。对以上三种工具从应用能力、抽取容错性、安全性以及语言支持方面进行简单地比较，结果如表2所示。",
    "context3": "表2ETL工具对比表",
    "context4": "<table><tr><td rowspan=1 colspan=1>ETL工具操作性质</td><td rowspan=1 colspan=1>Datastage</td><td rowspan=1 colspan=1>InformaticaPowerCenter</td><td rowspan=1 colspan=1>Kettle</td></tr><tr><td rowspan=1 colspan=1>应用能力</td><td rowspan=1 colspan=1>具有优秀的文本文件和XML文件的读取和处理能力</td><td rowspan=1 colspan=1>可访问和集成几乎任何业务系统、任何格式的数据提供了多个可选组件以扩展核心数据集成功能</td><td rowspan=1 colspan=1>提供丰富的SDK，开放了源代码以便于二次开发包装</td></tr><tr><td rowspan=1 colspan=1>抽取容错性</td><td rowspan=1 colspan=1>没有真正的Recovery机制</td><td rowspan=1 colspan=1>抽取出错的恢复(Recovery)可实现断点续传的功能</td><td rowspan=1 colspan=1>无 Recovery功能</td></tr><tr><td rowspan=1 colspan=1>安全性</td><td rowspan=1 colspan=1>只提供 Developer 和 Oper-ator</td><td rowspan=1 colspan=1>多范围的用户角色和操作权限权限可以分到用户或组使用细致的锁(Lock)</td><td rowspan=1 colspan=1>简单的用户管理功能</td></tr><tr><td rowspan=1 colspan=1>语言支持</td><td rowspan=1 colspan=1>支持目前几乎所有的编码格式</td><td rowspan=1 colspan=1>支持丰富的编码格式</td><td rowspan=1 colspan=1>支持常见的编码格式</td></tr></table>",
    "context5": "ETL工具应用于大数据的预处理阶段，主要为了提高大数据的数据质量，Sun设计了一种通用ETL工具，可以屏蔽异构数据源访问的差异，提供了大量转换组件，以便灵活处理复杂的业务应用[14];Song基于MapReduce 设计了一种分布式ETL体系结构，提高了ETL系统的运行效率[15]。ETL工具既有优势也有其自身的局限性，如不便扩展维护，过程不便调试与纠错等，因此需要更进一步地研究开发。"
  },
  "2.3数据存储与管理": {
    "context1": "在大数据处理流程中，数据存储与管理是十分重要的一环，为数据分析提供访问控制能力。目前大多数应用需要针对特定种类的数据建立专门的数据库进行存储，从而减少数据查询和访问的时间，以支持后续的数据分析流程。常用数据库技术大体分为三类，以MySq[16]、Microsoft SQL Server[17]和 Oracle[18]等为代表的SQL数据库，以 HBase[19]、MongoDB[20]和Re-dis[21]等为代表的 NoSQL数据库，以及以 Post-greSQL[22]、 ${ \\mathsf { N u o D B } } ^ { [ 2 3 ] }$ 和VoltDB[24]等为代表的NewSQL数据库。SQL、NoSQL、NewSQL数据库专为特定应用程序设计，具有不同的数据模型，并依赖于不同的底层数学[25]。需要注意的是，NoSQL并不是指 Not SQL,而是 Not Only SQL,SQL功能在之后进行了添加，除此之外NewS-QL数据库也包含SQL接口，因此它不仅具有NoSQL对海量数据的存储管理能力，还保持了传统数据库支持ACID(原子性、一致性、独立性以及持久性)和 SQL等的特性，同时具备了可扩展和高性能性。",
    "context2": "为了更好地了解不同类型的数据库，本文根据2016年12月数据库流行度排行榜[26]选取第一位和第二位的SQL数据库即Oracle 和MySQL，常用排行第五位以及第九位的NoSQL数据库即MongoDB和REdis，以及排行第四位的 NewSQL 数据库 PostgreSQL进行比较分析，如表3所示，以便帮助我们更好地了解当前数据库技术。",
    "context3": "表3数据库对比表",
    "context4": "<table><tr><td rowspan=1 colspan=1>数据库性质</td><td rowspan=1 colspan=1>Oracle</td><td rowspan=1 colspan=1>Mysql</td><td rowspan=1 colspan=1>MongoDB</td><td rowspan=1 colspan=1>Redis</td><td rowspan=1 colspan=1>PostgreSQL</td></tr><tr><td rowspan=1 colspan=1>数据库类型</td><td rowspan=1 colspan=1>SQL数据库</td><td rowspan=1 colspan=1>SQL数据库</td><td rowspan=1 colspan=1>NoSQL数据库</td><td rowspan=1 colspan=1>NoSQL数据库</td><td rowspan=1 colspan=1>NewSQL数据库</td></tr><tr><td rowspan=1 colspan=1>数据库模型</td><td rowspan=1 colspan=1>关系数据库系统</td><td rowspan=1 colspan=1>关系数据库系统</td><td rowspan=1 colspan=1>文档存储</td><td rowspan=1 colspan=1>键-值存储</td><td rowspan=1 colspan=1>关系数据库系统</td></tr><tr><td rowspan=1 colspan=1>实现语言</td><td rowspan=1 colspan=1>C和C++</td><td rowspan=1 colspan=1>C和C++</td><td rowspan=1 colspan=1>C++</td><td rowspan=1 colspan=1>C</td><td rowspan=1 colspan=1>C</td></tr><tr><td rowspan=1 colspan=1>SQL支持</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>否</td><td rowspan=1 colspan=1>否</td><td rowspan=1 colspan=1>是</td></tr><tr><td rowspan=1 colspan=1>是否结构化数据</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>自由</td><td rowspan=1 colspan=1>自由</td><td rowspan=1 colspan=1>是</td></tr><tr><td rowspan=1 colspan=1>是否预定义数据类型</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>部分</td><td rowspan=1 colspan=1>是</td></tr><tr><td rowspan=1 colspan=1>API以及其他访问方式</td><td rowspan=1 colspan=1>ODP.NETOracle Call In-terface(OCI)JDBCODBC</td><td rowspan=1 colspan=1>ADO.NETJDBCODBC</td><td rowspan=1 colspan=1>使用_JSON的专用协议</td><td rowspan=1 colspan=1>专用协议</td><td rowspan=1 colspan=1>native C librarystreaming APi forlarge objectsADO.NETJDBCODBC</td></tr><tr><td rowspan=1 colspan=1>是否支持事务</td><td rowspan=1 colspan=1>ACID</td><td rowspan=1 colspan=1>ACID</td><td rowspan=1 colspan=1>否</td><td rowspan=1 colspan=1>乐观锁机制，原子性执行的命令块和脚本</td><td rowspan=1 colspan=1>ACID</td></tr><tr><td rowspan=1 colspan=1>访问控制</td><td rowspan=1 colspan=1>根据SQL标准的细粒度访问权限</td><td rowspan=1 colspan=1>细粒度的用户访问权限</td><td rowspan=1 colspan=1>基于用户和角色的访问权限</td><td rowspan=1 colspan=1>简单的基于密码的访问控制</td><td rowspan=1 colspan=1>根据SQL标准的细粒度访问权限</td></tr></table>",
    "context5": "为不同种类的数据建立合适的数据库，可以有效减少数据查询和修改的时间，提高数据访问速度。目前在数据库方面的研究已相对成熟，然而在一些复杂的应用场景中，单一类型的数据库并不能完全满足人们对于海量数据存储管理、复杂分析和实时处理等多方面的需求，因此对不同类型的数据库进行混合部署将成为满足人们需求的选择之一。李东奎和鄂海红基于 Hibernate OGM为 SQL 和 NoSQL存储建立了统一的访问模型，能够按照统一规则对两类数据库进行读写[27]；Doshi等人针对企业大数据的挑战提出了混合SQL和NewS-QL方法，以便及时获取业务洞察，改进业务结果[28]。根据具体场景应用不同类型的数据库进行混合部署，有利于发挥每种类型数据库的特点和优势，使得数据库之间形成互补，从而保证数据资源的优化利用，这也是未来大数据存储发展的趋势所在。"
  },
  "2.4数据分析": {
    "context1": "面对大数据海量性、多样性以及异构性的特点，传统的统计工具已经难以应付，无法满足大数据分析的需求，因此人们需要扩展分析方法思路。而在大数据分析技术方面，Google公司成绩斐然，其内部各种数据的应用都是依托自主研发的一系列云计算技术[29]，例如分布式文件系统GFS[30]、批处理技术MapReduce[31]和分布式处理平台 Ha-doop[32]，以及Apache的实时计算系统Storm[33]等，这些系统和平台的产生，对大数据分析起到了支撑作用。",
    "context2": "掌握适用于大数据分析处理的软件工具，已经是研究者所必须掌握的知识技能。在实际的研究流程中，需要根据不同的应用情况选择合适的工具，甚至多种工具组合使用，一些情况需要研究者使用Java、R、Python 等编程语言自行编译程序以便研究的进行。本文仅介绍当前大数据研究分析所涉及到的一些技术平台和相关软件工具，并阐述其应用特点和适合场景，以便研究者更好地了解与使用，如表4所示。",
    "context3": "表4数据分析工具对比表",
    "context4": "<table><tr><td rowspan=1 colspan=1>软件工具</td><td rowspan=1 colspan=1>描述</td><td rowspan=1 colspan=1>优点</td><td rowspan=1 colspan=1>缺点</td></tr><tr><td rowspan=1 colspan=1>Hadoop</td><td rowspan=1 colspan=1>对大量数据进行分布式处理的开源软件框架，适用于批处理</td><td rowspan=1 colspan=1>高可靠性；高扩展性；高效性；高容错性；可以处理超大文件；对应急需求比较低，只须运行在低廉的商用硬件集群上，因此成本较低</td><td rowspan=1 colspan=1>不适合低延迟数据访问；无法高效存储大量的小文件；不支持多用户写入及任意修改文件；图计算与迭代计算不友好</td></tr><tr><td rowspan=1 colspan=1>Storm</td><td rowspan=1 colspan=1>开源软件，一个分布式的实时计算系统，适用于流处理</td><td rowspan=1 colspan=1>高扩展性；高容错性；快速—基准测试每节点每秒处理数百万字节数据；可靠性一每组数据至少处理一次；易于使用；低延迟数据处理</td><td rowspan=1 colspan=1>安装配置较为复杂，无综合指南可用；虽然提供了关键性能指标来衡量性能和可靠性，但并不足以称为用户友好，没有报告模块；对硬件要求较高</td></tr><tr><td rowspan=1 colspan=1>GoogleDreme[34]</td><td rowspan=1 colspan=1>组建规模成千上万的集群，处理PB级别的数据，适用于交互式计算</td><td rowspan=1 colspan=1>高扩展性；提供容错执行，嵌套的数据模型；能深入查看数据；能在海量数据中同时执行多个查询操作；大规模数据分析，规模与速度并存；提供高级SQL语言表达即席查询，查询方便，易于理解；列存储，降低CPU成本；结合了Web搜索和并行DBMS技术；弥补MR交互式查询能力的不足</td><td rowspan=1 colspan=1>数据只读，不支持修改或者建立功能，也没有表索引；按列分割数据，最后经常需要把列再组合成记录，组合数据比较耗时</td></tr><tr><td rowspan=1 colspan=1>RapidMiner</td><td rowspan=1 colspan=1>开源软件，应用于数据挖掘</td><td rowspan=1 colspan=1>免费提供数据挖掘技术和库，具有丰富数据挖掘分析和算法功能；简化数据挖掘流程的设计和评价，可以用简单脚本语言自动进行大规模进程；图形用户界面的互动原型，多层次的数据视图，确保有效透明数据；标准化格式减少数据处理复杂度</td><td rowspan=1 colspan=1>数据量过大会导致无法获取完整数据集；扩展性较低，优化较难</td></tr><tr><td rowspan=1 colspan=1>Weka[35]</td><td rowspan=1 colspan=1>开源软件，应用于基于JAVA环境的机器学习以及数据挖掘</td><td rowspan=1 colspan=1>集合了大量能承担数据挖掘任务的机器学习算法如分类，回归、聚类、关联规则等等；为数据挖掘整个流程提供了全面支持</td><td rowspan=1 colspan=1>数据预处理和结果分析较为麻烦；对数据格式要求严格</td></tr><tr><td rowspan=1 colspan=1>Gephi[36]</td><td rowspan=1 colspan=1>开源软件，适用于如信息传播，社交网络等的关系分析</td><td rowspan=1 colspan=1>擅长解决图网络分析的很多需求，其插件众多，功能强且易用；支持多种格式的文件输入，支持应用插件，更具可扩展性，满足用户对不同数据的处理需求</td><td rowspan=1 colspan=1>由java编写，限制了处理性能，如分析百万级节点关系时，需先做平滑和剪枝处理；处理更大规模（如亿级以上）的关系网络数据，则需要专门的图关系数据库如GraphLab/GraphX来支撑，其技术要求会相对较高</td></tr></table>",
    "context5": "除上述具体产品工具以外，科研人员对大数据分析也进行了一些技术上的研发改进。在大数据环境下有时需要对一些半结构化或非结构化的数据进行挖掘，由此Gubanov 等人设计了一种大规模文本文件的检索与挖掘技术[37],Kang等人研发了一种针对图片文件的挖掘技术[38];Nickel等人提供了一个可以审查大规模知识图谱的统计模型，可以从web 中自动构建知识图形[39];Kourou等人采用机器学习如人工神经网络、支持向量机、贝叶斯网络等检测来自复杂数据集的关键特征，为癌症分析提供支持[40]。除此之外，借助人工智能技术，特别是深度学习研究和大规模神经网络构建，进行大数据分析，是研究的趋势所在。"
  },
  "2.5数据展示": {
    "context1": "对于用户而言，最关心的并不是数据的处理分析流程，而是对其结果的展示与解释，因此，在一个完整的大数据处理流程中，数据结果的展示步骤至关重要。若数据分析的结果不能得到恰当的展示，则会影响到用户对数据的理解、处理与利用。为了提升数据解释与展示能力，数据可视化技术作为解释大数据的有力方式，被大多数企业引入。",
    "context2": "数据可视化就是利用计算机技术将数据以图形、图像的方式表示出来，并且支持交互处理，使人们可以直观地发现数据之间的内在联系，如Citespace工具能够分析和可视文献之间的共被引关系，显示一个学科或知识域在一定时期发展的趋势与动向[41]。对于大数据而言，一些数据分析工具如 SPSS[42]、Gephi、Weka等都具备可视化交互界面。单就可视化展现工具而言，目前市场上比较流行的有Tab-leau[43]、Qlik[44]以及 IBM Cognos[45]等,三者在数据交互和数据整合功能上都较为优秀，但也有着各自的特点，本节对以上三种工具进行了多方面比较，如表5所示。",
    "context3": "表5可视化工具对比表",
    "context4": "<table><tr><td rowspan=1 colspan=1>应用特点</td><td rowspan=1 colspan=1>Tableau</td><td rowspan=1 colspan=1>Qlik</td><td rowspan=1 colspan=1>IBM Cognos</td></tr><tr><td rowspan=1 colspan=1>可视化深入程度</td><td rowspan=1 colspan=1>优秀</td><td rowspan=1 colspan=1>一般</td><td rowspan=1 colspan=1>一般</td></tr><tr><td rowspan=1 colspan=1>可扩展性</td><td rowspan=1 colspan=1>良好</td><td rowspan=1 colspan=1>仅限RAM</td><td rowspan=1 colspan=1>良好</td></tr><tr><td rowspan=1 colspan=1>大数据支持能力</td><td rowspan=1 colspan=1>较好</td><td rowspan=1 colspan=1>一般</td><td rowspan=1 colspan=1>一般，属于传统BI产品</td></tr><tr><td rowspan=1 colspan=1>映射支持</td><td rowspan=1 colspan=1>优秀</td><td rowspan=1 colspan=1>一般</td><td rowspan=1 colspan=1>优秀</td></tr><tr><td rowspan=1 colspan=1>OLAP cubes 支持</td><td rowspan=1 colspan=1>是</td><td rowspan=1 colspan=1>否</td><td rowspan=1 colspan=1>是</td></tr><tr><td rowspan=1 colspan=1>最大容量</td><td rowspan=1 colspan=1>无限</td><td rowspan=1 colspan=1>数十亿行</td><td rowspan=1 colspan=1>无限</td></tr><tr><td rowspan=1 colspan=1>多维模型化处理能力</td><td rowspan=1 colspan=1>良好</td><td rowspan=1 colspan=1>一般</td><td rowspan=1 colspan=1>良好</td></tr><tr><td rowspan=1 colspan=1>API支持能力</td><td rowspan=1 colspan=1>优秀</td><td rowspan=1 colspan=1>良好</td><td rowspan=1 colspan=1>一般</td></tr></table>",
    "context5": "数据展示主要是以更直观和互动的方式展示分析结果，便于人们理解。目前可视化技术多与web技术相结合，三维动态可视化以及交互式可视化将是发展趋势。罗毅等人采用三维可视化重建技术评估儿童活体肝移植供着肝脏解剖情况，表现出了良好的展示效果[46];Moore等人采用了3D热图的交互式可视化方法探索微生物组成及其与健康疾病间的关系[47];Soklakova等人也利用了名为D3.js的交互式可视化技术对大学教职工以及发展进行了研究[48]。对大数据进行可视化探索仍处于初始阶段，需要人们对算法和模型进行进一步的研究，以便应对复杂结构的大数据。"
  },
  "3处理流程视角下大数据面临的问题": {
    "context1": "大数据的出现，对人们生活和社会发展产生了巨大影响。随着研究的深入，大数据给人们带来便利的同时，其发展也面临着诸多问题，本节从处理流程视角出发对大数据面临问题进行了分析。"
  },
  "3.1大数据采集面临的问题": {
    "context1": "在大数据时代，数据采集面临的最主要问题并非技术层面的问题，而是社会层面的问题，即数据孤岛现象。目前各行各业都产生了大量的数据，成为一个碎片化的“庞然大物”，无论是政府还是企业，部门与部门之间的数据尚且不能完全透明、开放，因此要求它们对外开放数据也就更加困难，而这些数据的不开放，就会导致大数据的市场相对狭险，很多创新的应用无法实现，也会使得政府和企业的决策缺乏相关大数据的支撑。",
    "context2": "电子科技大学周涛教授提出了大数据发展的3.0时代，即随着社会法律法规的健全，数据处理工具的丰富，数据交换规模的扩大，企业可以将内部数据包装成产品对外服务[49]。大数据3.0实际上就是消除数据孤岛现象，只有通过对数据进行聚集与融合，才能让来自不同行业的大数据产生关联和融合效应，发挥出“ $1 + 1 { > } 2 ^ { \\mathfrak { s } }$ 的效果。",
    "context3": "数据孤岛主要分为物理孤岛和逻辑孤岛，物理孤岛即数据物理上的孤立性，各行各业对其数据独立存储和维护，相互之间没有交流，造成数据的重复和资源的浪费，因此消除物理孤岛需要数据的集中存储和开放公布；逻辑孤岛即数据逻辑上的孤立性，各行各业对于数据的存储有着各自的规范，造成同样数据有着不同定义，因此消除逻辑孤岛要求制定数据规范，定义数据标准，使用唯一标识来确定数据。总而言之，消除数据孤岛需要全社会的共同参与，仍是一个任重而道远的过程。"
  },
  "3.2大数据预处理面临的问题": {
    "context1": "大数据具有规模性、多样性、高速性和价值性等明显的时代特征，因此在进行数据预处理的过程中，有更大可能产生数据的质量问题。如果没有良好的数据质量，将会加深大数据分析的难度，甚至得到错误的结果，从而影响人们做出决策等，因此如何解决质量问题，并且进行质量管理，是预处理过程中的核心问题。",
    "context2": "在进行大数据分析之前必须对数据的质量问题进行有效地处理，才能分析出有价值的信息，通过进行错误发现及修复可以解决数据的质量问题，从而获取高质量的数据。Taleb等人提出包含流程的QBD模型，通过追踪和记录发生在预处理阶段的数据转换效果，从而支撑数据选取以保证数据质量[50]；于飞等人针对Web日志数据预处理中会话识别这一环节，提出了一种优化的数据清洗方法，可以有效提高会话识别的质量[51]。",
    "context3": "大数据本身的特点也为数据的质量管理带来了诸多挑战。大数据的规模巨大并且增长速度快，因此大数据的质量管理需要更快的计算速度，在规定的时间范围内实现数据质量管理，分布式并行计算方法是其中的解决方案之一。Dedoop[52]工具可以将指定的工作流自动转换为 MapReduce 作业，以便在不同的 Hadoop 集群上并行执行，提高计算速度，并且支持无冗余的多次分块以及先进的负载平衡方案。同时大数据的价值密度低下，难以认知其全貌，对语义识别带来了困难，当前可以通过提取互联网信息从而获取相应的语义信息。Li等人采用了名为WebPut的原型系统利用不完整数据库中的可用信息制定了能够高精度高效地检索缺失值的web 搜索查询，为每一个缺失值自动选择最有效的插补方案[53]。Arasu等人也针对大数据特点，提出了半结构化和非结构化数据的清洗以及超大规模数据的集成方案[54]。数据的预处理关乎最终结果的准确度，对辅助决策有着重要的影响，需要研究者持之以恒的进行探索优化，从而解决数据的质量问题。"
  },
  "3.3大数据存储与管理面临的问题": {
    "context1": "数据的存储与管理和大数据应用密切相关，其发展也面临着几个重要的问题，一是规模问题，大数据主要应对高量级的数据，因此要求数据存储系统具有一定的扩展能力，以便增加容量存储数据；二是实时问题，大数据有时会要求对数据进行即时处理，因此要求数据存储系统能保持较高的响应速度，提升数据处理能力。",
    "context2": "为了应对上述问题，需要为多样性的数据建立合适的存储方案，由此各类技术如分布式缓存、分布式数据库、分布式文件系统等应运而生。Corbett等人介绍了Google的分布式事物系统数据库Spanner[55];lwazume 等人在开发大规模信息基础设施时引入了分布式内存数据库系统okuyama[56]；Jiang等人设计了名为 Clover的分布式文件系统，易于扩展，能够提升元数据的操作性[57]；Yanbo等人基于 Ha-doop 平台和MongoDB数据库设计了非结构化云存储平台，从而改善了非结构化数据的存储服务质量[58]。除分布式存储方案以外，各大数据库厂商如Oracle、IBM等面向大数据存储也都相应推出自己的产品，其中IBM提出了一种新型存储技术 SCM(Storage Class Memo-ry)[59]，引入了闪存和 PCM（Phase-ChangeMemory)等新型存储介质，产生了新型主存架构，使得大数据存储架构有了更多选择。",
    "context3": "近年来提出了一种叫做数据湖的新型数据存储概念，其主要是将数据或信息汇集到一个结合处理速度和存储空间的大数据系统—Hadoop集群或内存解决方案，以便访问数据进行探索。数据湖将其内部原始的信息字节相互整合分析，从而产生新的效益[60]。然而目前数据湖面临着重大挑战，市场研究机构Gartner提出数据湖需要针对不同的使用场合、并发性和多租户水平进行优化，同时其缺乏语义一致性和经过治理的元数据，因此对用户自身的技能素养要求较高，需要使用者认识或了解关于如何采集数据的上下文偏见，知道如何合并和协调不同的数据源，了解数据集的不完整性等等[61]。与此同时，数据湖中很多数据永远不会删除，所需存储空间架构庞大，其信息安全问题也显得极为突出[62]，因此科学界和工业界还需要在数据湖的存储和安全方面做更多工作。"
  },
  "3.4大数据分析面临的问题": {
    "context1": "传统的数据分析方法并不能满足大数据的要求，因此在大数据环境下对传统方法进行改进和开发新的算法也就成了必然。与此同时，大多数用户并不能自主研发算法工具协助自己进行大数据分析，因此他们对于各类专业大数据分析工具的需求也越来越急迫，这也是大数据分析所面临的重要问题。",
    "context2": "大数据分析主要关注传统的数据挖掘、文本处理、语义分析以及机器学习等方法在大数据环境下的改进。Chu等人结合了RBF神经网络与粗糙集理论提出了一种新的数据挖掘算法，可用于挖掘分类规则[63]；传统文本处理方法也有了改进，李宁等提出了一种基于MapRe-duce 计算框架的并行PLSA算法，可运用于文本挖掘和语义分析，并表现出了良好的效果[64];赵华茗提出了一种基于 Hadoop 分布式环境，结合Hive平台和PostgreSQL数据库的文档相似度计算方法[65]，并且还构建了一种基于分布式环境的文本聚类与分类应用平台[66]，可以有效解决海量文本的词聚类瓶颈问题。",
    "context3": "目前，软件工具是人们处理事务的主要形式，通过将事务处理的整个过程进行设计优化，并利用编程语言进行实现，可以极大方便人们的生活和工作。当前我们所熟知的数据分析工具有SPSS、SAS和R等，但是这些工具已经不能直接处理大数据所包含的海量半结构化和非结构化数据，所以开发专业的大数据分析工具已经成为必然。在研发大数据分析工具的过程中，需要考虑大数据分析流程的复杂性，并且从大数据自身特点出发考虑其分析工具的开发和平台的建设，针对不同分析对象进行相应的设计优化，从而保证大数据分析工具对其任务的支持度和匹配度。"
  },
  "3.5大数据展示面临的问题": {
    "context1": "数据展示是大数据处理流程的最后一个阶段，也可以说是最重要的一个阶段，常用可视化技术展现数据分析结果，通过图形清晰有效地表达数据，发现原始数据中不易观察到的数据联系。",
    "context2": "大数据可视化面临最大的一个挑战就是规模[67]，如何提出新的可视化方法帮助人们分析大规模、多样化、价值密度低的数据，并辅助决策，成为这个领域最大的挑战。Arlro等人设计了一个分布式可视化算法，可以在几分钟内绘制大约一百万条边的图[68];Okubo等人开发了名为不规则趋势搜索的大数据可视化工具，用于分析大量数据的时间戳和层次结构[69]；大多数可视化工具有着视觉表示问题，仅支持有限的交互式组件以供用户浏览和查询屏幕上的数据,Wee采用了名为ADT(the A-daptiveDiversityTable)的技术来解决视觉表示问题，可以更为有效地分析所提供的数据集[70]；Du等人集成了基于地图视图、日历视图和趋势视图的几种可视化方法，对空气质量进行综合分析[71]。",
    "context3": "目前对大数据的可视化探索还处于初级阶段，新型可视化产品面对大数据的快速增长，需要更快地收集、筛选、分析、归纳、展示相关信息，因此对实时性有了更高的要求，同时也需要更丰富的展现方式以及创新的交互方式，以便对大数据进行可视化交互和辅助决策。"
  },
  "4大数据发展趋势": {
    "context1": "大数据依赖于快速增长的社会资源，随着科学技术的不断提升，大数据也越来越展现出自身的价值，从而推动社会的进步，并且自身也将呈现出新的发展趋势。"
  },
  "4.1开源将成为大数据技术的主流": {
    "context1": "开源是技术发展的主要推动力之一，大数据处理相关的技术领域已经取得了较大的突破，产生了各类实用稳定的技术工具，基于此本文初步构建的从处理流程出发的大数据基本技术框架，而其中以 Hadoop、NoSQL数据库等为代表的技术都是开源软件。",
    "context2": "开源即在相关平台上进行源代码的开放，吸引全世界开发者来进行代码的开发、维护和完善，并基于自己的兴趣写出更好的、多样化的软件工具并进行分享，从而推动技术的不断进步。大数据的核心技术如分布式存储、云计算等均依赖于开源模式，当前全球各大企业如微软、VMware、EMC、Google等也都在开源的大趋势下纷纷开放了自身部分核心技术代码，加大了对开源的赞助和投入，由此可以看出，开源在大数据技术进步中产生了重要的影响，在全世界开发者的共同协助下，也将成为大数据技术创新的主要途径，从而引领大数据技术的蓬勃发展。"
  },
  "4.2大数据与人工智能的融合": {
    "context1": "大数据的核心并不是对于数据的简单统计分析，而是从海量的数据中获取人们未曾发现的深层次的有用知识，而一些知识往往需要人类智能的参与才能完成，因此需要计算机提升对于数据的认知能力，对人类的意识、思维过程进行模拟，能够像人类那样进行思考，具备感知、理解最终决策的能力，并且在计算机高计算能力的基础上，能够比人脑做得更快、更准确，而这些背后的核心技术就是人工智能。",
    "context2": "人工智能通过感知环境，对面临的环境有一个理解，最终在理解的基础上做出决策，并且能够进行自我学习，随着经验的积累而不断演化，对于人工智能而言，数据就是经验，随着经验演化也就是伴随着数据的不断增长，从而提升自身的能力。我们正处于大数据时代，各行各业无时不刻产生着海量的数据，这也就为人工智能的发展提供了沃土，两者融合将促进技术的进步和社会的发展。",
    "context3": "而深度学习将成为大数据智能分析的核心技术，百度首席科学家吴恩达(Andrew Ng)表示深度算法将和大数据结合，改进人工智能算法，产生人工智能的良性循环[72]。深度学习试图模仿大脑神经元之间传递、处理信息的模式，其本质是多层神经网络。目前深度学习应用于计算机视觉、语音识别以及自然语言处理等领域，结合大数据去延伸或互补人类的能力，对于人工智能的发展有着极其重要的影响。"
  },
  "4.3提高大数据的安全与隐私能力": {
    "context1": "随着互联网和物联网的发展，数据的来源和应用领域越来越广泛，计算机的出现使得越来越多的数据以数字化的形式存储在电脑中，因此大数据在存储、处理、传输等过程中面临着安全风险。",
    "context2": "解决大数据的安全与隐私问题，是保障大数据发展的重要内容。Roy等人提出了一种基于MapReduce的隐私保护系统Airavat，可以控制敏感数据的安全策略，防止信息泄露[73]；匿名保护是实现结构化数据隐私保护的核心手段，Cheng等人基于改进的微集合算法设计了一种满足不同敏感价值的保护等级的多样化k-匿名化模型[74]；数字水印技术也被应用于大数据存储时对于其可信性的保护，Guo等人通过将数据库指纹信息嵌入到水印中，一旦发现可疑拷贝，可以提供数字置信水平以识别所有者和非法分发者，从而保护有价值的数值关系数据免受非法复制和重新分配[75]；在大数据的传输、处理过程中，数据溯源技术可用于帮助人们确定各项数据的来源，以便验算结果的正确性或者用于文件的溯源与恢复，邓仲华等人对数据溯源本体模型、开放型数据源模型和基于DNA双螺旋结构的数据溯源模型进行了比较和评估，从而设计了一种层次划分的数据溯源安全模型[76]。与此同时，大数据本身也是解决信息安全问题的有效手段，基于大数据的威胁发现技术、身份认证技术、数据真实性分析方法[77]等为信息安全领域的发展带来了新的契机。",
    "context3": "提高大数据的安全与隐私能力，除了从技术手段出发以外，还需要社会各界的参与，加强对大数据安全形势的宣传，培养相关专业人才，政府部门也需要制定和完善相关法律制度，保障大数据的安全与隐私。"
  },
  "4.4大数据与“物云移\"融合发展": {
    "context1": "大数据的发展离不开物联网、云计算和移动互联网等技术的支持，《互联网进化论》一书中绘制了一副互联网虚拟大脑结构图，描述了大数据与“物云移”之间的关系[78]，其中物联网对应了虚拟听觉系统、虚拟视觉系统、虚拟感觉系统、虚拟运动系统等，云计算集合了互联网的核心硬件层和软件层，移动互联网作为一种数据传入形式，大数据则代表了互联网信息层，接收和汇聚来自物联网、云计算和移动互联网传输的数据，形成数据海洋。",
    "context2": "物联网的数据来源于音频采集器、视频采集器、各类传感器以及各种生活办公设备等等，其产生的数据体现了大规模性、异构性和多样性。针对物联网在不同行业的特性，使用大数据技术对其进行探索，从而产生实际的价值，价值推动需求，需求改进技术，因此物联网的发展也推动了大数据技术的进步。",
    "context3": "大数据以其海量的规模而得名，云计算和云应用在云平台的支撑下，让这庞大的数据得以保存和处理，同时在云计算的背景下，数据中心向着大规模共享平台推进，实现了软硬件资源的高度整合。EMC总裁基辛格认为大数据和云之间存在很多合力的地方，强调大数据应用必须在云设施上实行[79]，由此，大数据推动云计算的实施，云计算促进大数据的应用。",
    "context4": "截止2017年第一季度，中国移动互联网用户已经达到11.2亿[80]，用户对于移动产品的选择越来越多，也就更加注重移动互联网的使用场景和个性化需求。一方面，移动互联网行业在满足这些需求的同时，也提升了大数据的质量，丰富了大数据的类型;另一方面，用户个性化需求凸显促使移动互联网行业进入精细化运营阶段，使得数据分析技术成为移动互联网的核心竞争力，从而促进了大数据的发展。"
  },
  "5结语": {
    "context1": "目前，大数据的研究已经涉及到社会生活、商务经济、国防军事、科学研究等各方面，但依然存在着诸多挑战，人们必须面对规模更加庞大、结构更加复杂的大数据，这也促使着人们对于技术的探索和研究。",
    "context2": "本文在大数据背景分析基础上，归纳了大数据的5阶段处理流程，并基于该流程分析梳理了目前市场上大数据的主要技术产品和相关研究，总结了各阶段技术所面临的问题，最后指出大数据技术将向开源、智能化、安全及与\"物云移\"融合等方向发展。"
  },
  "参考文献": {
    "context1": "[1] CNNIC.中国互联网发展研究基础数据[EB/OL].[2017-05-04].htp://www.cnnic.cn/hlwfzyj/jcsj/[2] Zhou ZH，ChawlaNV,JinY，et al. Big dataoportunities and chalenges: Discussions from data analytics perspec-tives[discussion forum][J].IEEE Computational Intelligence Magazine，2014，9(4):62-74[3] 中国指数网.让数据\"发声\"[EB/OL].[2017-05-12].http://www.idx365.com/bigData/cont966.html[4] Kwon O,Lee N，Shin B.Data quality management，data usage experience and acquisition intention of big data ana-lytics[J].International Journal of Information Management，2014，34(3):387-394[5] Hari Shreedharan著，马延辉，史东杰译.Flume:构建高可用、可扩展的海量日志采集系统[M].北京：电子工业出版社，2015:10-29[6] 韩岩，李晓.用Fluent与MongoDB 构建高效海量日志采集系统[J].中国新技术新产品，2014(12):31-33[7] Zadrozny P，Kodali R.Big dataanalytics using splunk：Deriving operational inteligence from social media，machinedata，existing data warehouses，and other rea-time streaming sources[M].Berkeley:Apress,2013:3-15[8] 刘富源,王春露.基于Fluentd和 HDFS的日志收集系统设计与实现[EB/OL].[2016-12-20].htp://www.paper.edu .cn/html/releasepaper/[9] 付华峰，陈独，向勇等.分布式大数据采集关键技术研究与实现[J].广东通信技术，2015，35(10)：7-10[10]Bansal S K.Towards asemantic Extract-Transform-Load (ETL）framework for big data integration[C]//IEEE Inter-national Congress on Big Data,Alasku,USA.IEEE，2014:522-529[11]宋鹏，廉继红.ETL技术在复杂数据迁移项目中的应用[J].西安工程大学学报，2008，22(4):493-497[12]刘叶.基于Informatica的数据质量设计在数字供电中的应用[J].电子技术与软件工程，2014(19)：92-93[13]何涛.使用 ETL工具 Kettle实现图书馆联盟信息系统数据集成[J].科学咨询：决策管理，2009(11):47-48[14] Sun A.Researchand Implementation of auniversal ETL tool[J].Computer Aplications& Software,2012，29(12):  \n175-178[15]Sng J.Research of distrbuted ETLarchitecture basedon MapReduce[J].Computer Science，2013，40(6):152-154[16]SchramA，AndersonKM.MySQLtoNoSQL:Data modelingchalenges insupportingscalability[C]//ACMConferenceonSystems，Programming,Languagesand Applications：Software for Humanity，Porland,USA.ACM,2012:191-202[17]Larson B.Delivering businessinteligence with Microsoft SQL Server 2012[M].New York:McGraw-Hil Education.  \n2012:3-6[18]王海翔.Oracle数据库软件研究[J].现代商贸工业，2010，22(11):357-358[19]George L. HBase：The definitive guide[J]. Andre，2011，12(1):1-4[20] Jiang W,ZhangL,Liao X,et al.A novelclustered MongoDB-based storage system for unstructured data with high a-vailability[J].Computing，2014，96(6):455-478[21]马豫星.Redis 数据库特性分析[J].物联网技术，2015(3):105-106"
  }
}