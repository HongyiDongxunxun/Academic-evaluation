{
  "original_filename": "full_1426.md",
  "nothing": {
    "context1": "$\\bullet$ 刘轩，陈海彬²",
    "context2": "（1．中国人民公安大学法学院，北京100038；2．中国人民公安大学侦查学院，北京100038)"
  },
  "人工智能监管：理论、模式与趋势": {
    "context1": "摘要：［目的/意义］随着人工智能在经济社会中的广泛应用，加强对人工智能的监管治理，控制其内在风险已成为全球共识，考察世界主要国家和地区的监管设计，对于完善我国人工智能监管体系具有重要意义。[方法/过程］通过文献分析、比较分析的方法，明确人工智能监管的概念和人工智能应用的风险，并在此基础上介绍世界主要国家和地区的人工智能监管设计，总括出人工智能监管的发展趋势。[结果/结论]人工智能监管的全球竞赛已然开始且法治化程度不断加深，以技术风险分级进行人工智能监管成为主流趋势，我国也应当加强人工智能监管的顶层设计，采纳分级分类的监管思路，并积极参与人工智能监管的国际合作。",
    "context2": "关键词：人工智能；监管；ChatGPT；模式；趋势；风险",
    "context3": "DOI:10.16353/j.cnki.1000-7490.2023.06.003",
    "context4": "引用格式：刘轩，陈海彬：人工智能监管：理论、模式与趋势[J]．情报理论与实践，2023，46（6)：17-23，37."
  },
  "Artificial Intelligence Regulation: Theory，Model and Trend": {
    "context1": "Abstract[Purpose/significance]Withthe widespreadapplicationofartificialintellgenceintheeconomyandsociety，ithas becomeaglobalconsensustostrengtenteregulationandgoveranceofartificialintellgenceandcontrolitsinherenssIisf greatsignfcancetoinvestigateteregulatorydesignofmajorcoutriesandrgionsintheworldforimprovingourartificialinteli genceregulatorysystem.Method/process]Throughliteratureanalysisandcomparativeanalysis，theconceptofartificial inteligenceregulationandtessofrtificialinteligenceaplicationaredefid，andonthisasis，thedsignofartificialintellgnce regulatioinmajorcountriesndegionsintheorldisintroduced，andtedevelopmentrendfartficialintellgenceglationis summarized.Result/conclusion]Theglobalcompetitionforartificialintellgenceregulationhasbegunandthedegreeofruleof lawisdepenng.ArtificialintellgenceregulationbasedontchnicalriskcasifcationasecomeamanstreamtrendChinashould alsostrengtnthetopeveldsignofartficialitellgenceregulation，adoptteregulatorytinkingoflasification，activelypar ticipate in international cooperation in artificial intelligence regulation.",
    "context2": "Keywords:artificial intelligence；regulation;ChatGPT；model; trend;risk",
    "context3": "科技是推动社会变革的重要力量，在第四次工业革命浪潮的推动下，以人工智能为基石的新一代信息技术开始广泛应用于人类社会生产、生活等各类场景，并在诸多领域，如改善医疗水平、汽车无人驾驶、社会综合治理以及网络安全维护等方面展现出巨大的技术优势与广泛的应用前景。在国家层面，人工智能作为引领未来的新兴技术，已然成为世界主要发达国家建构国家发展战略、夺取科技前沿阵地的重要依托工具，甚至在一定程度上扮演着重塑未来世界格局的关键角色。然而，人工智能同样是把双刃剑，在推动科技创新和产业变革的同时，也会在应用过程中产生诸多风险，如侵犯隐私、算法权力、算法歧视等。因此，加强人工智能的治理，实现人工智能的发展与监管同频共振，已成为全球共识。目前，世界上大多数国家均已意识到加强人工智能监管的重要性和必要性，并出台了相应的法律规范和政策文件，旨在从根本上管控人工智能在研发、推广和应用过程中可能引发的各种潜在风险。近年来，我国在专注于人工智能技术发展的同时，也积极投身于人工智能监管体系的建设，分析世界主要国家和地区的人工智能监管设计，对于构建和完善我国人工智能监管体系具有重要意义。"
  },
  "1人工智能监管的内涵": "",
  "1.1人工智能监管的定义": {
    "context1": "在现有文献中，围绕“人工智能监管”这一主题或关键词进行讨论的不在少数，但是对“人工智能监管”这一概念加以界定的却较为鲜见。从词语组合来看，“人工智能监管”可以拆分为“人工智能”和“监管”两个核心用语。本来“人工智能”就结合了很多内容，使其成为一个极其混乱的概念[，难以准确定义，有外国机构统计显示，关于“人工智能”的定义有 50多种[2]。而“监管”一词同样是整个社会科学领域最富争议、也最容易被误解的概念之一[3]。两个概念的相互组合，势必增加了“人工智能监管”这一概念的界定难度。概念是辨识和区分社会现实中所特有的现象的工具，没有严格限定的概念我们就不能清楚和理性地思考[4]，而且明确、清晰的概念也是开展学科研究与交流的前提，是研究内容科学化、精细化的重要体现。为此，尝试对“人工智能监管”进行定义。",
    "context2": "界定人工智能监管的概念，需要首先明确人工智能的内涵。目前，学者们从多种研究角度对人工智能加以定义，但纵观已有论述的异同，大致可以归纳为3种观点。",
    "context3": "1）学科说。该观点认为，人工智能属于计算机科学的一个分支，是一门通过研究算法来解决问题和完成任务的学科[5]。",
    "context4": "2）技术说。该观点认为，人工智能是使机器像人一样去完成某项任务的软硬技术[6]",
    "context5": "3）机器说。该观点认为，人工智能是利用大数据、算法与算力为人类提供产品、服务、应用的智能体[]。",
    "context6": "从监管的角度而言，将人工智能理解为一种技术更为适宜，而且从一些国家已出台的相关政策文件和法律法规来看，也更多地倾向于将人工智能理解为一种技术或系统。监管一词的语义同样较为丰富，在不同的专业领域中含义不同[8。但是，就人工智能监管而言，由于该词汇主要出现在相关法律法规和政策文件中，其受众对象主要为所在区域的政府、企业、组织和公民，从便于理解的角度而言，采用日常语义即可，故监管是指基于某种规则对某事物进行控制或调节，以使其能够正常运转[9]。综上，所谓人工智能监管，是指基于某种规则，对模仿人类特征的技术进行控制和调节，以帮助人们更好地驾驭和使用该技术。"
  },
  "1.2人工智能应用的风险挑战": {
    "context1": "不可否认，人工智能时代的来临为我们描绘了一个美好的未来图景，但人们在充分享受人工智能技术红利的同时，也应当正视人工智能应用带来的风险挑战。如近期由美国人工智能公司Open AI发布的聊天机器人ChatGPT让人们对未来生活有了崭新体验，但与此同时其代写的“杭州取消限行”不实新闻被广泛传播，造成了不良影响。因此，有必要将人工智能纳入监管治理。总体而言，人工智能应用的风险主要包括4种类型。",
    "context2": "1.2.1技术风险人工智能是一种技术，其主要是基于数据分析和模型建构来进行深度学习，并通过建立数据变量之间的关系而做出自我决策[10]。然而，技术并非完美无瑕的，且由于人类认知的局限性，人工智能在应用过程中极易产生技术上的风险，具体表现为三种情形：一是因技术本身的缺陷而引起的风险，如输入代码错误、算法结构缺陷等，导致人工智能系统依据错误的代码、数据、程序进行计算，其结果必然会给人类的生命财产安全带来风险；二是因人工智能算法的不透明和不可解释性，无法提供做出决策所依据的材料和理由，导致人类无法准确解释算法自主决策的结果而引发未知的风险；三是因人工智能技术的肆意滥用而产生的风险，如一些不法分子利用人工智能系统进行国家情报的收集与窃取、个人隐私数据的采集等。",
    "context3": "1.2.2伦理风险伦理是指人应该遵守的行为规范和道德准则[11]。随着技术的创新和发展，人工智能已经渗透到人类社会生活的方方面面，科技发展与社会伦理之间的冲突和碰撞在所难免，人工智能由此引发的伦理风险也层出不穷，具体表现为：一是算法歧视，由于算法设计本身存在偏见和非高质量数据的输入而导致结果出现偏差，造成他人在招聘就业、信息咨询等服务过程中遭遇不公平、不平等的对待。二是决策偏差，算法通过搜集用户在网络世界中的各种数据和足迹进行用户画像，进而能够为特定主体过滤、屏蔽或定向推送相关信息。因此，企业可以利用算法来操纵消费者的接收信息，通过推送虚假信息、误导性信息来影响消费者决策。三是算法权力，企业借助于算法过度引导或者欺骗劳动者提供超过自己生理或心理承受能力的服务行为，以不合理的方式对劳动者进行考核等，严重损害劳动者的身心健康。",
    "context4": "1.2.3社会风险人工智能的创新应用可以充分利用社会资源，大幅提升人类的生产、生活效率，但人工智能在带来发展机遇的同时，也应当正视其可能引发的社会风险，主要表现为：一是劳动力的供大于求。人工智能的普及必然取代社会中原有的部分劳动力，且由于人工智能的低成本、高效率等突出特性，更易受到用人单位的青睐，造成以出卖劳动力为主的社会底层居民丧失劳动和就业机会，极大压缩其生存的空间，使其成为社会中的不稳定因素，进而引发不同群体间的对立和冲突。二是容易形成行业垄断。在市场中，资本与技术结合共谋实施行业垄断是时常发生的情形，由于掌握先进技术，部分企业可以借此获得垄断或支配地位，肆意打压中小企业或歧视性地对待合作商家而谋取巨额利益，进而严重破坏市场公平公正的竞争秩序。",
    "context5": "1.2.4法律风险人工智能应用可能引发的法律风险同样值得警惕，具体表现为：一是在人工智能产品具有了类似人类的思维，可以通过其内在设定程序进行自主决策，表现出自身“意志”后，其是否具有独立的法律人格，理论中就存在着否定说、代理说、有限人格说等观点纷争[12]。二是人工智能产品由于管理者的不当使用或人工智能产品超出内在程序设定而出现致人损害的情形时，责任归属应如何区分存在认识差异。如果没有相关法律予以事先明确，就会在追责过程中面临主体责任缺失的问题，出现涉事各方相互推责的局面，不利于人工智能技术的规范发展。三是人工智能产品在特定应用场景中也面临法律责任重构的难题，如在无人驾驶汽车引发的交通事故中，对于事故责任的认定，将只关注结果的“对与错”，而不存在主观上的“故意与过失”，这预示着以过错责任为基础建立的归责体系面临重构的风险[13]。",
    "context6": "<table><tr><td rowspan=1 colspan=1>风险等级</td><td rowspan=1 colspan=1>应用场景</td><td rowspan=1 colspan=1>监管措施</td></tr><tr><td rowspan=1 colspan=1>不可接受的风险</td><td rowspan=1 colspan=1>威胁人类安全、生计和权利的AI系统，包括操纵人类行为规避用户自由意志和允许政府使用社会信用评分等</td><td rowspan=1 colspan=1>必须禁止</td></tr><tr><td rowspan=1 colspan=1>高风险</td><td rowspan=1 colspan=1>可能会对人类安全和生活造成严重威胁和影响的AI系统，包括交通基础设施、教育或职业培训、产品安全、移民管理、司法民主程序</td><td rowspan=1 colspan=1>启用前履行严格义务，如充分的风险评估高质量的数据交换、确保可追溯的运行记录以及必要的人类监督</td></tr><tr><td rowspan=1 colspan=1>有限风险</td><td rowspan=1 colspan=1>使用人工智能时使用者意识到与机器互动进而做出明智决定</td><td rowspan=1 colspan=1>实现公开透明</td></tr><tr><td rowspan=1 colspan=1>最低风险</td><td rowspan=1 colspan=1>电子游戏、垃圾邮件识别软件等多数的人工智能应用</td><td rowspan=1 colspan=1>不做限制</td></tr></table>"
  },
  "2主要国家和地区的人工智能监管设计": {
    "context1": "为应对人工智能应用过程中可能引发的各种潜在风险，世界主要国家和地区都加强了监管治理，但是基于自身的文化背景、历史传统、地域特点等因素，形成了各具特色的监管模式，对一些代表模式予以介绍。"
  },
  "2.1技术风险分级的欧盟模式": {
    "context1": "欧盟作为欧洲国家的国际组织，注重统合区域内的资源，实现其在人工智能国际竞争中的优势。近年来，更是通过加强对人工智能的监管治理，寻求其在人工智能规范领域的主导地位。早在2018年4月25日，欧盟委员会就发布了《欧洲人工智能战略》，通过确立适当的道德和法律框架，以确保其走在全球人工智能发展的前沿[14]。2019年4月8日，欧盟高级别专家组发布了《可信人工智能伦理指南》，提出“可信人工智能”的概念和满足的条件[15]。2020年2月，欧盟委员会发布了《人工智能白皮书》，提出了一系列人工智能研发和监管的政策措施，为研发者提供可遵守的法律框架，也标志着欧盟人工智能政策从理论走向监管[16]。2021年4月21日，欧盟委员会发布了全球首部《人工智能法案》，标志着欧盟在人工智能的监管方面，构建起以技术风险分级为核心的监管框架。"
  },
  "2.1.1明确以高风险为主的监管思路": {
    "context1": "一是依据风险程度进行分类管理。如图1所示，欧盟将人工智能的应用场景依据风险等级区分为4种类型，并按照比例原则匹配了相应的监管措施。风险等级越高意味着监管越严，对于“不可接受的风险”的人工智能系统是必须被禁止使用的，而“极小风险”的人工智能系统则不受监管限制，但是鼓励供应商采用自愿认证的方式纳入监管。《人工智能法案》将监管的重心放在了高风险的人工智能领域，虽然其没有给出高风险的定义，但是通过列举的方式说明了高风险可能涉及的领域，说明现阶段对于高风险的认定标准仍较为模糊，需要通过不断地实践探索来认知发现。",
    "context2": "二是构建全生命周期的监测机制。在研发阶段，高风险的人工智能系统需要满足7方面要求： $\\textcircled{1}$ 建立独立的、贯穿整个生命周期的风险管理体系并做好记录和维护;$\\textcircled{2}$ 遵守数据规范，使用一定标准的数据进行训练、验证和测试，保证数据的代表性、准确性和完整性； $\\textcircled{3}$ 在投入服务前建立技术文档，并向主管部门提供用于评估； $\\textcircled{4}$ 能够自动记录日志，实现系统在整个生命周期内的可追溯性;$\\textcircled{5}$ 保持系统的透明度并向使用者提供说明信息； $\\textcircled{6}$ 系统应采取适当措施，以便自然人能够有效监督； $\\textcircled{7}$ 确保系统预期用途的准确性、鲁棒性，并在整个生命周期稳定运行。在评估阶段，需要由评定机构对人工智能系统是否符合《人工智能法案》第二章的各项要求进行验证。在上市前，供应商需要将人工智能系统注册到数据库中，并在商品上加贴CE标识以便用户知悉。在上市以后，供应商应当记录、收集人工智能系统在整个生命周期的监测数据。2.1.2建立监管沙箱支持技术创新沙箱（Sandbox）是一种安全机制，通过提供隔离环境，为一些来源不可信、具有破坏力或无法判定意图的程序提供实验之用[17]。传统监管手段多为事后监管，不仅成本较高，也不利于创新。《人工智能法案》引入监管沙箱机制，鼓励成员国建立监管沙箱为人工智能系统投放市场或投入服务前提供受控环境，体现了事中监管和动态监管的理念，能够有效实现人工智能领域在监管与创新之间的动态平衡。《人工智能法案》要求人工智能系统须在主管机构的直接监督或指导下进行开发、测试和验证，并允许系统出于合法的目的在监管沙箱中收集和处理个人数据，能够有效管控人工智能应用中潜在的风险，避免个人数据的过度采集与泄露。此外，《人工智能法案》规定中小企业可优先使用“沙箱”，并享受费用优惠，有效减轻中小企业和初创企业的负担，充分彰显欧盟鼓励、倡导创新的发展理念。"
  },
  "2.2两级协同治理的美国模式": {
    "context1": "美国作为世界上头号科技强国高度重视人工智能的发展，且较早通过法律法规、政策法规的制定，加强对人工智能的监管治理。但是，由于美国独特的政治体制，在人工智能的监管治理方面呈现出两个层面的治理逻辑，即联邦政府层面与州政府层面。",
    "context2": "2.2.1联邦政府层面早在2016年奥巴马执政时期，就发布了《国家人工智能研究与发展战略规划》[18]对人工智能开始系统性研究，促进人工智能的发展。2019年特朗普执政又在这份计划基础上进行了更新，新修订的战略规划要求理解和应对人工智能的伦理、法律和社会影响，新增了确保人工智能系统的安全性等内容[19]，将安全建设作为人工智能重大战略方向之一[20]。2020 年1月，白宫发布了《人工智能应用监管指南》[21]，该指南从监管和非监管两个层面提出了人工智能应用的相关原则和建议，并针对通用或者特定行业人工智能应用程序的设计、开发、部署和操作提出10条监管原则，包括：公众对人工智能的信任，公众参与，科学完整性与信息质量，风险评估与管理，成本效益分析，灵活性，公平性与非歧视性，信息与透明度，安全性与可靠性，跨部门协调。该指南的公布，意味着美国政府为人工智能的监管措施提供了法律依据，也为政府机关在抽象的原则和建立更具体的治理机制之间架起了一座桥梁，通过科学性、灵活性的监管措施，对人工智能系统可能产生的风险进行理解、分类和防范[22]。同时，也表明美国对人工智能监管的目的不是杜绝风险的发生，而是对风险进行有效的管理，将风险控制在最小或者社会可接受的范围内，以鼓励技术的创新发展，维护美国在人工智能的科学、技术、经济等方面的全球领导地位。与欧盟采取以政府为主导，市场为辅助的监管体系不同，美国的人工智能监管不把强制监管放在首位，而是最大程度发挥人工智能市场的自我调节性，以政府监管为辅，可以使人工智能市场充满活力[23]。",
    "context3": "2.2.2州政府层面美国对于人工智能的监管和规制，总体上呈现出政府部门早于立法机构，州政府早于联邦政府的特点。虽然各州的立法机构逐步通过立法加强对人工智能的规范和监管，但监管的内容主要集中在一些特定的领域。如2011年，内华达州就做出了第一个关于自动驾驶车辆检测的立法，该法规定了自动驾驶车辆的检测条件，要求对自动驾驶进行监管。目前已有40个州通过了法律或行政命令规制自动驾驶汽车[24]。又如在人脸识别技术的监管方面，美国在联邦政府层面仍未出台统一的规定，而主要依靠各州出台的立法进行监管，像得克萨斯州、弗吉尼亚州、加州等都针对“深度伪造”行为出台了相应法案，走在了联邦政府的前面[25]。"
  },
  "2.3自愿非强制的新加坡模式": {
    "context1": "近年来，新加坡为加快数字经济发展，在不断推动社会数字化转型的同时，也注意防范可能存在的安全风险，加强对人工智能的监管治理。在人工智能监管方面新加坡也处于全球领先地位。",
    "context2": "2.3.1出台专门监管框架2019 年1月，新加坡推出亚洲首个《人工智能监管模式框架》[26]，2020 年1月，新加坡又发布《人工智能监管模式框架（第二版)》（以下简称《模式框架》)[27]，在第一版内容的基础上进行了丰富和完善，但是框架不是一套硬性条例，而是供企业使用的指导模式，其主要包括以下4方面：",
    "context3": "一是明确相关概念和指导原则。该《模式框架》将人工智能定义为一组模拟人类特征的技术，如理解、推理、解决问题、感知、学习和计划，并根据人工智能模型产生输出或决策。而建立可信赖的人工智能，需要遵循两项指导原则： $\\textcircled{1}$ 确保人工智能的决策过程是可解释的、透明的和公平的； $\\textcircled{2}$ 人工智能解决方案应该以人为本。",
    "context4": "二是为企业研发人工智能在4个领域提供操作指南。$\\textcircled{1}$ 内部治理结果和措施：调整现有或建立内部治理结构与措施，以纳入与算法决策相关的价值、风险与责任； $\\textcircled{2}$ 确定人类参与人工智能增强决策：帮助组织设定其使用人工智能的风险偏好的方法，即确定可接受的风险并确定人类参与人工智能增强决策的适当程度； $\\textcircled{3}$ 运营管理：开发、选择和维护人工智能模型时需要考虑的问题，包括数据管理； $\\textcircled{4}$ 利益相关者互动和沟通：与组织的利益相关者沟通的策略以及与他们的关系管理。",
    "context5": "三是基于风险的规制路径。该《模式框架》根据风险控制提供了3种决策模型： $\\textcircled{1}$ 人类参与其中，该模型人类监督是积极的和参与的，人类保留完全控制权； $\\textcircled{2}$ 人类并不干涉，该模型人工智能系统具有完全控制权，没有人为干预的选择； $\\textcircled{3}$ 人类进行监督，该模型中人类处于监视或监督角色，并有能力在人工智能模型遇到意外情况时进行接管控制，允许人类在算法运行期间调整参数。该《模式框架》还提供了一个伤害概率模型（见图2)，以帮助组织机构做出的决定可能对个体造成伤害的概率和严重程度进行分类。",
    "context6": "![](images/5493a57abdd461b2ffdde65c1b7c51356d4db9131592e52d3758113d6e6f8acc.jpg)  \n图2伤害概率和严重程度分类模型  \nFig.2Injury probability and severity classification model",
    "context7": "四是确保算法的透明度。算法和模型应当具有可解释性、可重复性、鲁棒性、定期调整、可再现性、可追溯性和可审核性等措施以提高人工智能模型中算法的透明度。2.3.2引入监管评估工具2022年5月，新加坡发布了全球首个人工智能监管评估框架和工具集——A.I.Verify。该评估框架和工具集是由新加坡资讯通信媒体发展局（IMDA）和个人数据保护委员会（PDPC）共同开发，旨在结合人工智能系统的技术评估和程序检查，提高评估主体与利益相关者之间的透明度。在开发人工智能监管测试框架和工具集过程中，IMDA融入了国际普遍接受的人工智能伦理准则、指南和框架，最终形成了透明性、可解释性、公平性、安全性、鲁棒性、可复现性、可审计性、包容增长、数据治理、人类能动性与监管、社会和环境福利11个关键人工智能伦理准则和系统开发人员如何与消费者构建信任的5大支柱。当前，A.I.Verify并非强制适用，而是自愿性质，其目的在于提高公众对人工智能产品的信任度和接受度，有助于相关技术的推广。"
  },
  "3人工智能监管的发展趋势": "",
  "3.1人工智能监管的全球竞赛已然开始": {
    "context1": "面对人工智能深入赋能而引发的多方面风险挑战，全球各国越来越重视人工智能监管。自2017年以来，加拿大、美国、中国、英国、新加坡、韩国、加拿大、欧盟、经合组织等国家（地区）和组织已陆续发布人工智能发展原则和治理准则[28]。由于各国纷纷寻求将自己的监管措施与方法发展为全球共识，从而引发了一场关于人工智能监管的全球竞争。如在 2021年7月13日美国人工智能国安委员会主办的全球新兴科技峰会上，美国商务部长吉娜·雷蒙多就发表声明称，美国不能让中国制定与AI有关的规则，AI的开发和监管方式要与美国“自由、开放、保护知识产权、尊重人权和隐私的民主价值观”相一致[29]。欧盟借助《人工智能法案》的出台，意欲仿效《通用数据保护条例》一样，通过明确人工智能伦理、法律等治理方式，来提升其在全球人工智能治理的主导权，成为人工智能监管的全球领跑者。英国政府于2021年9月发布了《国家人工智能战略》，明确提出要建立世界上最值得信赖和支持创新的人工智能治理体系[30]。"
  },
  "3.2人工智能监管的法治化程度不断提升": {
    "context1": "当前，各国政府虽然对人工智能监管的侧重点略有不同，但是整体上呈现出加速演进态势，即从初期构建以“软法”为导向的规范体系向“硬法”为保障的风险防控体系转变[31]。这一点，从各国近年来不断加强人工智能的相关立法就能体现出来。根据2022年3月16日斯坦福大学以人为本人工智能研究所发布的 ${ \\ll } 0 2 2$ 年人工智能指数报告》[32]显示，自2015 年以来，在全球范围内人工智能监管趋势继续扩大，全球主要国家都相继加强了人工智能方面的相关立法（见图3)。其中，在全球选定的25个国家的立法机构通过的人工智能相关法案数量增加了18 倍（见图4)，而立法程序中提及人工智能的次数也在过去6年间增长了7.7倍。",
    "context2": "![](images/3e4f8a8afbfc63075d3921802f1b5beddad24f6b265b0d8a30386933cdd12848.jpg)  \nNUMBER of AI-RELATED BILLS PASSED into LAW in SELECT COUNTRIES,2016-21(SUM) Source:AI Index,2021| Chart:2022AI IndexReport   \n图3全球主要国家过去6年人工智能相关法案通过的数量  \nFig.3Number of AI-related bills passed in major countries over the past six years",
    "context3": "![](images/d465ceadf9036ef4baa6d4180d84b710fb744f141955d5557f8f735c93f84aba.jpg)  \n图4全球选定25个国家过去6年人工智能立法数量  \nFig.4Number of AI legislation in 25 selected countries in the past six years"
  },
  "3.3风险分类成为监管的新思路": {
    "context1": "对人工智能系统进行风险分级，按照比例原则确定监管措施成为全球人工智能监管的新思路，欧盟《人工智能法案》、美国《算法问责法案》以及英国《建立一种有利于创新的方法来监管AI》提案等世界主要国家的相关法律法规和政策文件均直接或间接采纳了这一监管思路。依据风险分级确定监管措施有以下优点：一是有利于实现监管对象科学化、精细化的管理，切实避免“一刀切”的监管措施阻碍和遏制人工智能技术创新，为人工智能产业发展提供宽松的成长环境；二是有利于合理控制人工智能的潜在风险，针对高风险人工智能系统加强监管治理，可以将其风险降至合理、可控的范围内，最大限度保护公民的生命健康等相关权利。当然，这种思路的贯彻需要有一个明确的前提，即需要对人工智能系统所具有的风险做到充分了解和认知，目前采取列举的方式显然不能穷尽高风险的人工智能系统，需要未来进一步细化高风险人工智能系统的判定标准和方法。"
  },
  "3.4人工智能监管的国际合作逐步扩大": {
    "context1": "在全球化时代，由于人工智能技术呈现出跨国家、跨文化和跨领域特点，应对人工智能技术挑战并非完全取决于个别的国家[33]，因此加强国际间的相互合作也就成为人工智能监管的必然趋势。这种国际间的相互合作主要表现为两方面：一方面是主权国家之间的相互协调，以美国为主的部分西方国家以所谓的“意识形态”“共同价值观”为合作纽带，以应对在人工智能领域不断提升的中国影响，确保其在该领域的领导地位。如美国不仅计划与欧盟在跨大西洋合作方面积极展开关于人工智能技术发展、规制的讨论与合作，还在与韩国来往时多次强调希望促进韩美两国在人工智能等新兴技术方面的合作[34]。另一方面是产业界、学术界等形成的行业宣言，如在首届全球数字经济大会人工智能产业治理论坛上发布的《人工智能产业担当宣言》，便是企业与学术机构在共同商讨下形成的倡议性文件[35]。"
  },
  "4启示": {
    "context1": "近年来，我国在大力推动人工智能产业发展的同时，也加强了对人工智能的监管力度。自2017年7月8日出台《新一代人工智能发展规划》（以下简称《发展规划》)以来，人工智能技术创新持续推进、技术迭代升级接连不断，与监管相关的法律法规也陆续出台。按照《发展规划》中对人工智能监管法律体系的战略目标要求，从2020 年到2030 年分三步走，逐步构建完善的人工智能法律法规、伦理规范和政策体系。目前，《中华人民共和国网络安全法》《中华人民共和国民法典》《中华人民共和国数据安全法》《中华人民共和国个人信息保护法》等法律法规的出台，已在国家层面为人工智能监管提供了坚实基础，初步具备了对人工智能的安全评估和管控能力。不仅如此，一些省市也成为人工智能立法的先行者，如深圳在2022年8月就通过了《深圳经济特区人工智能产业促进条例》（以下简称《促进条例》），在扶持、促进人工智能产业发展的同时，完善人工智能法律监管体系的构建。该《促进条例》将评级分类、算法规则、敏捷治理等纳入人工智能行业的监管方法中，显著提升行业监管水平。诚然，我国在人工智能监管领域取得了一定成绩，但也存在着法律供给整体不足、国际合作不够深化等问题，借鉴域外国家和地区的监管模式与经验，对于完善我国人工智能监管体系具有重要意义。"
  },
  "4.1加强人工智能监管的顶层设计": {
    "context1": "虽然我国目前针对人工智能技术应用的具体场景出台和实施了多个与人工智能相关的法律，但在国家层面尚未出台关于系统监管人工智能的专门法律。这种立法上的缺失，显然没有注意到人工智能领域作为高科技行业监管的特殊性，且过于分散的监管规则也容易引发监管部门之间的推诿扯皮，不利于企业的持续发展。因此，建议增设人工智能监管的专门法律《中华人民共和国人工智能法》或《中华人民共和国人工智能监管法》，完成我国人工智能监管体系的基础建构，具体内容包括：一是明确人工智能领域相关的概念，为加强人工智能监管提供准确范围与合理边界；二是明确人工智能的监管部门，由其对人工智能技术和项目进行审核把关，统筹协调人工智能监管的各项工作；三是总结提炼人工智能监管的共性规则与一般原则，为不同场景的人工智能监管提供操作指南;四是确定人工智能造成损害的责任划分，以立法形式明确不同情境下生产者、销售者以及操作者的责任分配与参照原则。"
  },
  "4.2采纳分级分类监管的思路": {
    "context1": "“技术是有用的仆人，但却又是危险的主人。”36」任何技术创新都是突破常规，都意味着存在未知的风险，人工智能的发展同样不例外。监管意味着降低风险，但过于严苛的监管方式不仅会阻碍，甚至会扼杀技术的创新；反之过于宽松的监管方式也将导致技术误入歧途，给人类带来更多的风险与威胁。在严苛与宽松的两级之间，依据人工智能技术应用的具体场景，建立分级分类的监管思路，既可以有效降低人工智能技术的未知风险，又能够培育出有利于人工智能创新的宽松土壤，符合国际上对人工智能监管的主流趋势，建议我国也积极采纳：一是明确分级分类的标准，依据人工智能的自主程度，区分为辅助人类智能系统、人机混合智能系统和完全自主智能系统三种类型。再将人工智能系统依据风险的等级区分为低风险、高风险和超高风险，每种自主类型的人工智能系统均可以匹配三种风险，并建立科学分类的标准，实现监管的精准化、精细化。二是积极探索监管沙箱等创新机制，为人工智能的技术研发、测试和验证提供一个受控的环境，一旦在实验过程中发现人工智能存在对人的生命、安全或其他权利造成损害的情形，可以立即采取措施降低风险。三是建立“事前、事中、事后”全面监管机制，事前注重风险评估，有效管控风险；事中进行有效监督，对于问题产品及时召回；事后加强完善学习，填补技术漏洞，共享风险"
  },
  "数据。": "",
  "4.3实现人工智能监管的国际合作": {
    "context1": "人工智能附带的风险具有全球性，全球任何一个国家、组织都不能凭借一己之力，以求妥善应对人工智能广泛应用而可能引发的一系列危机和挑战，因此深化人工智能监管的国际化合作意义重大，建议我国：一是要时刻警惕以美欧为首的西方国家利用主导人工智能监管治理规则制定的国际话语权，孤立、打压我国，阻止我国积极参与人工智能技术国际标准的制定[37] 。二是要主动构建常态化的国家合作和交流机制。借助于双边或多边的合作契机，邀请人工智能相关领域专家到我国开展交流研究，不断向世界输出人类命运共同体的合作理念和价值，搭建校企之间、科研院所之间等广泛的交流合作机制，推动构建人工智能国际监管的合作框架，为人工智能监管贡献中国方案，发出中国声音。三是利用我国在人工智能相关领域的技术优势，积极参与人工智能技术相关国际标准的制定工作，包括规范术语、技术框架、产品服务等，逐步实现我国在人工智能技术标准方面的国际化。□"
  },
  "参考文献": {
    "context1": "[1]MAAS M.Artificial intelligence governance under change foun-dations，facets，frameworks［D]．Denmark:UniversityofCopenhagen，2020.  \n[2］金玲．全球首部人工智能立法：创新和规范之间的艰难平衡[J]．人民论坛，2022（4)：44-47.  \n[3] 马英娟．监管的概念：国际视野与中国话语［J]．浙江学刊，2018(4):49-62.  \n[4] 博登海默E.法理学法律哲学与法律方法［M]．邓正来，译．北京：中国政法大学出版社，2017：504.  \n[5] WILLIAM J.Rapaport.What isartificial intelligence?［J].Journal of Artificial General Intelligence，2022，11（2）：52-56.  \n[6] ARRUDA A.An ethical obligation to use artificial intelligence?An examination of the use of artificial intelligence in law and themodel rules of professional responsibility［J]．American Jour-nal of Trial Advocacy，2017，40（3)：443.  \n[7] 段伟文．人工智能时代的价值审度与伦理调适[J]．中国人民大学学报，2017，31（6)：98-08.  \n[8] BLACK J.Critical reflection on regulation［J]．AustralianJournal of Legal Philosophy，2002，27:1-35.  \n[9] 马英娟．监管的语义辨析[J]．法学杂志，2005（5)：111-114.  \n[10] 唐要家，唐春晖．基于风险的人工智能监管治理［J]．社会科学辑刊，2022（1)：114-24.  \n[11] 胡建华，叶丽霞．人工智能治理：内涵、挑战与治理[J]．江西理工大学学报，2022，43（4)：99-04.  \n[12] 潘志玉．人工智能应用的伦理风险及法治应对［J]．学习与探索，2022，324(7)：61-67.  \n[13] 吴汉东．人工智能时代的制度安排与法律规制［J]．法律科学（西北政法大学学报），2017，35（5)：128-136.  \n[14] Artificialintelligence:commissionoutinesaEuropeanap-proach to boost investment and set ethical guidelines [EB/OL].[2022-12-01]．htps://ec.europa. eu/commission/presscor-ner/detail/en/IP_18_3362.  \n[15] Assessment list for trustworthy artificial inteligence(ALTAI)[EB/OL]．[2022-12-01]．https: //airegio.ems-carsa.com/nfs/programme_5/call_3/call_preparation/ALTAI_final.pdf.  \n[16] White paper on artificial intelligence-a European approach to ex-cellnce and trust [EB/OL]．[2022-2-01]． https://com-mission.europa.eu/document/d2ec4039-c5be-423a-81ef-b9e44e79825b_en.  \n[17] GOLDBERG I，WAGNER D，THOMAS R，BREWER E.Asecureenvironment for untrusted helper applications （confiningthe wily hacker)[EB/OL]．[2022-2-01]．https: //www.usenix.org/legacy/publications /library/proceedings /sec96 /full-papers/goldberg/goldberg. pdf.  \n[18] The national artificial intelligence research and developmentstrategic plan（2016)[EB/0L]．[2022-42-01]．https: //legacy-assets.eenews.net/open_files/assets/2016/10/12/doc-ument_gw_04.pdf.  \n[19] The national artificial inteligence research and developmentstrategic plan:2019 update [EB/OL]．[2022-2-01]．ht-tps://www.nitrd.gov/pubs/National-AI-RD-Strategy-2019.pdf.  \n[20] 贺斌，李红美，王周秀，等．美国人工智能国家战略行动最新动向：洞察与借鉴[J]．情报杂志，2021，40（1)：25-32.  \n[21] White House，guidance for regulation of artificial intelligenceapplications（2020）[EB/0L]．[2022-12-01]．https: //www.White house．gov/wp-content/uploads/2020/01/Draft-OMB-Memo-on-Regulation-of-AI--7-19.pdf.  \n[22] 陆凯．美国算法治理政策与实施进路［J]．环球法律评论，2020，42（3):5-26.  \n[23] 翁怡．人工智能立法及监管制度研究［M]．北京：中国广电影视出版社，2022：50.  \n[24] 韩春晖．美国人工智能的公法规制［J]．国外社会科学，2022 (2): 46-58.  \n[25] 李鹏飞．各国涉 Deepfake 等人工智能造假技术立法概况[EB/OL]．[2022-42-01]．http://lib.ia.ac.cn/news/news-detail/1592.  \n[26] A proposed model AI governance framework for public consulta-tion[EB/O0L]．[2022-2-01].https: //www.pdpc.gov.sg/news-and-events /announcements /2019/01/a-proposed-model-ai-governance-framework-for-public-consultationn.  \n[27] Model artificial intelligence govermance framework second edi-tion[EB/OL]．[2022-42-01].https:/ww.pdpc.gov.sg/-/media/files/pdpc/pdf-files/resource-for-organisation/ai/sgmodelaigovframework2.ashx.",
    "context2": "OpenAI gym [J]．arXiv preprint arXiv:1606.01540，2016. [2］VASWANI A，SHAZEER N，PARMAR N，et al. Atention is all you need [J]．Advances in Neural Information Processing Systems，2017，30(1)：5998-6008.",
    "context3": "[3]BROWN T，MANN B，RYDER N，et al.Language models are few-shot learners［J]．Advances in Neural Information Processing Systems，2020，33(1):1877-1901.",
    "context4": "[4]FLORIDI L，CHIRIATTI M. GPT-3:its nature，scope，limits，and consequences [J]．Minds and Machines，2O20，30 (1):681-694.",
    "context5": "[5]OpenAI. GPT-4 technical report[J]．arXiv preprint arXiv: 2303.08774，2023.",
    "context6": "[6］DEVLIN J，CHANG Mingwei，LEE K，et al.BERT:pretraining of deep bidirectional transformers for language understanding [J]．arXiv preprint arXiv:1810.04805，2018.",
    "context7": "[7］LIU Y，OTT M,GOYAL N，et al.Roberta:a robustly optimized BERT pretraining approach [J]．arXiv preprint arXiv: 1907.11692，2019.",
    "context8": "[8]DALE R. GPT-3:what’s it good for?[J].Natural LanguageEngineering，2021，27（1)：113-118.",
    "context9": "[9]SUN Yu，WANG Shuohuan，FENG Shikun，et al. Ernie 3.0: large-scale knowledge enhanced pre-training for language understanding and generation ［J]．arXiv preprint arXiv:2107. 02137，2021.",
    "context10": "[10]ZENG Wei，REN Xiaozhe，SU Teng，et al.PanGu-α:largescale autoregressive pretrained Chinese language models with auto-parallel computation ［J]．arXiv preprint arXiv:2104. 12369，2021.",
    "context11": "[11］叶鹰．智能信息分析的理论基础与技术模型[J]．情报学报，2005，24(2)：233-236.",
    "context12": "[12]叶鹰．智能信息处理的基础理论探讨［J]．情报科学,2008(9):1281-285，1291.  \n[13] 叶鹰．智能信息处理和智能信息分析前瞻［J]．图书与情报，2017(6)：70-73，95.  \n[14] 叶鹰．情报学基础教程[M]．3版．北京：科学出版社，2018.  \n[15] STOKEL-WALKERC，VAN NOORDENR.What ChatGPTand generative AI mean for science[J]．Nature，2O23，614(7947): 214-216.  \n[16] BOCKTINGC，VANDISEAM，BOLLENJ，etal.ChatG-PT:five priorities for research［J]．Nature，2O23，614(7947): 224-226.  \n[17] 叶鹰．图书情报学的学术思想与技术方法及其开新[J].中国图书馆学报，2019，45（2)：15-25.  \n[18] 叶鹰．试论图书情报学的主干知识及有效方法：兼论双证法和模本法之效用［J]．中国图书馆学报，2021，47(3):58-66.",
    "context13": "作者简介：叶鹰，男，1962年生，教授，特聘研究员。研究方向：定量信息分析，智能信息处理。朱秀珠，女，1995年生，博士生。研究方向：定量信息分析。魏雪迎，女，1997年生，博士生。研究方向：定量信息分析。王静静，女，1989年生，博士，副研究员。研究方向：智能信息处理。王婉茹（ORCID：0000-0001-6544-3660，通信作者，Email:wanruwang $@$ zufe.edu.cn），女，1995年生，博士，讲师。研究方向：定量信息分析。作者贡献声明：叶鹰，提出论题，撰写文稿，修改定稿。朱秀珠，素材处理，撰写文稿。魏雪迎，素材处理，撰写文稿。王静静，素材处理，撰写文稿。王婉茹，素材处理，撰写文稿，修改定稿。",
    "context14": "录用日期：2023-04-02"
  },
  "(上接第23页)": {
    "context1": "[28]清华大学人工智能国家治理研究院.2021年度全球人工智能治理趋势盘点［EB/OL]．[2022-2-04]．https://aiig.tsinghua.edu.cn/info/1442/1428.htm.",
    "context2": "[29]观察者网．美国商务部长放话：AI规则制定，不能交给中国［EB/OL]．［2022-12-04]．https://baijiahao．baidu.com/s?id=1705236724053026301&wfr $=$ spider&for $= \\mathrm { p c }$",
    "context3": "[30]National AI strategy[EB/OL]．[2022-12-01]．https: // www.gov.uk/government/publications /national-ai-strategy.",
    "context4": "[31］中国信息通信研究院．人工智能白皮书（2022年[EB/OL].[2022-12-01]．http://www.caict.ac.cn/english/re-search/whitepapers/202205 /P020220510506258498240.pdf.",
    "context5": "[32]HAI .Artificial intelligence index report 2O22［EB/OL]. [2022-42-01]．https: //aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AIHndex-Report_Master.pdf.",
    "context6": "[33］张东冬．人类命运共同体理念下的全球人工智能治理：现实困局与中国方案[J]．社会主义研究，2021（6)：",
    "context7": "164-172.",
    "context8": "[34］清华大学人工智能国家治理研究院.2021年度全球人工智能治理趋势盘点［EB/OL]．[2022-2-04]．https://aiig.tsinghua.edu.cn/info/1442/1428.htm.  \n[35]段家欣，赵瑜．全球人工智能治理的核心议题与规制趋势[J]．声屏世界，2022，515（12)：5-8.  \n[36] The Nobel Prize，Christian Lange Nobel lecture［EB/OL].[2022-l2-01]．https://www.nobelprize.org/priz-es/peace/1921/lange/lecture/.  \n[37］王楚.2022年人工智能领域国家安全风险评估及对策[J]．中国管理信息化，2022，25（9)：169-71.",
    "context9": "作者简介：刘轩，男，1986年生，博士生。研究方向：人工智能法，网络法。陈海彬，男，1993年生，博士生。研究方向：侦查学。",
    "context10": "作者贡献声明：刘轩，论文框架搭建，文献搜集与撰写。陈海彬，论文框架与内容修改。  \n录用日期：2023-03-07"
  }
}