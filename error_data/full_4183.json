{
  "original_filename": "full_4183.md",
  "图情领域LDA主题模型应用研究进展述评": {
    "context1": "A Review on Application Studies of LDA Topic Models in Library and Information Science Field",
    "context2": "张东鑫1 张敏²ZHANG Dongxin ZHANG Min",
    "context3": "(1.西南大学计算机与信息科学学院，重庆，400715；2.华中师范大学信息管理学院，武汉,430079)",
    "context4": "88888888888888摘要:[目的/意义]系统归纳梳理LDA模型的应用过程与应用领域,为图情领域LDA模型研究提供参考。[研究设计/方法]以Webof Science 核心集、LISA、Google Scholar、中国知网、维普和万方等为数据源,检索图情领域 LDA模型的研究文献,通过内容分析构建了LDA模型应用研究分析框架，从模型应用过程的视角对国内外研究现状进行系统地总结归纳。【结论/发现]LDA主题模型研究已经形成较为成熟的分析流程，已应用在主题探索、知识组织、学术评价、情感分析等很多领域,但是在应对大数据、多模态数据等复杂处理任务,提升建模结果的语义质量,扩展模型应用等方面还亟待加强。【创新/价值]基于LDA模型的应用过程,细致揭示了图情领域 LDA模型应用研究存在的问题和发展方向。",
    "context5": "关键词:LDA;主题建模;文本挖掘;图书情报领域 中图分类号:G250 DOI:10.13366/j.dik.2022.06.143",
    "context6": "引用本文:张东鑫,张敏.图情领域 LDA主题模型应用研究进展述评[J].图书情报知识,2022,39(6):143-157.(Zhang Dongxin,Zhang Min.AReviewonApplication StudiesofLDATopic Models inLibraryand Information ScienceField[J].Documentation,Information & Knowledge,2022,39(6):143-157.)",
    "context7": "Abstract:[Purpose/SignificancelAccording toprevious ork,thispaperaims tosummarizeandsorteouttheappliedprocessand appliedfieldsofLDAmodeltoprovidereferencefortheresearchofLDAmodelinibraryandinformationscience(LIS)field.Design/ Methodologyl We selected Webof Science Core Colection、LISA、Google Scholar、CNKlVIPand WANFANG Databaseasdata source, retrievedliteratureabouttheLDAmodelinthefieldofLISconstructedtheanalyticalframeworkofDAmodelaplicationresearch throughcontenanalysis,fromtheperspectiveofteappliedprocessofthesemodels,carefullyanalyedthecurrentresearchatome andabroad[Findings/Conclusion]Theresultsshowthatamore matureanalysisprocesshasbeenformedfortheresearchofLDAtopic modelsnLSfield,itasbeapdinichfieldsuchstopicexploation,kowedgeorganationacademicaluationit analysis,buttheresearchstillneedtobestrengthenedinthefuture indealingwithcomplextaskssuchasprocesingbigdataand multimodaldataimprovingthesemanticqualtofmodelingresultsandteapplicationofxtendedmodelOriginalityValue]Basedon theappliedprocessofDAmodel,theexistingproblemsaddevelopmentdirectionofDAmodelresearchinthefieldofLSrerevealed in detail.",
    "context8": "Keywords: LDA; Topic modeling; Text mining; LIS field"
  },
  "1引言": {
    "context1": "888888888888888888888888888888888888888888888",
    "context2": "潜在狄利克雷分布（Latent Dirichlet Allcation,LDA)是一种对文本主题进行建模挖掘的三层贝叶斯产生式概率模型[1]，该模型通过无监督学习，生成“文档-主题”和“主题-词”概率分布，被用于识别大规模文档集中潜藏的主题信息。LDA具有良好的数据降维能力和模型扩展性，被广泛应用于各种文本分析任务。",
    "context3": "目前，计算机学科的相关研究主要围绕LDA扩展模型的分类、算法改进[2.3]，尤其是深度学习主题模型[4]展开了较多探讨，相关研究强调主题模型对于文本挖掘及自然语言处理的重要作用，聚焦于LDA主题模型原理、参数估计及训练方法的总结归纳，注重不同主题建模技术之间性能的对比[5，少数研究归纳了主题模型在语言、政治、生物医学、地理等学科领域应用，指出LDA主题模型在多媒体信息加工处理等文本挖掘任务中存在的挑战及问题[2]。图情领域的学者则较多针对特定的文本挖掘任务[展开分析研究，已有部分综述针对某一应用场景或某一类扩展模型[进行了归纳总结。总体而言，现有研究针对LDA模型完整应用过程的梳理还较为缺乏。本研究聚焦图情领域LDA模型整体应用研究现状，细致剖析其应用过程关键环节和应用领域，以期为相关领域的理论研究和实践应用提供参考。本研究梳理了LDA模型应用的现存问题和创新发展，有助于更好应对多维度场景的复杂文本处理任务，增强LDA模型的泛化能力以及建模结果的准确性和可解释性，实现更精准的主题挖掘和识别。",
    "context4": "![](images/5dcb52c5f67ec47050c3415e15f37bb11ae47d0a191bc225bf94f705ce990300.jpg)  \n图1国内外发文量年代分布 Fig.1 The Chronological Distribution of Published Papers at Home and Abroad"
  },
  "2文献调研概述": {
    "context1": "<XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXYXX",
    "context2": "本研究以Web of Science核心集、LISA、GoogleScholar为英文数据源进行文献检索，以中国知网、维普、万方数据库为中文数据源进行文献检索。英文文献以主题 $=$ “Latent Dirichlet Allocation”OR“TopicModel\\*”为检索式进行检索，中文文献以主题 $=$ “LDA”OR“潜在狄利克雷分布”OR“概率主题模型”为检索式进行检索。中英文数据源均限定为图书情报领域期刊(中文进一步限定为CSSCI来源期刊)，检索时段设置为近十年（2012年1月1日到2022年1月31日)。基于文献标题、关键词与摘要，辅以内容审读，选取符合研究主题的文献，最终筛选得到369篇英文文献和426篇中文文献。文献分布如图1所示，近十年国内外研究发文量均处于持续增长的态势，且国内研究的发文量远高于国外。可以看出,LDA相关研究引起国内外图情领域学者的高度关注，研究成果较为丰硕。",
    "context3": "进一步，本研究深度研读代表性文献，基于应用过程的关键环节梳理构建了LDA模型应用研究分析框架（见图2）。LDA模型应用过程主要包括：在文本预处理环节，对主题建模所涉及的数据源进行预处理操作，获得模型所需的格式化数据；在模型构建环节，先依据研究情境选定合适的主题模型，然后结合相关模型评价方法确定最优主题数；在模型求解环节，采用合适的主题建模工具完成模型求解；最后，依据实际研究情境，结合相关方法与工具解决具体应用领域问题[7]。当前,LDA模型的应用涵盖主题探索、知识组织、学术评价、情感分析、推荐研究等诸多领域。本文将基于上述流程对现有应用研究现状进行归纳总结。",
    "context4": "![](images/346244b864719981aebd6d52b5679798f5bbed9fb7bb1c64e35d8ae41f504972.jpg)  \n图2图情领域LDA主题模型应用研究分析框架 Fig.2 The Analytical Framework for the Application Studies of LDA Topic Models in LIS field   \n(C)1994-2023 China Academic Journal Electronic Publishing House. All rights reserved.http://www.cnki.net"
  },
  "3LDA主题建模的应用过程": {
    "context1": "88888888888888888888888888888888888888888888888"
  },
  "3.1文本预处理": {
    "context1": "文本预处理的过程针对不同的数据源，通过分词、去停用词以及特征选择等预处理技术获取模型所需的格式化数据。该环节可实现文档内容初步降维，降低模型推理时间，是LDA主题建模的基础。其中，所获取表达文本主题语义的特征词对主题建模结果的可解释性具有重要影响。",
    "context2": "在主题建模的数据源方面，基于微博、Twitter等社交媒体平台短文本数据的主题挖掘成为近年来图情领域极具价值的研究方向。然而由于文本长度有限，稀疏性高，更新速度快以及规模巨大，LDA模型在处理短文本时效果较差。同时此类数据一般带有许多俚语、缩略词以及表情符号等，其文本语义相对模糊、逻辑关系较差，经过预处理后的文本能够有效表达主题信息的词项较少，这就使得抽取有意义主题的过程更加复杂[10]。针对稀疏、动态短文本，如何保障主题建模结果的质量是当前需解决的重点问题。学者们一是通过信息整合构建伪文档来增加文本长度；二是使用改进后的扩展模型，包括调整模型假设和改进主题生成过程等措施[]。前者如狄利克雷多项式混合模型（DirichletMultinomialMixture,DMM),针对短文本词项少于长文本文档的特点，严格限制模型假设中的主题数量;后者如词对主题模型（BitermTopic Model,BTM），从词间关系中挖掘局部语言信息，在词对上进行主题建模，以提高短文本主题挖掘的全面性和准确性。",
    "context3": "确定主题建模的数据源后，通过具体的文本预处理技术获取模型所需的格式化数据。得益于成熟的分词工具[7.12]与停用词表，中文文本数据在分词与去停用词阶段已经形成一体化的应用流程。而英文文本数据通常以空格为分隔符进行一元分词，导致单个单词所代表的语义较少，建模结果的可解释性较差。有研究提出按照词组分词[13]，或者引入短语生成算法[11]挖掘数据中的短语来提高特征词的主题表示能力。",
    "context4": "特征选择是在分词与去停用词的基础上对建模语料的进一步降维，常用的方法有评价函数[14]（如词频、信息增益等)、领域本体[15]、词性过滤[16]以及正则表达式[7]等。不同的特征选择方法在特征词降维上具有不同的性能，对建模结果的可解释性也具有不同程度的影响。以特征选择方法中的领域本体和词性过滤为例，基于领域本体进行词汇过滤可以有效提高特征词的领域贴切性，提高建模结果在专业领域背景下的可解释性。如林杰[15]等利用扩充后的汽车专业本体词汇对语料进行词汇过滤，有效提高了主题词的领域纯度与主题的可解释性，但缺点是依赖于研究人员的领域知识，花费的人工成本较高。而词性过滤[16]可以获取对主题贡献度较大的名词和动词，相对于基于本体的方法可以更便捷、高效地实现文本降维，但词的领域贴切性相对较差，专业领域背景下建模结果的可解释性弱。",
    "context5": "整体来看，分词、去停用词以及特征选择等预处理环节已形成较为成熟的处理流程，当前的应用研究多固化于已有的文本预处理技术工具与语义资源，侧重于单一方法或少数几种方法的简单结合。值得注意的是,分词算法[18]的选择,领域术语[19]与领域停用词表[20]的构建，以及不同的特征选择方法对特征词表达主题语义时的有效性都具有不同程度的影响。因此，需针对不同的应用场景深入探索，以提高文本预处理的质量。"
  },
  "3.2主题模型构建": {
    "context1": "经过文本预处理操作获得主题模型所需的格式化数据后，进入模型构建与求解环节。首先需要依据数据特征与研究情境，选择或构建合适的主题模型，然后通过模型评价方法确定最优主题数，最后选择或构建相应的主题建模工具进行自动参数估计，从而完成模型求解。"
  },
  "3.2.1主题模型选择": {
    "context1": "主题模型构建的第一步是选定合适的主题模型。LDA模型是基于词袋模型提出的三层贝叶斯概率主题模型，模型训练时无需人工标注数据，挖掘长文本如科技文献[21等语料的隐含语义时效果良好，且应用工具和流程比较成熟，是目前最常用的主题模型。随着所处理的语料对象、面临的文本分析任务更趋复杂多样,LDA模型应用具有一定局限性，比如无法有效处理动态短文本，应用于大规模数据集时训练时间过长[22],而且无法识别主题之间的关系[23]。模型泛化能力以及建模结果的准确性和可解释性受到挑战[4]。针对LDA模型的应用局限性，学者们根据文本特征与任务情境提出各类扩展模型[3以提升主题建模效果。综合LDA模型的扩展类型（如非参性、动态性、相关性等）及其在各数据库中的总被引频次，表1归纳了图情领域应用各类LDA模型的代表性研究。",
    "context2": "表1图情领域应用各类LDA模型的代表性文献 Table 1 Representative Literature About the Application of Various LDA Models in LIS Field",
    "context3": "<table><tr><td rowspan=1 colspan=1>模型类型</td><td rowspan=1 colspan=1>模型名称</td><td rowspan=1 colspan=1>提出时间</td><td rowspan=1 colspan=1>模型说明</td><td rowspan=1 colspan=1>应用实例</td></tr><tr><td rowspan=1 colspan=1>传统主题模型</td><td rowspan=1 colspan=1>LDA</td><td rowspan=1 colspan=1>2003</td><td rowspan=1 colspan=1>第一个完整意义上的产生式概率主题模型，适用于处理静态长文本数据</td><td rowspan=1 colspan=1>开放政府数据与信息自由相关研究文献的核心主题分析[24]</td></tr><tr><td rowspan=1 colspan=1>非参模型</td><td rowspan=1 colspan=1>HDP(HierarchicalDirichlet Process)</td><td rowspan=1 colspan=1>2006</td><td rowspan=1 colspan=1>自动确定主题数目，克服人工确定主题数的主观性与随机性</td><td rowspan=1 colspan=1>弗格森骚乱期间的推特子事件检测[25]</td></tr><tr><td rowspan=1 colspan=1>动态主题模型</td><td rowspan=1 colspan=1>DTM(Dynamic TopicModel)</td><td rowspan=1 colspan=1>2006</td><td rowspan=1 colspan=1>引入时间信息,动态追踪主题随时间变化的情况</td><td rowspan=1 colspan=1>Reddit用户智能手表关注主题与演化趋势分析[26]</td></tr><tr><td rowspan=1 colspan=1>相关主题模型</td><td rowspan=1 colspan=1>CTM(Correlated TopicModel)</td><td rowspan=1 colspan=1>2007</td><td rowspan=1 colspan=1>通过协方差矩阵描述主题间的关联关系,解决LDA模型建模结果之间不相关的问题</td><td rowspan=1 colspan=1>环境科学文献主题识别与相关性分析[27]</td></tr><tr><td rowspan=1 colspan=1>监督主题模型</td><td rowspan=1 colspan=1>Labeled-LDA</td><td rowspan=1 colspan=1>2009</td><td rowspan=1 colspan=1>引入标签信息以控制主题数量,提高建模结果的真实性与有效性</td><td rowspan=1 colspan=1>基于在线评论的产品属性极性分析[28]</td></tr><tr><td rowspan=1 colspan=1>结构主题模型</td><td rowspan=1 colspan=1>STM(Structural TopicModel)</td><td rowspan=1 colspan=1>2014</td><td rowspan=1 colspan=1>在计算每个主题和主题中单词条件分布时添加更多协变量(如文档级元数据),以提高模型推理能力</td><td rowspan=1 colspan=1>信息管理相关研究文献主题识别[29]</td></tr><tr><td rowspan=1 colspan=1>作者主题模型</td><td rowspan=1 colspan=1>ATM(Author TopicModel)</td><td rowspan=1 colspan=1>2004</td><td rowspan=1 colspan=1>引入作者信息以识别作者研究主题,多角度挖掘语料内容特征</td><td rowspan=1 colspan=1>基因组学科研人员之间的跨主题合作研究30</td></tr><tr><td rowspan=1 colspan=1>情感主题模型</td><td rowspan=1 colspan=1>JST (Jiont SentimentTopic Model)</td><td rowspan=1 colspan=1>2009</td><td rowspan=1 colspan=1>在文档与主题层之间构建附加的情感层,可同时检测主题和主题相关情感信息</td><td rowspan=1 colspan=1>平板电脑在线评论主题和主题相关情感信息检测[31]</td></tr><tr><td rowspan=1 colspan=1>短文本主题模型</td><td rowspan=1 colspan=1>BTM</td><td rowspan=1 colspan=1>2013</td><td rowspan=1 colspan=1>对语料库中的共现词对进行主题建模，以解决文档的稀疏性问题</td><td rowspan=1 colspan=1>自然灾害(台风海燕)推文主题识别[32]</td></tr><tr><td rowspan=1 colspan=1>词向量主题模型</td><td rowspan=1 colspan=1>TWE(Topical WordEmbeddings)</td><td rowspan=1 colspan=1>2015</td><td rowspan=1 colspan=1>在LDA 建模的基础上,联合TWE模型构建主题词向量,更好地发现主题之间的隐含关联</td><td rowspan=1 colspan=1>医学科技报告主题演化分析[33]</td></tr><tr><td rowspan=1 colspan=1>神经网络主题模型</td><td rowspan=1 colspan=1>NTM(Neural TopicModel)</td><td rowspan=1 colspan=1>2015</td><td rowspan=1 colspan=1>从前馈神经网络角度描述“文档-主题”和“主题-词”分布,通过后向传播算法学习模型参数,结构简单</td><td rowspan=1 colspan=1>类人对话系统构建研究[34]</td></tr><tr><td rowspan=1 colspan=1>联合训练主题模型</td><td rowspan=1 colspan=1>LDA2vec</td><td rowspan=1 colspan=1>2016</td><td rowspan=1 colspan=1>利用 Word2vec模型引入词的上下文关系进行建模,提高了文本隐含主题语义的识别效果</td><td rowspan=1 colspan=1>个性化新闻推荐研究[35]</td></tr><tr><td rowspan=1 colspan=1>多语言作者主题模型</td><td rowspan=1 colspan=1>JointAT(Joint AuthorTopic Model)</td><td rowspan=1 colspan=1>2020</td><td rowspan=1 colspan=1>同时引入作者信息与多语言信息,提高多语言环境下主题模型对作者研究兴趣建模的准确性</td><td rowspan=1 colspan=1>情报学领域多语言数据集下的科研人员研究兴趣识别[36]</td></tr></table>",
    "context4": "如表1所示，各类LDA模型的性能各具特色，基于模型的改进特点与已有的LDA扩展模型分类相关研究[3.7]，以上扩展模型大致上分为六类: $\\textcircled{1}$ 贝叶斯非参模型HDP; $\\textcircled{2}$ 基于时间因素的扩展模型DTM; $\\textcircled{3}$ 基于模型参数的扩展模型CTM; $\\textcircled{4}$ 有监督模型Labeled-LDA; $\\textcircled{5}$ 基于文档元数据的扩展模型STM; $\\textcircled{6}$ 面向特定任务的扩展模型ATM、JST、BTM、TWE、NTM、LDA2vec和JointAT。不同类型的扩展模型应用场景丰富，可以满足科研人员不同的建模需求。当数据处理对象为静态长文本，可直接选择传统LDA模型；如果数据处理对象具有明显的动态性、主观性或稀疏性等特征，可选择动态主题模型、面向特定任务的情感主题模型或短文本主题模型等来提高建模精度。在围绕LDA扩展模型的应用研究中，早期基于非参性、相关性等的扩展模型仍然以其良好性能而被广泛应用。",
    "context5": "随着新兴应用场景的不断涌现，主题挖掘任务的多元化使得近来面向特定任务的扩展模型成为显著趋势，如基于词向量、多语言作者信息以及混合语境[37]等扩展模型。然而扩展模型依然存在一些不足之处，其包含的隐变量和附加信息较多，算法复杂度相对较高，同时受训练语料与任务情境的影响，模型的领域通用性和建模结果的稳定性有待提高。",
    "context6": "值得注意的是，基于深度学习思想与方法的主题模型已成为LDA扩展模型研究的重要分支。相较于其他扩展模型，深度学习主题模型结合词向量技术、神经网络等方法充分挖掘词汇的上下文语境以及词间关系，具备较强的主题语义理解能力，建模结果的可解释更高[38]。目前，深度学习主题模型主要包括三类：词向量辅助的概率主题模型、基于神经网络结构的主题模型和联合训练主题模型[4。词向量主题模型通过训练低维稠密的词向量来刻画词汇间的语义相似度，应用于短文本和领域文本时可有效提高主题词的语义一致性,如基于高斯分布的Gaussian LDA模型[39]。基于神经网络结构的主题模型多以词袋作为模型输入，进而通过增加相应的网络层来捕捉词汇间的语义关系，同时结合稀疏约束解决“主题-词”分布的稀疏性，提高主题模型的生成质量。联合训练主题模型则融合了概率主题模型与神经语言模型的优势,可以在原有“文档-主题-词”全局语义关系发现基础上，通过语言模型发现句子级词序之间的依赖关系，克服“词袋”假设的局限性。以上深度学习扩展模型在短文本、领域文本等数据上的主题聚类效果相比传统模型性能更优，功能更丰富，但是在应用过程中通常需要大规模语料的支撑，训练过程也更为复杂，常面临参数调优等问题。除了词向量扩展模型较为常见外，其他两类深度学习扩展模型应用还有待进一步探索。"
  },
  "3.2.2最优主题数选择": {
    "context1": "依据研究情境选定最合适的主题模型后就要进行参数估计与设置。参数估计用于推理“文档-主题”和“主题-词”两组分布,目前已形成多种近似推理算法[7]。参数设置与模型性能密切相关，可以赋予模型特定属性[40],主要涉及Dirichlet先验α、β参数，以及主题数。α和β常按照经验值进行设置。",
    "context2": "主题数则依据主题模型质量评价方法做出选择，而最优主题数的确定是一个长久以来的难题。主题数过多容易导致主题概括范围小，语义内容差异小，主题划分困难；主题数过少则容易导致概括的语义内容过于宽泛，忽视小主题。主题数选择直接影响LDA主题建模结果的准确性和可解释性。目前相关研究在确定主题数时通常基于先验知识对文档包含的主题数进行初步估计，再结合困惑度、一致性以及主题间相似度等质量评价方法作出选择。本文对几种典型的主题数确定方法的核心思想、优缺点进行归纳比较，如表2所示。",
    "context3": "表2归纳总结显示，目前确定LDA模型主题数的方法较为丰富，评价角度各有侧重，差别较大，还没有形成一致的主题建模结果评价准则，客观评估建模结果有效性的问题仍未解决。从实际应用情况来看还是以困惑度居多，而有研究认为一致性是衡量主题质量最有效的方法[47]，该指标的使用在近两年的相关研究中有所提升。由于在上述模型评价方法的指导下依然可能产生混合主题、不合逻辑的主题和难以区分的主"
  },
  "表2常用主题数确定方法及其比较": {
    "context1": "'able 2 The List and Comparison of Common Methods for Determining the Number of Topic题等问题，为进一步保障建模结果的有效性，相关研究开始对传统评价方法进行改进[43],尝试提出新指标[41],注重以可解释性为标准进行模型评价[48]，引入专家意见类指标，如同质性、完整性以及V-Measure[49]，以保障主题生成的质量与可靠性。也有学者提出对相关方法进行联合应用，并在模型运行的过程中建立评价机制以动态调整最优主题数[10]，提高主题数选择的灵活性。此外,LDA模型基于随机抽样进行参数求解以及其对建模语料极为敏感的特征，导致建模结果稳定性较差。部分研究尝试引入新的稳定性分析算法[50]以及健壮性、描述能力等模型质量评价指标[51来选择最优主题数，以保障主题模型的预测能力，进而提高建模结果的可靠性。",
    "context2": "<table><tr><td rowspan=1 colspan=1>确定方法</td><td rowspan=1 colspan=1>核心思想</td><td rowspan=1 colspan=1>优点</td><td rowspan=1 colspan=1>缺点</td><td rowspan=1 colspan=1>应用实例</td></tr><tr><td rowspan=1 colspan=1>困惑度</td><td rowspan=1 colspan=1>文档中每个词汇产生的概率的几何平均值的倒数,词汇产生的概率越大,困惑度越小</td><td rowspan=1 colspan=1>衡量模型对新数据的预测能力</td><td rowspan=1 colspan=1>基于困惑度选取的主题数稳定性差,且往往偏大[41,导致抽取的主题语义空泛</td><td rowspan=1 colspan=1>Wu H[42],2018</td></tr><tr><td rowspan=1 colspan=1>一致性</td><td rowspan=1 colspan=1>主题下词语的语义关联性越紧密,一致性越高,模型可解释性越好</td><td rowspan=1 colspan=1>衡量主题的可解释性</td><td rowspan=1 colspan=1>对于低频主题词测量效果较差,而且无法区分高频词和表征主题的信息词[43]</td><td rowspan=1 colspan=1>Sharma A[29]，2021</td></tr><tr><td rowspan=1 colspan=1>主题间相似度</td><td rowspan=1 colspan=1>当主题之间平均相似度最小时,主题结构稳定,模型最优</td><td rowspan=1 colspan=1>衡量主题结构的稳定性</td><td rowspan=1 colspan=1>相似度测量指标选取和构造方法具有一定主观性[44]</td><td rowspan=1 colspan=1>Jeong Bl45],，2017</td></tr><tr><td rowspan=1 colspan=1>经验法</td><td rowspan=1 colspan=1>参考以往文献或者实际经验,不断进行选代实验,观察主题聚类效果后，人工判断决定</td><td rowspan=1 colspan=1>简单易用,人工监督下的可控性更高</td><td rowspan=1 colspan=1>主观性大,时间、人力成本高</td><td rowspan=1 colspan=1>曹树金[46]，2020</td></tr></table>"
  },
  "3.3模型求解": {
    "context1": "完成最优主题数选择后，就要选择或构建相应的主题建模工具完成模型求解。目前已研发出各类开源LDA建模工具来完成参数自动求解，在图情领域常用的有七种。从开发语言来看，分别是基于Java语言的Stanford TMT（Stanford Topic Modeling Toolbox）[52]、JGibbLDA[53]以及Mallet[24]，基于R语言的Lda库[54与Topicmodels[55库，这五种工具的模型基础均是LDA模型；另外两种是基于Python语言以OLDA（Online LDA）模型为基础的Gensim库[56]与Scikit-learn[57]库。利用上述工具完成模型求解得到“文档-主题”分布与“主题-词\"分布两组参数后,再通过主题词筛选进行主题命名，完成每个文档中的隐含主题发现。",
    "context2": "面向科技文献数据，以在线消费平台评论数据及网络舆情数据为代表的用户生成内容，以及新闻报道、政策文本等网络信息资源挖掘分析。"
  },
  "4.1.1科技文献的主题探索": {
    "context1": "科技文献是科学技术信息发布与传播的重要载体，主要包括科技期刊、会议论文、专利和科技报告等[7]。早期科技文献的主题发现依赖于以篇章为单位的词频统计、共词分析、引文分析等传统计量学方法，关注词或者文献等外部数量特征。而LDA模型可以对文本内容进行主题建模，逐渐成为科技文献主题探索的主流工具之一，比如针对SIGIR（Special InterestGroup on Information Retrieval)会议论文[58以及中国ICT产业[21]专利文献相关研究热点的主题分析。总体而言，科技文献主题发现研究存在过度依赖单一LDA模型的问题，只有部分学者尝试应用新方法进一步优化对文本语义的理解。比如裘惠麟等[59]将期刊论文与专利文献同时作为数据源，运用LDA2vec模型识别机器学习热点研究主题，该模型在LDA模型全局性建模的基础上，通过Word2vec词向量对语料局部的上下文信息进行建模，从而挖掘更丰富的隐含语义。然而Word2vec等经典词向量模型通常只对每个词汇训练一种向量表示[4，难以发现不同语境下词的不同含义。有研究引入TWE[33模型，可同时训练出词汇和主题的向量表示，从而学习不同主题下词向量的不同表示，有效提高了医学科技报告主题挖掘的精度。"
  },
  "4LDA主题模型的应用领域": {
    "context1": "LDA模型可以有效挖掘文本中隐含的语义信息，已经被广泛应用于主题探索、知识组织、学术评价、情感分析以及推荐研究等众多领域。"
  },
  "4.1主题探索": {
    "context1": "主题探索研究主要包含主题发现与演化分析[6]。LDA模型拥有良好的降维能力，可以从大规模文本中通过无监督的方式提取隐含语义，保证主题提取的相对客观性与效率，是主题探索的热门工具。本文基于相关文献的内容分析发现，当前图情领域主题探索主要",
    "context2": "主题演化分析以主题发现为前提，是对主题动态发展规律的把握。在主题演化分析中，如何提高主题演化路径分析的精度一直是研究热点，如引文层次狄利克雷过程[6]（Citation Involved Hierarchical DirichletProcess,CIHDP)，在人工智能领域期刊论文的主题提取中使用引文信息来增强文档文本表示，可自动确定每个时期的主题数量，同时识别更加详尽完整的路径分裂和融合信息；针对石墨烯专利文献，有研究在LDA模型的基础上，通过引入新颖性、关注度和主题结构指标衡量主题发展程度，并识别不同状态的主题类型[42]。此外，也有研究利用主题演化过程中的时间序列特征来提高主题演化分析的精度。比如以图情学科期刊论文为数据源，在LDA模型抽取学科主题的基础上，通过时间切片获得学科主题的热度序列，然后利用长短期记忆神经网络(Long Short-Term Memory,LSTM）[13]对学科主题热度演化的时间序列特征进行建模，可有效提高学科主题热度未来趋势预测的准确性。"
  },
  "4.1.2用户生成内容的主题探索": {
    "context1": "在用户生成内容的主题发现相关研究中，一是将在线消费平台用户评论作为数据源，目标是挖掘用户对产品或服务的观点。比如Opinion LDA[61],通过改进文档结构，将基于用户评论内容的词序列转换为基于用户观点的产品特征词序列，可有效识别用户对具体产品特征的偏好。二是将网络舆情数据作为数据源，目标是舆情管控。比如在LDA模型挖掘微博文本主题特征的基础上，结合随机森林算法进行谣言分类[62]，谣言识别的准确性显著提升。但是以上两类数据通常以短文本居多，反映文本主题内容的特征词较少，导致利用LDA进行主题发现时较难挖掘完整的语义信息。针对上述问题，常用的方法主要通过信息整合来增加文本长度或使用更适用于短文本的主题模型。也有研究尝试将LDA模型与其他方法相结合，比如在得到学术APP评论的建模结果以后，通过Glove词向量计算词语相似度来扩充主题下的特征词[63]，进而提高主题间的区分度，挖掘更加系统深层的主题信息。",
    "context2": "用户生成内容的主题演化分析关注话题内容的变化趋势，对企业、政府等机构具有重要的现实意义。面向在线消费平台用户评论数据，主题演化分析可以挖掘用户在不同时间节点对产品与服务的关注重点[64],辅助企业提升产品与服务品质。面向网络舆情数据的主题演化分析[65]可辅助有关部门进行舆情应急管控。然而社交媒体平台是一个极具动态性、复杂性的舆论场，舆情管控效果的好坏在于对舆情演化过程中的关键节点、热点主题[6]的发现。学者们以超网络理论为基础，通过LDA模型识别微博主题子网，然后结合相应的社交、内容以及情感子网构建微博舆情超网络，采用超边排序算法HyperEdgeRank识别出关键人物，全面挖掘微博舆情传播中的关键节点[7],有效服务于社交媒体舆情监管。"
  },
  "4.1.3其他网络信息资源的主题探索": {
    "context1": "新闻报道、政策文本等网络信息资源的主题发现可以为企业和政府决策提供有利的情报支持，也可辅助相关研究人员追踪研究热点。在新闻报道[68]的主题发现研究中，由于新闻文本主题识别一般存在文本数据不均衡的问题，有研究[69]结合特征检测方法（独立性检测、方差检测和信息熵检测)优化特征词的主题表示能力，文本主题识别的准确性得以显著提高。政策文本是指因政策活动而产生的记录文献，包括官方文献、公文档案以及政策舆情文本等[70]。不同语境下政策词语的内涵差别较大，而LDA 模型利用文本、主题、词之间的关系可以解决文本聚类中语义挖掘的问题，已经被广泛应用于气候[71、政府开放数据[72]等政策文本的主题发现。也有学者[73]利用LDA2vec模型进一步提高政策文本语义内涵挖掘的完整性。此外，标签是一类对网络信息资源进行分类或描述的词语，标签生成则是指从文档中提取出能体现文档主题的词语或短语[74]。LDA模型可以保证标签生成时的客观性与效率，已被广泛应用于微博[74]、在线医生[75]等的标签生成研究中。部分研究通过构建扩展模型将其用于特定领域数据的标签生成，如用于电子健康记录数据表型标签生成的sureLDA[76]（Surrogate-guided ensembleLatentDirichletAllocation）,使得LDA模型的应用范围得到进一步扩展。",
    "context2": "在新闻报道的主题演化分析中，当前研究多以LDA模型为基础，引入其他模型[77]与方法来提高演化分析的准确性。比如引入流形学习[7可从全局时间角度重构新闻主题间的关系，避免利用相邻时间窗□导致的演化路径断裂问题；也可利用基于密度的DBSCAN聚类算法[79]去除噪声文本，从而保障 LDA 模型主题抽取的纯度，提升主题演化分析的准确性。",
    "context3": "在政策文本的主题演化分析中,LDA模型结合主题相似度、主题强度等算法已经被应用于人工智能[80]、区域技术创新[81]等政策文本的量化分析，可有效支持相关政策的制定和完善。部分研究使用扩展模型如主题时间模型[82]（Topicover Time,ToT），将时间因素引入，获取不同时间切片下的主题分布强度，可避免繁琐的主题对齐环节。"
  },
  "4.2知识组织": {
    "context1": "LDA模型可以通过无监督的方式以主题和主题词为单元描述信息资源的内容，促进了分析单元从文档向主题词细化发展，被广泛应用于知识组织研究中。知识组织关注文本中的语义信息，强调知识之间的关联关系。而LDA模型可以通过挖掘隐含的主题特征构建文档与特征词之间的关联关系，方便知识推理，被图情领域学者应用于知识图谱与主题图谱构建研究。"
  },
  "4.2.1知识图谱构建": {
    "context1": "目前的知识图谱构建一般采用命名实体识别与模版匹配等方式来实现，在专业领域语料的知识图谱构建中可以获得较为完备的实体及其关系抽取。当语料内容涉及不同主题时，仅通过命名实体识别等方法抽取局部信息作为实体对象，会造成语义缺失等问题[83]。而利用LDA模型将基于全局信息抽取的文本主题作为实体，可实现知识图谱的精细化展示，将主题复杂、关联性差的文本数据进行结构化组织，提高实体间的关联关系，能有效提升知识推理的效果。比如华斌等[83]构建的电子政务领域知识图谱，利用LDA模型获取主题实体，完成电子政务领域实体扩充，从而解决实体抽取算法存在语义缺失的问题，以便更好地进行知识推理，辅助政务决策。除了将主题作为实体构建知识图谱外，也可联合主题词来实现。比如岳丽欣等[84首先通过LDA模型对医疗健康信息领域文献进行主题识别，然后通过社会网络分析挖掘核心主题词，最后基于核心主题词的共现关系构建医疗健康信息领域知识图谱，辅助领域知识关联分析。"
  },
  "4.2.2主题图谱构建": {
    "context1": "主题图谱是一种存储主题及其之间逻辑关系与层次结构的知识库[85]，相比于知识图谱，其更加适用于无序、非结构化、主题发散特征明显的网络信息资源组织。在处理非结构化文本信息时，传统主题聚类方法如共词分析方法易受词频、文本领域的复杂性的影响，难以解释文档间以及词汇间的语义关系，而K-means聚类分析结果描述比较复杂，并且两者都难以解决词项不匹配(即近义、同义词)的问题，导致主题识别效果较差。LDA模型在非结构化文本信息的主题建模上表现良好，通过主题的思想描述文档的隐含特征以及词汇之间的语义关系，一定程度上可以解决词项不匹配的问题，相比于传统主题聚类方法可以更好地挖掘文本中的语义信息，被广泛应用于主题图谱构建中，比如临床医学课程知识主题图谱[8。此外，主题图谱适用于舆情分析[8]。比如在基于微博信息的网络舆情管控中，通过LDA模型对用户评论转发文本进行主题聚类后，既可将用户所属的共同主题作为节点，主题分布的相似度为边构建用户主题图谱[88]，,也可将用户作为节点，转发评论关系为边构造用户主题图谱[89],从而挖掘舆情演化中的关键主题与关键用户，辅助监管部门实现精准舆情应对。",
    "context2": "尽管LDA模型能较好地解决非结构化文本信息的主题图谱构建问题，但是也需要注意增强主题词的专业领域相关性以及主题图谱的时效性，以提高主题图谱的应用价值。"
  },
  "4.3学术评价": {
    "context1": "学术评价主要包括文献影响力评价与作者影响力评价等。现有的定量学术评价方法主要通过综合传统的文献计量学指标如被引频次、网络特征指标如PageRank、H指数以及Altmetrics评价指标等进行评价。然而文献内容与作者涉及的研究领域一般具有主题差异[54]，从而导致上述指标难以有效地反映文献与作者在某一研究主题中的实际影响力。因此，相关研究开始以主题为单位对文献与作者进行细粒度的学术评价。对文献或作者的研究主题进行分类是按主题进行学术评价的首要环节。而LDA模型可通过概率推断求解“文档-主题”分布参数，从而将文献客观地分为若干主题类别，然后根据文献与作者之间的映射关系，实现作者研究主题的分类，再结合其他计量指标进行影响力计算[90。有研究直接使用相应的影响力评价模型如集合主题 PageRank 模型[91]（Collective TopicPageRankModel,CTPM)，在识别文献主题及主题间相关性的基础上，引入文献被引次数、期刊影响因子等元数据，有效反映了文献在特定主题内的影响力。作者影响力评价中，有研究采用ATM模型[92]来实现更加精准的作者研究主题分类。在当前科学研究领域不断细分背景下，LDA模型可以获取文献与作者的研究主题，较好地解决传统学术评价中忽视内容信息的问题，进一步推动精细化学术评价发展。"
  },
  "4.4情感分析": {
    "context1": "LDA模型主要用于挖掘语料中的主题信息，难以识别相关主题背后用户的情感态度。深入挖掘主题的情感倾向需要结合相应的情感分析方法，或者构建情感主题模型来实现，相关研究成果对企业与政府的决策制定具有重要的现实意义。例如采用LDA获取Reddit平台中公众关注的三星手机产品主题[45]，随后结合情感分析工具AlchemyAPI挖掘公众对各主题的情感态度，分析不同关注度下主题的情感倾向，从而帮助相关企业找准用户需求与市场痛点，辅助商业决策。也有研究直接采用情感与行为联合主题模型[16](Sentiment and Behaviour Topic Model,SBTM）,该模型可同时结合用户的情感与互动行为模式进行复杂主题发现，主题建模结果表现出更强的区分性。针对政府决策制定的相关研究主要体现在网络舆情管控与政务服务平台建设[93]中。比如在线话题情感识别模型[94] （Online Topic and Sentiment Recognition Model,OTSRM)，利用情感强度的传递性构造基于时间维的话题-情感分布，使用相对熵方法计算话题焦点在相邻时间片段上的最大情感值，可动态识别文本中的主题情感趋势，提高與情预警的精度。用户情感在不同的情境下呈现不同的意义和取向，具有多维性、强弱性以及隐秘性等特征，如何构建更加优化的情感主题模型，提升主题情感识别的精度仍需进一步探索。"
  },
  "4.5推荐研究": {
    "context1": "推荐系统可以有效缓解信息超载问题，其关键技术主要包括用户建模、推荐对象建模和推荐算法三个方面。面向文本信息建模时，采用TF-IDF、贝叶斯分类器以及k最近邻方法等难以识别文本更深层次的语义特征，而基于协同过滤与网络结构的推荐算法常因为数据稀疏问题导致推荐效果不理想。LDA模型在数据降维与潜在语义特征挖掘上性能良好，可以有效识别用户兴趣与推荐对象中的关键信息，被广泛应用于用户与推荐对象建模，比如社交网络好友推荐[95]、个性化新闻推荐[35等研究。大数据环境下，数据的稀疏性与海量动态性特征进一步突出，基于LDA模型的主题挖掘与信息推荐的性能受到较大挑战。崔金栋等[22]使用Hadoop平台对微博数据进行结构化处理后，再利用LDA模型进行用户微博主题信息提取，有效提升了大数据信息推荐的效果。",
    "context2": "LDA模型较好地解决了传统用户与推荐对象建模过程中缺乏语义性的问题，并以其良好的降维能力提高推荐的精度。但是大数据环境下信息冗余与过载等问题使得LDA模型的推荐性能受到影响，如何融合不同方法，进一步提高推荐效果还亟待探索。"
  },
  "5结论与展望": {
    "context1": "<XXXXXXXXXXXXXX<XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",
    "context2": "LDA模型因其良好的扩展性与数据降维能力可以满足研究人员不同的主题建模需求，已成为近年来应用最广泛的文本主题挖掘技术。传统主题挖掘分析通过词频统计、共词分析、社区探测以及引文分析等方法来实现，关注词或者文献的外部数量特征。而LDA主题模型通过“文档-主题-词”三层结构来描述文档的主题以及词汇之间的语义关系，相比于传统主题挖掘方法可以更好地挖掘文本中隐含的语义信息，在细粒度知识提取与挖掘分析中扮演着关键性角色。但其本身也具有一定的局限性，比如建模结果的可解释性较差，难以确定最优主题数等，对其模型的扩展与优化应用仍是未来重要的研究方向。",
    "context3": "本文梳理近10年图情领域相关研究文献，通过内容分析，构建了LDA模型应用研究分析框架，基于LDA模型应用过程视角，从文本预处理、模型构建（主题模型选择与最优主题数选择）以及模型求解三个方面系统归纳了LDA模型应用的核心环节和技术难点，全面总结了LDA模型在主题探索、知识组织、学术评价、情感分析以及推荐研究等应用领域的研究现状。研究发现图情领域LDA模型已经形成较为成熟的分析流程，研究热度仍在持续增长。国内外研究方向整体较为相似，然而在具体的应用环节还存在一定的差异。例如在最优主题数选择方面，国外学者尝试克服传统概率类评价指标(如困惑度）的不确定性，侧重于引入新的模型评价指标，注重主题建模结果的可靠性、稳定性以及可解释性；国内学者则多依赖于困惑度、经验法等指标，较少尝试新评价指标。在应用领域中，国外多将LDA模型用于基础的信息组织研究，国内学者在知识图谱与主题图谱构建研究中有较多尝试。从整体上来看，如下问题值得进一步探讨：",
    "context4": "（1）应对海量规模数据、多模态数据等复杂处理任务挑战，进一步挖掘LDA主题模型的应用价值。当前LDA模型应用主要是面向文本数据建模，缺乏在音频、图像以及视频等资源类型上的应用探索。随着图情领域主题建模对象大数据特征愈加明显,LDA主题建模面临数据规模庞大和数据结构日趋复杂的挑战；同时相较于单模态文本数据，音频、图像、视频等多模态数据的内容丰富，主题表示能力强，基于多模态数据的主题挖掘成为引人关注的重要发展方向[3。未来研究可尝试引入计算机领域的分布式和并行计算来减少LDA模型处理海量规模文档的时间，提高其处理多源异构数据的能力，同时进一步探索结合词向量、语言模型以及神经网络结构的深度学习主题模型，进行多模态数据的主题提取研究，提高模型的主题挖掘深度与发现能力，提升图情领域精准信息服务能力。",
    "context5": "（2）重视文本预处理阶段特征词抽取，提升特征词的主题表征能力，保障主题建模结果的语义质量。主题建模结果的语义质量直接关系到主题分析的可靠性，进而影响其在情感分析、推荐研究等具体应用领域中的实际应用效果。高语义质量的主题建模结果具备同一主题内主题词间关联性高，而主题间语义区分性高的特征，可以清晰表征语料所属领域的内容主题。文本预处理是主题建模的基础步骤，对于建模结果的可读性与可解释性具有直接影响。而现有研究在文本预处理阶段对特征词抽取的质量重视不够，多固化于已有的技术工具与语义资源，特征词抽取的领域纯度存在较大提升空间。借助相应的自然语言处理技术，面向不同主题挖掘任务构建领域词典、语义资源以及高质量大规模的标注数据集是未来重要的研究方向。",
    "context6": "（3）构建系统的LDA模型质量评价体系，优化主题数选取方法。当前针对主题模型质量评价多利用困惑度与经验法，然而不同评价指标下模型性能表现差异较大，片面依赖一种方法难以客观有效地评价主题模型质量。对传统评价方法改进、引入新方法以及多指标联合应用进行模型质量评价成为显著发展趋势。未来可尝试构建更系统的主题模型质量评价体系，优化主题数选取方法，提升主题建模结果的质量。",
    "context7": "（4）丰富LDA模型的应用方式，深化模型应用研究。现有研究存在过度依赖传统LDA模型的问题，对新兴扩展模型的应用探索较为欠缺。由于各类扩展模型参数较多，结构复杂，对图书情报研究人员计算机技术应用能力提出更高要求。面向各类扩展模型，未来需进一步优化模型的时间或空间复杂度，可尝试研发简易操作的开源工具包，构建一体化的模型应用工具体系，以提高模型应用效率和普适性。",
    "context8": "此外，从模型应用现状来看,LDA模型的建模结果常作为相关研究任务的中间环节，需要根据应用情境结合使用不同的方法工具解决具体的研究问题。在处理大规模数据时，可更多尝试基于分布式、深度学习的LDA扩展模型；在处理中小规模数据时，可将LDA模型与传统的共词分析、聚类分析、社区探测等主题分析方法协同应用，保障主题挖掘的准确性，达到优势互补的效果。比如共词分析在中小规模数据集（文档数 $< 1 0 0 0$ )上的主题聚类结果的可读性更高[96],而LDA主题模型相比共词分析在选择代表性主题词方面虽缺乏灵活性，但能以最原始的状态反映潜藏的主题结构，有助于减少偏见。综上所述，进一步探索扩展模型在图情领域应用的有效性，将LDA模型与传统主题挖掘分析方法的协同应用，或将LDA模型作为基础环节，结合机器学习、知识图谱、大数据以及相关领域特殊算法的综合应用，是当前LDA模型应用研究的重要趋势。"
  },
  "支撑数据": {
    "context1": "支撑数据由作者自存储,E-mail:zdx1996@email.swu.edu.cn。  \n1.张东鑫.Literature review data.xlsx.文献综述数据."
  },
  "参考文献": {
    "context1": "[1] BleiDM,NgAY,JordanMI.LatentDirichletAlocation[J].JournalofMachineLearning Research,2O0,3(4-5):993-022.   \n[2] JelodarHWangYYuaCetal.Latentcetlocation(D)ndTopicde:ModelslicatiosaSureyJ]utimedio Applications,2019,78(11):15169-15211.   \n[3] 韩亚楠，刘建伟,罗雄麟概率主题模述[J]算学报224(6)095-9.(HanYnanLuaneLuoXonglinAurveyonProbbistic Topic Model[J]. Chinese Journal of Computers,2021,44(6):1095-1139.)   \n[4] 黄佳佳,李鹏伟，彭敏，等.基于深度学习的主题模型研究[J].计算机学报,2020,43(5):827-85.(Huang Jiaja,LiPengwei,Peng in,etal. Review of Deep Learning-Based Topic Model[J].Chinese Journal of Computers,2020,43(5):827-855.)   \n[5] Vayansky l,KumarSAP.A Review of Topic Modeling Methods[J].Information Systems,2020,94:101582.   \n[6] 何伟林，谢红玲，奉国和．潜在狄利克雷分布模型研究综述[J].信息资源管理学报,2018.8(1):55-64.(He Wilin,Xie Hongling.Feng Guohe. Review on Latent Dirichlet Allcation Model[J].Journalof Information Resources Management,2018,8(1):55-64.)"
  }
}