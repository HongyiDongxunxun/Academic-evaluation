{
  "original_filename": "full_4661.md",
  "基于知识基因增强的BERT科技文献自动综述研究": "",
  "赵梦梦’　白如江’　张玉洁’　刘明月²　邢莹'": {
    "context1": "丨山东理工大学信息管理研究院丨淄博 255000 ²南京大学信息管理学院南京 210023摘要：[目的/意义]揭示文献核心创新点，自动生成多篇文献综述,帮助科研人员快速掌握文献核心内容,提高科研效率。[方法/过程]提出一种基于知识基因增强的 BERT科技文献自动综述研究方法,分为3个步骤,首先综合考虑主题相似度、论文发表时长和被引次数，提出一种核 $\\therefore \\because$ 文献推荐指数，选取文献综述候选文献；然后对文献综述候选文献中的代表科技文献核心观点的知识基因进行抽取；最后提出一种基于知识基因注意力增强的BERT科技文献自动综述模型,将知识基因融入到注意力机制中,判断语句显著度并进行排序抽取,以获取更多的语义信息。[结果/结论]经过多组实验,与单纯的BERT相比,本文模型在ROUGE-1分别提高了 $1 4 . 2 8 \\%$ ;ROUGE-2分别提高了 $1 2 . 1 3 \\%$ ;ROUGE-L分别提高了 $1 7 . 6 9 \\%$ 。在ROUGE-1与ROUGE-2 测评中基于知识基因增强的 BERT科技文献自动综述模型效果均优于 TextRank 模型。基于知识基因注意力增强的 BERT科技文献自动综述能够深入文本内容，挖掘文献核心内容，生成简明扼要的文献综述。",
    "context2": "关键词：知识基因文献综述自动摘要",
    "context3": "分类号：TP391",
    "context4": "DOI: 10. 13266/j. issn. 0252 - 3116. 2022.23.013"
  },
  "1引言": {
    "context1": "随着大数据时代的到来，信息过载现象也随之产生。在科学研究领域,科技文献数量逐年递增,据中国科学技术信息研究所调研发现2020年中国作者共计发表55.26篇论文，其中卓越科技论文数量为46.38万篇,较2019 年增加了 $1 9 . 8 \\% ^ { [ 1 ] }$ 。在信息泛滥的今天，从大量繁杂的信息中获取知识成为亟需解决的问题。科研人员在进行科学研究时，往往需要进行大规模的文献调研,以掌握领域最新研究课题和研究方向，但是，通过人工阅读方式进行分类、总结和归纳需要大量的时间、人力和物力,效率低下，有时无法快速获取每一份文件的核心创新点内容。2017年,我国首个“全国科技工作者日”之际，中国青年报社联合中国科学院青年创新促进会发起“青年科研人员生存发展状况调查”,调查结果表明科研人员超六成每周工作超过50小时。帮助科研人员从繁杂的科技文献中筛选核心文献,并快速准确地在文献正文中获取科研关键信息，通过先进的算法自动生成文献综述迫在眉睫。"
  },
  "2研究现状": "",
  "2.1文本自动摘要技术研究": {
    "context1": "文献自动综述实质上是自然语言处理研究领域的多文档自动文本摘要研究,但又有所区别。自动文本摘要技术是H.P.Luhn于1958 年首次提出，他提出通过计算单词和句子重要性的方式来抽取重要性得分最高的句子,然后将它们作为摘要输出，自此拉开了自动文本摘要技术研究的序章[2]。随后在1961年,H.P.Edmundson通过测量单词和句子之间的相似度的方法,提出可以使用相似度来评估其重要性[3]。G.Salton在1975年的研究中首先提出使用TF-IDF算法来计算单词和句子的 TF-IDF 值,确定关键句作为摘要输出[4]。J.Kupiec 和 J.Pedersen 等首次在文本自动摘要中应用机器学习方法[5]。随着计算机技术的飞速发展,机器学习方法在自然语言处理领域的应用越来越广泛。在2014 年,GoogleBrain 团队提出了Sequence-to-Sequence序列,正式开启了自然语言处理领域中端到端网络的研究[6]。同年,D.Bahdanau 提出将 Attention机制应用于自然语言处理领域,在摘要和翻译任务中取得了良好的成绩[7]。2017年,Google 提出使用 Self-Attention 和Encoder-Decoder完成端到端翻译任务，在WMT-14英、德、法3种语言的翻译任务中取得了优异的成绩，极大地促进了文档自动翻译和摘要技术的发展[8]。",
    "context2": "文本自动摘要技术分类方式有很多种，按照摘要生成的形式可分为抽取式摘要、生成式摘要和混合式摘要。"
  },
  "2.1.1抽取式摘要": {
    "context1": "抽取式摘要,顾名思义,就是把已有的句子作为摘要来抽取,抽取的摘要语句为原作者斟酌所写，语句通顺流畅，可读性较强。",
    "context2": "抽取式摘要通常首先对文章进行遍历理解，然后根据重要性对句子进行排序,选择重要性最高的句子，最后作为摘要输出。抽取式摘要可分为4类： $\\textcircled{1}$ 基于统计的自动摘要,统计特征主要有：词频TF、词条 TF-IDF值、词条性质、关键词位置[9]等。基于统计学方法的摘要从原文文本形式出发，无需考虑复杂的语法结构，不仅易于实现而且应用较为广泛，但由于仅利用了词语的表层特征,并没有充分的挖掘语义特征和关系，存在较大的局限性。 $\\textcircled{2}$ 基于序列标注的自动摘要,核心思想为:将原文语句进行向量编码,根据该向量进行二分类任务。M.Nallapati 等构建了SummaRuNNer 模型，该模型首先选取原文中与标准摘要中ROUGE得分最高的语句加入候选合集，然后继续对原文中语句进行选择，确保摘要集合ROUGE得分增加，直到无法满足该条件,最后将候选摘要集合中语句设为1标签,其余为0标签[10]。 $\\textcircled{3}$ 基于机器学习的自动摘要,摘要生成方法分为无监督机器学习方法和有监督机器学习方法，无监督方法通过对文本进行相似度聚类，再选出重要的聚类簇生成文本摘要，有监督方法通过辨别段落中的关键句和非关键句，将关键句子组成后生成摘要，主要算法有：朴素叶贝斯[5]、隐马尔可夫模型(Hidden-MarkovModel,HMM）[11]等。 $\\textcircled{4}$ 基于深度学习的自动摘要,该方法直接从段落中提取句子作为摘要句,缓解了机器学习方法在人工筛选句子特征方面的困难。T.J.Osbome提出了基于线性回归模型和神经网络模型的文章摘要生成研究,取得了很好的效果[12];L.Liu 等采用生成对抗网络（GenerativeAdversarialNetwork,GAN）生成了可读性强和多样化的文本摘要[13];CSlamet 等利用向量空间模型（VectorSpaceModel,VSM)进行单词相似性测评，以此来评价文本自动摘要的生成",
    "context3": "效果[14] 。"
  },
  "2.1.2生成式摘要": {
    "context1": "大多数生成式摘要都是基于NLP技术，算法模型通过同义替换、句子转述、缩写等方式生成摘要。生成式模型基本结构由编码器和解码器组成,模型中的编码和解码通过神经网络实现。K.Cho 等首先提出了一个由编码器和解码器构成的序列到序列的（Sequence-to-Sequence, $\\mathrm { S e q } 2 \\mathrm { S e q }$ )框架[15]。此后，研究人员在Seq2Seq 的框架基础上进行了多项研究,T.Siddiqui等优化了Seq2Seq 模型,将局部注意力机制转换为全局注意力机制,缓解了生成重复的问题[16]。A.Celiky-ilmaz 等借鉴通信系统模型,提出了一种分段处理长文本的Encoder-Decoder 结构算法，解决了长文本远距离解码、编码问题[17]。江跃华等基于 Seq2Seq 和注意力机制,根据词汇特征生成文本摘要[18]。李维勇等对Seq2Seq模型进行了优化，以解决长文本信息丢失及逆向信息的补充问题[19]。吴世鑫等提出了一种基于语义对齐的神经网络自动摘要方法，该方法在编码器和解码器之间引入语义对齐网络，实现了原始文本和生成摘要的语义信息对齐[20]。"
  },
  "2.1.3混合式摘要": {
    "context1": "混合式自动摘要可以看作抽取式自动摘要方法和生成式自动摘要方法的结合。根据抽取与生成的顺序不同,混合式自动摘要有3种不同的方式，分别为先抽取后生成、先生成后抽取、抽取和生成同时进行。由于抽取式摘要和生成式摘要各有优缺点，为了进一步提升自动摘要的生成效果，许多学者将两种自动摘要方式进行结合研究,并取得了一定的研究成果。邱俊提出一种基于强化学习的混合式文本摘要模型,首先抽取出文本中重要的句子,其次通过Encoder-Decoder 模型对抽取出的句子进行改写,从而获得摘要[21]。该模型结合了抽取式摘要和生成式摘要的优点，使得生成的摘要在精准概括文本的同时语句更加流畅。吕瑞、王涛等人提出了一种基于预训练的三阶段复合式文本摘要模型,该模型结合了抽取式摘要方法和生成式摘要方法，首先将文本进行预训练,生成双向上下文信息的词向量，然后给句子评分抽取关键句,在生成摘要阶段,将关键句作为完形填空的形式进行填写生成摘要，该模型在实验中取得了不错的效果[22]。"
  },
  "2.2　科技文献自动综述研究": {
    "context1": "科技文献自动综述研究是多文档自动摘要技术的关键应用之一。科技文献是学者在其学术领域对科学研究成果进行论述的文章,与一般新闻语料相比,科技文献具有理论逻辑性强、领域专业性强、结果具有创新性、文献间存在引用关系等特点,这也使得科技文献自动综述研究需在文本自动摘要技术研究的基础上探寻其适用的技术与方法。",
    "context2": "国内外对单篇科技文献自动摘要已经取得了较多研究成果,例如M.S.Teufel等人最早通过训练叶贝斯分类器文献内容进行筛选生成文献摘要[23]；为缓解由于不同引文之间表述不一致导致的不能全面且准确反映原文内容这一问题,任潇雨将引文的比较信息和贡献信息进行提取,取得了一定的效果[24]。相比单篇科技文献自动摘要技术,多文档科技文献自动综述研究面临信息冗余、语义关联复杂等诸多问题。H.Nanba在1999年通过文献之间的引用关系及引用术语等信息首次提出了领域科技文献自动综述的构想[25]。随后,众多研究学者提出了自动综述器,如ReWos[26]SciSumm[27]、ARWG[28]等。",
    "context3": "在国内,张占江构建了基于短语主题模型的科技文献自动综述系统,该系统利用平滑短语主题模型对句子的主题权重进行计算,然后抽取综述语句[29]。唐晓波等提出了基于混合机器学习模型,融合句子深层语义进行了科技文献自动综述实证研究,有效地提高了文献综述的质量[30]。国内针对科技文献自动综述研究较少的原因主要包括： $\\textcircled{1}$ 相较国外，目前国内还没有面向中文科技文献自动综述的开放数据集。用户输入自己设置的检索内容与文献关键词存在差异，且科技文献质量参差不齐,存在“噪声”文献干扰,影响科技文献自动综述的结果。 $\\textcircled{2}$ 与英文语料相比,中文在分词、词性标注、语义挖掘等研究过程中更为复杂。如与英文有天然的分隔符不同,中文灵活的句法使得其在分词时极易产生歧义语义。同时,科技文献具有学科领域性,专业词汇的存在也加大了分词难度。除此之外，现有的大多数科技文献自动综述模型缺少对科技文献核心价值内容的细粒度表达研究,未考虑文献知识元间的语义连结和知识元的时间属性,导致抽取的核心价值缺失,进一步影响综述结果的质量。",
    "context4": "基于此,本文从科技文献内容本身出发,提出新的文献推荐指数进行文献综述候选文献的筛选，提高候选文献与综述需求之间的相关性,选取高质量文献综述候选文献,提出一种代表核心文献核心观点的知识基因抽取方法,并将BERT句向量对知识基因向量注意力增强,得到新的特征,帮助模型获取更深层次的语义信息，从而生成覆盖完整语义信息和简洁凝练高质量的文献综述。"
  },
  "3 研究思路": {
    "context1": "基于知识基因注意力增强的BERT科技文献自动综述模型研究思路如图1所示，主要包括文献综述候选文献选取、科技论文核心观点知识基因获取和基于知识基因注意力增强的BERT科技文献综述自动生成三大部分。本文首先在文献综述候选文献选取部分提出了文献推荐指数以获取符合用户检索需求且质量较高的综述候选文献,然后根据团队前期研究成果构建科技文献知识基因抽取方案,最后利用BERT将科技文献与其获取的知识基因进行向量化,利用LexRank算法实现文献自动综述。"
  },
  "3.1核心文献识别研究": {
    "context1": "科技文献的价值决定了文献综述的价值,进行文献自动综述的第一步需要选取高质量的文献。文献内容与用户检索内容之间的语义相关性是衡量综述候选文献是否满足用户需求的重要依据[31]。但仅仅考虑语义相关性是不够的,刘旭辉在基于内容的文献选取的基础上进行了扩展,引入文献影响力因素构建了DACMPR模型，通过引文对文献的影响力进行探讨，选取优质的文献,实验结果表明该模型在推荐文献影响力方面取得了不错的成果[32]。科技文献被引用次数是目前最可靠的评论论文影响力的单因素指标之一。文献总被引用数与时间的增长呈正相关的关系，文献的总被引次数会随着时间的推移累计，而年被引次数在逐渐减少[33]。K.Berberich 提出文献被引用数与被引用的时间息息相关。因此,为了选择符合用户检索需求且优质的综述候选文献,本文在DACMPR模型的基础上增加了时间因素[34],提出一个用于核心文献识别的文献推荐指数R的构建流程,思路如下：",
    "context2": "第1步,根据用户输入检索内容生成文献集合。用户首先在文献检索系统中输入检索内容,文献检索系统根据用户输入的检索词或句子输出相应的文献集合。",
    "context3": "第2步,基于推荐指数R选择核心文献。",
    "context4": "本文根据科技文献内容、发表时间、被引次数等特征提出了核心文献推荐指数R,主要思想如下：",
    "context5": "首先,计算用户输入的检索内容与文献关键词的余弦相似度 $\\mathrm { S i m }$ ,方法如公式(1)所示：",
    "context6": "$$\nS i m = c o s ( \\boldsymbol { X } , \\boldsymbol { Y } ) = \\frac { \\sum _ { i = 1 } ^ { n } \\left( x _ { i } \\times y _ { i } \\right) } { \\sqrt { \\sum _ { i = 1 } ^ { n } x _ { i } ^ { 2 } } \\times \\sqrt { \\sum _ { i = 1 } ^ { n } y _ { i } ^ { 2 } } }\n$$",
    "context7": "在计算余弦相似度 $S i m$ 时分别将用户检索内容 $x _ { i }$ 和文献关键词 $y _ { i }$ 进行分词编码,得到两组词频向量,然后进行余弦相似度计算，当 $S i m$ 的值越接近1,说明检索内容与文献关键词越相近。",
    "context8": "![](images/4588b4d7a434cae42a4d9f1a62cda17471e73102ed49a62b28afdd5fcd1d133a.jpg)  \n图1基于知识基因注意力增强的BERT科技文献自动综述研究思路",
    "context9": "其次，计算文献的发表时长Y（本年时间－发表时间）,用文献被引次数C 除以文献发表时长Y。文献的被引用次数与该篇论文的论文质量、作者影响力、发表期刊水平等因素有关，能够作为评价文献质量高低的指标。文献的被引次数除以其发表的时长能够反映出一篇文献的影响力是否具有广泛性。",
    "context10": "最终将两组参数取对数进行归一化。Sim与值域所在区间存在较大的差异,将两者取对数能够缩小其值域区间差异所带来的影响，同时对参数取对数还消",
    "context11": "除了异方差问题。",
    "context12": "综上,本文提出每篇文献i的推荐指数的表达式如下所示：",
    "context13": "$$\nR _ { i } = \\ln ( { \\mathit { S i m } _ { i } + \\left( \\frac { C _ { i } } { Y _ { i } } \\right) } )\n$$",
    "context14": "根据文献推荐指数R将文献集合进行降序排列，选取前h篇文献作为综述核心文献 $\\mathrm { A }$ 。"
  },
  "3.2　科技文献核心观点知识基因获取": {
    "context1": "本团队在前期的研究中已经对知识基因的定义、辨析、特征、表达模型、自动识别等进行了广泛的研究，并取得了一定的成果和进展[35-37]。在前期研究的基础上，本文进行后续的科技文献核心观点知识基因获",
    "context2": "取研究。"
  },
  "3.2.1知识基因与知识元的辨析": {
    "context1": "科技文献知识基因是科技文献文本内容中表征文献价值的知识对象的有机结合体，由原始文献摘要及施引文献引文内容组成,是科技创新中最基本、最活跃、影响面最宽的知识内容[35]。知识元是组成知识的基本单位和结构要素,不可分割且具有完备的知识表达。课题组从显性表现形式、隐性角色功能和横向相关关联3个角度对知识基因与知识元进行了辨析[36]。如表1所示：",
    "context2": "表1知识基因与知识元辨析",
    "context3": "<table><tr><td></td><td>知识基因</td><td>知识元</td></tr><tr><td>显性表现形式</td><td>动态表现</td><td>静态表现</td></tr><tr><td>隐性角色功能</td><td>具有完整语义信息</td><td>离散的碎片化知识</td></tr><tr><td>横向相关关联</td><td>知识基因是相互关联的知识元的排列组合;满足条件的知 识元是知识基因组成单元</td><td></td></tr></table>"
  },
  "3.2.2知识基因表达模型与判别条件": {
    "context1": "本文提出了一种自动抽取表达文献核心观点和思想的知识基因抽取模型。该模型将科技文献的核心内容与SAO语句进行融合生成文献知识基因，一篇文献知识基因的表达式如下所示，C为知识基因集合。",
    "context2": "$\\mathrm { C } = \\{ \\mathrm { S A O } _ { \\mathrm { o } } , \\mathrm { S A O } _ { \\mathrm { p } } , \\mathrm { S A O } _ { \\mathrm { R } } , \\mathrm { S A O } _ { \\mathrm { u } } \\cdots \\cdots \\}$ 公式(3)",
    "context3": "其中 $\\mathrm { S A O } _ { \\mathrm { Q } }$ 为表达文献研究内容的 SAO 语句,$\\mathrm { S A O _ { \\mathrm { p } } }$ 为表达文献研究动机的 SAO 语句, $\\mathrm { S A O } _ { \\mathrm { R } }$ 为表达文献研究结果的 SAO 语句， $\\mathrm { S A O _ { M } }$ 为表达文献研究方法的 SAO 语句。",
    "context4": "根据知识基因的定义以及知识基因独有的动态流动性、分布稳定和语义关联性等特征,提出了知识基因的3个判定条件，分别为： $\\textcircled{1}$ 在影响深度上，随时间的变化拥有较高的复现率； $\\textcircled{2}$ 在影响广度上，领域内或领域间的分布具有较强的传播率; $\\textcircled{3}$ 在语义角色功能上，知识基因能够完整地表达语义信息。"
  },
  "3.2.3知识基因自动识别": {
    "context1": "知识基因的起源最早可以追溯到R.Dawkins 提出的 Meme这一单词，后由我国学者何自然和何雪林将Meme 译为“模因”[38],模因的定义经历了两个阶段，第一个阶段指文化领域内通过模仿的方式传播的思想或观点;第二个阶段被看作大脑里的信息单位,是存在于大脑中的一个复制因子,思想基因诞生于此,即具有稳定性、再现性和逐渐变异性的科学思想基本单元。",
    "context2": "本文认为科技文献知识基因是模因的意义表达类型之一，基于知识基因的基本理念,本文在知识基因相关理论研究基础上提出了科技文献知识基因自动识别方法,具体过程为：首先,进行时间切片,基于TF-IDF识别备选知识基因。其次,构建领域知识词典,基于SAO识别备选知识基因。最后,根据上述标注计算遗传与变异结果[35,37],融合TF-IDF 备选知识基因和 SAO知识基因自动识别知识基因。",
    "context3": "领域科技文献知识基因抽取步骤如下：",
    "context4": "第1步,数据预处理与时间切片。",
    "context5": "将数据进行分词、去停用词和时间切片。",
    "context6": "第2步,基于TF-IDF识别备选知识基因。",
    "context7": "首先计算TF-IDF值进行筛选,然后将筛选出的词汇与领域词典进行匹配,最后观察选取随时间变化仍持续存在的词汇作为备选知识基因。",
    "context8": "第3步，基于SAO识别备选知识基因。",
    "context9": "抽取 SAO结构语句作为文献核心观点。相对于完整的句子,SAO三元组的结构能够更为简洁地对句子的语义信息进行表达。利用哈尔滨工业大学的语言技术平台（Language Technology Platform,LTP）进行句法分析，通过LTP平台和Python对句法分析的结果进行语义角色标注,将语义角色标注结果中的主语、谓语、宾语按照 SAO三元组的结构抽取出来,组成 SAO结构语句。只有当SAO 语句中包含专业领域内的知识元,该SAO语句才可以表征一篇文献的核心内容,具有实际研究意义。首先构建领域自定义词典，然后将抽取出的SAO结构语句与专业领域词典进行映射，保留S、A、O中任何一部分存在于词典中的 SAO 结构语句作为备选知识基因。",
    "context10": "第4步,融合TF-IDF 和 SAO 自动识别知识基因。",
    "context11": "将 TF-IDF和SAO两种方法识别出的备选知识基因进行融合，识别满足知识基因判定条件的备选知识基因为知识基因。"
  },
  "3.3融合知识基因和BERT的科技文献自动综述模型": {
    "context1": "在自动抽取能够表征科技文献核心思想的知识基因基础上，本文提出了一种基于知识基因注意力增强的BERT科技文献自动综述模型。模型结构主要由3个部分组成： $\\textcircled{1}$ BERT编码器输入； $\\textcircled{2}$ 强化知识基因的注意力机制； $\\textcircled{3}$ 基于LexRank 的综述语句抽取。见图2。"
  },
  "3.3.1 BERT编码器输入": {
    "context1": "为了实现知识基因注意力增强的BERT模型，首先需要将科技文献本文转化为向量，BERT的语言输入表示包含了3个组成部分，分别为词嵌入张量TokenEmbeddings 语句分块张量 Segment Embeddings 和位置编码张量 Position Embeddings。Token Embeddings 在科技文献语句的开始添加一个标记到输人Word tokens中,同时在每个文献语句的末尾插入一个 token;Seg-ment Embeddings 为了编码器区分句子,在每一个 token中添加句子A与句子B的标记;Position Embeddings 将位置编码添加到每一个 token 来指示其在句子中的位置。BERT 的 input embeddings 为 Token Embeddings、Segment Embeddings 和 Position Embeddings 之和。",
    "context2": "![](images/56b0d491c2c7ad661ffa51ed249e0844f7b31e0e3831a9862cbdb75ee3f3c581.jpg)  \n图2模型结构图"
  },
  "3.3.2强化知识基因的注意力机制": {
    "context1": "注意力机制可以为重要的文本内容添加高的权重以保留主要信息，在文本摘要领域被引入来解决长句子的问题。为了将科技文献文本内容中更深层次的信息嵌入模型中，突出科技文献贡献核心观点,本文提出了强化知识基因的注意力机制。",
    "context2": "注意力机制的计算过程可以归纳为两个阶段，首先是根据解码器该时刻隐层状态和编码器全部输入的隐层状态计算权重系数,然后根据权重系数对编码器全部的隐层状态加权求和。第一个阶段主要分为两个过程，第一个过程是计算解码器该时刻隐层状态和编码器中各个输入的隐层状态的相关性,作为注意力分数,第二个阶段是将原始注意力分数作为归一化处理得到权重系数。",
    "context3": "为了充分抽取科技文献表达观点，强化科技文献核心价值内容,本文将知识基因与注意力机制融合，步",
    "context4": "骤如下：",
    "context5": "（1)计算Query 和Key 相似度,得到注意力得分。",
    "context6": "$$\nS _ { i } = F ( \\theta , k _ { i } ) = k _ { i } ^ { T } Q\n$$",
    "context7": "(2)用softmax 函数对注意力得分进行数值转换。使用softmax函数的特性突出知识基因的权重，同时进行归一化,得到所有权重系数之和为1的概率分布。",
    "context8": "$$\n\\alpha _ { i } = s o f t m a x ( S _ { i } ) = \\frac { e x p ( S _ { i } ) } { \\sum _ { j = 1 } ^ { N } e x p ( S _ { j } ) }\n$$",
    "context9": "（3)根据权重系数对Value 进行加权求和。",
    "context10": "$\\begin{array} { r } { A t t e n t i o n ( \\left( K , V \\right) , Q ) = \\sum _ { i = 1 } ^ { N } \\alpha _ { i } v _ { i } } \\end{array}$ 公式(6)将知识基因进行强化的注意力机制会加强模型对知识基因的认识,准确识别科技文献核心贡献点，提高文献综述的准确性。"
  },
  "3.3.3基于LexRank的综述语句抽取": {
    "context1": "为了更加准确地判断科技文献语句的显著度,生成简洁凝练且高质量的自动文献综述,本文利用LexRank算法进行文献综述语句的进一步抽取。LexRank 算法是密西根大学的G.Erkan 和D.R.Radev提出的一种基于图论的自然语言处理方法,LexRank通过句子之间的相似度对文本、词汇进行分类。在进行科技文献自动综述时，LexRank 将句子作为节点构造出一个标量图,节点间的连线代表两个句子的相似程度。当句子相似程度越大,节点间的连线越粗,若两个句子无关,则句子代表的节点间没有连线[39]。知识基因的加入使得科技文献中核心语句可以得到更高的评分。",
    "context2": "LexRank算法将科技文献文本表示为图形结构，首先选择文本图结构类型,文本图形有多种表现类型，如加权图、无权图、有向图、无向图等。科技文献语句在LexRank算法中作为图的顶点，语句之间的相似度表示图的相应顶点边权值,文献语句间的相似度关系是没有方向的,即边是无向的。同时，LexRank中边之间的权值使用语句间相似度表示,所以边是加权的。因此,本文使用无向加权图来表示科技文献语句,然后通过计算句子之间的余弦相似度,得到科技文献语句之间的关系,根据得到的关系构造顶点之间的边。LexRank使用余弦相似度作为句子Si与Sj之间的相似度计算方式,如公式(7)所示：",
    "context3": "$$\nf ( i , j ) = \\frac { S _ { i } \\cdot S _ { j } } { | S _ { i } | | S _ { j } | }\n$$",
    "context4": "其次将图排序算法思想应用于文本图形结构中,迭代计算图中每个顶点的权值，最后根据每个顶点的最终权值，排序并从高到低对文献语句进行抽取，得到最终的科技文献自动综述。",
    "context5": "LexRank采用基于图的方法确保了选取文献综述句子彼此不相似,同时还有效地排除了弱相关语句对科技文献综述结果的影响。"
  },
  "4 实证研究": "",
  "4.1数据获取与预处理": {
    "context1": "本文实验数据集采自图书情报与档案管理学科领域18种CSSCI期刊（《大学图书馆学报》《国家图书馆学刊》《情报科学》《情报理论与实践》《情报学报》《情报杂志》《情报资料工作》《数据分析与知识发现》《图书馆》《图书馆建设》《图书馆论坛》《图书馆学研究》《图书馆杂志》《图书情报工作》《图书与情报》《现代情报》《中国图书馆学报》)2000 年－2019 年被引频次前500 的文献,共计9000 条数据。本数据集中每条数据包括日期、题目、作者、来源、摘要、DOI、参考文献等题录信息。"
  },
  "4.2文献综述候选文献选取": {
    "context1": "(1)检索文献。本文设置4组不同的检索词组进行实验,分别为“高校图书馆研究现状”“大学生信息素养”“图书馆云计算”“数字图书馆建设”。以检索词组\"大学生信息素养”为例,检索得到原始文献51篇，以文献的 DOI作为唯一标识。",
    "context2": "(2)计算文献推荐指数。通过文献推荐指数R计算各篇文献的推荐指数,将原始文献集合进行降序排列,选取前30 篇文献作为综述候选文献A。部分候选文献如表2所示：",
    "context3": "表2文献综述的候选文献(部分)",
    "context4": "<table><tr><td>排名</td><td>发表年份</td><td>文献题目</td><td>作者</td><td>推荐指数R</td><td>DOI</td></tr><tr><td>1</td><td>2014</td><td>大学生信息素养教育的&quot;慕课&quot;化趋势</td><td>潘燕桃,廖昀赞</td><td>2.246 28</td><td>CNKI:SUN:DXTS.0.2014-04-006</td></tr><tr><td>2</td><td>2007</td><td>大学生信息素养培养模式的转换与创新</td><td>李智晔</td><td>2. 157 63</td><td>CNKI:SUN:QBKX.0.2007 -07-009</td></tr><tr><td>3</td><td>2008</td><td>高校图书馆对大学生网络阅读的指导</td><td>林小勇</td><td>1.872 43</td><td>CNKI:SUN:TSSS.0.2008-01-029</td></tr><tr><td>4</td><td>2013</td><td>书单策展：大学生阅读推广的众包策略</td><td>黄静</td><td>1.697 24</td><td>CNKI:SUN:TNGZ.0.2013-09 -011</td></tr><tr><td>5</td><td>2009</td><td>泰山医学院的阅读疗法研究与实践</td><td>宫梅玲</td><td>1.562</td><td>CNKI:SUN:BOOK.0.2009 -02-003</td></tr></table>"
  },
  "4.3知识基因抽取": "",
  "4.3.1数据预处理和时间切片": {
    "context1": "首先以1年为时间跨度,将科技文献分为10个时间段,然后对科技文献文本进行分词、去停用词处理，时间切片结果见表3。"
  },
  "4.3.2　基于 TF-IDF识别备选知识基因": {
    "context1": "(1)分词与领域词典构建。本文使用Python 中的Jieba分词工具包对候选文献的摘要部分进行分词处理,由于本研究使用的数据均来自图书情报与档案管理学科,因此在实验中引入自制图书情报与档案管理学科词典,该自定义词典综合了中国大百科全书出版发行的《中国大百科全书—图书馆学、情报学、档案学》和《图书馆学情报学大辞典》的内容，后经人工筛选出10328个词语作为自制图书情报与档案管理学科词典的内容。",
    "context2": "表3时间切片结果",
    "context3": "<table><tr><td>时间段/年</td><td>文献数量/篇</td></tr><tr><td>2000 -2001</td><td>954</td></tr><tr><td>2002-2003</td><td>1303</td></tr><tr><td>2004-2005</td><td>1 490</td></tr><tr><td>2006-2007</td><td>1 472</td></tr><tr><td>2008-2009</td><td>1 052</td></tr><tr><td>2010 -2011</td><td>1033</td></tr><tr><td>2012 -2013</td><td>853</td></tr><tr><td>2014-2015</td><td>632</td></tr><tr><td>2016-2017</td><td>208</td></tr><tr><td>2018 -2019</td><td>3</td></tr><tr><td>总计</td><td>9000</td></tr></table>",
    "context4": "(2)计算TF-IDF。对数据预处理后的文本数据进行 TF-IDF计算并排序,保留每个时间段内 TF-IDF 权重前1000的文本词汇，部分结果如图3所示：",
    "context5": "图3　每个时间段内 TF-IDF 前1000 的词项(部分)",
    "context6": "<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>2000-2001</td><td rowspan=1 colspan=1>2002-2003</td><td rowspan=1 colspan=1>2004-2005</td><td rowspan=1 colspan=1>2006-2007</td><td rowspan=1 colspan=1>2008-2009</td><td rowspan=1 colspan=1>2010-2011</td><td rowspan=1 colspan=1>2012-2013</td><td rowspan=1 colspan=1>2014-2015</td><td rowspan=1 colspan=1>2016-2017</td><td rowspan=1 colspan=1>2017-2018</td></tr><tr><td rowspan=1 colspan=1>2</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td><td rowspan=1 colspan=1>图书馆</td></tr><tr><td rowspan=1 colspan=1>3</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>智慧图书馆</td></tr><tr><td rowspan=1 colspan=1>4</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>2知识管理</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>文章</td></tr><tr><td rowspan=1 colspan=1>5</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>分析</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>大数据</td><td rowspan=1 colspan=1>高校图书馆</td></tr><tr><td rowspan=1 colspan=1>6</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>4参考文献</td><td rowspan=1 colspan=1>论述</td><td rowspan=1 colspan=1>高校图书馆</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>大数据</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>用户</td></tr><tr><td rowspan=1 colspan=1>7</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>论述</td><td rowspan=1 colspan=1>参考文献</td><td rowspan=1 colspan=1>论述</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>微博</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>服务</td></tr><tr><td rowspan=1 colspan=1>8</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>6网络环境下</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>参考文献</td><td rowspan=1 colspan=1>参考文献</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>云计算</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>政府数据开放</td></tr><tr><td rowspan=1 colspan=1>9</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>7高校图书馆</td><td rowspan=1 colspan=1>知识管理</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>阅读推广</td><td rowspan=1 colspan=1>图书馆服务</td></tr><tr><td rowspan=1 colspan=1>10</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>网络环境下</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>知识付费</td></tr><tr><td rowspan=1 colspan=1>11</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>informatior</td><td rowspan=1 colspan=1>informatior</td><td rowspan=1 colspan=1>基于</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>网络與情</td><td rowspan=1 colspan=1>互联网+</td><td rowspan=1 colspan=1>ace</td></tr><tr><td rowspan=1 colspan=1>12</td><td rowspan=1 colspan=1>10</td><td rowspan=1 colspan=1>信息资源</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>论述</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>云计算</td><td rowspan=1 colspan=1>微博</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>构建</td></tr><tr><td rowspan=1 colspan=1>13</td><td rowspan=1 colspan=1>11</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>微信</td><td rowspan=1 colspan=1>人工智能</td></tr><tr><td rowspan=1 colspan=1>14</td><td rowspan=1 colspan=1>12</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>知识管理</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>参考文献</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>模型</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>分析</td></tr><tr><td rowspan=1 colspan=1>15</td><td rowspan=1 colspan=1>13</td><td rowspan=1 colspan=1>研究</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>数字阅读</td></tr><tr><td rowspan=1 colspan=1>16</td><td rowspan=1 colspan=1>14</td><td rowspan=1 colspan=1>14信息服务</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>概念</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>知识共享</td><td rowspan=1 colspan=1>模型</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>研究</td></tr><tr><td rowspan=1 colspan=1>17</td><td rowspan=1 colspan=1>15</td><td rowspan=1 colspan=1>网络信息资</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>网络</td><td rowspan=1 colspan=1>知识服务</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>微信</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>影响因素</td></tr><tr><td rowspan=1 colspan=1>18</td><td rowspan=1 colspan=1>16</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>概念</td><td rowspan=1 colspan=1>知识管理</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>参考文献</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>移动图书馆</td><td rowspan=1 colspan=1>信息素养教育</td><td rowspan=1 colspan=1>文化扶贫</td></tr><tr><td rowspan=1 colspan=1>19</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>存在的问题</td><td rowspan=1 colspan=1>领域</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>网络與情</td><td rowspan=1 colspan=1>发展</td><td rowspan=1 colspan=1>内容</td><td rowspan=1 colspan=1>发展</td></tr><tr><td rowspan=1 colspan=1>20</td><td rowspan=1 colspan=1>18</td><td rowspan=1 colspan=1>18图书馆学</td><td rowspan=1 colspan=1>知识</td><td rowspan=1 colspan=1>构建</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>领域</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>文章</td><td rowspan=1 colspan=1>应用</td><td rowspan=1 colspan=1>基于</td></tr><tr><td rowspan=1 colspan=1>21</td><td rowspan=1 colspan=1>19</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>公共图书馆</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>学科服务</td><td rowspan=1 colspan=1>数字图书馆</td><td rowspan=1 colspan=1>高校</td><td rowspan=1 colspan=1>过程</td><td rowspan=1 colspan=1>应用</td></tr><tr><td rowspan=1 colspan=1>22</td><td rowspan=1 colspan=1>20</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>概念</td><td rowspan=1 colspan=1>知识</td><td rowspan=1 colspan=1>知识</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>影响</td><td rowspan=1 colspan=1>微信公众平台</td><td rowspan=1 colspan=1>数字人文</td></tr><tr><td rowspan=1 colspan=1>23</td><td rowspan=1 colspan=1>21</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>现状</td><td rowspan=1 colspan=1>系统</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>利用</td><td rowspan=1 colspan=1>利用</td><td rowspan=1 colspan=1>实践</td><td rowspan=1 colspan=1>实践</td><td rowspan=1 colspan=1>模型</td><td rowspan=1 colspan=1>技术</td></tr><tr><td rowspan=1 colspan=1>24</td><td rowspan=1 colspan=1>22</td><td rowspan=1 colspan=1>网络环境</td><td rowspan=1 colspan=1>内容</td><td rowspan=1 colspan=1>存在的问题</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>存在的问题</td><td rowspan=1 colspan=1>建设</td><td rowspan=1 colspan=1>网络</td><td rowspan=1 colspan=1>利用</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>知识</td></tr><tr><td rowspan=1 colspan=1>25</td><td rowspan=1 colspan=1>23</td><td rowspan=1 colspan=1>内容</td><td rowspan=1 colspan=1>管理</td><td rowspan=1 colspan=1>实现</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>实现</td><td rowspan=1 colspan=1>领域</td><td rowspan=1 colspan=1>技术</td><td rowspan=1 colspan=1>高校</td><td rowspan=1 colspan=1>平台</td></tr><tr><td rowspan=1 colspan=1>26</td><td rowspan=1 colspan=1>24</td><td rowspan=1 colspan=1>服务</td><td rowspan=1 colspan=1>元数据</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>利用</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>概念</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>阅读推广</td><td rowspan=1 colspan=1>移动图书馆</td><td rowspan=1 colspan=1>提升</td></tr><tr><td rowspan=1 colspan=1>27</td><td rowspan=1 colspan=1>25</td><td rowspan=1 colspan=1>方法</td><td rowspan=1 colspan=1>系统</td><td rowspan=1 colspan=1>网络环境下</td><td rowspan=1 colspan=1>用户</td><td rowspan=1 colspan=1>实现</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>高校</td><td rowspan=1 colspan=1>数据</td><td rowspan=1 colspan=1>数据素养</td><td rowspan=1 colspan=1>大数据</td></tr><tr><td rowspan=1 colspan=1>28</td><td rowspan=1 colspan=1>26</td><td rowspan=1 colspan=1>管理</td><td rowspan=1 colspan=1>信息素质教育</td><td rowspan=1 colspan=1>知识服务</td><td rowspan=1 colspan=1>模型</td><td rowspan=1 colspan=1>图书馆服务</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>关联数据</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>文章</td><td rowspan=1 colspan=1>知识服务</td></tr><tr><td rowspan=1 colspan=1>29</td><td rowspan=1 colspan=1>27</td><td rowspan=1 colspan=1>概念</td><td rowspan=1 colspan=1>存在的问题</td><td rowspan=1 colspan=1>读者</td><td rowspan=1 colspan=1>现状</td><td rowspan=1 colspan=1>系统</td><td rowspan=1 colspan=1>信息</td><td rowspan=1 colspan=1>利用</td><td rowspan=1 colspan=1>问题</td><td rowspan=1 colspan=1>数据</td><td rowspan=1 colspan=1>开放数据</td></tr><tr><td rowspan=1 colspan=1>30</td><td rowspan=1 colspan=1>28</td><td rowspan=1 colspan=1>模式</td><td rowspan=1 colspan=1>信息资源</td><td rowspan=1 colspan=1>文章</td><td rowspan=1 colspan=1>实现</td><td rowspan=1 colspan=1>学科馆员</td><td rowspan=1 colspan=1>网络</td><td rowspan=1 colspan=1>特点</td><td rowspan=1 colspan=1>网络</td><td rowspan=1 colspan=1>创客空间</td><td rowspan=1 colspan=1>移动图书馆</td></tr></table>",
    "context7": "(3)遍历领域词典。将根据TF-IDF值筛选出的结果与自制的图书情报与档案管理学科词典进行映射，保留在图书情报与档案管理学科词典中出现的知识元。",
    "context8": "(4)分析TF-IDF 随时间变化趋势。对词典遍历后保留的词项在其所在的时间段进行频率分析，保留存在两个时间段以上，在每个时间段排名前1000 的词汇作为备选知识基因。",
    "context9": "（5)TF-IDF 备选知识基因。本文通过TF-IDF共识别出7696个知识基因,作为备选知识基因A组,部分结果如图4所示：",
    "context10": "图4 TF-IDF 备选基因(部分)",
    "context11": "<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>2000-2001</td><td rowspan=1 colspan=1>2002-2003</td><td rowspan=1 colspan=1>2004-2005</td></tr><tr><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>（图书馆，1.1361985230652256）</td><td rowspan=1 colspan=1>（图书馆，1.3817379008831818）</td><td rowspan=1 colspan=1>（图书馆，1.1915271088128931）</td></tr><tr><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>（数字图书馆，0.6312640569246785）</td><td rowspan=1 colspan=1>（数字图书馆，0.5848097302813422）</td><td rowspan=1 colspan=1>（数字图书馆，0.3431621698945654</td></tr><tr><td rowspan=1 colspan=1>2</td><td rowspan=1 colspan=1>（知识管理，0.3794125937992886）</td><td rowspan=1 colspan=1>（知识管理，0.2754888812069132）</td><td rowspan=1 colspan=1>（参考文献，0.18920880546337687）</td></tr><tr><td rowspan=1 colspan=1>3</td><td rowspan=1 colspan=1>（文献，0.3264415861827635)</td><td rowspan=1 colspan=1>（参考文献，0.2371707707051546）</td><td rowspan=1 colspan=1>（公共图书馆，0.1889319811790677</td></tr><tr><td rowspan=1 colspan=1>4</td><td rowspan=1 colspan=1>（参考文献，0.24547661438511628）</td><td rowspan=1 colspan=1>（文献，0.22364472872536081)</td><td rowspan=1 colspan=1>（知识管理，0.18893198117790677）</td></tr></table>"
  },
  "4.3.3基于 SAO 识别备选知识基因": {
    "context1": "（1)SAO三元组抽取。首先通过LTP平台进行依存句法分析，后利用LTP平台抽取SAO三元组。然后将 SAO三元组S、A、O项进行组合形成SAO 结构语句。三元组部分抽取结果如表4所示：",
    "context2": "表4SAO 三元组抽取结果(部分)",
    "context3": "<table><tr><td>S</td><td>A</td><td>0</td></tr><tr><td>高校图书馆</td><td>具</td><td>潜力</td></tr><tr><td>文章</td><td></td><td>认为 嵌用户环境是学科服务中关键问题</td></tr><tr><td>美国高校图书馆</td><td>开始</td><td>数据监护研究</td></tr><tr><td>移动图书馆</td><td>是</td><td>图书馆发展必然趋势</td></tr><tr><td>美国</td><td>作为</td><td>移动图书馆界先导</td></tr><tr><td>我国</td><td>加大</td><td>移动图书馆服务推广力度</td></tr><tr><td>新加坡南洋理工大学图书馆</td><td>推广</td><td>阅读文化</td></tr></table>",
    "context4": "(2)遍历领域词典。将抽取出的SAO结构语句与自制的图书情报与档案管理学科词典进行映射，保留S、A、O任一部分在图书情报与档案管理学科词典中出现的SAO结构语句作为揭示科技文献核心观点的知识基因,去除对实验无意义的 SAO 结构语句,共获得基于SAO抽取的知识基因18895条，保存为备选知识基因B。部分结果见图5。"
  },
  "4.3.4 融合 TF-IDF 和 SAO 自动识别知识基因": {
    "context1": "将备选知识基因A组与备选知识基因B组进行相互映射,选取共同存在的知识基因作为最终知识基因。本文实验共识别图书情报与档案管理领域知识基因17 149条。",
    "context2": "赵梦梦，白如江，张玉洁，等.基于知识基因增强的 BERT科技文献自动综述研究[J].图书情报工作,2022,66(23):125-136.  \n图5备选基因B组",
    "context3": "<table><tr><td>DOI</td><td>s</td><td>A</td><td>0</td><td>SAO</td></tr><tr><td>CNKI:SUN:TSQB.0.2007-03-014</td><td>高校图书馆</td><td>具</td><td>潜力</td><td>高校图书馆#具#潜力</td></tr><tr><td>CNKI:SUN:TSQC.0.2010-01-016</td><td>文章</td><td>认为</td><td></td><td>嵌用户环境是学科服务中关文章#认为#嵌用户环境是学科服务中关键问题</td></tr><tr><td>CNKI:SUN:DXTS.0.2011-02-004</td><td>美国高校图书馆</td><td>开始</td><td>数据监护研究</td><td>美国高校图书馆#开始#数据监护研究</td></tr><tr><td>CNKI:SUN:DXTS.0.2011-02-004</td><td>数据</td><td>监护在</td><td>美国</td><td>数据#监护在#美国</td></tr><tr><td>CNKI:SUN:TSGJ.0.2011-12-021</td><td>移动图书馆</td><td>是</td><td>图书馆发展必然趋势</td><td>移动图书馆#是#图书馆发展必然趋势</td></tr><tr><td>CNKI:SUN:TSGJ.0.2011-12-021</td><td>美国</td><td>作为</td><td>移动图书馆界先导</td><td>美国#作为#移动图书馆界先导</td></tr><tr><td>CNKI:SUN:TSGJ.0.2011-12-021</td><td>我国</td><td>加大</td><td>移动图书馆服务推广力度</td><td></td></tr><tr><td>CNKI:SUN:TSQC.0.2012-01-012</td><td>论文</td><td>进行</td><td>综述</td><td>我国#加大#移动图书馆服务推广力度</td></tr><tr><td>CNKI:SUN:TSGJ.0.2012-05-019</td><td>新加坡南洋理工大学图书馆</td><td></td><td></td><td>论文#进行#综述</td></tr><tr><td>CNKI:SUN:TSGJ.0.2012-05-019</td><td>等</td><td>推广 推广</td><td>阅读文化</td><td>新加坡南洋理工大学图书馆#推广#阅读文化 等#推广#阅读文化</td></tr><tr><td>CNKI:SUN:TSGJ.0.2012-05-019</td><td>我国高校图书馆</td><td>落后于</td><td>阅读文化 国外高校图书馆</td><td>我国高校图书馆#落后于#国外高校图书馆</td></tr><tr><td>CNKI:SUN:TSQB.0.2012-07-021</td><td>嵌入式服务</td><td>成为</td><td>学科服务发展新趋势</td><td></td></tr><tr><td>CNKI:SUN:TSQB.0.2012-07-021</td><td>服务内容</td><td>进行</td><td>分析</td><td>嵌入式服务#成为#学科服务发展新趋势</td></tr><tr><td>CNKI:SUN:TSQB.0.2013-03-010</td><td>新型媒介</td><td>推广</td><td>崭露头角</td><td>服务内容#进行#分析</td></tr><tr><td>CNKI:SUN:TSQB.0.2013-03-010</td><td>阅读</td><td>推广</td><td>组织机构</td><td>新型媒介#推广#崭露头角</td></tr><tr><td>CNKI:SUN:TSQB.0.2013-03-010</td><td>阅读</td><td>推广</td><td>环境</td><td>阅读#推广#组织机构</td></tr><tr><td>CNKI:SUN:XDQB.0.2013-01-020</td><td>国内高校图书馆新媒体</td><td>阅读</td><td>服务开展现状</td><td>阅读#推广#环境</td></tr><tr><td>CNKI:SUN:XDQB.0.2013-01-020</td><td>新媒体</td><td>阅读</td><td>推广缺失</td><td>国内高校图书馆新媒体#阅读#服务开展现状</td></tr><tr><td>CNKI:SUN:XDQB.0.2013-01-020</td><td>高校图书馆</td><td>开展</td><td>新媒体阅读四个策略</td><td>新媒体#阅读#推广缺失 高校图书馆#开展#新媒体阅读四个策略</td></tr><tr><td>CNKI:SUN:DXTS.0.2013-01-008</td><td>厂商提供产品</td><td>满足</td><td>图书馆需求</td><td>厂商提供产品#满足#图书馆需求</td></tr><tr><td>CNKI:SUN:DXTS.0.2013-01-008</td><td>RFID技术</td><td>存在</td><td>缺陷</td><td></td></tr><tr><td>CAKICIInYTCn2n1n1nng</td><td>宣坊图书馆</td><td></td><td>新田</td><td>RFID技术#存在#缺陷 宣校图书馆#开辟#新里政</td></tr></table>"
  },
  "4.4模型评估": "",
  "4.4.1基线模型": {
    "context1": "为了更好地衡量基于知识基因增强的BERT科技文献自动综述模型效果，本文选择TextRank作为基线模型对比。设置加入知识基因特征与无知识基因特征两组实验。2004 年,R.Mihalcea 等基于TextRank 算法构建了TextRank 模型[40]。TextRank 算法的基本算法来源于谷歌的 PageRank 算法,TextRank 将文本划分为单个的句子，计算句子之间的相似度,并以句子为顶点，句子之间的相似度作为边的权重构建节点连接图，计算句子的TextRank 值,抽取排名高的句子构",
    "context2": "$$\nR O U G E - N = { \\frac { \\big ( } { \\sum _ { S \\in \\{ R e f e r e c s u m m a r i e s \\ } } }\n$$",
    "context3": "其中， $\\mathbf { n }$ 表示 $\\mathbf { n }$ -gram的长度,{ReferemceSummaries}表示参考摘要,即事先获取的标准摘要,Count match（gramn)表示生成摘要和参考摘要中同时出现的 $\\mathbf { n }$ gram的个数, $C o u n t \\left( g r a m _ { n } \\right)$ )则表示参考摘要中出现的n-gram 个数。本文选择 ROUGE-1、ROUGE-2、ROUGE-L 作为评价标准。其中，ROUGE-1与ROUGE-2考察自动摘要包含的关键信息量，ROUGE-L考察自动生成摘要的可读性与流畅性。",
    "context4": "ROUGE-L计算时使用最长公共子序列,L为（lon-gestcommonsubsequence,最长公共子序列）,通常采用ROUGE-L的F1值作为评价标准。计算公式如下所示。",
    "context5": "$$\n{ \\cal R } _ { l c s } = { \\frac { L C S ( X , Y ) } { m } }\n$$",
    "context6": "$$\n\\boldsymbol { P } _ { \\mathit { l c s } } = \\frac { L C S ( X , Y ) } { n }\n$$",
    "context7": "$$\nF _ { _ { l c s } } = \\frac { ( 1 + \\beta ^ { 2 } ) \\ R _ { l c s } \\ P _ { _ { l c s } } } { R _ { l c s } + \\beta ^ { 2 } \\ P _ { _ { l c s } } }\n$$",
    "context8": "其中,LCS(X,Y)为参考摘要 $\\mathrm { X }$ 与自动生成摘要Y",
    "context9": "成摘要。"
  },
  "4.4.2评估指标": {
    "context1": "本文采用ROUGE评分体系对模型性能进行评估。ROUGE是一种面向 $\\mathbf { n }$ 元词召回率的自动摘要评价方法,基于参考摘要和生成摘要中的n元词（n-gram）的共现信息对生成摘要进行评价[4I]。ROUGE 通过将自动生成的综述与人工生成的参考综述进行比较计算得到相应分值,以衡量自动生成综述与参考综述之间的相似度,从而对模型效果进行评估，是自动摘要评价技术的通用标准之一。ROUGE-N的公式如下所示：",
    "context2": "$$\n\\frac { \\sum _ { g r a m _ { n } \\in S } C o u n t _ { m a t c h } ( g r a m _ { n } ) } { \\sum _ { g r a m _ { n } \\in S } C o u n t ( g r a m _ { n } ) }\n$$",
    "context3": "的最长公共子序列的长度, $m _ {  } , n$ 分别为参考摘要与自动生成摘要的长度， $R _ { l c s } \\ : , P _ { l c s }$ 分别表示召回率与精确率，$\\boldsymbol { F } _ { l c s }$ 为 ROUGE-L值。 $\\beta$ 用于调节召回率与精确率的关注度 $\\displaystyle { , \\beta = \\frac { P _ { \\mathit { l c s } } } { R _ { \\mathit { l c s } } } }$ ,当 $\\beta$ 很大时， $\\boldsymbol { F } _ { l c s }$ 会更关注 $R _ { l c s }$ 。"
  },
  "4.5结果分析": {
    "context1": "本文选取了四组检索词组进行实验,设置 Tex-tRank 含知识基因、TextRank 不含知识基因、基于知识基因增强的BERT自动综述模型、不含知识基因的BERT模型四组对照实验。以ROUGE作为评价指标，以词语为粒度进行评估,结果分析见表5。",
    "context2": "从上述结果可以看出，总体而言,本文提出的基于知识基因增强的BERT科技文献自动综述模型在ROUGE-1与ROUGE-2 测评上的表现均优于TextRank-KM、TextRank-无KM和无知识基因增强的BERT模型。以检索词组1为例,在使用BERT预训练模型生产自动综述的结果中,加入知识基因的自动综述结果相较于不包含知识基因的综述结果,在ROUGE-1提高了 $1 4 . 2 8 \\%$ ;ROUGE-2提高了 $1 2 . 1 3 \\%$ ;ROUGE-L提高了 $1 7 . 6 9 \\%$ 。除此之外,加入知识基因特征后,Tex-tRank 模型在ROUGE-1测评与ROUGE-2 测评中均有提高。这表明本文模型使得自动综述结果包含了更多的信息内容，增强了自动综述结果对文献内容的揭示力度。",
    "context3": "表5ROUGE评估结果  \n（单位 ${ \\% }$",
    "context4": "<table><tr><td rowspan=\"2\">检索词组</td><td colspan=\"3\">TextRank-无 KM</td><td colspan=\"3\">TextRank-KM</td><td colspan=\"3\">BERT-无 KM</td><td colspan=\"3\">BERT-KM</td></tr><tr><td>ROUGE-1</td><td>ROUGE-2</td><td>ROUGE-L</td><td>ROUGE-1</td><td>ROUGE-2</td><td>ROUGE-L</td><td>ROUGE-1</td><td>ROUGE-2</td><td>ROUGE-L</td><td>ROUGE-1</td><td>ROUGE-2</td><td>ROUGE-L</td></tr><tr><td>1</td><td>63.26</td><td>50.64</td><td>53.74</td><td>65.26</td><td>52.38</td><td>54.42</td><td>72.79</td><td>55.84</td><td>48.98</td><td>87.07</td><td>67.97</td><td>66.67</td></tr><tr><td>2</td><td>64.02</td><td>52.80</td><td>56.71</td><td>68.29</td><td>56.80</td><td>59.75</td><td>73.17</td><td>55.60</td><td>59.15</td><td>76.22</td><td>60.80</td><td>59.93</td></tr><tr><td>3</td><td>72.97</td><td>59.77</td><td>71.62</td><td>74.19</td><td>61.90</td><td>70.81</td><td>79.73</td><td>60.89</td><td>69.59</td><td>86.49</td><td>70.11</td><td>69.92</td></tr><tr><td>4</td><td>88.27</td><td>78.32</td><td>81.32</td><td>89.76</td><td>78.47</td><td>82.52</td><td>87.59</td><td>71.37</td><td>69.66</td><td>92.41</td><td>79.25</td><td>75.86</td></tr></table>",
    "context5": "在检索词组3与检索词组4的ROUGE-L测评中，TextRank算法模型的结果要高于基于知识基因增强的自动综述模型,本文经过分析后发现出现这种情况的原因是TextRank 模型是从原文中抽取句子，故而综述结果流畅性更高。而知识基因增强的自动综述结果包含了通过句子分析、语义标注抽取的知识基因,与原文语句相比可读性较差但对文献重点内容表述更为全面。",
    "context6": "通过上述科技文献自动综述测评结果及示例可以看出知识基因的加入使得模型在生成科技文献自动综述的过程中加强了对文献核心贡献知识点的关注,将原文献的核心思想、核心观点进行提取,生成的科技文献综述语句更为凝练、文献综述包含的信息量有显著的提升。"
  },
  "5结语": {
    "context1": "本文从科技文献本身出发，首先设置了核心文献识别指标识别科技文献自动综述候选文献，然后对科技文献核心贡献观点进行了抽取，进行筛选得到科技文献知识基因,之后构建了图书情报与档案管理学科领域的数据集，最后设计了基于知识基因增强的BERT科技文献自动综述模型。文中选取了4组检索词组进行实验,自动生成了相应的科技文献综述,并设置了对比实验对相关结果进行了测试,在本文选取的检索词组上,该模型在 ROUGE-1、ROUGE-2 和 ROUGE-L上均优于不进行知识基因增强的模型。知识基因的加入能够帮助模型更好地识别科技文献核心观点，提高科技文献综述所包含的信息量。下游任务中使用LexRank可以排除噪声句,减少冗余句，增大科技文献自动综述的可读性。本文提出的科技文献自动综述模型可以有效地提炼科技文献中的核心知识点,生成易读、信息丰富的科技文献综述，能够帮助科研人员快速掌握文献核心内容,提高科研效率,为科技文献自动综述研究提供了可行的研究思路。",
    "context2": "同时，本研究存在一定局限性。在数据集方面，本文使用图书情报与档案管理学科领域的数据集，具有领域局限性，未来研究将关注更多学科领域的科技文献,扩大数据规模,探究学科交叉现象，提高模型的适用性。此外,本文重点关注知识基因增强对于科技文献自动综述结果的信息内容揭示力，未来将进一步研究如何提高科技文献自动摘要的可读性与连贯性，以期帮助用户更好地掌握当前研究热点的发展脉络，促进科研创新发展。"
  },
  "参考文献：": {
    "context1": "［1］中国科技论文统计与分析课题组.2020 年中国科技论文统计 与分析简报[J].中国科技期刊研究,2022,33(1)：103－112.   \n[2]LUHN HP.The automatic creation of literature abstracts[J].IBM journal of research and development,1958,2(2）：159-165.   \n[3]EDMUNDSON HP,WYLLYS R E.Automatic abstracting and indexing -survey and recommendations[J]．Communications of the ACM，1961,4(5):226-234.   \n[4］SALTONG，YU C T.On the construction of effective vocabularies for information retrieval[J]．ACM sigplan notices,1975,10（1）： 48-60.   \n[5］KUPIEC J,PEDERSENJO，CHEN F．A trainable document summarizer[C]//Proceedings of the 18th annual international ACM SIGIR conference on research and development in information retrieval.Seattle：ACM,1995:68-73.   \n[6]SUTSKEVER I，VINYALSO，LEQV.Sequence to sequence learning with neural networks[C]//Proceedings of the 27th international conference on neural information processing systems. Cambridge：MIT Press,2014：3104-3112.   \n[7］BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate［EB/OL]．［2022-10- 11]．https://arxiv.org/pdf/1409.0473.pdf.   \n[8］VASWANIA,SHAZEERN,PARMARN,etal.Attention is all you need[C]//Proceedings of the 31st international conference on neural information processing systems.Red Hook：Curran Associates，2017:6000 -6010.",
    "context2": "[9]EDMUNDSON H P.New methods in automatic extracting[J]."
  }
}