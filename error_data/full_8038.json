{
  "original_filename": "full_8038.md",
  "生成式自动文摘的深度学习方法综述": {
    "context1": "赵洪1,2",
    "context2": "(1．南开大学商学院信息资源管理系，天津300071；2.中电科大数据研究院有限公司，贵阳550081)",
    "context3": "摘要自动文摘是文本挖掘的主要任务之一。相比于抽取式自动文摘，生成式自动文摘在思想上更接近人工摘要的过程，具有重要研究意义。近几年伴随着深度学习方法的发展，基于深层神经网络模型的生成式自动文摘也有了令人瞩目的发展。为了更全面地理解该类方法的思想和研究现状，本文从生成式自动文摘的任务描述入手，梳理了基于RNN（recurrent neural network，循环神经网络）的模型、基于CNN（convolutional neural network，卷积神经网络）的模型、基于 $\\mathrm { R N N + C N N }$ 的模型、融合注意力机制的模型和融合强化学习的模型共五大类生成式自动文摘的深度学习方法。这类方法表明，在深层神经网络的训练下，特别是融合注意力机制和强化学习后，摘要效果得以明显提升。在生成式自动文摘研究的未来发展中，除深度学习方法本身的不断应用和改进外，还需关注如何有效实现篇章级语义理解下的摘要、面向不同文本对象特点的摘要和摘要结果自动评价等问题。此外，如何结合传统摘要研究中的成熟方法进一步提高摘要效果，也是一个很有价值的研究方向。",
    "context4": "关键词生成式自动文摘；深度学习；循环神经网络；卷积神经网络；注意力机制；强化学习"
  },
  "A Survey of Deep Learning Methods for Abstractive Text Summarization": {
    "context1": "Zhao Hong1,2",
    "context2": "(1.DepartmentofInformation Resources anagement,Business School,Nankai Universityianjin0001; 2.CETC Big Data Research Institute Co.Ltd., Guiyang550081)",
    "context3": "Abstract:Abstractive text summarization (ATS)is a main topicofresearch in text mining. Compared with extractive text summarization,which extracts shallow meaning from a text,ATS more closely resembles the process ofhuman summarization,giving it importantresearch significance.Withthe developmentof dep learning methods and deep neural networks in recent years,remarkable progressinATS has been made.To gain amore comprehensive understanding ofthe theory and state ofresearch onATS,this paper describes theATS task andcombines five dep learning methods to support it,namely recurrent neural networks (RNN),convolutional neuralnetworks (CNN),RNN+CNN,atentional models,andreinfored models.These results show that ATS performance can be improved significantly through deep neural network training, especialy after joining atention mechanisms and reinforcement learning.In future development ofATS,in aditionto continued application and improvementofdeep learning methods themselves,esearchers must consider to how to effectively implement ATS with text-level semanticcomprehension,ATSof more text categories,andATS evaluation.Integrationof maturetraditional research methods to further improve ATS performance is alsoavaluable direction forfutureresearch.",
    "context4": "Keywords:abstractive text summarization;deep learning;recurrent neural network;convolutional neuralnetwork;attention mechanism; reinforcement learning"
  },
  "1引言": {
    "context1": "自动文摘是文本挖掘的主要任务之一，它是指利用计算机程序对文本进行处理，生成一段长度被压缩的摘要，并且该摘要能包含原始文本的主要信息[。其研究和应用受到图书情报学、计算机科学、应用语言学和认知心理学等相关学科的广泛关注。典型的应用场景包括对新闻[2-4]、社会化短文本[5-8]和专业领域文献[9-13]等文本自动生成简短摘要，一则使人们快速浏览和筛选信息，二则方便在手机等便携式设备有限的阅读空间上展示更多内容[14]。",
    "context2": "最早的自动文摘方法是由Luhn[15]于1958年提出的，该研究首先使用词频来识别文本中的重要词，然后根据给定句子中重要词的数量和词之间的接近程度来确定这些句子的重要性，最后按重要性排序输出句子集合作为摘要。此后，围绕关键词标引、句子相似度计算、句子重要性排序和文本表示方法等技术问题[16-23]，自动文摘的研究不断发展，并由DUC（Document Understanding Conference）和TAC（TextAnalysisConference）等会议产生了自动文摘的标准化评价基准[24]。",
    "context3": "自动文摘按实现方式分为抽取式（extractive）和生成式（abstractive）。抽取式自动文摘直接从原文中抽取若干词语、句子或段落等作为摘要，常用的方法包括基于图的方法（如Erkan等[25]的LexRank方法）、基于中心性的方法（如Radev等[26的Centroid方法）和基于语料库的方法（如Lin等[27]的TsSum方法）。而生成式自动文摘则需要在对文本进行语义理解后，应用自然语言生成的算法，通过转述、同义替换、句子压缩等技术，生成更凝练简洁的摘要。抽取式和生成式文摘效果对比如表1[28]所示。",
    "context4": "与抽取式自动文摘相比，生成式自动文摘在思想上更接近人工摘要的过程（如表2[29所示），因而具有重要研究意义。但历史上，受限于传统方法很难实现生成式自动文摘所需要的文本表征、理解和生成能力，使得该领域的发展一直比较缓慢，生成式的效果也通常差于抽取式[30]。近几年伴随着深度学习方法的发展，基于深层神经网络模型的生成式自动文摘有了令人瞩目的发展，在DUC测试集上已经超越了最好的抽取式模型[31-33]，未来的自动文摘研究也将主要集中于深度学习方法上[34]。为了更全面地理解该类方法的思想和研究现状，本文从生成式自动文摘的任务描述入手，梳理了基于RNN（recurrentneuralnetwork，循环神经网络）的模型、基于CNN（convolutional neural network，卷积神经网络）的模型、基于 $\\mathrm { R N N + C N N }$ 的模型、融合注意力机制的模型和融合强化学习的模型这五大类生成式自动文摘的深度学习方法，总结了当前发展的不足并对未来的发展方向进行了展望。",
    "context5": "表1抽取式和生成式自动文摘对比[28]",
    "context6": "<table><tr><td rowspan=\"3\">原文</td><td>McDonald&#x27;says...Thecompanysays it expecthenew‘Artisan GriledChicken’tobe in itsmoretan143oU.S.stores bythe</td></tr><tr><td>endofnextweek,inproducts includinganesandwichaswelasexistingandwche,wrasandsalads.Itsays thebgescangeis theremovalofsodiumphosphates,whichitsaidwasusedtokepthechickenmoistinfavorofvegetablestarch.Thenewrecipealso</td></tr><tr><td>does notusemaltodextrin,whichMcDonald&#x27;ssaidis generallyusedasasugartoicreasebrowingorasacarrerforseasongJesica Foust,directorofculinaryinnovationatMcDonald&#x27;s,saidthechangeswere madebecausecustomerssadtheywant‘simple,cleanin- gredients’they are familiar with…</td></tr><tr><td>抽取式自 动文摘</td><td>Thecompanysays itexpectsthenew‘ArtisanGriledChicken’tobeinits morethan14,30oU.S.storesbytheendofnextwek,in products includinganesandwich,aswellasxistingsandwicheswrapsandsalads.Itsasthebgestchangeistheemovalofsodi- umphosphates,whichitsaidwasusedtokepthechicken moist,infavorofvegetablestarch.Tenewrecipealsodoesnotuse malto dextrin, which McDonald’s said is generally used as a sugar to increase browning oras acarier for seasoning.</td></tr><tr><td>生成式自 动文摘</td><td>McDonald&#x27;ssaysitexpectsthenew‘Artisan GrilledChicken’tobeinitsmorethan14,30oU.S.storesbytheendofnextweek.The companysays the changes were made because customers said they want‘simple,clean ingredients’they are familiar with.</td></tr></table>",
    "context7": "表2生成式自动文摘与人工摘要对比[29",
    "context8": "<table><tr><td>抽取式自动文摘句</td><td>海湾报刊对美国新当选总统克林顿,能否帮助振兴中东和平进程感到怀疑,但也确实看到了一丝希望。</td></tr><tr><td>人工摘要</td><td>海湾报刊对克林顿是否会恢复和平进程,持怀疑态度。</td></tr><tr><td>生成式自动文摘</td><td>海湾新闻界对克林顿恢复和平进程的前景,持怀疑态度。</td></tr></table>"
  },
  "2生成式自动文摘任务描述": {
    "context1": "自动文摘的过程可以抽象为三个阶段。 $\\textcircled{1}$ 文本分析：对原文进行分析处理，从中提取基本特征信息，如线索词、关键词、指示性短语、句式及位置信息等； $\\textcircled{2}$ 表示变换：从特征信息中识别重要信息，通过摘录或概括的方法压缩文本，或者通过信息抽取的方法形成文摘表示等，以得到生成初级摘要的必要内容；但其中会存在许多语法和语义错误等情况，如指代不明、语义不连贯等； $\\textcircled{3}$ 摘要合成：实现对文本内容的重组或者根据内部表示生成文摘，解决表示变换阶段所产生的初级摘要不平滑、词语冗余等问题，按照某种顺序以人们可理解的方式输出最终摘要，并确保其连贯性[35-36]。",
    "context2": "在抽取式自动文摘中，一般认为文档的核心思想可以用文档中的某一句或几句话来概括，将摘要任务转变为文档中冗余句的识别和重要句的选取问题，主要关注句子的相似度计算（如余弦相似度、词重叠、LDA（latent Dirichlet allocation）和 KL（Kullback-Leibler）散度等）和句子排序算法（如贪心算法、基于中心性的方法、基于图的方法和基于权重一频次的方法等），文本的特征表示方案包括TF-IDF （term frequency-inverse document frequency）、word2vec 和LSA（latent semantic analysis）等。抽取式方法不需要进行复杂的语义分析，能适应大多数文本对象的特征规律，因而具备较好的通用性。但因为各个句子都是从不同的位置中选择出来的，缺乏一定的逻辑次序，连接起来的句子由于脱离上下文语境而难以理解，很多时候还会产生语义错误。此外，按照重要性排序选取前 $N$ 个句子作为摘要结果，也常常影响了文摘的全面性和简洁性。",
    "context3": "不同于抽取式自动文摘对文本内容的“浅层”理解，生成式自动文摘需要对文本进行深入的语义分析等“深层”理解后生成摘要。经典的生成式方法需结合语言学知识和领域知识进行推理和判断。在文本分析阶段，利用知识库中的词典、语法规则对文本进行语法分析，形成语法结构树；在表示变换阶段，通过知识库中的语义知识对文本进行标注，表示出词间依赖关系、句子间衔接关系和段落间逻辑关系，将语法结构树转换成语义表示（如语义网络），并结合领域知识和上下文语境进行判断和推理后提取出关键信息；在摘要合成阶段，将关键信息转换为一段完整连贯的文字输出。生成式自动文摘虽然结果质量较高，但其不足在于领域严格受限，必须依赖大规模真实语料库和专业领域知识库[37]，传统的方法和技术也一直没有产生本质型的突破，使其在较长一段时间内发展缓慢。",
    "context4": "近年来，随着深度学习方法在生成式自动文摘任务中不断研究与应用，通过其深层神经网络来表征输入的数据，模型不再完全依赖于领域的特征，实用性得以大幅度提升。在该类方法中，将生成式自动文摘转换为 Sequence-2-Sequence（Seq2Seq，序列到序列）问题，基本结构主要由编码器（encoder)和解码器（decoder）组成，如图1[38]所示。编码器将文档表示成 Sequence粒度的若干带有语义向量的输入序列，解码器则从输入序列中提取重要内容，生成文本摘要输出。在该 Seq2Seq结构中，编码器和解码器通常由RNN或CNN实现。同时，为了使模型的效果进一步提升，解决生成摘要时出现的不通顺、重复词句等问题，一般还会加入注意力机制（attentionmechanism）函数提升训练效率等[39]",
    "context5": "![](images/05bdeb84ef577b6f0032384a651c5e9eea1b1bc7f70069f9cff0a90948755a13.jpg)  \n图1深度学习的序列模型(Seq2Seq)[38]",
    "context6": "图 $2 ^ { [ 4 0 ] }$ 展示了一个基于深度学习的生成式自动 文摘实例，输入的句子（图2中纵坐标）为“russian defense minister ivanov called sunday for the creation of a joint front for combating global terrorism”, 生成的摘要（图2中横坐标）为“russia calls for joint front against terrorism”。而矩阵中每一列代表生成词 对应输入词的注意力分配概率，颜色越深代表概率 越大。",
    "context7": "![](images/9d050f20fde22865d2e7f8bbc74d3ee5c29873c431f6eceac0cf6f541701109f.jpg)  \n图2基于深度学习的生成式自动文摘实例[40]",
    "context8": "在生成式自动文摘任务中，Rush等[40]是较早使用深度学习方法的代表性研究之一，在此之后，产生了许多有价值的研究。这些研究中模型构建的基本思路为： $\\textcircled{1}$ 选择一个大型语料库作为训练集和测试集； $\\textcircled{2}$ 选择合适的编码器，如RNN和CNN等，将文本输入编码到语义空间，得到一个固定维数的语义向量； $\\textcircled{3}$ 选择合适的解码器，作用是相当于一个语言模型（language model），用来生成摘要词语（summary words）; $\\textcircled{4}$ 设计合适的注意力机制，基于输入中“注意力”更高的词来预测输出文本序列。此外，还包括结合强化学习来提升模型训练效果等。",
    "context9": "如何对摘要生成的质量进行评价，也是自动文摘研究中一项较为困难的任务。摘要生成结果的判断标准具有很强的主观性，常常因人而异。为有效地推动自动文摘研究的发展，自20世纪90年代末开始，一些会议和组织开始致力于制定评价摘要的数据和标准，也有一些机构、企业和研究团队开放了自建的数据集，目前形成了一批较为常用的评价数据集和评价方法。英文数据集包括DUC会议的系列数据集（DUC2001-2007）[41]、TAC会议的系列数据集（TAC2008-2011）[42]、CNN/DailyMail数据集[43]、NYT数据集[44]和Gigaword数据集[45]等；中文数据集包括哈尔滨工业大学从新浪微博上采集的中文短文本摘要数据集LCSTS（Large Scale ChineseShort Text Summarization Dataset）[46]、NLPCC会议（NLPCC2017、NLPCC2018）的单文档摘要数据集[47-48]和搜狗实验室的新闻数据集[49]等。",
    "context10": "在摘要的自动评价方法中，目前最常用、也最受到认可的评价指标是 $\\mathrm { L i n } ^ { [ 5 0 ] }$ 提出的ROUGE（re-call-oriented understudy for gisting evaluation），其评价思想是计算生成摘要和参考摘要的重叠内容程度，包括ROUGE-N（N元语法共现）、ROUGE-L（最长公共子序列共现）和ROUGE-W（ROUGE-L基础上的连续匹配）、ROUGE-S（顺序词对统计）和ROUGE-SU（ROUGE-1 和 ROUGE-S 的综合加权）。考虑到摘要结果的多样性，通常会使用几篇摘要作为参考和基准，以及加入预训练词向量使ROUGE评价时能兼顾到语义信息[51等。但是，在生成式自动文摘评价中，目前的自动评价方法仍然难以定量测试摘要的语法正确性（grammaticality）、语言连贯性（coherence）和关键信息完整度（infor-mativeness）等方面。评价时除采用自动评价方法外，还常常结合人工评价的方法，通过设置评价指标和规则进行专家打分[52-54]。"
  },
  "3基于RNN的生成式自动文摘模型": {
    "context1": "RNN是一种对序列数据建模的神经网络[55]，其特点是隐藏层之间的神经元是有连接的，并且隐藏层的输人不仅包括输入层的输出还包括上一时刻隐藏层的输出[5。典型的基于RNN的生成式自动文摘模型如图 $3 ^ { [ 3 2 ] }$ 所示，在该类模型中，编码器和解码器采用的均是RNN。",
    "context2": "![](images/d03264a631f8909b22e7497a98fef844acb540e1858669f61dc1424f96389ad3.jpg)  \n图3基于RNN的生成式文本摘要模型[32]",
    "context3": "编码器依次处理输入文本对象（如新闻文本）中的每个词，在输入层（input layer）通过嵌入（embedding）将其表示成分布式的词向量（wordembedding）形式；然后，使用多层神经网络将此分布式向量与前一个词 （第一个词定义为0向量）通过前向传播组合生成隐藏层（hiddenlayer）。解码器将文本完全输入后的隐藏层作为输入，并将eos（end-of-sequence，序列结束）符也通过词嵌入表示成分布式向量形式；然后，解码器使用soft-max层（以及结合注意力机制等）来生成摘要，即输出层（ouput layer）完成输出。模型训练时，目标文本（如新闻标题）的每个词以eos符结尾，生成每个词之后，在下一个词生成时均以相同的词作为输人[32]。",
    "context4": "由于基本的RNN模型在训练的时候会遇到梯度爆炸（gradient explode）或梯度消失（gradient van-ishing）的问题，导致无法训练，所以在实际中经常使用的是经过改进的LSTM（long short-term mem-ory，长短时记忆）[57]或者GRU（gated recurrent unit,门控循环单元）[58]以及双向（bi-directional）传播算法[59]等对输入序列进行表示。",
    "context5": "生成（generate）摘要时，模型需要生成新的句子（文本序列），计算时除考虑语言规则和上下文生成概率最高的词外[60-61]，还需从较大的候选序列中搜索最优输出序列。常用的搜索算法包括greedysearch（贪心搜索）[62]、random search（随机搜索）[63]和 beam search（集束搜索）[64]等。在 greedy search算法中，语言模型根据前面已生成词与当前候选词的条件概率，每次挑选出最大生成概率的词，加入到生成序列，这种算法简单明确，列举出所有候选句子并选择最优，但是可能会由于候选句子数量过大而使得计算时间成本过高。random search算法是针对巨大数据规模下难以在一定时间内计算出精确结果的情况，采用随机策略求取近似解的方法，但求解过程中也很容易陷入局部最优。而beamsearch是一种启发式图搜索算法，在每一步搜索时，去掉生成概率较低的序列，保留 $K$ 个概率较高的序列用于继续下一步搜索，最终达到算法结束条件找出最优解，该算法减少了空间消耗的同时提高了时间效率，在Seq2Seq模型生成摘要时常采用此算法[40.65]。",
    "context6": "在基于RNN的生成式自动文摘模型中，每个词都是按顺序输入网络的，RNN记录了文本的序列信息，并在一定程度上解决了长距离依赖问题，但是由于每一时刻的状态值都需结合上一时刻的状态值，无法并行计算，因而限制了模型训练和生成摘要的效率，不适用于大样本数据。"
  },
  "4基于CNN的生成式自动文摘模型": {
    "context1": "不同于RNN直接处理时序数据，CNN通过卷积核从数据对象中提取特征，间隔地对特征作用最大池化，得到不同层次的、由简单到复杂的特征，常用于图像任务。但通过文本的分布式向量表示，将一句话/一个词用一个实数矩阵/向量表示后，就可以使用CNN在文本任务中进行卷积应用[6]。2016年，Facebook AI Research（FAIR）将其加人 Seq2Seq模型编码器，在与自动文摘序列生成原理类似的机器翻译任务中，达到了当年的state-of-the-art（最新水平）[67]。",
    "context2": "在基于CNN的生成式自动文摘模型中，最具代表性的是由Facebook于2017年提出的ConvS2S 模型[68]，它的编码器和解码器都采用了CNN，如图4所示。在该模型中，输入层除了输入每个词的词向量（wordembedding）外，还输入了词的位置嵌入（positionembedding），两者拼接后形成该词的em-beddings，使模型能够模拟RNN对词序的感知，并利用卷积模块对embeddings进行卷积（convolutions）和非线性变换（gated linear unit，GLU）[69-70]。非线性变换将卷积后的结果变换成两部分，其中一部分使用sigmoid变换，并将其变换结果和另一部分向量按对应元素（element-wise）相乘，即图4所示模型中的点积（dotproducts）处理。该模型还使用了残差连接（residualconnection）[71]构建更深的网络和缓解梯度消失/爆炸等问题。在DUC-2004和Giga-word数据集上取得了与RNN相似的ROUGE值，但训练速度却得到较大提升。",
    "context3": "![](images/2cd67713104fe81c93f628ab503dfb75b2c6a8dc04f99f1ca3de1235063f50a1.jpg)  \n图4基于CNN的生成式文本摘要模型[68]",
    "context4": "在序列建模时，虽然CNN不能直接处理变长的序列样本，其卷积层只能生成固定大小的上下文表征，但通过卷积层的叠加可以增加上下文大小表征，形成一种层级式结构，使得序列中的元素可以在层间并行化计算，并且还能在较短路径下解决元素之间的长距离依赖问题。由于具有可高度并行化的特点，因而基于CNN的生成式自动文摘模型训练比RNN更高效[70]。但是，相比于RNN的链式结构，CNN的这种层级式结构使得参数的调整量大增，需要使用很多调参技巧（trick)，而在大数据量的样本上调参代价也会相应较高。"
  },
  "5基于 $\\mathbf { R } \\mathbf { N } \\mathbf { N } { + } \\mathbf { C } \\mathbf { N } \\mathbf { N }$ 的生成式自动文摘模型": {
    "context1": "在 Seq2Seq模型中，编码器或解码器也可以结合使用不同的神经网络，如Song等[72]提出的基于RNN的LSTM和CNN的生成式自动文摘模型，如图5所示。",
    "context2": "在图5的模型中，其编码过程为：首先，将文档 $W$ 表示成一个稠密列矩阵（densecolumn ma-trix），设 $d$ 代表词向量的维度， $s$ 代表由 $n$ 个词$( w _ { 1 } , \\cdots , w _ { n } )$ 组成的序列，则 $W { \\in } R ^ { n ^ { * } d }$ 。然后，对 $W$ 和 $c$ 宽度的卷积核 $K { \\in } R ^ { * _ { d } }$ 进行时间窄卷积（temporal nar-row convolution） : $f _ { j } { = } { \\mathrm { t a n h } } ( W _ { j ; j + c - 1 } \\otimes K { + } b )$ ，其中， $\\otimes$ 为所有元素的哈达玛积（Hadamard product）， $f _ { j } ^ { i }$ 代表第 $i$ 个特征映射 $f ^ { \\prime }$ 的第 $j$ 个元素， $^ b$ 为偏置。接着，将 $c$ 宽度的卷积核 $K$ 上对第 $i$ 个特征作用的最大池化为 $S _ { i , k } { = } \\mathrm { m a x } _ { ( j } f _ { j } ^ { i }$ 。最后，在CNN编码后，采用RNN的LSTM对文档进行循环编码，形成循环文档编码器（recurrent document encoder）。",
    "context3": "模型的解码器结合Generate（生成）和 Copy（拷贝）两种模式，并通过阈值控制解码模式。其中，Generate模式的任务是根据语义来决定输出，而Copy模式的任务是根据输入文本的位置来决定拷贝输出。当生成概率大于阈值 $\\delta$ 时，进入Gener-ate 模式，解码器根据编码中获得的所有标注以及已生成的短语来预测下一个短语；当生成概率不大于阈值 $\\delta$ 时，进人Copy模式。在Copy模式下，模型认为Generate模式生成的短语不适合匹配当前短语，因此将原文中当前短语位置的下一个短语复制到摘要中，从而较好地解决了低频词和未登录词的问题。",
    "context4": "Seq2Seq模型的编码器一解码器（encoder-de-coder）是一种通用的计算框架，可以基于RNN、CNN和 $\\mathrm { R N N + C N N }$ 等构建生成式自动文摘模型。这些模型中，在生成目标序列的单词时，不论生成哪个单词，原则上它们使用的中间语义表示都是一样的，没有任何区别。而中间语义表示是输入序列经过编码器编码产生的，这意味着输入序列中的任何单词对目标序列单词的影响力是相同的，导致模型的“注意力不集中”，模型并未良好地“理解”输入序列[73]。因而，在模型中需融合注意力机制（at-tention mechanism），体现出输入序列单词对于生成单词的不同影响程度，即注意力分配概率信息，例如，图5中的解码器模式就是一种基于注意力机制的应用扩展。",
    "context5": "![](images/a70c50b7d4841b647d3dde817154d0167877ff0f2134feed49d3f0889b87e435.jpg)  \n图5基于LSTM-CNN的生成式文本摘要模型[72]"
  },
  "6融合注意力机制的生成式自动文摘模型": {
    "context1": "Seq2Seq模型通过编码器可以得到输人序列的全局信息，并将其进行语义编码后输入解码器中生成摘要。而经过固定的语义编码表示的中间语义向量，词自身的信息已经消失，输入序列中任意词对生成目标词的影响力都是相同的，特别是输入句子或文档比较长时，会由此出现信息瓶颈（informa-tion bottleneck）[74]问题。而解决此问题的关键在于如何将中间语义的固定表示替换成按当前生成单词不断变化的动态表示。为了解决此类问题，有研究抽象出了注意力机制（attentionmechanism）的思想，即从众多信息中选择出对目标更为关键的信息，融合到 Seq2Seq模型中[75]。注意力机制在模型中通过注意力函数实现，本质上可以描述为：将查询（query）和键-值对（key-value pairs）映射（map-ping）到输出（output)；其中，查询、键、值和输出都是向量，输出被计算为值的加权和，而分配给每个值的权重由查询与对应的键进行计算。",
    "context2": "在融合注意力机制的生成式自动文摘模型中，注意力机制通过目标序列中每个词对输入序列中每个词的注意力概率的学习，使解码器可以动态利用输入序列中的词，并在生成摘要时关注已生成的词，从而解决生成长句子时出现的不通顺、重复词语等问题。注意力机制一般用在模型的解码阶段，能帮助模型更好地理解输入数据（如专有名词和数字等），并将输出和输入序列中的词之间建立权重关系（注意力概率），从而使解码器判断出当前输出词与哪个输入词的关系更大。Lopyrev[32]在摘要自动生成中，研究了两种不同的注意力机制——复杂注意力机制（complex attention mechanism）和简单注意力机制（simple attention mechanism），分别如图6和图7所示。",
    "context3": "在图6中，复杂注意力机制采用相同的隐藏单元计算以及生成注意力权重向量（attentionweightvector）和上下文向量（contextvector）[76]。模型中， $t ^ { \\prime }$ 位置的输出词 $y _ { t ^ { \\prime } }$ 对 $t$ 位置的输入词 $x _ { t }$ 的注意力权重计算公式为",
    "context4": "$$\na _ { y _ { t ^ { \\prime } } } ( t ) = \\exp { ( h _ { x _ { t } } ^ { \\scriptscriptstyle \\mathrm { T } } h _ { y _ { t ^ { \\prime } } } ) } \\bigg / \\sum _ { \\tilde { t } \\in T } \\exp { ( h _ { x _ { \\tilde { t } } } ^ { \\scriptscriptstyle \\mathrm { T } } h _ { y _ { t ^ { \\prime } } } ) }\n$$",
    "context5": "其中， $h _ { x _ { t } }$ 表示处理 $t$ 位置输入词后生成的最后一个隐藏层； $h _ { y _ { t } }$ 表示当前解码步骤生成的最后一个隐藏层。在图7中，简单注意力机制是对复杂注意力机制的一种改进，将隐藏层的最后一层表示分为两部分，小部分用来计算注意力权重，大部分用来计算上下文，使得神经网络学习注意力权重变得更加容易。",
    "context6": "![](images/fc11e19bc9934fcbfe20f0b5e2c8bf03ab97eee2866204bf740787d25f9111d8.jpg)  \n图6复杂注意力机制[32]",
    "context7": "![](images/de23659c0d1472d09118e312b9663c851dd6e38b4bf5c0045ab1da32359c0735.jpg)  \n图7简单注意力机制[32]",
    "context8": "Nallapati等[77]做了进一步的研究，主要体现在：基于负采样思想创建大词表策略（large vocablarytrick，LVT）来解决解码器词表过大的问题；使用TF-IDF、词性标注和命名实体识别等提取句子中的关键词特征，并将其做嵌人（embedding）转换后与词向量拼接，共同作为编码器的输入；解码时，将词的生成概率和拷贝概率分开计算，并通过生成指针（generator-pointer）的切换（switch）来判断是否正常地进行词表预测，不正常时直接指向原文位置的词，从而解决未登录词和低频词的问题；对长文本中的每个句子计算权重，作为句子对应的分级注意力（hierarchical attention）；引入Sankaran等[78]的时间注意力（temporalattention）计算方法，将当前位置的注意力权重除以在所有源位置上积累的权重以调节注意力权重，用于缓解重复词的问题。在长句子较多的文本中，该模型的摘要效果比其他方",
    "context9": "法有较大的提升。",
    "context10": "Gu等[79]的研究中，不同于其他将生成概率和拷贝概率分开计算的方法，而是将两个概率叠加计算。其拷贝概率也不是注意力机制的直接应用，而是扩展后提出了一个CopyNet模型，如图8所示。",
    "context11": "图8a是该模型的Seq2Seq结构。编码器采用双向RNN，将源序列转换为一个隐藏层表示的矩阵 $M =$ $\\{ h _ { 1 } , \\cdots , h _ { t } , \\cdots , h _ { T s } \\}$ 作为decoder的输入；其中， $h _ { t }$ 是 $t$ 时刻隐藏层的最后一层表示。解码器采用的是结合注意力机制后改进的RNN。",
    "context12": "![](images/a5402f99238ceb7ae934f1c23217d4243b8c2d4be8f15351a3c8e781177355fa.jpg)  \n图8生成式自动文摘的CopyNet模型[79]",
    "context13": "（1）基于生成模式（generate-mode）和拷贝模式（copy-mode）的混合概率进行下一个词的预测。设有词表 $\\mathcal { V } = \\{ \\nu _ { 1 } , \\cdots , \\nu _ { N } \\}$ ，源输入序列 $X = \\{ \\ : x _ { 1 } , \\cdots , x _ { T s } \\}$ 中只出现过一次的词集 $\\mathcal { X }$ ，并用UNK代表未登录词（out-of-vocabulary，OOV），则 $X$ 中的词属于$\\mathcal { V } \\cup \\{ \\mathrm { U N K } \\} \\cup \\mathcal { X } _ { \\circ }$ 解码器在 $t$ 时刻预测词 $\\boldsymbol { y } _ { t }$ 的概率计算公式为",
    "context14": "$$\np \\left( y _ { t } | s _ { t } , y _ { t - 1 } , c _ { t } , M \\right) = p \\left( y _ { t } , \\mathrm { G } | s _ { t } , y _ { t - 1 } , c _ { t } , M \\right) +\n$$",
    "context15": "$$\np \\left( \\boldsymbol { y } _ { t } , \\mathrm { C } \\vert \\boldsymbol { s } _ { t } , \\boldsymbol { y } _ { t - 1 } , \\boldsymbol { c } _ { t } , M \\right)\n$$",
    "context16": "其中，G代表生成模式；C代表拷贝模式； $S _ { t }$ 和 $c _ { t }$ 分别是 $t$ 时刻的RNN状态和语义向量； $y _ { t - 1 }$ 是 $t { - } 1$ 时刻生成的词。由公式(2)可见，生成词的预测概率由生成模式和拷贝模式的概率叠加，预测过程如图8b所示。两种模式的概率计算公式分别为",
    "context17": "$$\np \\left( y _ { \\varepsilon } , \\mathbf { G } \\middle \\vert \\cdot \\right) = \\left\\{ \\begin{array} { l l } { \\displaystyle \\frac { 1 } { Z } \\mathbf { e } ^ { \\varphi _ { \\mathrm { G } } \\left( y _ { t } \\right) } , } & { \\quad y _ { t } \\in V } \\\\ { \\displaystyle 0 , } & { \\quad y _ { t } \\in X \\cap \\overline { { \\mathscr { V } } } } \\\\ { \\displaystyle \\frac { 1 } { Z } \\mathbf { e } ^ { \\varphi _ { \\mathrm { G } } \\left( \\mathrm { U N K } \\right) } , } & { \\quad y _ { t } \\notin V \\cup X } \\end{array} \\right.\n$$",
    "context18": "$$\np \\left( \\boldsymbol { y } _ { t } , \\boldsymbol { \\mathbf { C } } | \\cdot \\right) = \\left\\{ \\begin{array} { l l } { \\displaystyle \\frac { 1 } { Z } \\sum _ { j : x _ { j } = y _ { t } } \\mathrm { e } ^ { \\varphi _ { \\mathrm { c } } ( x _ { j } ) } , } & { \\boldsymbol { y } _ { t } \\in X } \\\\ { \\displaystyle 0 , } & { \\mathrm { o t h e r w i s e } } \\end{array} \\right.\n$$",
    "context19": "其中， $\\varphi _ { \\mathrm { { G } } } ( \\cdot )$ 和 $\\varphi _ { \\mathrm { c } } ( \\cdot )$ 分别是生成模式和拷贝模式的",
    "context20": "得分函数；e是自然指数； $Z$ 是两种模式的归一化项，",
    "context21": "$$\nZ = \\sum _ { \\nu \\in \\mathcal { V } \\cup \\{ \\mathrm { U N K } \\} } \\mathbf { e } ^ { \\varphi _ { \\mathrm { G } } ( \\nu ) } + \\sum _ { x \\in X } \\mathbf { e } ^ { \\varphi _ { \\mathrm { C } } ( x ) }\n$$",
    "context22": "（2）更新 $t$ 时刻的状态时考虑 $t { - } 1$ 时刻已生成词$y _ { t - 1 }$ 的信息，除了利用其词向量 $e \\left( y _ { t - 1 } \\right)$ 外，还利用$M$ 矩阵中对应位置隐藏状态权重之和 $\\varsigma ( y _ { t - 1 } )$ ， $y _ { t - 1 }$ 的表示为 $[ e ( y _ { t - 1 } ) ; \\varsigma ( y _ { t - 1 } ) ] _ { \\mathrm { ~ \\scriptsize ~ \\circ ~ } } ^ { \\mathrm { \\scriptscriptstyle T } } \\varsigma ( y _ { t - 1 } )$ 的计算公式为",
    "context23": "$$\n\\varsigma \\left( y _ { t - 1 } \\right) = \\sum _ { \\tau = 1 } ^ { T _ { s } } \\rho _ { t \\tau } h _ { \\tau }\n$$",
    "context24": "$$\n\\rho _ { t \\tau } = \\left\\{ \\begin{array} { l l } { 1 } \\\\ { K } \\\\ { 0 , } & { \\mathrm { o t h e r w i s e } } \\end{array} \\right.\n$$",
    "context25": "其中， $K$ 是归一化项，",
    "context26": "$$\nK = \\sum _ { \\tau ^ { \\prime } x _ { \\tau ^ { \\prime } } = y _ { t - 1 } } p \\left( x _ { \\tau ^ { \\prime } } , c _ { t } \\middle | s _ { t - 1 } , M \\right)\n$$",
    "context27": "（3）采用attentive read 和 selective read两种方式来读取 $M$ 矩阵，采用attentive read方式时获取内容信息（语义），即生成模式；采用selective read方式时获取位置信息，即拷贝模式。状态更新过程如图8c所示。位置信息的更新方式为",
    "context28": "$$\n\\varsigma \\left( y _ { t - 1 } \\right) { \\stackrel { \\mathrm { u p d a t e } } { \\longrightarrow } } s _ { t } { \\stackrel { \\mathrm { p r e d i c t } } { \\longrightarrow } } y _ { t } { \\stackrel { \\mathrm { s e l e c t i v e r e a d } } { \\longrightarrow } } \\varsigma \\left( y _ { t } \\right)\n$$",
    "context29": "CopyNet很好地将解码器中词的常规生成方式与新的拷贝机制相结合，这种拷贝机制可以在输入序列中选择合适的子序列，并将它们拷贝到输出序列中的适当位置。",
    "context30": "生成式自动文摘的Seq2Seq模型通过注意力机制引入了更多上下文信息来帮助模型生成更连贯、多样性更强和信息更丰富的摘要[80]。除上述注意力机制外，许多Seq2Seq模型的研究中还提出了多跳注意力机制（multi-step attention mechanism）[68]、自注意力机制（self-attentionmechanism）[75]、多头注意力机制（multi-head attention mechanism）[75]和变分注意力机制（latent alignment and variational atten-tion mechanism）[81]等，使模型在生成序列的输出过程中不断增强对输入序列的理解。但是，现阶段的注意力机制研究尚有不完善之处，如未记忆历史信息、缺乏对注意力的有效评价机制以及还可以使用更加复杂的网络结构来改善其效果等[82]。"
  },
  "7融合强化学习的生成式自动文摘模型": {
    "context1": "深度学习的模型训练过程中，一般采用最大似然估计（maximum likelihood estimation，MLE）或交叉熵（cross-entropy）等似然方法评价学习模型的损失（loss），通过最小化模型的损失函数来优化目标，即对于给定的输入，使其输出值不断逼近真实值。但在生成式自动文摘中，仅仅采用似然方法并不够。一是因为在训练过程中已标记的真实数据（ground truth）能纠正每一时刻生成词的偏差（bi-as），避免了错误的积累；但在预测应用过程中，这样的偏差会随着序列长度的增加而不断加大，产生曝光偏差（exposure bias）[83]问题。二是基于似然方法的监督式学习过程中，模型尽可能生成与已标记的真实数据（ground truth）一样的摘要结果，但一篇文本往往可以有不同的摘要，因此生成的模型缺乏灵活性。相比于似然方法，用于摘要任务评价的ROUGE指标却能考虑到曝光偏差（exposurebias）和灵活性问题，但由于ROUGE是不可导的，训练时并不能直接应用梯度下降（gradientdescent）和反向传播（back propagation）等算法进行模型优化，需要利用强化学习（reinforcement learning）将其加入训练目标[84]。",
    "context2": "强化学习，又称评价学习、增强学习，通过采取持续的“交互-试错”机制在环境中不断交互学习到有效策略（policy），模拟人脑如何做出决策的反馈系统运行机理，符合人类面向实际问题时的经验性思维与直觉推理的一般决策过程，是一种重要的机器学习模式[85]。强化学习系统由主体（agent）、状态（state）、行动（action）、回报（reward）和环境（environment）五部分组成，系统示意图如图9所示。系统旨在学习一个最优策略，让主体在环境中，根据当前的状态做出行动，从而获得最大回报。学习过程中，主体根据当前时刻（t）的状态$\\left( { { s } _ { t } } \\right)$ 和已获得的回报 $\\left( \\boldsymbol { r } _ { t } \\right)$ ，向环境发出以行动（ $\\left( a _ { t } \\right)$ 为形式的输出，环境则返回主体的新状态（ $s _ { t + 1 }$ ）与回报（ $r _ { t + 1 }$ )，依此不断反馈循环。",
    "context3": "![](images/d73af4e49dbb0efccc78059389ed31a50176a1e73dc647dc1c156fe3079e517d.jpg)  \n图9强化学习过程示意图",
    "context4": "为了将强化学习与序列生成模型训练结合，Ranzato 等[86]提出了一个评判模型（critic model），在基于RNN的序列生成任务中，通过加入额外的神经网络来预测预期回报和稳定目标函数梯度，相比于传统的监督学习方法，效果有了很大提升。Rennie等[87]在此基础上了设计了一个自我评判的序列训练方法（self-critical sequence training method）,使得效果进一步提升。Paulus等[88]将该方法应用于生成式自动文摘：在每训练完一次全样本后输出ys和 $\\hat { y }$ 两个序列，其中， $y ^ { \\mathrm { s } }$ 是由每时间步编码时的概率分布 $p \\left( y _ { t } ^ { s } | y _ { 1 } ^ { s } , \\cdots , y _ { t - 1 } ^ { s } , x \\right)$ 中采样（sample）得到的， $\\hat { y }$ 是直接用greedy search（贪心搜索）产生的基线（baseline）输出的，即通过最大化每时间步编码时的概率分布得到的输出；设输出序列 $y$ 的回报函数为 $r ( y )$ ， $y$ 与 ground truth 中的序列 $y ^ { * }$ 对比评价的度量公式为",
    "context5": "$$\nL _ { r l } = \\left( r \\left( \\hat { y } \\right) - r \\left( y ^ { s } \\right) \\right) \\sum _ { t = 1 } ^ { n ^ { \\prime } } \\log p \\left( y _ { t } ^ { s } | y _ { 1 } ^ { s } , \\cdots , y _ { t - 1 } ^ { s } , x \\right)\n$$",
    "context6": "由公式(10)可见，如果采样序列 $y ^ { \\mathrm { s } }$ 获得比基线序列 $\\hat { y }$ 更高的回报，则最小化 $L _ { r l }$ 值等价于最大化采样序列$y ^ { \\mathrm { s } }$ 的条件似然，从而增加了模型的回报期望。但这种强化训练目标的方法用于生成式自动文摘时也存在一个潜在问题，完全依靠ROUGE这类离散度量的评价指标并不能保证输出序列的质量和可读性[89]。因而在Paulus等[88]的研究中，将强化学习与语言模型的输出相结合，最终训练目标是最大似然与ROUGE指标的加权平均，即",
    "context7": "$$\nL _ { \\mathrm { m i x e d } } = \\gamma L _ { r l } + ( 1 - \\gamma ) L _ { m l }\n$$",
    "context8": "其中，y是衡量 $L _ { r l }$ 和 $L _ { m l }$ 之间大小差异的比例系数。$L _ { m l }$ 使模型生成的摘要语法正确、可读性强，而 $L _ { r l }$ 则降低了exposure bias 和增加了摘要的灵活性，同时也能直接提升模型的ROUGE评分。",
    "context9": "Keneshloo等[90]总结了一个融合自我评判（self-critical）和简单注意力机制（simple attention mecha-nism）的Seq2Seq通用模型。首先，将编码器的注意力值（attentionvalues）组合成上下文向量（con-text vector)；然后，在每个解码步骤中，计算解码器的上下文向量，并将其与解码器组合输出以获得行动的分布（actiondistribution）；接着，在生成模型中，进一步将注意力的分布（attentiondistribution）和行动的分布通过生成指针（generator-pointer）的切换（switch）进行组合，以获得在行动的最终分布；随后，针对每个输出，模型进行采样和选择贪心行动（greedyaction）；最后，结合样本创建采样和贪婪序列，并分别计算两者与ground-truth比较后的回报，利用两者的差值更新模型的loss值。",
    "context10": "Li等[9]则提出了一个融合行为-评判（Actor-Critic）的生成式自动文摘模型训练框架。Actor采用典型的Seq2Seq模型，编码器和解码器均为RNN的 GRU（gated recurrentunit，门控循环单元）结构[38]，并融合注意力机制增强解码性能[92]；Critic标准除了最大似然估计外，还设计了一种具有二分类神经网络结构的全局摘要质量估计器（globalsummaryqualityestimator）与之结合。在该框架中，首先预训练Actor，然后引人Actor-Critic交替训练方法进行参数学习，以实现对Actor和Critic进行联合优化，最后返回已训练的模型。设训练集 $T$ 中每个输入的序列 $X = \\{ x _ { 1 } , x _ { 2 } , \\cdots , x _ { m } \\}$ ，ground truth输出的序列 $Y = \\{ \\ : y _ { 1 } , y _ { 2 } , \\cdots , y _ { n } \\}$ ，生成的序列 $\\hat { Y } = \\{ \\hat { y } _ { 1 } , \\hat { y } _ { 2 } , \\cdots$ ，$\\hat { y } _ { n } \\}$ ；Actor记为 $G _ { \\theta }$ ，其中 $\\theta$ 为神经网络的参数；Critic$\\operatorname { I } ( C _ { I } )$ 为最大似然估计，其对数似然函数为 $V _ { \\theta } ( \\hat { Y } , X )$ ；Critic II $( C _ { U } )$ 是参数为 $\\phi$ 的二分类器 $V _ { \\phi } ( \\hat { Y } , X )$ ，并将ground truth 中的 $Y$ 作为正例，其损失函数为 $J \\left( \\cdot \\right)$ 。融合Actor-Critic 的模型训练框架的算法[91]描述如下：",
    "context11": "输入：参数 $\\theta$ 和 $\\phi$ ；训练集 $T$ ；Iteration数 $K _ { 1 }$ 、 $K _ { 2 }$ 和 $K _ { 3 }$ 输出：最优的摘要模型Model $( \\boldsymbol { \\theta } ^ { * } )$ 1: Initialization: 初始化 $\\theta$ 和 $\\phi$ 2:while Not Converged: 3:#使用CriticI预训练Actor； $\\alpha$ 为学习率",
    "context12": "4:for i in range $( 1 , K _ { 1 } )$ ：  \n5: $\\theta = \\theta - \\alpha _ { I } \\nabla V _ { \\theta } ( \\hat { Y } , X )$   \n6: end for  \n7: # Actor-Critic 训练  \n8: foriinrange $( 1 , K _ { 2 } )$ ：  \n9: #每 $K _ { 3 }$ 步进行一次Critic I优化  \n10: $i f i \\ \\% { \\cal K } _ { 3 } = 0 \\colon$   \n11: 从 $T$ 中采样 $( X , Y )$ 作为正例  \n12: 采样 $\\hat { Y } _ { \\sim } G _ { \\theta } ( \\cdot | X )$ 作为负例  \n13: 优化Critic II:  \n$\\phi = \\phi - \\alpha _ { \\phi } \\nabla J \\left( \\phi \\right)$   \n14: end $i f$   \n15: #交替训练:  \n16: 使用 Critic I训练 Actor:  \n$\\theta = \\theta - \\alpha _ { I } \\nabla V _ { \\theta } ( \\hat { Y } , X )$   \n17: 使用Critic II训练Actor:  \n$\\theta = \\theta - \\alpha _ { \\mathit { I I } } \\nabla J \\left( \\theta \\right)$   \n18:end for  \n19:end while  \n20:return Model( $\\boldsymbol { \\theta } ^ { * } = \\boldsymbol { \\theta } _ { * } ^ { * }$",
    "context13": "Chen 等[93]为了解决面向长文本时生成式摘要速度缓慢的问题（解码生成摘要时需要注意所有编码的词），设计了“抽取-生成式（Extractive－Abstrac-tive）”结构的模型，并采用强化学习算法将两种结构连接，如图10所示。抽取器（extractor）用于选取关键性的句子，生成器（abstractor）则对选取的句子进行重写（rewrite）后生成摘要。其中，抽取器主体（extractoragent）是一个编码器结构为$\\mathrm { C N N + }$ 双向RNN和解码器结构为RNN的 Seq2Seq模型，生成器采用Bahdanau 等[92]的模型，并加入 See等[94]的未登录词拷贝机制。强化学习过程中，对于第 $t$ 步的选取，主体根据当前的状态 $C _ { t } = ( D , d _ { j _ { t - 1 } } )$ ，通过 $p \\left( j _ { t } \\middle | j _ { 1 } , \\cdots j _ { t - 1 } \\right)$ 采样得到 $d _ { j _ { t } }$ 后生成句子 $g \\left( d _ { j _ { t } } \\right)$ ，在与 ground truth中的句子进行ROUGE评价后得到回报，最后采用异步优势的行为-评判（asynchro-nous advantage actor-critic，A3C）方法[95]，将其作用于 $t { + } 1$ 步的策略梯度的更新（policy gradient update）。模型训练时，如果抽取器选择了一个好句子，那么在生成器重写之后，ROUGE回报将很高，因此鼓励该行动；如果选择了一个不好的句子，尽管生成器仍然会对其压缩，但是与ground truth比较后的低回报将阻碍该行动。这种基于句子级强化学习的文摘模型由于并不改变生成器的语言模型，相比于单词级别的强化学习，所获得的摘要结果具有更好的语言流畅性。"
  }
}