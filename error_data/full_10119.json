{
  "original_filename": "full_10119.md",
  "面向学术文献的作者名消歧方法研究综述": {
    "context1": "沈喆王毅姚毅凡成颖21（南京大学信息管理学院南京210023）2（山东师范大学文学院 济南250014)",
    "context2": "摘要：【目的】分析并评述面向学术文献的作者名消歧的相关工作,为该领域的后续研究提供借鉴【文献范围】在Web of Science、谷歌学术、中国知网和万方数据库中检索2016年1月1日至2020年3月28日的相关研究，共选择51篇文献进行综述。【方法】以作者名消歧的流程为主线系统梳理各项研究成果,分类总结特征提取、特征表示以及模型训练与预测等主题的研究,并针对研究中的共性问题进行多维度的讨论。【结果】在特征表示方面,相较于2016年之前的研究,基于图、概率和混合模型的方法优化了复杂特征的相似度计算。在模型训练与预测方面,基于机器学习的算法仍需要提高效率与泛化能力,使其能够满足大型数据库和增量消歧的需求。多数研究尚未解决数据中存在的诸如训练数据不均、特征数据缺失、一人多名等问题。【局限】由于各项研究的实证数据差异较大,未能对不同方法进行量化比较。【结论】提出从多源数据融合、用户干预以及预训练模型的引入等视角开展后续研究的思路。",
    "context3": "关键词：作者名消歧姓名歧义重名消歧文献数据库分类号：TP393G250DOI:10.11925/infotech.2096-3467.2020.0384",
    "context4": "引用本文：沈喆，王毅，姚毅凡等.面向学术文献的作者名消歧方法研究综述[J].数据分析与知识发现, 2020,4(8):15-27.(Shen Zhe, Wang Yi, Yao Yifan,et al.Author Name Disambiguation Techniques for Academic Literature:A Review[J]. Data Analysis and Knowledge Discovery, 2020, 4(8): 15-27.)"
  },
  "1引言": {
    "context1": "数字图书馆规模的持续增长以及人才队伍的不断扩大有力地推动了文献资源的传播、共享与利用，同时也带来了较为严重的作者名歧义问题。学者完整、准确的学术成果集是文献计量与科学评价等的基础。对此，开放研究者与贡献者身份识别码（Open Researcherand Contributor ID,ORCID)[为追踪与记录个人的学术贡献、跨数据集消解姓名歧义等提供了可能的解决方案。不过,ORCID使用率较低的现状以及系统间数据接口不完善等使得姓名消歧（Author Name Disambiguation,AND)问题在短期内难以根本解决。学者个人主页数据的不完整或空白、更新不及时以及网页结构的异构性等降低了外源性数据的可用性。因此,在可预期的时间内AND仍将是一个需要持续研究的重要课题。",
    "context2": "目前，AND面临4个方面的挑战：一人多名（Synonyms）;一名多人（Homonyms）;元数据缺失或不完整;多作者、多学科以及跨机构的合作[2]。学界围绕AND已经形成了相当丰富的研究成果,并据此发表了多篇综述类文献。Smalheiser等[2]梳理了AND的部分方法;Elliott[3重点介绍了采用人工和机器学习方法的多项AND研究;Ferreira等[4从特征与算法维度构建了AND研究的分类框架并对部分典型案例进行了讨论;Hussain等[5借鉴Ferreira的工作，对2010\\~2016年的AND研究进行较为系统的梳理；付媛等[概括归纳了国内外的AND研究。这5项综述纳入的文献均发表于2016年之前。Sanyal等[7对截至2019年基于PubMed数据库的消歧方法进行评述,但仅聚焦于单一文献数据库;单嵩岩等[8]对AND中特征相似度计算方法的优缺点进行分析，未揭示该主题研究的全貌；Delgado等[9分别从特征、表示模型以及聚类算法等视角对网页人名消歧研究进行整理,工作集中于Web中的人名消歧问题。鉴于AND在图书情报学（Libraryand InformationScience,LIS)中的基础性价值,且近几年学界围绕该主题仍在持续不断地改进原有方法或提出新思路，成果丰硕，因此，有必要对2016年至今的面向学术文献的AND新进展进行系统归纳与提炼，为后续研究与应用提供参考或切入点。",
    "context3": "本文在WebofScience、谷歌学术、中国知网和万方数据库中进行了题名和主题检索，检索式中选用英文\"disambiguat\\*\"和中文“消歧”、“同名\"或\"重名”表达存在或消解歧义的含义，并使用英文“name”、“author\"和中文“作者”、“人名\"或\"姓名\"筛选应用领域,手工排除误检后，结合参考文献的浏览等方式进一步补充相关文献，最终纳入文献51篇，包括会议论文29篇，期刊论文22篇，其中开放存取论文6篇。如图1所示，鉴于大多数AND系统框架中均包括特征提取、特征表示以及模型训练与预测等模块,本文的组织以此为主线。",
    "context4": "![](images/2b7114b435c977bcf4dd89d93a5b30665ee67dcbf6e214efce233cc69fa5a7c6.jpg)  \n图1AND系统框架  \nFig.1General Framework for AND"
  },
  "2特征提取": {
    "context1": "AND研究中的特征主要来源于文献数据库中的元数据和外源性数据，后者典型的例子有科研机构、ResearchGate以及ORCID平台等提供的个人主页,以及搜索引擎的检索结果等。不过，,外源性数据的收集与处理存在诸多问题,如采集难度大、高声誉高产的学者拥有更多网页信息、单位变动导致同一作者有多个主页等,因此，现有AND研究中外源性数据仅起辅助作用。参考Delgado等[9]对特征的分类，本文将面向学术文献的AND特征分为作者特征、文献特征以及外部特征。图2展示了纳入研究中的特征分布情况。",
    "context2": "![](images/4a86b1fd139af9065ed9c131426a23ae54f97e46be468abd5170565820e7b274.jpg)  \n图2AND特征使用频率  \nFig.2Frequency of Features Used in AND"
  },
  "2.1作者特征": {
    "context1": "作者特征包括地址、邮箱、ORCID、各大数据库（如WOS、SCOPUS等)分配给作者的唯一标识码以",
    "context2": "及合作关系等。",
    "context3": "邮箱和作者ID具有精准识别的能力，可以快速过滤出同一作者。地址信息包含的机构实体能够辨"
  },
  "16 数据分析与知识发现": {
    "context1": "识不同单位的个体,但难以解决同一机构内的重名问题。有研究发现二级机构中重名的概率很低[10-13],采用逗号分隔符和\"大学、院系、实验室\"等模式从地址中提取一级和二级机构名的方法可以消解一级机构中的重名问题。",
    "context2": "合著关系是消歧的重要依据，大部分纳入研究使用了该特征,即通过一阶合作网络识别作者实体;部分研究将合著关系扩展到二阶[14-21]。将合著特征应用于AND的研究均默认一个假设，即二元组（合著者,待消歧作者)同时出现重名的概率极低。不过,考虑到大型文献数据库中作者的数据集庞大，该假设是否鲁棒有待进一步实证检验。"
  },
  "2.2文献特征": {
    "context1": "文献特征包括标题、关键词、摘要、全文、出版物、学科分类、引文列表和发表时间等。",
    "context2": "学术数据库使用的学科分类体系是研究领域粗粒度的描述,在AND中使用较少;学者们更多地以出版物名表征作者的投稿偏好和研究领域。例如，Shen等[21]利用标注数据采集涉及某一领域的出版物集合,将其人工标注为单一或多领域,以评估将出版物的领域特征用于消歧的置信度。相比出版物的领域特征,标题、关键词和摘要信息能提供更详细的内容和作者的研究兴趣信息，并能挖掘出更多隐含的语义关联。其中，摘要在AND研究中更受重视，原因在于摘要简明、确切地记述了文献的主要内容,篇幅多在400字左右[22],且现有的WOS等引文以及全文数据库均可便捷地获取。",
    "context3": "纳入研究中，全文特征的应用仅见于Han等[23]和Li等[24的工作,前者采用全文中实词的TF-IDF生成语义指纹以描绘作者的研究领域和写作风格，后者通过虚词的词频分布描述作者的写作习惯,实证结果表明实词与虚词特征均具有一定的区分度。引文信息对于AND也有一定的价值。例如，自引[25]现象可以反映同一作者连贯递进的研究内容;引文耦合关系[26-27]可以判断文献所属研究领域是否相似；引文作者间的合著关系也吸引了研究者的注意[28-30] 。",
    "context4": "部分研究将作者特征中的地址信息以及文献特征中的发表时间信息相结合,用于解决作者的机构变动问题。例如，刘林[15]认为在一段时间内作者的单位会相对稳定,因而从文献发表时间的间隔可计算作者的科研活跃区间,进而排除该区间内大范围重叠的不同单位的同名作者，不过仅能达到部分过滤效果。"
  },
  "2.3外部特征": {
    "context1": "除文献数据库的元数据外，不同渠道的作者个人主页中包含的学术成果列表可为AND提供部分标注数据,可据此生成作者实体的特征集合，并通过定期爬取实现持续更新[15]。这些数据可用于机器学习算法的训练、优化[31]以及消歧结果的修正等[28.30],有助于解决部分跨学科研究对AND造成的误检、漏检等问题。鉴于个人主页数据难以满足消歧的需求，Abdulhayoglu等[26]还收集了来自搜索引擎返回的结果页，从中提取出文献在网页中的共现信息。考虑到网页结构的复杂性且存在大量歧义,该特征的提取对网页解析技术和检索策略均提出更高的要求。"
  },
  "3特征表示": {
    "context1": "特征提取之后，需要使用表示模型将特征转换为便于复杂计算或推理的数学形式,Huang等[32]根据表示模型的数学理论基础,将其分为基于集合论、代数、概率、图结构以及混合方法等5种。"
  },
  "3.1集合论模型": {
    "context1": "该模型将特征表示成单词或字符的集合。对于邮箱、ID以及时间等具有固定格式的特征，可使用布尔逻辑判断特征是否一致。对于普通文本则依据共现的单词或字符数计算特征相似度,前者主要有Jaccard 系数[3]、N-gram[26.34]、Sorensen Dice系数[35],后者主要有Jaro-Winkler相似度[13.26]、Hamming 距离[23]以及Ratcliff/Obershelp模式识别[14]。部分研究对于机构名的相似度判断采用布尔逻辑运算[10,12.23],也有研究考虑到机构名普遍存在的缩写、略写以及顺序等问题而采用文本相似度以提高召回率。例如,Zhang等[36]对编辑距离进行优化，采用1-编辑距离/最长字符串算法;Zhang等[\"]将机构名分词为单词集,通过两两配对计算编辑距离,分别为完全相同和部分相同的单词赋予不同的权重，采用加总后的得分反映机构名的相似度,该方法结合了基于单词和字符的两种方法，增强了算法对不同拼写形式的同一机构实体的识别能力。"
  },
  "3.2代数模型": {
    "context1": "该模型以向量或矩阵的形式表示特征。基于TF-IDF的向量空间模型[23.28]是经典的文本特征转换为向量的方法,但与One-Hot编码[37-39]一样存在高维稀疏的缺点。主要的降维方法有基于矩阵分解的潜在语义索引模型(Latent Semantic Indexing,LSI)[40]、包含更多语义信息的语义指纹[23.41]以及Word2Vec[42-45]和 $\\mathrm { D o c } 2 \\mathrm { V e c } ^ { [ 4 6 - 4 8 ] }$ 等词嵌入模型。训练语料的质量在很大程度上能够影响词嵌入模型的性能，多数研究使用文献特征进行训练,少量研究也使用外源性数据,如Muller[34的待消歧语料是DBLP子集，在包括网页、DBLP全集、微软学术和DBLP全集 $+$ 微软学术这4个数据集上的训练结果显示仅采用DBLP全集的F值最优,不过,将网页、DBLP全集和微软学术三者独立训练后进行拼接的F值表现则优于DBLP全集。",
    "context2": "代数模型常用余弦相似度计算向量相似度，但同一特征使用不同表示模型得到的相似度排序结果存在差异，如共现词较多的两个文本使用词向量计算相似度可能低于基于字符的结果,仅少量研究关注了两者的平衡。例如,Lin等[39计算了新文献与候选文献簇标题的Jaccard系数、余弦相似度和欧氏距离,对于每一簇都根据三种相似度排序结果的置信度选择最优的聚类;Chen等[45]则将两篇文献的某一特征分词后,形成由单词对构成的词向量相似度矩阵,使用RBF核函数将矩阵的每一行转换为特征向量，再将各行的向量求和,该方法综合了单词的精确匹配和语义匹配,取得了较优的消歧效果。"
  },
  "3.3概率模型": {
    "context1": "该模型使用特征共现的频率刻画对象间的关联强度,部分研究[27,29.49]使用条件概率 $\\mathrm { P } ( C _ { 1 } | C _ { 2 } )$ 而非联合概率 $\\mathrm { P } \\left( C _ { 1 } | C _ { 2 } \\right) \\times \\mathrm { P } \\left( C _ { 2 } \\right)$ ，原因在于Backes[29]发现后者会导致马太效应,即如果簇间规模不均衡，则后者易于将样本归并至规模比较大的簇,而前者则较少受到簇规模的影响。为进一步平衡数据不均的问题,Santana等[50]赋予了常用特征词和大规模簇更低的权值。",
    "context2": "对于文本中隐含的语义信息，学界采用多种更复杂的概率表示方法。使用LDA模型输出的主题词概率分布作为待消歧文献的特征表示[51],依据已知作者所有文献的主题分布生成代表该作者的聚类中心。Amplayo等[52]扩展了LDA模型使其能够区分一词多义的情况。Ding等[13]使用聚类方法划分研究领域的类别后,对单篇文献,将标题和摘要进行分词,分别计算每个词与各聚核的相似度并排序,将词的簇间区分度乘以簇相似度，并汇总以计算文献属于不同研究主题的概率;对于作者的文献集,类似地可以计算出作者涉入不同研究主题的概率,将前两者主题共现的概率乘积之和作为文献归属于该作者的概率。"
  },
  "3.4图结构模型": {
    "context1": "该模型在AND中通常以作者或文献为节点，根据合著、引用以及隶属等关系构建边，以关系出现的次数作为边的权重。其中，合著是最常用的关系，不过,该关系不能识别无合著者或合著频率低的文献,也存在少量合著者重名的现象。研究中，学者们采用多个特征对边进行剪枝[28],或使用特征共现相似度建立多特征网络[30]或异构网络[12,47-48]。",
    "context2": "异构网络可以反映节点间由多种关系构成的关联,描述的方法是元路径[47-48]。具体而言，异构网络$G$ 的网络模式为 $\\mathrm { T } _ { \\mathrm { \\it G } } = ( N , R )$ ,其中， $N$ 是节点类型的集合，包括文献 $( D )$ 、作者 $\\left( \\boldsymbol { A } \\right)$ 、出版物 $( V )$ 等； $R$ 是关系类型的集合，包括撰写/被撰写 $( W R / - W R )$ ）、发表/被发表 $( P U / - P U )$ 以及引用/被引用 $( C I / - C I )$ 等。元路径可定义为 $N _ { 1 } { \\xrightarrow { \\quad R _ { 1 } } } N _ { 2 } { \\xrightarrow { \\quad R _ { 2 } \\quad } } \\cdots { \\xrightarrow { \\quad R _ { i + 1 } \\quad } } N _ { i }$ 如$a _ { 1 } \\xrightarrow { \\scriptscriptstyle { \\it \\# R a _ { 1 } d _ { 1 } } } \\mathcal { d } _ { 1 } \\xrightarrow { \\scriptscriptstyle { \\it \\# P U d _ { 1 } \\nu _ { 1 } } } \\nu _ { 1 } \\xrightarrow { \\scriptscriptstyle { \\it \\# P U \\nu _ { 1 } d _ { 2 } } } d _ { 2 } \\xrightarrow { \\scriptscriptstyle { \\it \\# R d _ { 2 } a _ { 2 } } } a _ { 2 }$ 描述了作者 $a _ { 1 } , a _ { 2 }$ 撰写的论著发表于同一出版物的关系，是 ${ \\cal A } \\xrightarrow { \\quad \\psi _ { R } ^ { R }  D \\mathrm { ~ } \\xrightarrow { - P U } \\gamma V \\xrightarrow { P U } D \\xrightarrow { - W R } \\gamma A }$ 这一元路径的实例。元路径可以反映的相似性有两种：当开始节点和结束节点类型相同时两者的相似性;当开始节点和结束节点间存在多条同一元路径实例时,路径经过的中间节点的相似性。"
  },
  "3.5混合模型": {
    "context1": "该模型在AND中多综合了代数和图结构模型，即采用表示学习等方法将节点和边表示为低维向量。在经典的图模型中，节点多表示为高维的稀疏向量，牺牲了网络的时空复杂度;随着数据集规模的扩大,节点间的关系也呈指数级递增,使得在整个网络上的推理难以进行。对此,学者们提出采用网络表示学习将网络中的节点转换为低维向量表示的思路。网络表示学习,也称为网络嵌入方法,其核心思想是找到一种映射函数，在降低节点表示复杂度的同时不影响节点间的相似度计算。该方法已成为近几年AND研究中的热点，其中，成对似然排序备受关注[16,19.31,47,53-55]，部分研究也使用了DeepWalk、Node2Vec以及图卷积方法。",
    "context2": "以文献相似性网络为例,成对似然排序中的节点向量表示 $( \\overrightarrow { d } _ { i } , \\overrightarrow { d } _ { j } , \\overrightarrow { d } _ { t } )$ 要使得在节点三元组$( d _ { i } , d _ { j } , d _ { t } )$ 中,节点对间的相似度排序满足基本假设“有连接边的节点间相似度大于无连接者”,即如果节点 $d _ { i }$ 与 $d _ { j }$ 有边相连，而与 $d _ { t }$ 无边相连，则$S \\left( d _ { i } , d _ { j } \\right) > S \\left( d _ { i } , d _ { t } \\right)$ ,其概率的表示如公式(1)所示。",
    "context3": "$$\n\\begin{array} { r l } & { P \\left[ S ( d _ { i } , d _ { j } ) > S ( d _ { i } , d _ { t } ) | \\vec { d } _ { i } , \\vec { d } _ { j } , \\vec { d } _ { t } \\right] } \\\\ & { = s i g m o i d \\left( S ( d _ { i } , d _ { j } , d _ { t } ) \\right) } \\\\ & { = s i g m o i d \\left( \\vec { d } _ { i } { \\cdot } \\vec { d } _ { j } \\right) - ( \\vec { d } _ { i } { \\cdot } \\vec { d } _ { t } ) } \\end{array}\n$$",
    "context4": "图中所有点的向量表示可构成矩阵 $\\pmb { D }$ ,遍历图中所有邻接的节点对集合 $P G _ { d d }$ 和非邻接的节点对集合 $N G _ { d d }$ ,可得所有节点对排序正确的概率为$P ( { \\bf \\theta } > | { \\bf D } )$ ,如公式(2)所示，连乘每一个节点三元组排序正确的概率即公式(1)所得的计算结果,得到的值越大，则越能准确地反映整个网络图中的节点关系。",
    "context5": "$$\n\\begin{array} { r l } & { \\prod _ { ( \\vec { d } _ { i } , \\vec { d } _ { j } ) \\in P G _ { d d } , ( \\vec { d } _ { i } , \\vec { d } _ { t } ) \\in N G _ { d d } } P \\left[ S \\left( d _ { i } , d _ { j } \\right) > S \\left( d _ { i } , d _ { t } \\right) | \\vec { d } _ { i } , \\vec { d } _ { j } , \\vec { d } _ { t } \\right] } \\\\ & { = \\prod _ { ( \\vec { d } _ { i } , \\vec { d } _ { j } ) \\in P G _ { d d } , ( \\vec { d } _ { i } , \\vec { d } _ { t } ) \\in N G _ { d d } } { S i g m o i d } \\left( \\vec { d } _ { i } { \\cdot } \\vec { d } _ { j } \\right) - \\mathinner { ( \\vec { d } _ { i } { \\cdot } \\vec { d } _ { t } ) } } \\end{array}\n$$",
    "context6": "为了求解公式(2)中的向量表示，须设立排序正确概率最大化的目标函数，并转化为求负对数似然函数的最小化以便计算,如公式(3)所示。在求解过程中常用随机梯度下降法，通过迭代更新参数，以得到最优的向量表示。$\\begin{array} { l } { { \\displaystyle O B J { = } \\mathrm { M i n } \\left( - \\ln P ( > | D ) \\right) } \\ ~ } \\\\ { { \\displaystyle { = } \\mathrm { M i n } \\left( - \\sum _ { ( \\vec { d } _ { i } , \\vec { d } _ { j } ) \\in P G _ { d d ^ { * } } ( \\vec { d } _ { i } , \\vec { d } _ { t } ) \\in N G _ { d d } } \\ln \\left( s i g m o i d \\left( \\vec { d } _ { i } { \\cdot } \\vec { d } _ { j } \\right) { - } ( \\vec { d } _ { i } { \\cdot } \\vec { d } _ { t } ) \\right) \\right) } } \\end{array}$",
    "context7": "DeepWalk[17-18]以及通过Node2Vec改进的DeepWalk算法[46]等的基本思路是将自然语言处理中的词向量模型迁移到网络表示。具体做法是将单词当作网络节点,利用随机游走或改进的采样方法采集节点构成序列,节点序列构成词向量模型中的句子。词向量模型的目标函数是预测目标词在其上下文出现的概率。类似地，在网络中当已知$( d _ { 1 } , d _ { 2 } , \\cdots , d _ { i - 1 } )$ 的游走路径后，须计算下一个节点是 $d _ { i }$ 的概率,其目标函数是最大化相近节点的共现概率 $P ( d _ { i } | d _ { 1 } , d _ { 2 } , \\cdots , d _ { i - 1 } )$",
    "context8": "图卷积网 络（Graph Convolutional Network,GCN)基于网络 $G = ( F , A )$ 生成节点向量表示[42.48.56],其中， $F$ 是节点的特征表示， $\\pmb { A }$ 是网络结构的邻接矩阵。GCN的目标是使节点向量得出的邻接矩阵 $A ^ { \\prime }$ 与原矩阵 $\\pmb { A }$ 的差异最小。现有研究通常采用两层GCN模型,代表与目标节点一阶和二阶相连的图结构，上一层的输出为下一层的输人。Qiao等[48将该方法应用于单类型节点、多类型关系的异构网络,使用元路径寻找不同关系类型相连的边节点。",
    "context9": "考虑到上述方法各自的优势，余传明等[18]综合采用多种网络表示方法,分别得到文献和作者的表示向量，并用其初始化成对相似性排序模型中的表示向量，通过对后者的训练得到最终的文献节点表示。使用单一方法在多个网络学习到同一对象的不同表示后，涉及如何融合的问题,有学者将不同网络目标函数的加权和作为融合后的目标函数，重新训练后得到最终的向量表示[31.4-55]。Wang等[46]则引人对抗生成网络,融合两种嵌入表示向量,通过生成器和判别器的相互训练使生成器尽可能找到真实的样本，最终使得综合向量表示反映出的相似度排序接近真实情况。"
  },
  "4模型训练与预测": {
    "context1": "特征表示提供了可进行复杂处理的数学形式，模型训练与预测将完成待消歧文献作者实体的识别。Ferreira等[4]归纳了两种实现思路，一是分组（Grouping）,依据共性特征归并事先未知的作者实体文献集;二是指派(Assignment),根据特征相似度将文献指派给已知的实体，该方法所需人工标注工作量很大，现有AND研究多集中于分组方法。参照文献［5,7]对AND算法的分类,本文将消歧方法分为基于机器学习、基于图和基于启发式规则三类。"
  },
  "4.1基于机器学习": {
    "context1": "基于机器学习的方法可以分为有监督学习或无",
    "context2": "监督学习两类。",
    "context3": "有监督学习方法有两种应用方式。一是用于分组,即训练二元分类器判断两篇文献是否由同一作者完成,常用算法包括神经网络[34]、随机森林[49]、朴素贝叶斯[24.27]等,研究显示多特征模型相较于单特征有更强的判断能力。针对学术文献数据库中较为普遍的数据缺失问题,柯昊等[10]提出了特征对于重名辨识的贡献度评价体系,即在训练集上训练BP神经网络，得到在不同数据缺失情况下特征的权值，提升了模型的判断能力。二是用于指派,即分类模型基于完备的已知作者实体集,对于新增文献准确指派其作者归属[57]。有监督方法存在一些有待改进之处,如消歧效果很大程度上依赖于标注数据的质量，而标注数据多源于作者ID的检索结果或个人主页等外部数据,通常仅涵盖了作者的部分成果;其他还包括忽略训练数据分布不均等，如负例数据量常远大于正例,其结果只能增加计算量却没有显著提升消歧性能[58]。",
    "context4": "鉴于有监督学习方法的诸多不足，在AND研究中，无监督学习方法更为常见。层次凝聚聚类（Hierarchical Agglomerative Clustering,HAC）是最常用的聚类算法[1-18,46-47,56],相比于K-means算法,该算法无需明确初始聚类点和聚类数 $K$ ，避免了局部最优的问题。HAC的难点在于如何确定聚类结束的条件,多数研究仅设定了一个相似度阈值，即当簇间距离均低于阈值时停止。此外,部分研究还提出其他思路，如Protasiewicz等[40]提出使用时部法则确定 $C$ 值的最佳阈值,如公式(4)所示。",
    "context5": "$$\nC _ { i n d e x } = \\frac { C _ { d } - C _ { m i n } } { C _ { m a x } - C _ { m i n } }\n$$",
    "context6": "其中, $C _ { d }$ 是簇内所有文献的距离和; $C _ { m a x }$ 和 $C _ { m i n }$ 是簇内距离的极大值和极小值，当 $C$ 值低于阈值时算法停止。肘部法则确定阈值需要多次迭代,对不同数据集的泛化能力较弱。Zhang等[42]基于用户干预的标注数据，训练循环神经网络(RecurrentNeuralNetwork,RNN)模型以估计不同数据规模时的合适聚类数,较X-means缩小了误差。Qiao等[48]在图结构中进行层次凝聚聚类，边的构建及其权重根据网络表示结果的相似度计算，当簇间没有边相连时聚类停止，最佳聚类为 $M$ 值最大时的结果。M值的计",
    "context7": "算如公式(5)所示。",
    "context8": "$$\nM = \\frac { 1 } { 2 m } \\sum _ { n _ { i } , n _ { j } \\in N } \\left| \\left| e _ { i j } \\right| - \\frac { w _ { i } w _ { j } } { 2 m } \\right| b o o l e a n { ( C _ { i } = C _ { j } ) }\n$$",
    "context9": "其中， $m = { \\frac { 1 } { 2 } } \\sum _ { n _ { i } , n _ { j } \\in N } { \\bigg | } e _ { i , j } { \\bigg | }$ 是网络图中所有边权重的和， $w _ { i }$ 是连接节点 $i$ 所有边的权重和, $C _ { i }$ 是节点 $i$ 所属的簇。",
    "context10": "除层次聚类外， $\\mathbf { A P }$ (Affinity Propagation）聚类也不需要给定初始聚类数，在AND研究中也受到了关注。Yu等[19]使用网络表示向量的欧氏距离矩阵S作为AP算法的相似度依据,通过迭代计算每篇文献的吸引度 $r ( i , k )$ （即点 $k$ 适合作为数据点i的聚类中心的程度)以及归属度 $a ( i , k )$ （即点 $i$ 选择点 $k$ 作为其聚类中心的适合程度),直到产生 $n$ 个吸引度和归属度均稳定的高质量聚核，然后将数据聚类到相应的簇中。 $\\mathrm { X u }$ 等[54]分别运行HDBSCAN和AP算法，计算基于平均分散度和总体分离度的聚类有效性指标SD值[59],在二者中选择SD值表现更优的聚类结果。AP算法具有准确率高、鲁棒性强等优点，也具有时间复杂度高的缺点。个别研究[44]使用谱聚类算法，实证结果显示虽然该算法的时间复杂度较低,但聚类效果亦欠佳。",
    "context11": "当使用单个或少量特征聚类时会降低准确率，Zhang等[36]和Lin等[39]使用基于规则的方法对聚类结果进行优化;Peng等[31将标注数据分为关联文献集合和不相关文献集合，在运行K-means算法时，约定初始节点不能从关联集合中选择，簇归并时不能包含不相关文献对。使用多特征聚类时，为避免过度分裂,则需要判断不同特征的重要性,有研究在少量标注数据中训练逻辑回归分类器,以确定不同特征的区分能力[29.40]； $\\mathrm { X u }$ 等[35]基于每个特征都完成一次聚类，基于F1值占比赋予每个特征不同权重后再完成聚类。"
  },
  "4.2基于图": {
    "context1": "使用图表示文献特征后，常基于图中的路径识别同一作者实体。Momeni等[0]以文献为节点,以作者列表的共现关系建立边，计算文献间的最短路径，如果节点间的最短路径低于阈值,则认为是同一作者。尚玉玲等[12]在作者合著及机构隶属关系的异构网络中,计算作者节点间的所有有效路径[6]的连接强度之和，根据强度之和是否大于阈值判断是否为同一人,强度的计算方法为路径概率与路径权重的乘积。有两项研究采用机器学习模型[26.34],训练二分类器决定文献节点是否相似,进而根据判断结果决定网络中边的连接,最后使用连通分量将有边相连的节点归为同一作者。",
    "context2": "除了使用边关系作为划分依据之外,Franzoni等[62]使用网络拓扑结构中的共有邻居节点数（Neighborhood Counting,CN）、Adamic-Adar(AA)以及点互信息（Pointwise Mutual Information,PMI)等指标，结果证实三个指标均能识别出结构相似的同一作者实体。Ding等[13]使用概率图模型,在基于作者共现的文献网络中，文献节点具有属于不同作者的概率分布信息,根据最大后验概率推理节点所属作者,该模型的优势在于当确定某一节点的作者后，会正向影响与其相连节点的推理过程。"
  },
  "4.3基于启发式规则": {
    "context1": "启发式规则又称捷径法、经验法则或基于观察的方法。当处理海量信息时，机器学习算法和基于图的算法的时间复杂度通常较高，此时，基于规则的算法则凸显出高效的优势。",
    "context2": "规则的制定需要人工确定处理顺序的优先级以及合理的特征组合，刘林[15]确定的判断顺序是作者机构活跃时间 合著者 研究主题,并为每个特征设定阈值。与上述方法不同,Hazra等[14]也利用文献发表时间窗辅助消歧，但没有使用机构进行限制，即认为不同机构的同一实体,其研究高峰年以及活跃区间可以相似。另外,研究兴趣也被作为区分不同作者的有效特征,Katsurai等[51]将未知文献的研究领域与已知作者文献集的研究兴趣中心进行比较;Sun等[43]认为在细分领域下作者重名的可能性很小,使用两次聚类细化研究领域的描述，将其作为区分不同作者的主要依据。基于规则的方法需要解决的一个重要问题是阈值的设定，现有研究多通过观察已消歧数据得到经验值。",
    "context3": "启发式方法在取得高准确率的同时牺牲了召回率,因而其常用于数据的初步筛选,获得训练机器学习算法的标注数据，少数研究使用启发式方法弥补其他算法容易忽略的问题。Zhang等[3发现使用RNN估计聚类数[42]导致识别作者数少于实际的问题,从而使用基于规则的方法优化消歧结果,对于已识别作者文献集按照规则重新分类与合并,以纠正初始分类的错误。Hussain等[33]针对合著关系无法识别单作者和合著强度低的文献的离群点问题,在基于合著关系的划分后，使用摘要相似度将离群点合并至最相似的簇。启发式方法对特征提取和表示提出了更高的要求，在近几年的AND研究中多起辅助作用。"
  },
  "5讨论": {
    "context1": "本文根据AND流程梳理了各阶段采用的主要方法及进展,具体到各项研究,本文整理了纳入研究的主要技术环节、实验数据来源和消歧表现评估（评测指标摘自原始研究,指标的具体涵义见文献[7]),依据整理结果(见支撑数据[2])所展现的近几年研究的全貌以及与2016年之前研究工作[5的纵向比较,本文将对研究中共性的语言影响、特征提取、网络表示学习、增量消歧、模型推广以及时间复杂度等问题进行讨论。"
  },
  "5.1语言影响": {
    "context1": "综合各项研究可以发现,数据集的语言差异对消歧效果有很大影响。中文、日文、意大利语以及葡萄牙语等较英文有更好的表现。本文通过对比不同语种的测试数据集发现的一个可能原因是，对英文姓名而言，一名多人对应的数据子集的平均数据量高于其他语种。",
    "context2": "除常用名的问题外，一人多名的情况常出现在国内作者使用英文名发表学术成果的时候，主要原因有拼写不规范、复姓、双名连写、多音字等造成的中文姓名英译问题[63]。一次仅解决一个名字的歧义消解策略是降低计算量的通用方法，多项研究使用全名拼写的形式对数据进行划分，导致初始待消歧集合排除了作者姓名的变体;使用名字首字母缩写的形式能够提高召回率,但同时也使得候选数据量显著提升，应用在大型数据库时运行速度过慢是可预见的表现。对此,Hussain等[25.33使用名字的相似度进行划分；也有研究[6465]考虑了中文名音译时的排序和缩写规则;Kim等[6针对英文名，结合机器学习方法和合取范式的思想,使用多特征的组合构建筛选规则进行数据分区。总的来说，现有研究对该问题关注仍然不足,值得后续研究跟进。",
    "context3": "另外，一人多名对消歧方法的评估结果造成的影响还未得到重视，现有研究多在一个姓名数据分块内计算评价指标,缺失了分块间的部分一人多名数据,影响了算法优劣的评判。后续研究应对方法评估做出改进,基于整体数据评估召回率。"
  },
  "5.2特征提取": {
    "context1": "由于单特征对消歧贡献有限,多数研究采用作者和文献特征相互补充的方法，以提高消歧能力。现有研究选取特征并判断其重要性的依据有两点，一是特征的易获取性,如作者ID和邮箱虽提供了准确且稳定的信息，但数据缺失严重，非第一作者尤甚,因此难以成为消歧主要依据的特征;二是特征包含信息的丰富性，因作者、引文列表可以提取出科研合作和交流中的复杂关联，在多数研究中得到广泛应用,并向更深和更多元的方向拓展,如引文作者网络、异构网络中的元路径等。相较于以往研究,文本语义层面的信息被更多地关注和利用,学者们对研究主题和作者的研究兴趣进行更准确和细致的刻画,并赋予高于机构、期刊信息的权重或优先级,使消歧更接近人工判断同名作者文献的过程。",
    "context2": "需要指出的是，现有研究对特征的稳定性重视不够,如科研人员学习和工作单位的变动、跨学科研究的趋势渐强等。对此,现有特征只能辅助过滤，不能解决特征明显不同时的合并问题。选用更多的特征和外部数据是一种有效的解决方法，更关键的是对于时间特征的利用不宜仅停留在活跃时间是否重叠等浅层应用。由于多数特征在短时间内是稳定的,即使发生变动,部分特征也会存在关联,因此按时间顺序宜避免长时间跨度的比较,从而减轻信息变动较大造成的错误结果。"
  },
  "5.3网络表示学习": {
    "context1": "关系网络是消歧方法的重要依据。网络表示学习在近几年的消歧研究中得到广泛应用,同时其思想也影响了其他方法。例如，Chen等[45]没有依托网络结构，在比较待消歧文献与某作者文献集合时，借鉴了成对似然排序的方法，用于扩大不同作者间的相似度。",
    "context2": "网络表示模型的学习结果主要受三方面因素的影响。一是网络的构建,网络结构是得到准确结果的基础。现有研究建立多特征尤其是文本特征网络时,都是基于字符的简单共现关系,存在忽略潜在语义关联的可能。另外，异构网络元路径可以描绘节点间多类型关系构成的序列,其复杂关系可以通过网络表示学习进行降维,其中关键点是在不增加计算复杂度的前提下,选择元路径找到更多有关联的节点。二是节点的初始化表示,部分研究[17.47-48]使用文本词向量作为网络节点的初始表示;Zhang等[42]和Kim等[53]先在所有数据中学习不同名字特征的差异,后在单个名字构成的关系网络中再学习其中的细微差异;还有研究[31,54-55]通过将点度小的节点归并至邻接的点度大的节点，以更优地获取网络的全局信息。上述研究表明,初始节点的表示可在全局中训练得到,能够提升网络表示学习的效果。三是算法的选择和参数的设置，就评测表现而言，两层GCN的方法[48.56]表现更优,另外,根据网络的特点选择合适的表示模型也具有可行性。总体来看，提升性能的关键在于参数的合理设置,表示向量的维度需要根据数据规模和网络特点设定，避免过高的维数导致计算复杂度过高，以及过低的维数使得学习不充分。"
  },
  "5.4增量消歧": {
    "context1": "Hussain等[5提出增量消歧的难点在于每当新增一篇文献后，即需对数据和模型进行更新，对大型数据库造成了巨大的计算负担。现有研究充分关注了该问题,在保证方法有效的同时,也注重算法的简洁性,使其适用于大型文献数据库的应用场景。例如,Hussain等[25]和Zhao等[27]将已消歧作者的所有文献特征构成个人信息集，使用更新信息集合的方式降低计算量;Chen等[45]同样构建了作者信息集，为了降低信息集中不相关文献的影响而引入注意力机制;Santana等[50]使用更新待确认文献集的方式使初始作者分类随着新文献的进入逐渐优化，在识别新作者的同时,减少错误和过度分类。概率模型结合机器学习的方法也取得了效率和性能均衡的较好表现,Zhang等[37-38]使用的狄利克雷混合过程模型允许聚类中的类别数随着新数据的进入而变化，将增量消歧转换成一个“中餐馆过程”67],大幅提高了处理大规模数据的效率。",
    "context2": "目前，增量消歧的大多数解决方案很大程度上也依赖于标注数据的规模和质量，对新文献的判断能力随着数据库消歧系统的完善、已消歧数据的积累才能逐步提高。因此,除了算法的创新,学者们开始注重人工干预的作用[21,42,45,68]。 文献数据库作为科研人员常用的检索平台，通过用户群体干预消歧结果能够获得标注数据数量和质量的大幅提升。同时，随着姓名歧义问题已经引起了学界重视，有更多标注了作者唯一身份信息的新文献进入文献数据库，使用半监督学习方法的消歧也是一种可行的思路。"
  },
  "5.5模型推广": {
    "context1": "现有的实证研究多基于AMiner、DBLP、CiteSeerX、BDBComp等数据库。Muller等[9]发现上述数据库提供的已消歧数据存在一些共性问题，如以作者为中心集成的数据不全、仅识别了少量的一人多名情况和单个作者文献，从而导致训练数据不均匀,以及训练得到的模型偏向于识别高产作者等问题。",
    "context2": "除数据本身的问题之外，这些数据库大多仅涵盖计算机、信息科学领域的研究成果，应用于大型综合数据集(如WebofScience)的相关研究较少。部分研究发现推广算法时泛化能力不够理想，如在不同数据库上的表现有较大差距[18.37,5-54]。导致上述现象的可能原因有两点，一是不同学科领域引起的数据差异,如计算机学科、化学等细分领域下的专业术语相较于管理学科等更具辨识度;二是数据规模的不同,影响算法表现的关键因素是参数的设定，应用至不同规模数据集时需要动态修改参数以取得最优表现。"
  },
  "5.6时间复杂度": {
    "context1": "时间复杂度是评价消歧算法的重要指标，尤其当面对大型数据库和增量消歧等应用需求时更是如此。影响时间复杂度的因素可归纳为三点：一是数据的规模,涉及上文提及的数据分区方法，以及增量消歧对候选集的选择和数据更新的规模和频率；二是模型的复杂程度，现有研究常融合词向量模型、网络表示模型和机器学习方法，多模型的训练过程也使得整体运行速度下降;三是处理流程的设计，目前学界对该问题的关注较少,Tang等[70]采用并行处理方法降低了大型数据和复杂问题的处理时间，但对计算机性能提出更高的要求。现有研究显示，最常用的HAC聚类方法的时间复杂度最高，其后依次是AP、DBSCAN以及谱聚类等。Qiao等[48]使用图结构避免无邻接边的节点参加比较，显著提高了HAC的时间效率。另外，基于概率的狄利克雷混合模型聚类算法在增量消歧中的表现更优,其时间复杂度为$O ( n )$ ,值得深入探究。"
  },
  "6结论": {
    "context1": "不同于基于模型分类的综述框架[5.7],本文根据消歧流程深入剖析了AND的新近研究，得到以下结论。",
    "context2": "(1)相较于2016年以前的工作，学者们对特征表示提出诸多改进,其中网络表示学习、异构网络元路径和概率模型备受青睐。",
    "context3": "(2)现有模型仍以机器学习算法为主，重点在于优化聚类算法效率，提高泛化能力，以使其能够满足大型数据库和增量消歧的需求。",
    "context4": "(3)多数研究尚未解决数据中存在的问题,包括训练数据不均、特征数据缺失、一人多名等。",
    "context5": "面向大型学术文献数据库，后续的AND研究宜从多源数据融合、引入预训练模型、用户干预等视角进行整合研究。例如，从数据源角度，可以针对DBLP、Scopus以及PubMed等异源元数据，利用语义网技术进行融合，以获取更全面的特征；从模型角度，可以引入诸如BERT等前沿的预训练模型作为特征表示的基础或以此为基础构建消歧模型;从用户干预角度,可采用弱监督或半监督等人工干预的方法，从源头上控制歧义。"
  },
  "参考文献：": {
    "context1": "[1]Haak L L,Fenner M,Paglione L,et al.ORCID:A System to Uniquely Identify Researchers[J].Learned Publishing,2012,25 (4): 259-264.   \n[2] Smalheiser N R,Torvik V I.Author Name Disambiguation[J]. Annual Review of Information Science & Technology,2009,43 (1):1-43.   \n[3] Elliot S.Survey of Author Name Disambiguation: 2004 to 2010[J/ OL].Library Philosophy and Practice.[2020-04-10].https:// digitalcommons.unl.edu/libphilprac/443/.   \n[4] Ferreira AA,Gongalves MA,LaenderAHF.ABrief Survey of Automatic Methods for Author Name Disambiguation[J].ACM SIGMOD Record,2012,41(2): 15-26.   \n[5] Hussain I,Asghar S.A Survey of Author Name Disambiguation Techniques: 2010-2016[J]. The Knowledge Enginering Review, 2017,32: e22.   \n[6] 付媛,朱礼军,韩红旗.姓名消歧方法研究进展[J].情报工程, 2016,2(1): 53-58.(Fu Yuan, Zhu Lijun, Han Hongqi. A Survey of Name Disambiguation[J]. Technology Inteligence Engineering, 2016,2(1): 53-58.)   \n[7] Sanyal D K,Bhowmick PK, Das PP.A Review of Author Name Disambiguation Techniquesfor the PubMed Bibliographic Database[J].Journal of Information Science,2019(3):1-28.   \n[8] 单嵩岩,吴振新.面向作者消歧和合作预测领域的作者相似度 算法述评[J].东北师大学报(自然科学版),2019,51(2):71-80. (Shan Songyan,Wu Zhenxin.Review on the Author Similarity Algorithm in the Field of Author Name Disambiguation and Research Collaboration Prediction[J].Journal of Northeast Normal University(Natural Science Edition),2019,51(2):71-80.)   \n[9] Delgado AD,Montalvo S,Martinez-Unanue R,et al.A Survey of Person Name Disambiguation on the Web[J]. IEEE Access, 2018, 6: 59496-59514.   \n[10] 柯昊,李天,周悦,等.数据缺失时基于BP神经网络的作者重名 辨识研究[J].情报学报,2018,37(6):600-609.(Ke Hao,Li Tian, Zhou Yue,et al.Author Name Disambiguation Using BP Neural Networks Under Missing Data[J]. Journal of the China Society for Scientific and Technical Information,2018,37(6): 600-609.)   \n[11] Zhang S Y,E X H,Pan T.A Multi-Level Author Name Disambiguation Algorithm[J].IEEE Access,2019,7:104250- 104257.   \n[12] 尚玉玲,曹建军,李红梅,等.基于合作作者与隶属机构信息的 同名排歧方法[J].计算机科学,2018,45(11):220-225,260. (Shang Yuling, Cao Jianjun,Li Hongmei,et al. Co-author and Affiliate Based Name Disambiguation Approach [J]. Computer Science,2018,45(11): 220-225,260.)   \n[13] Ding X, Zhang H, Guo X Y.An Unsupervised Framework for Author-paper Linking in Bibliographic Retrieval System[C]// Proceedings of the l4th International Conference on Semantics, Knowledge and Grids (SKG).2018:152-159.   \n[14]Hazra R,Saha A,Deb S B,et al.An Efficient Technique for Author Name Disambiguation[C]//Proceedings of 2016 IEEE International Conference on Current Trends in Advanced Computing.2016: 1-6.   \n[15]刘林.面向科技人才情报的多策略组合模型同名消歧方法[J]. 通信技术，2018,51(8):1836-1843.(Liu Lin.Multi-strategy Combination Model for Scientific and Technological Talent Disambiguation[J]. Communications Technology,2018,51(8): 1836-1843.)   \n[16] Zhang B C,Hasan M A.Name Disambiguation in Anonymized Graphs Using Network Embedding[OL].arXiv Preprint,arXiv: 1702.02287.   \n[17] Zhang W, Yan Z, Zheng Y. Author Name Disambiguation Using Graph Node Embedding Method[C]/Proceedings of 2019 IEEE 23rd International Conference on Computer Supported Cooperative Work in Design (CSCWD). 2019:410-415.   \n[18] 余传明,钟韵辞,林奥琛,等.基于网络表示学习的作者重名消 歧研究[J].数据分析与知识发现,2020,4(2/3):48-59.(Yu Chuanming,Zhong Yunci,Lin Aochen,et al.Author Name Disambiguation with Network Embedding [J].Data Analysis and Knowledge Discovery,2020,4(2/3): 48-59.)   \n[19] Yu Z Z,Yang B. Researcher Name Disambiguation: Feature Learning and Afinity Propagation Clustering[C]// Proceedings of the International Symposium on Methodologies for Intelligent Systems.2018:225-235.   \n[20] Zhu J,Wu X C,Lin XQ,et al.A Novel Multiple Layers Name Disambiguation Framework for Digital Libraries Using Dynamic Clustering[J]. Scientometrics,2018,114(3): 781-794.   \n[21]Shen Q M,Wu T S,Yang HY,et al.NameClarifier: A Visual Analytics System for Author Name Disambiguation[J].IEEE Transactions on Visualization and Computer Graphics,2017,23 (1): 141-150.   \n[22]GB/T 6447-1986,文摘编写规则[S].北京:中国标准出版社, 1986.(GB/T 6447-1986,Rulesfor Abstractsand Abstracting [S].Beijing: Standards Press of China,1986.)   \n[23]Han HQ,Yao C Q,Fu Y,et al.Semantic Fingerprints-based AuthorName Disambiguationin ChineseDocuments[J]. Scientometrics,2017,111(3): 1879-1896.   \n[24]Li N,Han J. The Application of Naive Bayes Classifier in Name Disambiguation[C]//Proceedings of the 3rd International Conference on Cloud Computing and Security. 2017: 611-618.   \n[25]Hussain I,Asghar S. Incremental Author Name Disambiguation Using Author Profile Models and Self-citations[J]. Turkish Journal of Electrical Engineering and Computer Sciences, 2019, 27(5):3665-3681.   \n[26] Abdulhayoglu M A,Thijs B. Use of ResearchGate and Google CSE for Author Name Disambiguation[J]. Scientometrics,2017, 111(3): 1965-1985.   \n[27] Zhao Z Q,Rollins J,Bai L G,et al.Incremental Author Name Disambiguation for Scientific Citation Data[C]//Proceedings of 2017 IEEE International Conference on Data Science & Advanced Analytics.2017: 175-183.   \n[28]Pooja K M,Mondal S,Chandra J.A Graph Combination with Edge Pruning-Based Approach for Author Name Disambiguation [J].Journal of the Association for Information Science and Technology,2020,71(1): 69-83.   \n[29] Backes T.Effective Unsupervised Author Disambiguation with Relative Frequencies[OL].arXiv Preprint,arXiv:1808.04216.   \n[30]Pooja K M,Mondal S,Chandra J.An Unsupervised Heuristic"
  }
}