{
  "original_filename": "full_9213.md",
  "自动文摘综述": {
    "context1": "郭燕慧　钟义信　马志勇　姚均勇",
    "context2": "(北京邮电大学智能研究中心，北京100876)",
    "context3": "摘要本文概述了自动文摘的发展历史和研究状况,给出当前自动文摘领域主要的研究方法和策略,剖析了它们的优点和不足。进一步结合自动文摘自身的特点和难点，提出近期自动文摘的研究重点是基于篇章话语形式的浅层分析方法生成指示型文摘。",
    "context4": "关键词 自动文摘话语形式浅层分析指示型文摘"
  },
  "Introduction of the Development of Automatic Summarization": {
    "context1": "Guo Yanhui， Zhong Yixin，Ma Zhiyong and Yao Junyong (Intelligence Research Center of Beijing University of Posts and Telecommunications，Beijng 100876)",
    "context2": "Abstract This paper outlines the development of automatic summarization and describes the current research methodology andresearchstrategyinthisfield，analyzesthe meritsanddefectsaswell.Futhemore，itarguesthisanalysis，togetherwiththe stateof theaitandtheintrinsicdificultyofsummarizing，implyanearertemstrategyconcentratingonshalow，butnotsuface, text analysis based on discourse structure and on indicative summarizing·",
    "context3": "eywords automatic summarization,discourse structure,shallow analysis， indicative summarizing."
  },
  "1简 介": {
    "context1": "概括介绍一篇文章的内容可以有多种方式，其中最主要的方法就是做文摘。文摘是准确全面地反映某一文章中心内容的简洁连贯的短文，与索引相比更能满足信息获取的要求。",
    "context2": "自动文摘的概念是由 Luhn[1]首先提出的。当时，自动文摘并未引起人们的足够重视。但随着近年来Internet的迅速普及,信息量激增，信息的自动化处理成为一个亟待解决的问题。在此时代背景下，自动文摘越来越引起人们广泛的兴趣。",
    "context3": "自动文摘包括三个步骤(见图1)。文本分析过程寻找最能代表原文内容的成分。转换过程通过摘录或概括的方法压缩文本;最后一步是重组原文内容,生成文摘。文摘的用途和它所面向的读者群,决定了文摘输出时对原文内容的再现形式。",
    "context4": "![](images/3be3a633162727f62e4f9fa9f75dd820cd97b08a99fcee7b8ba781708fe2ea81.jpg)  \n图1自动文摘的处理过程",
    "context5": "这里我们将讨论与上述三个步骤相关的自动文摘技术。文本分析和转换这两步对充分表示原文十分重要，我们的重点放在这上面。就目前的自动文摘的研究状况而言，既有采用符号、规则的基于知识的方法，也有基于词频及话语形式等文本表层特征的统计学方法;面向特定领域的自动文摘似乎不难实现，而建立一个通用的文摘系统却几乎不太可能。另外,文摘的评估也是一个难题。"
  },
  "2文摘评估方法": {
    "context1": "自动文摘通常被视为自然语言处理的一项任务。从广义的角度可将自动文摘的评价方法大致分为两类[2]：一种称作内部评价(Intrinsic)方法,与系统的目的相关，它通过直接分析摘要的质量来评价文摘系统。第二种称作外部评价(Extrinsic)方法，它是一种间接的评价方法，与系统的功能相应，将文摘应用于某一个特殊的任务中，根据摘要功能提高这项任务的效果来评价自动文摘系统的性能。文摘的评价较索引的评价要复杂的多，它需要更多的知识(语言学、领域知识和上下文关系)做支持。",
    "context2": "内部评价方法[2]按信息的覆盖面和正确率来评价文摘的质量，一般采用与\"理想摘要”相比较的方法[3-6]。这种评价方法源于信息抽取技术。信息抽取是将原文的关键要点抽取出来，并与人工抽取的内容在召回率（recall）、准确率（precision）、冗余率(overgeneration）及错误率(fallout）几个指标上进行比较7",
    "context3": "召回率 $=$ 系统正确响应数专家正确响应数  \n准确率=系统正确响应数系统响应数  \n错误率=系统不正确响应数和伪响应数专家不正确响应数  \n冗余率=系统的伪响应数系统响应数",
    "context4": "这其中“理想摘要”的获得是个问题。通常可直接用原文作者摘要作为“理想摘要”，但也有人认为原文作者对文章所作的摘要具有一些不足之处，如：作者撰写的摘要可能不够规范;编写摘要时可能不够客观等缺点。所以很多人主张采用专家对文章直接抽取句子进行摘要。不同的专家所撰写的摘要是不同的，有时在内容上很少交叠[6,10]。特别是评论或解释性文摘，内容更难达到一致。许多情况下，只能判断文摘的合理性。",
    "context5": "评价一个文摘是否能满足用户的需求以及它是否能文独产成篇也很更如，若文摘虽囊括了原文的要点，但可读性差，不利于人的理解,那么就没起到它应有的作用。外部评价方法与文摘的目的相联系，即将摘要应用于特定的任务，根据文摘系统对该任务的促进作用来评价文摘系统的性能(如对比采用摘要进行检索与原文进行检索的准确度，来确定是否可以在IR中利用摘要来代替原文)。近来，又有人尝试在基于任务的环境下测试文摘的个性特征参数[1I\\~13]。例如，在文本搜索中，可测试采用文摘对提高搜索速度和质量的影响。",
    "context6": "因为许多文摘系统采用了基于知识的方法，可移植性和可维护性就成了测试文摘的主要指标[2]。可移植性衡量文摘系统用于新领域时所付出的代价，包括系统的顺应性和可替代性;可维护性指系统的可变性和可分析性。因文摘较索引复杂的多，对句法分析的评价也是一个很重要的方面[2]。",
    "context7": "评价文摘的工具通常比较昂贵。它要求在完全受控条件下进行足够多次的试验。例如，要比较不同人写的文摘,测试文摘对文献筛选的影响。一般认为要建立一种客观有效的文摘评价方法，还有待进一步的探索和研究[14]。"
  },
  "3文本分析": {
    "context1": "最初的一些方法主要是借助知识来分析文本的表层特征。这些方法可归入自然语言理解的范畴，能生成质量很好的文摘，但领域受限。还有一类是以研究文献中的词频及其他一些浅层统计信息为主的方法。这类方法属于信息抽取的范畴(用自然语言对文献作索引)，结果较差，但适用范围广。运用统计的方法研究文本的话语形式来自动做文摘，则介于上述两者之间。"
  },
  "3.1利用知识对文本进行深层处理": {
    "context1": "文本分析的最终目的是要完全理解原文，这可从句子的理解到由句子组成的文章的理解。虽然自然语言处理中的信息识别技术已成功地运用于自动文摘系统，但要想达到前面提到的那种成熟水平，还有漫长的路要走。"
  },
  "3.1.1 知识": {
    "context1": "符号知识主要包括语言学知识、特定的领域知识和上下文知识。语言学知识一般指修辞、句法和语义知识，此外还包括以文本表层线索为特征的话语结构知识。领域知识指示文本的语义特性。知识再现要综合运用以上两种知识模型。此外，结合信息提取技术进行文本分析时，还需要代表交际对象倾向的上下文知识。",
    "context2": "知识常以生成规则和生成框架的形式表示，如概念和框架的语义网络。这种结构化的知识表示又称为内容规划、脚本、模板或文本语法。内容规划的知识表示方法不仅指导文本分析，还决定了文摘的生成目标，即通过框架或脚本实例化得到摘要。",
    "context3": "在讨论自动文摘和信息提取技术中常用的分析技术前，有必要先描述一下常用的几种语法模型[15]。这些语法是由语言学家给出的。上下文语法是最常用来表示一个句子或一篇文章结构的语法。它将句子或文章分解成一棵树的形式,其中每个叶节点都是一个终结符，表示分解到此结束，得到有关句子或文章的真实语法结构。上下文无关语法可用来描述自然语言中的许多结构，进行有效分析。",
    "context4": "一种较为简单的语法规则是规则语法。它是上下文无关语法的子集，允许非终结符存在,适于描述文本的修辞结构。",
    "context5": "较复杂的语法结构可用上下文敏感语法分析。"
  },
  "3.1.2句法分析技术": {
    "context1": "句法分析是按语法分析文本，得出文本结构的方法。可根据覆盖层面的不同、采用语法的不同及语义或语法元素的不同对句法分析方法进行分类。",
    "context2": "自动文摘系统只需部分句法分析[1.7]。完全句法分析要分析文献中的每一个词，给出它对全文的贡献。完全句法分析囊括了修辞、句法和语义知识及文献的话语结构属性。这对知识库的要求很高，目前只适用于特定领域(如对子语切分)。多数情况下，自动文摘系统只对文本进行部分句法分析，对于一些未知的语言学知识可借助领域知识来弥补。",
    "context3": "有时文摘中所含的信息与它上下文之间的关系可用规则语法来描述。此时的句法分析经常表现为形式匹配。有限状态自动机就是利用这种方式识别文本中词的形式。",
    "context4": "大多数自动文摘系统中，都要用到句法分析和话语结构分析。这种句法分析依靠上下文无关语法，可分为自顶而下和自底而上两种方法[16]。自底而上的方法仿照语言学中遣词造句的方法，将单个的词组成短语和句子，进而再把这些短语和句子组成一篇文章。该方法适用于完全句法分析，可对文本进行深层分析。尽管它能很好地完成文摘工作，但富要木的语言学知识和领撼知识做支撑，复杂度高，效率低[18] 。",
    "context5": "自顶而下的方法是期望驱动式的。它试图在文本中寻找预期的结构，经常用于部分句法分析或文本浏览。框架知识、模板或脚本提供了基本的语义单元，句法分析就是要在原文中找到与这些单元相匹配的信息。因此，自顶而下的方法对未知词的词或语法现象有很好的规避性，可以忽略许多复杂的知识,缺点是不能给出文本中没有预期到的信息。由于这种方法无法刻画原文的细节，一般用于自动文摘的前期处理。若把自顶而下和自底而上两种方法结合起来使用(先用自顶而下的方法选取原文中特定片断,接着再用自底而上的方法对这些重点片断进行详细的内容分析)，则可充分利用它们所获得的信息，了解主题领域,生成通顺流畅的文摘[6,19]。",
    "context6": "信息提取和自动文摘所采用的句法分析主要是基于语义的分析[20]。这种句法分析方法需要修辞、句法、语法、话语结构知识和领域知识。这些知识组成的一套规划语法系统基本上是语义的，经常用来表示一个特殊的主题领域。自然语言的句法分析将话语映射成语义结构，不考虑逻辑上与之相分离的中介一—句子层次上的语法知识。虽然语法结构可为语义解释提供辅助信息(如单个句子和短语的语法，话语片断的语法顺序),但语义较语法更为基本，这是由语义决定自然语言话语含义的功能决定的。因此句法分析的结果是文本的语义描述而非语法描述。",
    "context7": "更深层的文本分析还要借助有关文本内容和表层特征的一组期望值。这种基于预期的方法能分析原文的话语特征并识别上下文提示信息，对原文内容的预见和理解的效果很好(如新闻故事、财经和商业报道)。"
  },
  "3.1.3原始模型": {
    "context1": "最早的自动文摘和信息取模采用子语语法，从医学文章中抽取信息。该方法依赖子语领域的语义知识。Rumelhart提出用“故事语法”来理解和概括文章。该方法用层次结构描述特定文献类型的话语特征。Schank 则在故事脚本中给出一系列事件和动作。",
    "context2": "成功的例子是Frump 系统[7,26]。Frump 概括出典型的新闻故事(绑架、殖民、外交会议等),并能从故事中预先选定的主题领域里准确地抽取特定信息(如，事件的性质和发生的地点),生成基于信息抽取的文摘。以上所需的各种预期知识在规划脚本中给出，脚本常用自顶而下的结构表示，它描述一系列事件，为事件套上一种结构，推导可能发生的意外事件。语法知识用来判定某个预期词在句子中的位置。句法分析遍历全文寻找标示已知脚本的词语或短语，建立故事梗概。它只关心原文中与脚本基本元素相关的部分，其余则忽略不计。Frump 只能针对特定用户和特定任务分析摘录原文中的部分内容。据报道,Frump 对原文的理解程度高于 $50 \\%$ （比如,它对脚本中所涉及的每件事都能理解)。",
    "context3": "Lehnert 系统[2]可识别故事中未定的情节单元。这些情节单元以命题形式出现，有三种状态(如正事件、反事件和中间状态)和四种连接关系(动机、行为、终结和等价)。系统借助大量的先验知识对这些情节单元进行分析，生成一个反映各单元从属关系的复杂网络，并以此为蓝本生成文本摘要。"
  },
  "3.1.4其他应用": {
    "context1": "另外还有许多基于信息抽取的文摘系统[28～31]。其中比较著名的有： $\\mathrm { T E S S ^ { [ 3 2 ] } }$ ， SCISOR[19],CONSTRUE[34]和FASTUS[35]。在由美国政府发起，多家研究小组和机构参与的消息理解年中会议上(MUCs)以及美国国防部高级研究计划署(DARPA）的 TIPSTER 文本计划项目中（Tipster Text Program）,专家们对现有的文摘系统进行了评估，召回率为$40 \\%$ 左右,准确率为 $50 \\%$ 左右。每个系统的性能大体相似，但不同的系统对同一文献信息抽取的难易程度不同。速度上，机器的表现远远超过人类。"
  },
  "3.1.5话语结构的重要意义": {
    "context1": "信息抽取在自动文摘系统中对文本的分析、文摘句的选取都起着很重要的作用。前面介绍的那些文摘系统的共同缺点是需要大量的领域知识。自然语言(口头或书面)的交流受话语形式控制,这一点是理解文章时不可或缺的。在自动文摘中我们也需要话语知识(尽管只是一部分)[36]。一般来说,话语结构较少依赖于特定领域。虽然一些结构，如依赖于超结构的文章类型仅被用于文章拓扑结构的分析中，但其他更多的交际结构应用范围则广泛得多。因此，在自动文摘的研究中话语形式引起了人们重视。实际上早期的自动文摘中也在某种程度上采用了该技术。",
    "context2": "规划结构或超结构以及语言信息线索在自动文的详细的规划结构可用来做新闻故事的摘要[41]。与文章类型有关的超结构和与文章类型无关的层次结构常常能暗示出文章的语言特色。早期的自动文摘系统中线索词和标志短语常用来标示文章中的重要句子[3,42.43]。线索词在目前的文摘系统中仍受到高度重视[11.4]。尤其是能揭示文章层次关系的线索词已被公认为提取文摘时的首选，并取得了不错的效果[45\\~47] 。",
    "context3": "不容置疑，文章的主旨结构对于提取文摘十分重要。早期的自动文摘把段落的首句或尾句及文章的首句或尾句作为文章的中心句[3,48]。 Kieras[49]和Kupiec[4]等证实这些位置线索能标示文章的主题及其变换,有助于提取文摘句。TOPIC 系统就是利用主题结构生成摘要的极好例证。Hahn 给出了识别主题的三个步骤;先在文章的一段内找到一个主题，通过分析句子检测主题的变化，接着再根据文章各个段的主题推断整个文章的主题。Kieras[49]指出，主题提取只需关于主题的有限语义知识，无需理解全文。文章的主题结构尤其对要反映主题和子主题的文摘有用，并满足生成文摘的不同颗粒度要求。",
    "context4": "话语形式在自动文摘中的作用启发了人们借助文章语法来分析文章内容[38.3.40,50]。文章像句子一样有一种语法。如一组能暗示作者意图的规则有助于指导话语中各组成部分合理布局，使文章更易为人理解[51]。话语结构对自动文摘的重要性在由美国人工智能协会主办的智能文摘春季年会(1998)上得到了重申。"
  },
  "3.2统计过程": {
    "context1": "近年来在自动文摘中应用统计的方法正成为一个趋势。统计的方法独立于领域知识和语言知识，通过识别重要的主题项来抽取包含这些主题项的上下文相关句，并以此来构建摘要，应用范围比较广泛。自动文摘使用统计的方法可追溯到 $\\mathrm { L u h }  { \\mathrm { I n } } ^ { [ 1 ] }$ 当时自动文摘和文章索引关系紧密[48.52]。基于统计方法的自动文摘在1997年由计算语言学协会组织的智能化文摘研讨会中受到了极大关注并予以立项。"
  },
  "3.2.1 识别文章的主旨": {
    "context1": "在信息抽取的研究中，一直以词或短语在文章或语料库中出现的频率作为识别主题的重要指标。主题词成为构建文摘的基础。有重要意义的词和短语能反映文章的内容，可以构成粗略的文摘(基于关键词的文摘)[53]。短语，特别是名词短语被认为是语义信息的重要载体[4,37]。计算文章中词和短语权值的方法有多种。生成文摘时先将句子中的重要词聚类,然后按权值对句子进行排序,再根据排序结果依次选取权值较大的句子构成文摘[1,3.2.54]。当这种方法用于基于用户提问的文摘时，排序应以提问项为基准[13]。",
    "context2": "由于不同用途的文摘选取的信息不同，话语形式的权值也会不同。Kupiec[4等人提出了通过学习获取话语参数的方法。该方法基于原文和样本文摘一一对应的语料库，通过对样本文摘的分析，并结合有限几个属性和参数，获得具有文摘价值的数学模型。这些属性包括：句子长度，句子包括的标志短语，紧跟在章节标题后包含标志短语的句子，包含主题词",
    "context3": "![](images/54692d583353bec85f264d9c2f8b8acf1cea49b07ad267d2c9128958b5c48543.jpg)  \n图2段落组识别主题：低相似度意味着将有更多的段落归属于一个较完整的主题",
    "context4": "在词频统计基础上识别文章的主题已成为自动文摘的研究热点(如图2)。该方法按内容的相似性对文本单元归类(对句子或段落进行编号)。Salton等人对此进行了详细的研究[6.55]。他们将内容享有足够交叠的段落划归一组，揭示整个文章的主题。两个段落间的相似度用代表两段的空间向量夹角余弦计算[56]。段落间的相似度超过规定阈值就归为一组，通过阈值的调整可扩大或缩小组的大小,这样用户就可以自主选择文摘的长度。Heast 和Plaunt[5]也作了类似的研究，来寻找文章的子主题。一般说明文的主题贯穿全文,子主题仅在文章的某一部分出现。对经文本切割后得到的文本单元（一般由 $3 { \\sim } 5$ 个句子组成)进行相似度计算,其结果可用图的形式来表示。该方法是由Prikhod'Ko和Skorokhod $^ \\mathrm { \\prime } \\mathrm { K o } ^ { [ 5 8 ] }$ 首先提出的。他们认为与其他文本单元都有关联的文本单元所含的信息量较大，可选入文摘中。近来，依据上述思想已有了一些算法，如日本已有靠提取文章的代表性段落生成主题平衡的可读性文摘[,但效果并不理想,与手工文摘相比最大重叠率仅为 $46 \\%$ 。"
  },
  "3.2.2获取文摘的特征参数": {
    "context1": "中通形式包括市题包的分布形式及其语言上的标记，它随文章类型和语料库的变化而变化。同时，的句子和包含多次出现的常规词的句子，段落的头、尾句和中间句。分类函数(如Bayes无关分类器)根据某句在训练库的属性，估计它在文摘中出现的可能性。该方法在话语模式的启发下可直接寻找到生成文摘所需的最佳参数组合。对科技领域文献进行测试,得出最佳的参数组合是位置，线索短语和句长。Tenfel 和Moens[59]用该方法做过实验，得到的文摘与手工文摘的重叠率为 $43 \\%$ ，这表明该方法对文本分析和句子选取具有一定的实用性。近来,基于归纳逻辑的区别函数技术(C4.5，1993)用于获取话语模式也取得了令人满意的效果。",
    "context2": "综上所述，利用监督或非监督的学习方法获取话语模式，可避免或部分避免文本分析中对领域知识和语言学知识的依赖，很有发展前景。目前语言学对话语模式的研究还很不够，迫切需要人们对此进行深入研究。"
  },
  "4文本转换": "",
  "4.1 内容的选择和泛化": {
    "context1": "做文摘的第一步是要对原文进行分析，形成对文摘内容的表示;第二步是对这种表示进行修剪和压缩以形成文摘。生成文摘的过程中总要包括对原文内容的选择和泛化。用户的需要决定了文摘所要选取的内容，而领域知识则是泛化时所要遵循的准则。选择和泛化在多文档文摘中显得尤为重要。",
    "context2": "相关信息的选择与原文的话语结构密切相关。例如，文章的主旨结构可为文摘提供原文的主题线索，超结构的一些片断也对选择正确的文摘信息有帮助。实际上现有的自动文摘系统均综合了文本分析技术和信息抽取技术，把原文中具有高相关值的句子抽取出来形成文摘。",
    "context3": "目前较难实现的工作是信息泛化。泛化就是把信息自动压缩为更抽象的形式。例如，“女孩玩布娃娃。”和“男孩玩玩具火车。”两个句子,可简单地用一句话“孩子玩玩具。”概括。这其中包含了大量的语义知识，修辞、语义词典和本体论的知识都要用到[6]。但要在更一般的意义上描述被选信息,这还不够。 $\\mathrm { H a h n } ^ { [ 2 0 ] }$ 在领域知识的基础上实例化层次框架中各子部分，并用泛化/归类的方法得出原文的主题。",
    "context4": "选择和泛化可以控制文摘的长度，即原文的压缩度——文摘长度与原文长度之比。理想状态下,人们可自由扩充和精简文摘中的细节，但这还需要长期的努力才能实现。"
  },
  "4.2选择和泛化多文档内容": {
    "context1": "选择和泛化是生成多文档文摘的重要一步。用户对信息的侧重决定了文摘对每篇文档信息的选择。这就要求作文摘时能将多篇文档中的异同点分别提取出来(见图3)。例如，对有关某件事的系列报道，人们所关心的是这件事的发展变化情况，那么在对这些报道作摘要时重点就应放在随时间发展变化的部分;反之，若有人只想了解这件事的大体概况，摘要只需抽取每篇文档中的相同部分，加以泛化概括则可。Mckeown 和 Radev[60]对新闻报道中的同一件事或一系列事采用多角度观察，分析文本片断中人物的变化、言语的冲突等信息差异,确定多文档文摘所要提取的信息。这种对比性文摘需要对原文的高质量再现，目前只能在受限领域才能实现。Mani 和Bloedorm[12]指出 Salton[6]以单词的重叠、语义的联系为依据，从多文档中提取相似的文本单元生成多文档文摘的方法切实可行。但是在一个文本语料库中词语的变化远大于一篇文章中词语的变化，同义和歧义现象十分突出。"
  },
  "5文摘生成": {
    "context1": "中国知网htps://www.cnki.net经过文本的分析和转换，接下来就是文摘的生成了。这项工作的复杂程度取决于用户对文摘形式的要求。如果只要求把原文片断所提供的语义信息简单罗列出来,则文摘生成这步工作几乎可以省略。若要求文摘是一篇内容完整、语句连贯通顺的文章，达到能与手工文摘相媲美的程度，文摘生成这一步的工作就复杂了。目前的实用文摘系统所能做到的只是把从原文中抽取的片段和句子稍加修改和润色。",
    "context2": "![](images/60f39c455ef973d9bf47b60a92afe58e8cacaf2d073163046432ac24afa3ec04.jpg)  \n图3多文档( $T _ { 1 } \\ : \\Lambda T _ { 2 }$ )文摘",
    "context3": "理想上，文摘应该在理解原文的语义层面上生成,这就涉及到文本生成技术。文本生成是个宽泛的研究领域，包括交际信息的抽取、篇章的构架和生成合乎语法的表达(句子和短语)等[6]。使用文本生成工具生成的文本要具有可读性，能起到实际的交际功能。Horacek 和 $\\mathrm { Z o c k } ^ { [ 6 2 ] }$ 对这方面的内容进行了专门的论述。",
    "context4": "从原文中抽取句子生成的文摘，会由于句子间缺少连贯性而使文摘行文不流畅，可读性较差。而靠抽取段落生成的文摘效果就好些，因为段落本身就是一个连贯的单元。",
    "context5": "(1)影响文摘连贯性的最主要问题是主语悬垂和不明指代[2.0.45]。例如，在句中用于指示和对比的代词其确切含义就只能靠它前面或后面的内容来推断。省略问题也是同样。首语重复已引起人们的普遍重视，目前简单的解决办法是删除带指代词的句子[45],或增加能说明指代词含义的句子[42]。前者有可能会损失信息，而后者也不能保证指代问题一定解决。指代有可能发生在文章中更前面的几句。某些情形下，可将包含特定线索词的前几个文本单元都纳入文摘当中，然而要确定哪些是所需的先行句则需要话语结构的分析[63.64],这是文本分析阶段",
    "context6": "要解决的问题[65] 。",
    "context7": "(2)其他的层次关联关系可能会影响由抽取句子所得到的文摘的可读性[45]。例如，从原文中抽取的句子中含有关联词“另一方面”,在文摘中该句就会与其前面的句子形成对比关系，而实际上原文中该句和它前面的文摘句并不相邻，因此二者不存在对比关系。删除这样的关联词或增加一个先导句并不能很好地解决这个问题，只有通过文本分析中对话语结构的深入探讨才能从根本上攻克这一难题。",
    "context8": "(3)原文中的图表及一些插入成分在作文摘时，都是要省略的。这一项工作现已能实现[45,66]。",
    "context9": "(4)文摘要能简洁明了地反映原文内容，一方面需将原文中的重复性、并列性成分合并[]，另一方面，还应利用上下文知识将短句子加以扩充。",
    "context10": "尽管语言学知识有助于提高文摘的可读性，但多数情况下文摘系统并不需要它。首先，文摘是为了提高选取文献的速度和效率，修饰和润色工作不会对此有太大帮助，相反还会增加系统的处理时间[]。其次，有时文摘要尽可能多引用原文[]。例如，在对法律文档作文摘时，就必须援引原文的词句，否则会造成很大的曲解。"
  },
  "6自动文摘研究所取得的成绩和面临的问题": {
    "context1": "在进行文献检索时，一篇语义信息丰富的文摘显然比一些只言片语的关键词组合能更好地完成检索任务，尽管这种文摘作起来较复杂。自动文摘是一个很有价值的研究课题，虽然目前存在的问题还很多,但鼓舞人心的研究成果也层出不穷[68]。",
    "context2": "(1)信息抽取领域的研究成果为文本信息的识别提供了许多可供借鉴的东西。可是这些方法严重依赖于外部知识，尤其是领域知识。受知识获取的瓶颈限制，该方法只在受限领域得到成功应用。一旦领域知识的人工获取变得容易，这种方法还是有发展前景的[18]。目前的自动文摘领域人们更关注一般性知识的获取，尤其是对篇章话语模式的研究开始多了起来。经典的句法分析技术有助于对文章的理解,确无法从全局的高度对文章的内容进行把握。话语分析研究了口语和书面语中大量的话语现象，得出关于文章的拓扑结构，这对于自动文摘意义重大。根据一篇文章的话语结构，我们能判定该文章断属类进而采取想应的抽取策：另外话语结构对定位文本中的重要信息也很有帮助。我们应结合语言学和社会学知识对话语结构作进一步的深入研究。机器学习是获取语言学知识和话语模式的重要手段，它为用统计的方法研究自然语言开辟了崭新的道路，是当前人们研究的热点。",
    "context3": "(2)信息抽取一般采用统计的方法识别非受限领域的内容。近几年迅速发展起来的一些主题结构识别技术可用于自动文摘，有监督的分类学习模型就是其中较有发展前途的一类。",
    "context4": "(3)自动文摘中的转换过程还仅限于对原文信息的抽取，而采用更一般的概念对原文内容进行某种程度的概括，还无法实现。",
    "context5": "(4)手工文摘是机器文摘很好的模仿对象。心理学的研究成果可为自动文摘提供一些有意的启示",
    "context6": "(5)多文档文摘能帮助人们迅速地获取大量信息，日益受到人们的重视。该项技术对原文的理解程度要求较高，系统必须能识别出相关文档中的异同点。",
    "context7": "(6)为了能有针对性地对文摘进行剪裁，需要深入研究文摘的形式和文摘所要完成的任务之间的关系[14]",
    "context8": "(7)最后是对文摘的评估。寻找一种客观有效的文摘评估方法还有很多工作要做。"
  },
  "7中文自动文摘的研究现状": {
    "context1": "由于中文信息处理的困难以及现代信息技术发展阶段的限制，我国对自动文摘的研究起步较晚，80年代后期才开始。",
    "context2": "在形式特征方面，汉语和西文主要区别是汉语词间没有空格,而真正负载信息的是词而不是字，因而存在自动分词问题。同时,汉语的词汇极为丰富，同一个概念可以用很多不同的词汇表达，这给词频统计带来了一定的困难。在语言的深层结构方面，汉语也有着自己的特点。比如，汉语缺乏词形的变化,增加了句法分析的难度;汉语有一些特殊的句式,如兼语、连动等。",
    "context3": "我国研究者针对汉语特点进行了不懈的努力，取得了可喜的成就。",
    "context4": "上海交通大学王永成教授从80 年代末就开始研究自动摘录技术,1997 年研制了0A中文文献自动摘要系统。其关键技术有三：构造关键词词典；从文献的有关部位(如前言、结束语)中自动摘取包含关键词词典中的词的句子作为候选文摘句，并根据其中包含的词典词的个数、相距远近、句子在文中的部位等信息加权，然后再根据文摘长度的要求来选择权值较大的作为文摘句;对文摘句进行去毛边、排序、润色而生成文摘[69,0,7,72,73] 。",
    "context5": "80 年代末，东北大学姚天顺教授和香港城市理工大学联合开展了“中文全文自动摘要系统”的研究，该系统采用脚本知识表示，通过与用户交互获取文摘[74]",
    "context6": "复旦大学吴立德教授等研制的自动文摘系统分析了篇章段落之间的语义联系，建立了语义网，具有一定的篇章理解能力，并能对任意文章给出任意长度的摘要。",
    "context7": "哈尔滨工业大学王开铸教授等人提出了偏重于篇章物理结构的\"篇章计算模型”,并于1992 年研制了一个基于篇章理解的军事领域自动文摘实用系统MATAS（Millitary Area Text Automatic Abstract System）。该系统考虑了句子之间的语义联系，但是系统不能自动判断段落的文体，需要人工干预。由于文体将直接影响到该系统中篇章的形式化表示，所以该系统提出的方法难以实现[75,76]。 。",
    "context8": "北京邮电大学的钟义信教授多年从事信息科学领域的教学和研究工作,倡导用\"全信息”的理论指导自动文摘的研制开发。在他的带领下,先后实现了面向计算机病毒方面的Glance 系统[7],面向新闻报道的News系统[8],以及面向神经网络学习算法领域的Ladies 自动文摘系统[79]。",
    "context9": "近几年，从事自动文摘的企事业单位不断增加，彼此间的交流与合作也在增多。例如，IBM中国研究中心和大陆微软公司都在研制中文自动文摘的产品。信息时代的飞速发展，对于自动文摘的研究工作者既是机遇也是挑战。回顾自动文摘四十余年的发展历史，我们有理由相信自动文摘必将会在不远的将来为人类做出应有的贡献。"
  },
  "参考文献": {
    "context1": "1Luhn HP.The automatic creation of literature abstract ·IBM Journal of Research and Development，1958,2(2):159～165   \n2 Spark Jones $\\kappa \\&$ Galliers JR·Evaluating Natural Language Processing ：An Analysis and Review·New York ：Springer, 1996   \n3 Edmundson HP．New methods in automatic abstracting ex tracting·Journal of the Association for Computing Machinery, 1969,16(2):264\\~285   \n4 Kupiec J，Pedersen J& Chen F．A trainable document sum中国知网:E AtssP/AngwerwercRi Fidelt ed. Proceedings of the 18th SIGIR Conference（TREC-4),1995.449～ v·;GauICISDuy，i;UI JI 5Hand TF.A proposal for task based evaluation of text summarizationsystems·In:ProceedingsoftheACL $9 7$ Workshop on Intellgent Scalable Text Summarization(ISTS '97）1997. 31 ${ \\sim } 3 8$   \n6Salton G, Singhal A， Mitra M. $\\&$ Buckley C. Automatic text structuring and summarization: IP&M，1997,33(2):193～207 7 DeJong G．An overview of the FRUMP system·In: Processings of the 5th International Joint Conference on Artificial Intelligence·Cambridge，MA：William Kaufmann，1982.16 8ChinchorN.MUC-4Evaluationmetrics：In:Fourth Message Understanding Conference(MUC-4）.Proceedings of a Conference Held in McLean，Virgjinia June 16-18，San Mateo，CA: Morgan Kaufmann，1992.22～29 9Chinchor N， Hirschman L, $\\&$ Lewis D D. Evaluating message understanding systems ：an analysis of the third Message Understanding Conference（MUC-3）．Computational Linguistics, 1993,19(3):409～449   \n10LancastorFW．Indexing and Abstracting inTheoryand Prac tice·London： The Library Assciation，1991   \n11Miike S，Itoh E，Ono K, $\\&$ Sumita K.Afulltext retieval system with a dynamic abstract generation function· In：W B Croft $\\& _ { \\mathrm { ~ C ~ J ~ } }$ van Rijsbergen，ed·Proceedings of the Seventeeth SIGIR Conference·London: Springer，1994.152～161   \n12 Mani I， $\\&$ Bloedorn E.Multi-document summarization by graph search and matching·In: Proceedings of the Fourteenth National Conference on Artificial Intelligence and Ninth Inno\" vative Applications of Artificial Intelligence Conference·Menlo Park，CA:The MIT Press，1997．622～628   \n13Tombros A, $\\&$ Sanderson M. Advantages of query biased summaries in information retrieval·In：WB Croft，A Moffat，C J van Rijsbergen，R Wilkinson & J Zobel，ed.Proceedings of the 2lth SIGIR Conference：New York：ACM，1998．2～10   \n14Spark Jones K, $\\&$ Endres-Niggemeyer BIntroductiontouto matic summarizing: IP&M，1995,31(5): 625～630   \n15AllenJNaturalLanguageUnderstanding2ndedeood City，CA :Benjamin/Cummings ,1995   \n16Rau L F, $\\&$ Jacobs P S NL IR: natural language for infoma tionretrieval．International Journal of Intellgent Systems, 1989,4,319\\~343   \n17 McDonald D D．Robust partial-parsing through incremental, multialgorithm processing·In：P S Jacobs，ed·Text-based Intelligent Systems :Current Research and Practice in Infomation Extraction an Retrieval．Hillsdale，NJ：Lawrence Erlbaum,1992.83～99   \n18Cowie J, $\\&$ Lehnert W.Informationextraction.Communica tions of the ACM,1996,39(1):80～91   \n19Jacobs P S $\\&$ RauLF.\"SCISOR\"；extracting infomatiofrom on'line News·Lommunications ot tne AuM，1Jyu,ou(1l）:oo \\~97   \n20Hahn UTopicparsing：accoutingforextmacrostructuresi fulltext analysis:IP&M，1990,26(1):135～170   \n21Sager N. Sublanguage grammars in science information processing: JASIS,1975,26（1):10～16   \n22Rumelhart D E.Notes on a schema for stories·In:D G Bobrow $\\&$ A Cloins，ed·Representationand Understanding:Studies in Cognitive Science:New York：Academic Press,1975.211 ～236   \n23Rumelhart DE.Introduction to Human Infomation Processing·New York：John Wiley $\\&$ Sons，1977   \n24Schank RC.ConceptalIfoationProcesingAstr North Holland，1975   \n25Schank R C $\\&$ Abelson R·Scripts，Plans,Goals and Under standing：An Inquiry into Human Knowledge Structures·Hills dale，NJ：Erlbaum，1977   \n26DeJong G.Skimming newspaper tories bycomputerIn:Pro ceedings of the 5th International Joint Conference on Artificial Intelligence.Cambridge，MA:William Kaufmann,1977.16   \n27Lehnert WGPlotunits:anarraivesummariztionstrategy· In:W G Lehnert $\\&$ M H Ringle，ed． Strategies for Natural Language Processing·Hillsdale，NJ：Lawrence Erlbaum, 1982.375～412   \n28TaitJI.Generatingsummariesusingasriptbasedlanguage analyzer· In: L Steels $\\&$ JA:Campbell，ed·Progress in Arti ficial Intelligence．Chichester，UK：Ellis Horwood，1985. 313 $\\sim$ 317   \n29Fum D,Guida G $\\&$ Tasso CEvaluatingimpoace:astto wards text summarization·In：Proceedings of the Ninth International Joint Conference on Artificial Intelligence·San Mateo, CA:Morgen Kaufmann，1985． 840～844   \n30Berrut C $\\&$ Chiaramella Y.Indexing medical reports ina multimedia environment：the RIME experimental approach·In: Proceedings of the Twelfth SIGIR Conferernce．New York: ACM，1989．181 $\\sim$ 197   \n31Ciravegna F.Understanding messages in a diagnostic domain· IP& M,1995,31(5):687\\~701   \n32Young S R $\\&$ Hayes P J.Automaticlasification and sm marization of banking telexes·In:The Second Conference on Artificial Intelligence Applications：The Engineering of Knowledge Based Systems $\\cdot ^ { \\ast }$ Washington，DC: IEEE Computer Society Press:1985．402～408   \n33Weinstein S P $\\&$ Hayes P J. CONSTRUE/TIS： a system for content-based indexing of a database of exemplars·Journal of Verbal Learning and Verbal Behavior，1991,16:321～338   \n34国ua lnw.domain-enenifin tarhnimnac.In.DS Iaonhe.ad.Tavt",
    "context2": "based Intelligent Systems：Current Research and Practice inInformation Extraction and Retrieval $\\cdot$ Hillsdale：Lawrence Erl-baum,1992.227～241  \n35Appelt D E，Hobbs JR，Bear J， Israel D& Tyson M. FAS-TUS ：a finite-state processor for information extraction from re-alworld text·In：Proceedings of the Thirteenth InternationalJoint Conference on Artificial Intellgence，San Mateo，CA:Morgan Kaufmann．1993.1172～1178  \n36Moens MF, Uttendaele C $\\&$ Dumortier J.Infomationextraction from legal texts：the potential of discourse analysis·Inter-national Journal of Human-Computer Studies：l999,51:1155\\~1171  \n37Maeda T，Momouchi Y $\\&$ Sawamura H. An automatic methodfor extracting significant phrases in scientificor technical documents:IP& M，1980,16:119 $\\sim$ 127  \n38Paice C D.The rhetorical structureof expository text $\\cdot$ In: K PJones，ed·The Structuring of Information（Informatics 11).London：Aslib，1991．1～25  \n39Bernsten C $\\&$ WillimsonREeioflaeretrieval system for a full text knowledge base．JASIS，1984,35(4):235\\~247  \n40Paice C D $\\&$ JonesPA.The indentificationof importantcon-cepts in highly structured technical papers· In: R Koifhage，ERasmussen $\\operatorname { \\& } \\operatorname { \\mathrm { \\mathrm { } } }$ Wilett， ed.Proceedingsof theSixteenth S-GIR Conference：New-York:ACM，1993．69～78  \n41Liddy ED， McVearry K A,Paik Yu E $\\&$ Mckenna M. Devel-opment，implementation and testing of a discourse model fornewspaper texts·In：Human Language Technology·Proceed-ings of a Workshop Held at Plainsboro，New Jersey March 21-24.San Francisco： Morgan Kaufmann，1993.159～164  \n42Rush JE, Salvador R $\\&$ Zamora A· Automatic abstracting andindexing·II.Production of indicative abstracts by the aplica-tion of contextual inference and syntactic coherence criteria·JASIS，1971，22(4):260～274  \n43Paice C D.The automatic generation of iterature abstracts ：anapproach based on the indentification of self-indicating phras-es：In:R N Oddy，S E Robertson，C Jvan Rijsbergen $\\operatorname { \\& } \\operatorname { \\mathrm { \\mathrm { } } }$ WWilliams，ed·Information Retrieval Research·London：But-terworth $\\& \\_ { \\mathrm { { C o } } }$ ，1981，172～191  \n44Brandow R，Mitz $\\kappa \\&$ Rau L F·Automatic condensation felectronic publications by sentence selection· $\\mathbb { P } ^ { \\ell \\mathrm { \\cdot } } \\mathbb { M }$ ,1995,31(5)： $6 7 5 { \\sim } 6 8 5$   \n45Paice C D. Constructing literature abstracts by computer: tech-niques and prospects · $\\mathbb { P } ^ { \\textrm { \\tiny \\textrm { \\textrm { \\tiny \\textrm { \\textrm { \\tiny ~ \\textrm {  } } } } } } } \\mathbb { M }$ ，1990,26(1):171\\~186  \n46Mann W C， Mathiessen C MI M& Thompson S A· Rhetori-cal Structure Theory and Text analysis:In: W V Mann & S AThompson,ed·Discourse Description : Diverse Linguistic Anal-vses of a Fund raising Text·Amsterdam.Iohn Beniamins,1992.39～78  \n47 Hovy E·Automated discourse generation using discouse structure relations·Artificial Intelligence, $1 9 9 3 , 6 3 , 3 4 1 { \\sim } 3 8 5$   \n48Baxendale PB.Machinemade index for technical literatureanexperiment $\\cdot$ IBM Journal of Research and Development，1958,2(4):354\\~361  \n49Kieras DE.Thematic proceses in thecomprehesiondf technical prose·In； B K Britton $\\& \\_ { J }$ B Black,ed·UnderstandingExpository Text·Hillsdale，NJ：Lawrence Erlbaum，1985.89\\~107  \n50 Rama D V $\\&$ Srinivasan P.An investigation of contentrepresentation using text grammars·ACM Transactions on Informa-tion Systems，1993,11(1):51～75  \n51Reichman R·Geting Computers to Talk Like You and Me:Discourse Context，Focus，and Semantics：Cambrige，MA;The MIT Press,1985  \n52EarlLLExperiments inautomaticextractingandindexing.Infomation Storage and Retrieval，197O,6(6):313～334  \n53CoheJDHighlightslanguageanddomainindependentautomatic indexing terms for abstracting·JASIS，1995,46（3）:162～174  \n54Salton G．Automatic Text Processing：The Transformation,Analysis，andRetrievalofIfomationbyComputerading,MA:Addison-Wesley，1989  \n55Salton G，AllanJ,， Buckley C $\\&$ Singhal A: Automatic analys-is，theme generation，and summarization of machine readabletexts · In: M Agosti $\\&$ A F Smeaton，ed·Information Retrievaland Hypertext：Boston：Kluwer Academic Publishers，1994.51\\~96  \n56Jones W P $\\&$ Furnas G W. Pictures of relevance:a geometricanalysis of similarity measures:JASIS，1987，38（6): $4 2 0 \\sim$ 442  \n57Heast M A: $\\&$ Plaunt C.Subtopic structuring for full-lengthdocument acces In: R Korthage， E Rasmussen $\\operatorname { \\& } \\operatorname { \\mathrm { \\mathrm { } } }$ Willet，ed·Proceedings of the Sixteenth SIGIR Conference $: \\ast$ New York:ACM，1993．59～68  \n58Prikhod'Ko S M $\\&$ Skorokhod’KoEF.Automaticabstractingfrom analysis of links between phrases·Nauchno-Tekhni-cheskaya Infomatsiya，Seriya 2，1982,16(1):27～32  \n59Tenfel S，Moens M．Sentence extraction asa clasificationtask：In:Proceedings of the ACL/EACL'97 Intelligent Scal-able Text Summarization Workshop.1997  \n60 Mckeown K $\\&$ Radev D R·Generating concise natural lan\"guage summaries: IP & M，1995，31(5): 703～733  \n61MeDonaldDDoesnaturalgagegeneratiatfromspecification? In: H Horacek $\\&$ M Zock， ed· New Concepts in\\~ 11591  \n62Horacek $\\mathrm { ~ H ~ } ^ { \\& } \\mathrm { { Z o c k } \\textbf { M } }$ ，ed·New Concepts inNturalLanguageGeneration：Planning，Realizationsand Systems·London;Pinter Publishers，1985  \n63Grosz BJ.Foeusing and description innatural language dia-logues： In：A K Joshi，B L Webber $\\&$ I A: Sag, ed· Ele-ments of Discourse Understanding· Cambridge,UK : CambridgeUniversity Press，1981.84～105  \n64Sidner C L·Focusing inthe comprehensionof definite anapho-ra· In:JM Brady& R C Berwick，ed·Computational Modelsof Discourse.Cambridge，MA:The MIT Press，1983. $2 6 7 \\sim$ 330  \n65Bonzi S $\\&$ Liddy E D. The use of anaphoric resolution for doc-ument description in information retrieval·IP & M，1989，25(4)：429～442  \n66Mathis B A，Rush JE $\\&$ Young CEImprovement fautomatic abstracts by the use of structural analysis·JASIS，1973,24(2)：101\\~109  \n67Endres-NigemeyesBContent analysaspecialaseoftext comprehension $\\cdot$ In : S Koskiala $\\& \\mathbf { R }$ Launo ， ed· Informa-tion·Knowledge Evolution：Proceedings of the Forty fourth FIDCongress·Amsterdam：North Holland，1989.1O3～112  \n68Edmundson H.Problems in automaticabstracting·Communi-cations of the ACM,1964,7(4):259～263  \n69苏海菊,王永成·中文科技文献文摘的自动编写·情报学报,1989,8(6):433～439  \n70莫燕，王永成·中文文献摘要的自动编制·现代图书情报技术,1993(3): $1 0 { \\sim } 1 2$   \n71王永成,中文信息处理技术及其基础·上海交通大学出版社,1991  \n72王永成,徐慧·OA中文文献自动摘要系统·情报学报,1997,16(2): $1 2 8 \\mathrm { \\sim } 1 3 2$   \n73陈桂林,王永成,Intermet 网络信息自动摘要的研究·高技术通讯, $1 9 9 9 ( 2 ) , 3 3 \\mathrm { \\sim } 3 6$   \n74姚天顺等．自然语言理解一 一种让机器懂得人类语言的研究·清华大学出版社，广西科学技术出版社,1995  \n75刘挺,吴岩，王开铸·基于信息抽取和文本生成的自动文摘系统设计．情报学报,1997,16(增刊) $2 4 \\sim 2 9$   \n76王建波,杜春玲,王开铸．基于篇章理解的自动文摘研究．中文信息学报, $1 9 9 5 , 9 ( 3 ) { \\scriptstyle : 3 3 \\sim 4 2 }$   \n77杨小兰，宋帆,钟义信·基于选择生成文摘法的自动文摘系统研究与实现·见：全国第四届计算语言学联合学术会议论文集,北京:清华大学出版社,1997. $3 1 3 { \\sim } 3 1 8$   \n78刘伟权·自然语言理解与汉语文本信息处理理论研究：〔博士论文]·北京邮电大学图书馆,1997  \n79李蕾,郭祥昊,钟义信·面向特定领域的理解型中文自动文摘系统·计算机研究与发展,2000,37（4)： $6 \\sim 1 0$"
  }
}