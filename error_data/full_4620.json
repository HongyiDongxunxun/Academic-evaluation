{
  "original_filename": "full_4620.md",
  "$\\bullet$ 马浩，崔运鹏（中国农业科学院农业信息研究所，北京100081)": "",
  "基于混合深度学习模型的科技文献自动综述模型构建研究": {
    "context1": "摘要：回的/意义]在大数据时代，如何高效地进行科技文献知识组织与服务已成为图情领域的研究热点。因此，开展科技文献综述自动生成模型研究具有重要意义。防法/过程文章中，综述的自动构建分为两步：首先基于语步理论对输入文本的句子按语步类别进行识别与抽取，然后以各类语步的句子集为输入通过生成模型进行综述生成。研究分别基于SciBERT深度学习模型和Transformer网络构建了语步识别模型和综述文本生成模型。结果/结论]语步抽取模型整体识别效果评价 $F 1$ 值达到 $8 7 . 1 2 \\%$ ，生成模型的生成效果与TextRank 模型和BiLSTM模型相比在ROUGE-、ROUGE-2和ROUGE-L三项评价指标上分别提高了 $4 . 5 \\%$ 、 $2 . 9 \\%$ 和 $3 , 3 \\%$ 。研究完成了科研文献综述自动生成任务的整体模型构建与实现。",
    "context2": "关键词：科技文献；自动综述；语步识别；深度学习模型；SciBERT",
    "context3": "DOI:10.16353/j.cnki.1000-7490.2021.09.025",
    "context4": "引用格式：马浩，崔运鹏，基于混合深度学习模型的科技文献自动综述模型构建研究，情报理论与实践，2021，44(9):176-82，168."
  },
  "Research on the Construction of Model for Automatic Review of Scientific Literatures Based on Hybrid Deep Learning Model": {
    "context1": "AbstractPurpose/significance]Intheeraofbigdata，howtoeficientlyprovide knowledge organizationandserviceof scientificliteratureshasbecomearesearchhotspotinthefieldofibraryandinformationscienceTherefore，itisofgreatsignificance tostudytheautomaticgenerationmodelof scienticliteraturesreview.Method/process]Inthispaper，thereviewisconstructed in twosteps:firstly，themodelidentifiesandetractsthesentences intheinputextaccording totherhetoricalmovetheory.hen, withallkindsofsentencesetsasinput，theeviewisgeneratedthroughthegenerationmodel.BasedonSBERTandTrasforer, this paper constructs a move recognition model and text generation model.Result/conclusion] The $F 1$ value of the move recognition model reached 87. $12 \\%$ . Compared with TextRank model and BiLSTM model，the evaluation results of the generated model are improved by $4 . 5 \\%$ ， $2 . 9 \\%$ and $3 , 3 \\%$ in the three evaluation indexes of ROUGE-1，ROUGE-2 and ROUGE-L，respectively. This paper constructs and implements the overall model of automatic generation task of scientific literatures review.",
    "context2": "Keywords:scientific literature；automatic review；move recognition； deep learning model; SciBERT",
    "context3": "万维网的诞生使得世界正在被海量的数据所覆盖，据统计全世界每天发表的论文量超过一万篇。为紧跟科学前沿发展趋势，众多高校和图书馆都构建了自己的电子文献数据库。以中国农业图书馆为例，截至2018年底，其构建的中国农业科技文献与信息服务平台共引进网络版数据库80余种，包括外文数据库60余个，中文数据库11个。面对丰富的文献资源，开展提高图书馆文献知识组织和服务效率的研究变得尤为迫切且重要。文献综述自动生成是科技文献自动摘要领域的具体研究应用之一，其任务内容可以简单描述为：程序输入一系列同一研究主题的科研文档集合，旨在输出一篇能描述该研究主题研究现状的文本。这种对多文档科技信息进行抽象总结和归纳的研究能够有效地提高信息的获取效率，但是由于其较高的复杂性和困难度使之相比于单篇科研文献的自动摘要研究发展较缓。",
    "context4": "究其原因，Teufel和Moens认为科学文章与普通文本其实有三个方面的区别。首先，与普通文本不同，科学论文具有特定的结构，这种结构通常以引言开始，然后是相关的工作、方法论、实验和发现，最后是结果和含义;其次，科学文章通常比普通文章更长；最后，由于研究人员需要从文章中寻找新的贡献、发现和提出的解决方案，因此信息获取的目标也不是唯一的。由此可见，对科研文献进行信息的精练和抽取本就是一项艰难的工作。同时区别于普通文章的多文档摘要对多篇文档信息和内容的直接糅合，科研文献的文献综述生成任务还要求生成文本具有一定的结构性，即对研究的背景和目标、方法、结果及结论的分别总结与讨论。虽然基于目前的自然语言处理技术完整实现文献综述生成任务仍充满挑战，但是本研究仍基于语步理论融合目前性能领先的深度学习模型，对文献综述生成任务进行了探索性实现。具体步骤是首先对多文档的科研文献摘要进行语步分类抽取，然后对抽取得到的句子集合进行生成，以分步化方式实现对多文档科研文献自动综述的模型构建研究。"
  },
  "1相关研究": "",
  "1.1文献综述生成研究": {
    "context1": "在21世纪到来之际，眼光长远的科学家们就已意识到在新的纪元信息量将呈爆炸式的增长，而高效获取和利用各种信息和数据的方法必将会成为驾驭巨量信息的缰绳。面对科研文献数量的快速增长，1999年Nanba就首次提出生成特定领域科研文献综述的系统的构想，在2003年郑义利用Textiling算法对新闻的文本段进行识别与分割，再对通过聚类得到的各功能集进行抽取、排序，最后聚合生成综述。2004年葛加银等在郑义研究的基础上提出了基于实体名的文本自动综述方法。2010年，为实现文献综述的自动生成任务Hoang和 $\\mathrm { K a n } ^ { \\perp }$ 设计了一个自动摘要器ReWoS，其具体功能是根据句子内容分别采取不同的后发式规则，并通过一棵人工构造的主题树来组织文摘句，以达到提高生成文摘的可读性的目的。在此基础之上，2012年Agarwal等提出了一个无监督的自动摘要器SciSumm，其在以多文档自动摘要系统MEAD为基线的实验中表现出色。相对应的， $\\mathrm { H u }$ 和Wan在2014年利用有监督的方法构造了自动摘要器ARWG，他们的方法分为两个阶段，首先利用概率潜在语义索引（Proba-bilisticLatent SemanticIndex）按照不同主题对文摘句的候选集进行划分，再利用一种回归技术来评判每个句子的重要性。与此类似，在2016年Zhang和Liu提出了一种基于引用聚类的多文档自动摘要方法[，其方法的核心以引用位置为依据对引文集合做聚类分析，然后对各个类簇中的多篇文档利用LexRank $^ +$ MMR算法予以概括，同时他们还发现基于摘要生成的“评述性综述”效果更好。Chen等则认为其实可以将“文献综述生成”看作一个顶点覆盖问题，首先通过从引文集合中选择代表性的关键词来建立一颗最小斯坦纳树，然后以抽取尽可能少的文摘句来覆盖该树为目标进行生成[]。",
    "context2": "上述文献综述生成研究基本都使用了传统的机器学习方法，主要依赖于人工经验预先从文本数据中提取属性特征，再通过机器学习执行预测或者分类算法，这使得科研工作者不得不花费大量的时间和精力去完成数据的观察、标注等预处理工作，从而限制了这些方法的应用规模。此外，由于人工提取的特征往往缺失很多的内在信息，因此导致计算机对文本数据的表示能力十分的弱，进而影响了最终生成文本的质量。"
  },
  "1.2科研文献中的语步识别研究": {
    "context1": "语步是语言学概念，概念最初是由Swales提出的，其目的是为了实现完整交流的目的而在功能上描述研究文章的一部分或章节[。研究论文中的语步是对论文阅读者认知起关键作用的信息，也可以说是一篇研究论文的核心框架，这些信息可以为研究人员提供一个简明扼要的论文整体概念，对于那些需要通过阅读一系列研究论文来了解自己研究领域研究现状的研究人员来说，能高效的获取这些信息将使其科研活动事半功倍。在科技文献的摘要中，研究论文的作者通常需要以摘要的形式解释研究的背景与目标、方法、结果和结论等要素，而这些要素就可以被称为科研文献摘要的语步，能够精炼地反映科研文献所希望表达的主要意图。之前的研究者在进行科技文献综述生成研究时大多都集中在利用引文及其背景在创建摘要中的作用，并使用引用信息对要提取的内容进行排名，对于预期生成的科研文献综述的文本结构他们并没有做太多考虑。为实现文献综述内容的结构性，本文选择首先研究科学论文中的语步结构，并将其应用到文献综述生成研究之中。",
    "context2": "语步识别研究的早期主要采用传统的机器学习方法。Teufel和Moens在2002年提出了非常严谨的论述结构AZ（Argumentative Zoning）的概念，用以对科学文献进行更精细的分析，并对自己构建的来自计算语言学领域的80 篇会议文章的数据集利用朴素贝叶斯的方法进行了实验。在Teufel研究的基础上Lin等在2006年利用HMM（隐马尔可夫模型）对研究论文摘要中的句子作用类别进行了划分[。同样受Lin等的研究的后发，2008年 Hiro-hata 等利用条件随机场（CRF）对来自Medline的包含五万多条摘要的研究数据集进行了实验并取得良好效果[14。这些传统方法具有良好的识别性能，但应用非常复杂，因为它们基本都严重依赖大量精心设计的手工处理，例如词汇、语义、结构以及统计和顺序特征。2019 年张智雄等完成了不同深度学习模型的科技论文摘要语步识别效果对比研究[，认为深度学习方法在语步识别研究中具有较大潜力。"
  },
  "2方法": {
    "context1": "近年来蓬勃发展的神经网络具有很强的非线性拟合能力，可以自动地学习更好、更深入的输入表示而无须进行复杂的特征工程。在本文中即利用了SciBERT深度学习模型[和Transformer[网络通过分步化方式实现具有一定结构性的文献综述生成研究。本节将详细介绍科技文献综述生成研究的实现方法。如上文所述，本文所提出的文献综述生成模型分由两部分组成： $\\textcircled{1}$ 语步识别与抽取模型MRM（Move Recognition Model）。 $\\textcircled{2}$ 综述文本生成模型LRGM（Literature Review Generation Model）。语步识别与抽取模模型的任务是基于语步理论对输入文本进行语步的识别和抽取，从而得到具有不同语步功能的句子集合；综述文本生成模块负责利用上一步得到的句子集合进行文本生成，具体流程见图1。",
    "context2": "![](images/b76b47e00b97e8f1021f587b4a14cc52de7534b68456f09ab953543a2a418e51.jpg)  \n图1数据与实验流程"
  },
  "2.1语步识别与抽取模块": {
    "context1": "在进行文献综述生成之前，必须先考虑输入生成模型的文本来源。目前很多关于科研文献摘要的研究都是利用一篇已有文献的引文中的句子作为输入文本来生成这篇文献的“评述性摘要”，这样的摘要通常只是作为已有摘要的补充。引文句作为输入在此任务下表现确实较好，但是本研究的目标是基于已有的文献集合生成一篇新的文献综述，在这样的目标下引文句显然并不符合要求。摘要是一篇文献内容的高度凝练，在本研究中即选取科技文献的摘要作为文本处理的对象，并基于语步理论对摘要的整体信息结构进行剖解。",
    "context2": "虽然目前很多学术期刊出版的论文都采用了结构化的摘要，论文作者在提交论文时也通常已经按照固定的结构化摘要模式撰写摘要，指明其论文的目的、背景、方法、结果、结论等。但是，这并不是整体统一要求，未进行结构化摘要论文出版的期刊仍有很多，要对非结构化摘要的内容进行语步的识别和抽取仍是一个较难解决的问题。本研究通过分析摘要的信息结构将摘要所具有的语步类别确定为：背景、目标、方法、结果、结论，一共五类，而文献摘要中的所有句子都可以根据其语步功能归纳到相应类别之中。则任务定义为：对于一篇文献的摘要 $Z$ ，其包含的句子集合为 $S = \\left\\{ { { s } _ { 1 } } , { { s } _ { 2 } } , { { s } _ { 3 } } , \\cdots , { { s } _ { n } } \\right\\}$ ，设已有的语步类别标签集合为 $C = \\{ c _ { 1 } , c _ { 2 } , \\cdots , c _ { m } \\}$ ，存在一个函数 $f ( \\boldsymbol { s } _ { i } , \\boldsymbol { s c } _ { j } )$ ，对于$\\forall s _ { i }$ 其中 $i \\in \\ U , n ]$ ， $\\exists c _ { j }$ 其中 $j \\in \\ [ 1 , m ]$ 使得 $f ( \\boldsymbol { s } _ { i } , \\boldsymbol { s c } _ { j } )$ 取得最大值，即此时句子 $s _ { i }$ 的语步类别标签为 $c _ { j }$ 。",
    "context3": "这种按类划分不同信息内容的形式使得非结构化摘要内容的语步识别与抽取任务可以转化为一个文本分类任",
    "context4": "务，即通过利用带标注的句子对神经网络模型进行训练，得到一个针对科研文献摘要语步的分类器，以实现对所有类型摘要的语步识别与抽取。",
    "context5": "本研究用于构造分类器MRM（Move Recognition Mod-el）的神经网络模型是SciB-ERT（scibert_scivocab_un-cased）预训练模型，SciB-ERT是BERT经过科学文本训练后得到的预训练模型，并拥有针对科学文献的词汇表（Scivocab）。本文在研究中选择对SciBERT预训练模型进行微调训练并增加了一个额外的输出层，选择",
    "context6": "取模型[CLS]标签的最终隐层状态 $L \\in R ^ { \\beta }$ 乘上一个权重矩阵 $\\ b { W } \\in \\ b { R } ^ { \\alpha \\times \\beta }$ ，其中 $\\alpha$ 为语步类别标签个数（ $( \\alpha = 5 )$ ，最后通过一个softmax层来得到句子语步类别的概率（如公式（1）所示)，以使其满足实现科研文献语步分类的任务要求：",
    "context7": "$$\nP = \\mathrm { s o f t m a x } ( L W ^ { T } )\n$$",
    "context8": "结合之前的任务定义，最大概率 $P _ { \\mathrm { { M a x } } }$ 对应 ${ f ( \\boldsymbol { s } _ { i } , \\boldsymbol { s c } _ { j } ) }$ ，即句子 $s _ { i }$ 的语步类别标签为 $c _ { j }$ ,并将 $s _ { i }$ 纳入语步标签为 $c _ { j }$ 的句子集合 $C _ { j }$ 。",
    "context9": "本研究进行微调训练所使用的数据集是由Franck等于2017年所发布的 $\\mathrm { P u b M e d } _ { - } 2 0 \\mathrm { k } _ { - } \\mathrm { R C T }$ 数据集。PubMed_20k_RCT数据集包含超过20万条带标注且来自基于PubMed数据库的生物医学领域文献摘要句子，其中总标注类型与上文确定的摘要语步类别一致，分别为：背景（Background），目标（Objective），方法（Methods），结果（Results），结论（Conclusions)；各标注类型句子在数据集中的相对比例约为 (按上述顺序)： $1 . 5 \\colon 1 : 4 : 4 : 2$ 。经过预处理，最终得到训练数据，其中训练集：162000条，开发集：18040条，测试集：30135条，平均句子长度约为34个tokens。模型训练参数设置：最大输入长度为128，训练批次为22506，其中批次大小（batch size）为8，Dropout值为0.1，学习率设置为 $4 \\mathrm { e } ^ { - 5 }$ ，优化器（Opti-mizer）选择Adam。最终实验结果见表1。",
    "context10": "表1MRM模型语步识别训练结果",
    "context11": "<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Precision</td><td rowspan=1 colspan=1>Recall</td><td rowspan=1 colspan=1>F1</td></tr><tr><td rowspan=1 colspan=1>Background</td><td rowspan=1 colspan=1>69.28</td><td rowspan=1 colspan=1>78.51</td><td rowspan=1 colspan=1>73.60</td></tr><tr><td rowspan=1 colspan=1>Objective</td><td rowspan=1 colspan=1>75.34</td><td rowspan=1 colspan=1>57. 27</td><td rowspan=1 colspan=1>65.07</td></tr><tr><td rowspan=1 colspan=1>Methods</td><td rowspan=1 colspan=1>92.03</td><td rowspan=1 colspan=1>95.59</td><td rowspan=1 colspan=1>93.77</td></tr><tr><td rowspan=1 colspan=1>Results</td><td rowspan=1 colspan=1>92.08</td><td rowspan=1 colspan=1>92. 17</td><td rowspan=1 colspan=1>92.18</td></tr><tr><td rowspan=1 colspan=1>Conclusions</td><td rowspan=1 colspan=1>86.85</td><td rowspan=1 colspan=1>81.22</td><td rowspan=1 colspan=1>83.94</td></tr><tr><td rowspan=1 colspan=1>avg (平均值)weightedavg（加权平均值）</td><td rowspan=1 colspan=1>83.1287. 23</td><td rowspan=1 colspan=1>80.9587.28</td><td rowspan=1 colspan=1>81. 7187.12</td></tr></table>",
    "context12": "由表1可知，在所有标签中Methods和Results的识别效果最好， $F 1$ 值均达到了 $90 \\%$ 以上，而标签Objective 的识别效果最不理想只达到了 $6 5 . 0 7 \\%$ ，还存在较大改进空间。对于模型的整体语步识别效果的评价，由于语料分布并不均衡所以本文采取加权平均各个标签的 $F 1$ 值的方式进行计算，权重根据测试集各标签类别比例确定，本模型最终的训练结果 $F 1$ 值 $= 8 7 . 1 2 \\%$ 。本文选取了当前主流预训练模型 BERT，RoBERTa， $\\mathrm { X L N e t } ^ { \\mathtt { [ 2 ] } }$ ，ALBERT作为基线模型进行了对比实验，在相同数据集下本文模型表现最佳（见表2），并优于Beltagy等[利用SciBERT在此数据集上所取得的结果，达到了构造综述文本生成模型的基本要求。",
    "context13": "表2语步识别模型实验结果对比",
    "context14": "<table><tr><td rowspan=1 colspan=1>模型</td><td rowspan=1 colspan=1>F1值</td></tr><tr><td rowspan=1 colspan=1>BERT(bert-base-uncased)</td><td rowspan=1 colspan=1>86.09</td></tr><tr><td rowspan=1 colspan=1>RoBERTa(roberta-base)</td><td rowspan=1 colspan=1>86.61</td></tr><tr><td rowspan=1 colspan=1>XLNet (xlnet-base-cased)</td><td rowspan=1 colspan=1>86.58</td></tr><tr><td rowspan=1 colspan=1>ALBERT(albert-base-v2)</td><td rowspan=1 colspan=1>85.61</td></tr><tr><td rowspan=1 colspan=1>SciBERT(Beltagy et al，2018)</td><td rowspan=1 colspan=1>86.80</td></tr><tr><td rowspan=1 colspan=1>MRM (Our Model)</td><td rowspan=1 colspan=1>87. 12</td></tr></table>"
  },
  "2.2综述文本生成模块": {
    "context1": "本模块的功能是，利用由语步识别与抽取模块得到的各语步类别的句子集合 $C _ { j }$ 作为文本生成模型的输入序列，并按背景和目标、方法、结果及结论的语步顺序结构分段生成，最终生成具有语步结构的文献综述。本研究构建了文献综述生成模型LRGM（Literature Review GenerationModel）见图2，模型主要结构为一个12层的Transformer结构，其中包含12个自注意力头，隐层向量维度为768。本节的任务定义为：对于源序列 $x \\ \\in \\ C _ { j } \\ = \\ \\{ \\cdots , s _ { i } , \\cdots \\}$ ，$\\textit { x } = \\{ x _ { 1 } , x _ { 2 } , x _ { 3 } , \\cdots , x _ { o } \\}$ ，其中 $x _ { i } ~ \\in ~ V$ $V$ 表示由30522个 to-$\\mathrm { k e n }$ 构成的词汇表）是一系列输入文本的源 tokens，令$y \\ = \\{ \\ : y _ { 1 } \\ : , y _ { 2 } \\ : , y _ { 3 } \\ : , \\cdots , y _ { g } \\}$ 为目标序列， $y _ { j } ~ \\in ~ V$ 是参考序列的tokens，训练目标是使用Transformer体系结构对条件概率分布 $P ( \\boldsymbol { y } \\mid \\boldsymbol { x } )$ 进行建模得到最佳模型。本研究模型的损失函数为公式（2），其中 $x$ 为输入序列和 $y$ 为 $j$ 时间步之前的目标序列。",
    "context2": "$$\nL ( \\mathbf { \\theta } \\mathbf { \\theta } ) = - \\sum _ { j = 1 } \\log P ( \\mathbf { \\theta } _ { y _ { j } } \\mid \\mathbf { \\alpha } _ { y } \\mathbf { , } x )\n$$",
    "context3": "由于本研究的任务是学术文献综述的自动生成，基于科学研究本身的严肃性和真实性，本文认为对于学术文献来说在利用模型进行文本生成研究时不仅要将文本的可读性和内容的丰富性纳入研究的目标，更重要的是要保证生成内容相较于源文本的事实准确性。目前精炼文本信息主要有两种生成方式：抽取式和生成式。抽取式因其生成结果主要是复制源文本中的句子和词，所以在语法、句法上错误率低而事实准确性强；而生成式的过程更像人类进行写作的方式，模型先“理解”源文本的信息内容然后再对文本进行自组织概括，虽然其灵活性和概括性更好但是事实准确性还有待提高。为在保持生成结果灵活性和概括性的同时提高其事实准确性，Song等认为可以通过提高生成文本中对源文本的复制比例来提高信息的事实准确性。由此本研究在模型训练时通过增加训练文本中参考序列重复输入序列中词汇的比例使得模型在训练中学习更多复制能力。",
    "context4": "![](images/dd1b7ba269876323d5f0545ad1658c2c5705e161bc1913b776aa1a34ea2e73ee.jpg)  \n图2LRGM(Literature Review Generation Model) 模型输入结构",
    "context5": "针对训练语句本文设定了三个特殊标记：START，END 和MASK，它们分别表示序列的开始、结束和掩码标记。对于输入文本序列 $x$ 通过在开头添加“START”并在其末尾添加“END”来构造标识，与此类似目标序列 $y$ 通过在摘要结尾附加“END”来构建，同时目标序列结尾的“END”标识也被作为模型在文本生成的训练过程中文本生成的边界标识，使模型学习在何时停止文本生成。在编码端，输入表征方式与 BERT的构建方式一致，由 token,position，segment三种嵌入方式合成输入。同时本文使用了参数绑定，从而允许在Transformer模型的输入层和最终 softmax层中使用相同的 token嵌入。LRGM骨干网络由12层Transformer组成，输入序列 $\\left\\{ x _ { i } \\right\\} _ { i = 1 } ^ { o }$ 首先会经过三个嵌入层的叠加得到具有上下文信息的向量，然后送入该12层Transformer网络（见图2）被转换成文本表征向量$H _ { \\mathbf \\Phi } = \\{ h _ { 1 } , \\cdots , h _ { \\mathbf \\Phi _ { o } } \\}$ ,其中每一层编码输出见公式（3)：",
    "context6": "$$\nH _ { \\mathit { \\Phi } } ^ { l } = \\mathrm { T r a n s f o r m e r } _ { \\mathit { l } } \\left( \\mathit { \\Pi } _ { \\mathit { \\Pi } } H ^ { l - 1 } \\right)\n$$",
    "context7": "此外，本文研究参考了Dong等在研究中对 Trans-former框架结构的自注意机制应用的掩码矩阵设计（见图3），其目的是让模型在训练过程中允许源文本token的信息能被包括其自身在内的所有源文本获取，而参考摘要当前时间步的token则可以获取所有源文本还有之前时间步的摘要token的信息，从而学习到深入的上下文表示。通过这样的掩码矩阵 $M$ 在每一个Transformer层控制每个词的注意力范围，其中当取值为0时表示可以获取信息，取值为负无穷则表示会被掩码掉而不能获取信息。对于第l-thTransformer层，其自注意头 $A _ { l }$ 的注意力分布输出的计算方式为：",
    "context8": "$$\nQ \\ : = \\ : H ^ { l - 1 } W _ { l } ^ { Q } , K \\ : = \\ : H ^ { l - 1 } W _ { l } ^ { K } , V \\ : = \\ : H ^ { l - 1 } W _ { l } ^ { V }\n$$",
    "context9": "$$\nM _ { i j } = \\left\\{ \\begin{array} { l l } { { 0 , } } & { { \\overline { { { \\sf { e J } } } } \\bot \\chi _ { 3 \\mathrm { { R } } } ^ { + } \\tt { b } \\breve { { e } } \\breve { { e } } \\breve { { e } } \\breve { { e } } } } \\\\ { { - \\infty , } } & { { \\overline { { { \\sf { e J } } } } \\bot \\chi _ { 3 \\mathrm { { R } } } ^ { + } \\tt { b } \\breve { { e } } \\breve { { e } } \\breve { { e } } } } \\end{array} \\right.\n$$",
    "context10": "$$\n{ A _ { l } } \\ = \\ \\mathrm { s o f t m a x } \\bigg ( \\frac { Q K ^ { \\mathrm { T } } } { \\sqrt { d _ { k } } } + M \\bigg ) V _ { l }\n$$",
    "context11": "公式（6）中， $Q , K , V$ 分别表示自注意力机制计算过程中的查询（Query）向量矩阵、键（Key）向量矩阵和值（Value）向量矩阵，是通过嵌入向量 $H$ 乘以三个不同的权值矩阵 $\\mathbb { W } _ { l } ^ { Q }$ ， $\\boldsymbol { W } _ { l } ^ { K }$ ， $\\boldsymbol { W } _ { l } ^ { V }$ 得到，如公式（4）所示。查询向量矩阵 $Q$ 和键向量矩阵 $K$ 进行点乘得到注意力分数，考虑到维持梯度稳定的问题再除以 $\\sqrt { d _ { k } }$ ，其中 $d _ { k }$ 为查询向量和键向量的维度。 $\\frac { Q K ^ { T } } { \\sqrt { d _ { k } } }$ 与掩码矩阵 $M$ 对应相加后通过softmax进行归一化，最后再与值向量矩阵 $V _ { l }$ 相乘得到相应的注意力分布 $A _ { l }$ 。",
    "context12": "在Decoder阶段，对于给定训练有素的模型和输入文本，解码阶段将搜索使 $P ( \\boldsymbol { y } \\mid \\boldsymbol { x } )$ 最大化的摘要序列。在这一阶段本文使用的是波束搜索（Beam Search），其本质上是广度优先搜索。它在任何时间步长都保持大小为 $t$ 的波束，其中包含相同长度的正在生成过程中的部分摘要。对于每个部分摘要来说扩展一个单词，都需要通过该算法将概率 $\\log P ( \\boldsymbol { y } _ { j } \\mid \\boldsymbol { y } , \\boldsymbol { x } )$ 最高的前 $t$ 个词附加到部分摘要中从而生成 $t$ 个新序列。该过程通过扩展 $t$ 个部分摘要中的每一个摘要总共生成 $t ^ { * } \\ t$ 个新摘要序列，最后算法选择 $t$ 个最佳候选，并将其放入波束中以进行下一次迭代。如果候选摘要以句子结尾符号“END”结尾，则表示生成结束应将其移至“已完成摘要”库中。",
    "context13": "![](images/e0240db094fa8be3acfc0b18a74de3a4e5f40501dfa730504d70110dce9e566c.jpg)  \n图3文本生成模型Transformer框架结构的自注意机制的掩码矩阵设计"
  },
  "3实验": {
    "context1": "由于综述文本生成模块为本文主要研究部分，所以在本部分中进行详细描述。"
  },
  "3.1数据集": {
    "context1": "目前可用于科技文献 Seq-to-Seq训练的语料库十分有限，本研究所用语料来自Zanzotto等创建的GASP（Generating Abstracts of Scientific Papers）数据集，他们认为科学论文的创作就是一种文本到文本的过程，特别是综述性文章更是如此，由此他们进行了通过获取被引论文的摘要生成引用论文摘要的多文档文本生成的研究，并为此构建了GASP数据集，其中语料内容主要涉及生物及医学领域。",
    "context2": "GASP语料库基于 Semantic Scholar构建而成，一共选择了至少有一篇引用文献的120000 篇论文，构建了训练集，测试集和验证集分别为100000、10000和10000 实例的数据格式为JSON的数据集。数据集中大多数目标摘要的长度在400个单词以下，其中词汇量的峰值在100,150，200，250，300和400处，摘要的长度最多达到了1400个字。本研究在进行模型训练之前对语料进行了预处理，对长度超过510个token的摘要进行了截取以满足模型最大输入的限制要求，其中截取方式采用了Sun等在研究中所采用的“head $^ +$ tail”即截取文本头尾部分的方法，以最大程度减少信息遗失。"
  },
  "3.2训练参数设置与评价指标": {
    "context1": "模型训练主要参数设置：波束搜索范围值（beam_size) $t = 1 0$ ，序列最大输入长度为512，Dropout值为0.1,学习率设置为 $4 \\mathrm { e } ^ { - 5 }$ ，批次大小（batch size）为32，训练时期（epoch）为18轮，优化器（Optimizer）选择Adam。在训练过程中本文采取在每一轮epoch结束之后进行一次模型保存，并在验证集上对目前训练的模型进行评估，选取loss值最小的模型为最佳模型并保存，若下一轮epoch得到的模型loss值更低则保存更新最佳模型。在本研究中，在epoch进行到第12轮后最佳模型不再更新，即为最后保存的最佳模型，训练过程见图4。",
    "context2": "![](images/9db059dc97f1c594f940d21f5c2bc9aa56a301c4e832042600fe4370ae1ebdb4.jpg)  \n图4训练过程loss值变化情况",
    "context3": "模型训练完成之后，为验证模型效果，本文采用了目前在文本摘要任务中最常用的评价方法ROUGE来对模型生成结果进行评估，并在最后的评估中计算了生成序列的N-ROUGE( $N = 1 , 2 )$ 和L-ROUGE值。"
  },
  "3.3基线对比模型": {
    "context1": "为了更好地衡量研究所提出的模型的效果，参考Zanzotto等d的工作分别利用 TextRank 和BiLSTM构造的模型在GASP语料库上进行训练后得到的ROUGE评估结果作为基线对比。其中TextRank模型是使用TextRank算法构建的，输入摘要被连接为一个由换行符分隔的文档作为模型输入。TextRank算法是一种典型的提取式文本摘要算法，其本质是基于图的一种排序算法，通过把文本分割成若干个句子并用向量表示构建节点连接图，再用句向量之间的相似度作为边的权重，通过循环迭代计算句子的TextRank值，最后抽取排名高的一部分句子组合成文本摘要。",
    "context2": "BiLSTM模型是用于文本摘要的标准序列到序列系统，该系统使用针对序列标记问题的最大似然损失函数进行训练。模型的输入序列由输入摘要组成，这些摘要被连接为一个完整的文档并由标签SEP] 分隔以界定摘要的结尾和下一个摘要的开头，输出序列即为生成文本。本文中的模型采用双向LSTM构造并带有复制机制，该机制允许将输入单词复制到输出序列中。"
  },
  "3.4结果与讨论": {
    "context1": "实验对比结果见表3。",
    "context2": "表3文本综述生成模型生成结果",
    "context3": "<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>R1Recall</td><td rowspan=1 colspan=1>R1Precision</td><td rowspan=1 colspan=1>R1F1</td><td rowspan=1 colspan=1>R2Recall</td><td rowspan=1 colspan=1>R2Precision</td><td rowspan=1 colspan=1>R2F1</td><td rowspan=1 colspan=1>RLRecall</td><td rowspan=1 colspan=1>RLPrecision</td><td rowspan=1 colspan=1>RL F1</td></tr><tr><td rowspan=1 colspan=1>TextRank</td><td rowspan=1 colspan=1>0.325</td><td rowspan=1 colspan=1>0.118</td><td rowspan=1 colspan=1>0.161</td><td rowspan=1 colspan=1>0.053</td><td rowspan=1 colspan=1>0.018</td><td rowspan=1 colspan=1>0.024</td><td rowspan=1 colspan=1>0.207</td><td rowspan=1 colspan=1>0.074</td><td rowspan=1 colspan=1>0.101</td></tr><tr><td rowspan=1 colspan=1>BiLSTM</td><td rowspan=1 colspan=1>0.109</td><td rowspan=1 colspan=1>0.334</td><td rowspan=1 colspan=1>0.154</td><td rowspan=1 colspan=1>0.019</td><td rowspan=1 colspan=1>0.058</td><td rowspan=1 colspan=1>0.027</td><td rowspan=1 colspan=1>0.077</td><td rowspan=1 colspan=1>0.238</td><td rowspan=1 colspan=1>0.108</td></tr><tr><td rowspan=1 colspan=1>LRGM (Our Model)</td><td rowspan=1 colspan=1>0.568</td><td rowspan=1 colspan=1>0.134</td><td rowspan=1 colspan=1>0.216</td><td rowspan=1 colspan=1>0. 147</td><td rowspan=1 colspan=1>0.034</td><td rowspan=1 colspan=1>0.056</td><td rowspan=1 colspan=1>0.403</td><td rowspan=1 colspan=1>0.085</td><td rowspan=1 colspan=1>0. 141</td></tr></table>",
    "context4": "评估中计算了N-ROUGE( $N = 1 { , } 2$ ）和L-ROUGE的召回率Recall值用来衡量生成文本的重要度，精确值Preci-sion值用来衡量生成文本的冗余度，召回率和精确值的调和平均值 $F 1$ 值则表示生成模型的总体表现。",
    "context5": "从结果来看以抽取为主的TextRank算法模型具有较高的召回率和较低的精度，本文认为出现这种情况的原因是TextRank算法是从原序列中抽取句子，所以会有较多的单词重复出现，但是生成的文本过于冗余导致精确率较低。相反，以抽象生成为主的BiLSTM模型由于更多的生成了原序列中没有的单词导致召回率更低，但是其精确率更高，说明生成的文本信息更加精炼。",
    "context6": "基于科研文献文本生成过程中对生成结果真实可靠性的更高要求，研究中模型在进行训练时就有意的提高生成序列对源序列的复制比例，所以在各项ROUGE指标评估的最终结果中召回率和F1值均在对比模型中达到最佳表"
  },
  "现，分别较基线模型最佳指标提高了 $4 . 5 \\%$ 、 $2 . 9 \\%$ 和$3 , 3 \\%$ ，同时在降低生成文本冗余度的方面也相较Tex-tRank模型得到改进。": "",
  "4结束语": {
    "context1": "本文为提高现代图书馆文献知识组织与服务的水平，开展了科研文献综述自动生成任务的研究。在对前人研究进行分析之后，在本研究认为基于语步理论对原始的文献信息进行划分并提取将提高获取信息的功能密度，而通过生成模型按语步类别进行文本生成的方法可以构建具有背景和目标、方法、结果及结论的语步结构的综述文本。所以在研究中采取分步化方式，构建了由基于语步理论的语步识别与抽取模块和综述文本生成模块构成的科研文献综述自动生成模型，其中生成模型LRGM在GASP数据集上达到了目前最佳表现。",
    "context2": "本研究目前还有一些明显的不足，首先语步识别模型的识别效果仍有待提高，其次在生成实验中无论是作为基线的对比模型还是本文所提出的模型其总体的ROUGE值评价结果其实都不太理想，与在其他公开数据集所进行的生成实验结果相比差距也很明显。这既反映了科研文献综述生成任务本身的困难程度，也说明这一任务的研究空间还很充足。另一方面，本文的研究工作为科研文献综述生成任务提供了一个具有一定可行性的研究思路，并计划在今后的工作中进一步完善语步识别和抽取效果，同时在文本生成过程中更好地协调生成文本的冗余度和精确度，争取让科研文献综述生成模型的在图书馆知识服务系统中的实际应用更近一步。□"
  },
  "参考文献": {
    "context1": "[1]GUO Jianfeng，et al. Measurement framework for assessing disruptive innovations[]．Technological Forecasting & Social Change，2019:250-265.   \n[2] CARLEY SF，et al.A measure of staying power is the persistence[．Scientometrics，2017，111:2077-2087.   \n[3] PORTERA L，et al．Emergence scoring to identify frontier R&D topics and key players[．Technological Forecasting & Social Change，2019:628-643.",
    "context2": "．中国工程科学，2017，19（1)：133-42.[7] “中国工程科技2035发展战略研究”项目组．中国工程科技2035发展战略·综合报告[M]．北京：科学出版社，2019.",
    "context3": "作者简介：谭玉珊，女，1972年生，硕士，研究员。研究方向：科技信息大数据建设。罗威，男，1979年生，硕士，正高级工程师。研究方向：科技信息大数据建设。毛彬，男，1990年生，硕士，工程师。研究方向：科技信息大数据建设。宋宇，男，1990年生，硕士，助理研究员。研究方向：科技信息大数据建设。",
    "context4": "录用日期：2021-03－10"
  },
  "(上接第182页)": {
    "context1": "[4]SONG K，WANG B，FENG Z，et al.Controlling the amount of verbatim copying in abstractive summarization [C]//proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence，F，2020.   \n[5] DONG L，YANG N，WANGW，et al. Unified language model pre-training for natural language understanding and generation [C]//proceedings of the Advances in Neural Information Processing Systems，2019.   \n[6] ZANZOTTO FM，BONOV，VOCCAP，et al.GASP!Generating Abstracts of Scientific Papers from Abstracts of Cited PapersEB/O1]．[2020-05-18]．https://arxiv.org/pdf/2003. 04996. pdf.   \n[7]SUN C，QIU X，XU Y，et al.How to Fine-Tune BERT for",
    "context2": "Text Classification?[C]//proceedings of the China National Conference on Chinese Computational Linguistics，Springer, 2019. [28] MIHALCEA R，TARAU P.Textrank:bringing order into text []//proceedings of the Proceedings of the 2O04 Conference on Empirical Methods in Natural Language Processing，2004.",
    "context3": "作者简介：马浩，男，1995年生，硕士生。研究方向：自然语言处理。崔运鹏（通信作者)，男，1972年生，研究员，博士生导师。研究方向：农业信息技术，农业知识管理，数据挖掘技术研究。",
    "context4": "作者贡献声明：马浩，研究方法选取，数据处理，模型构建与训练以及撰写论文。崔运鹏，研究选题，关键研究思路指导。",
    "context5": "录用日期：2021-03－29"
  }
}