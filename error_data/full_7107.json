{
  "original_filename": "full_7107.md",
  "文本挖掘工具述评\\*": "",
  "张雯雯许鑫": {
    "context1": "华东师范大学商学院信息学系上海200241",
    "context2": "（摘要）简要介绍一些商业文本挖掘工具和开源文本挖掘工具，针对其中四款典型的开源工具进行详细的比较，包括数据格式、功能模块和用户体验三个方面;选取三种各具特色的工具就其文本分类功能进行测评。最后，针对开源文本挖掘工具的现状，提出几点建议。",
    "context3": "（关键词）文本挖掘文本挖掘工具开源文本挖掘工具",
    "context4": "（分类号）TP391"
  },
  "Review of Text Mining Tools": {
    "context1": "Zhang Wenwen Xu Xin",
    "context2": "Department of Informatics，Business School,East China Normal University，Shanghai 200241 (Abstract）Theauthors brieflydescribesomecommercialtext mining tolsandopensource textminingtools，coupled withdetailed comparisonsoffour typicalopensourcetolsconcerningdataformat，functionalmoduleanduserexperencefirstlyThen，theuthors realizetetestigoftextclasificationfunctionforthindsofdistinctivetoldsignFinall,teutorsofersomesuggestionsfor the status of open source text mining tools.",
    "context3": "(Keywords） text miningtext mining toolsopen source text mining tools"
  },
  "1 文本挖掘工具概述": {
    "context1": "文本挖掘隶属于数据挖掘这一交叉学科的一个具体研究领域,它的主要任务是从海量文本中发现潜在规律和趋势。文本类数据源由新闻文章、研究论文、书籍、期刊、报告、会议文献、技术档案、技术标准、产品样本、专利说明书、Web页面等半结构化或者高度非结构化的数据构成，含有较多机器所难于理解的自然语言，这使得文本挖掘工具与传统的以结构化数据为对象的数据挖掘工具有很大不同。"
  },
  "1.1商业文本挖掘工具": {
    "context1": "近年来,国内外文本挖掘技术发展较快,许多技术已经进入商业化阶段。各大数据挖掘工具的提供商也都推出了自己的文本挖掘工具。这些工具除具备常规的文本挖掘功能(如数据预处理、分类、聚类和关联规则等)外,针对庞大的、非结构化数据都能做出较好的应对,支持多种文档格式,文本解析能力强大,大部分支持通用数据访问，但是价格都十分昂贵。由于每个提供商的专注领域或企业背景不同,工具的定位和适用性也有所不同。本文以目前市面上较为主流的10款商业文本挖掘工具为对象，针对其不同点进行了简要的分析比较4-1,见表1。"
  },
  "1.2开源文本挖掘工具": {
    "context1": "目前开源文本挖掘较多，但大部分工具由于其固定的算法只适用于特定的场景，应用范围较窄，与其相关的文献资料极少,故不纳入本文的比较范围。本文对10款较具普适性的主流开源工具进行了比较[1-18,见表2。"
  },
  "1.3小结": {
    "context1": "大部分商业文本挖掘工具都对多语言、多格式的数据提供了良好的支持，且数据的前期处理功能都比较完善，支持结构化、半结构化和完全非结构化数据的分析处理。开源文本挖掘工具一般会有自己固有的格式要求，国外开源文本挖掘工具对中文的支持欠佳，而且大部分开源工具仍然停留在只支持结构化和半结构化数据的阶段。",
    "context2": "商业文本挖掘工具的分类、回归、聚类和关联规则算法普遍都较开源文本挖掘工具齐全,包含了目前主流的算法，只是每个工具在算法的具体实现上存在差异。同时，前者在处理庞大的数据量时依旧能够保持较高的速度和精度，后者则显得有些望尘莫及。",
    "context3": "表1商业文本挖掘工具简介",
    "context4": "<table><tr><td rowspan=1 colspan=1>工具名称</td><td rowspan=1 colspan=1>提供商</td><td rowspan=1 colspan=1>工具简介</td><td rowspan=1 colspan=1>价格（美元）</td><td rowspan=1 colspan=1>试用期</td><td rowspan=1 colspan=1>工具名称</td><td rowspan=1 colspan=1>提供商</td><td rowspan=1 colspan=1>工具简介</td><td rowspan=1 colspan=1>价格</td><td rowspan=1 colspan=1>试用期</td></tr><tr><td rowspan=1 colspan=1>IntelligentMiner for Text</td><td rowspan=1 colspan=1>IBM</td><td rowspan=1 colspan=1>挖掘结果展现能力较强，系统具有可扩展性，但是缺乏统计方法，限制了其本身的挖掘能力。在连接除DB2以外的数据库时，需要安装中间件。图形界面不友好且操作复杂，适合专业人员。</td><td rowspan=1 colspan=1>专业版$73000,学术版$3000</td><td rowspan=1 colspan=1>60天</td><td rowspan=1 colspan=1>SQL Server</td><td rowspan=1 colspan=1>Microsoft</td><td rowspan=1 colspan=1>基于OLAP,利用数据源系统对数据进行清洗、转换和加载。挖掘功能集成于SQL Serv-er系列产品中，易于使用。但是由于算法不足,解决问题有限,只适合小型业务。</td><td rowspan=1 colspan=1>$5999-$24999</td><td rowspan=1 colspan=1>180天</td></tr><tr><td rowspan=1 colspan=1>Text Miner</td><td rowspan=1 colspan=1>SAS</td><td rowspan=1 colspan=1>算法齐全,360°数据视图展示。提出 SEMMA方法论。用户界面灵活友好,但是操作复杂,分析结果难以理解，适合专业人员。</td><td rowspan=1 colspan=1>租赁</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Clear Forest</td><td rowspan=1 colspan=1>ThomosonReuters</td><td rowspan=1 colspan=1>基于文本挖掘的专利分析工具，有自己的专属领域。数据的前期处理能力较强，但在分类、聚类、关联等方面算法简陋。分析结果以列表、矩阵和聚类图呈现。缺少基本的统计方法和引证分析。</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>=</td></tr><tr><td rowspan=1 colspan=1>Text Mining</td><td rowspan=1 colspan=1>IBMSPSS</td><td rowspan=1 colspan=1>提出Crisp-DM方法论。图形界面非常友好，易于操作,支持脚本功能，应用领域广泛且维护和升级成本较低。但是缺少最新的统计方法,且分析结果与其他软件的交互性较弱。</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>Themescpease</td><td rowspan=1 colspan=1>Cartia</td><td rowspan=1 colspan=1>同样是以专利文档为基础数据，通过标准的文本挖掘流程,生成强大的主题(词汇)地形图，拥有高级神经网络技术和统计分组技术。系统响应速度较快，分析结果交互性强。</td><td rowspan=1 colspan=1>$20000起</td><td rowspan=1 colspan=1>网站提供演示版</td></tr><tr><td rowspan=1 colspan=1>IDOL Server</td><td rowspan=1 colspan=1>Autono-my</td><td rowspan=1 colspan=1>基于贝叶斯概率论和香农信息论。工具性能较高，支持SOA,提供完全可配置的监控。但是系统的维护与管理缺乏相应的图形化应用界面，且工作过程中没有相关报告输出。</td><td rowspan=1 colspan=1>$50000$3000000</td><td rowspan=1 colspan=1>二</td><td rowspan=1 colspan=1>方正智思</td><td rowspan=1 colspan=1>北大方正技术研究院</td><td rowspan=1 colspan=1>支持二次开发,具有良好的可扩展性。框架设计灵活，功能模块相对独立。</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Darwin</td><td rowspan=1 colspan=1>Oracle</td><td rowspan=1 colspan=1>通过ODBC访问数据，提供wizard引导用户构建模型。可扩展性较高，模型能够作为C、C++和Java代码导出并集成于其他应用，用户界面友好。但是工具的适用面窄，市场份额较小;数据展示需要额外的工具，交互性差。</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>TRS文本挖思（TRS）掘软件</td><td rowspan=1 colspan=1>北京拓尔TRS文本挖思（TRS）信息技术有限公司</td><td rowspan=1 colspan=1>基于统计原理的自动分类和基于语义规则的规则分类、自动过滤、政治常识校对以及标准的文本挖掘技术。系统性能较高，文本分析速度快。</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr></table>",
    "context5": "表2开源文本挖掘工具概述",
    "context6": "<table><tr><td rowspan=1 colspan=1>工具名称</td><td rowspan=1 colspan=1>工具开发者</td><td rowspan=1 colspan=1>开发语言</td><td rowspan=1 colspan=1>操作系统</td><td rowspan=1 colspan=1>授权协议</td><td rowspan=1 colspan=1>工具URL</td></tr><tr><td rowspan=1 colspan=1>Weka</td><td rowspan=1 colspan=1>新西兰怀卡托大学</td><td rowspan=1 colspan=1>C/C++</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>GPL</td><td rowspan=1 colspan=1>http://www.cs.waikato.ac.nz/ml/weka/index.html</td></tr><tr><td rowspan=1 colspan=1>GATE</td><td rowspan=1 colspan=1>谢菲尔德大学自然语言处理研究小组</td><td rowspan=1 colspan=1>JAVA</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>GPL</td><td rowspan=1 colspan=1>http: //gate.ac.uk/</td></tr><tr><td rowspan=1 colspan=1>Orange</td><td rowspan=1 colspan=1>斯洛文尼亚卢布尔雅那大学计算机与信息科学学院人工智能实验室</td><td rowspan=1 colspan=1>C++</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>GPL</td><td rowspan=1 colspan=1>http: //orange.biolab.si/</td></tr><tr><td rowspan=1 colspan=1>Bow</td><td rowspan=1 colspan=1>卡内基梅隆大学 McCallum 团队</td><td rowspan=1 colspan=1>C</td><td rowspan=1 colspan=1>Linux/Unix</td><td rowspan=1 colspan=1>LGPL</td><td rowspan=1 colspan=1>http://www. cs.cmu. edu/ ~ mccallum/bow/</td></tr><tr><td rowspan=1 colspan=1>Mallet</td><td rowspan=1 colspan=1>马萨诸塞大学 AndrewMcCallum团队</td><td rowspan=1 colspan=1>Java</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>CPL</td><td rowspan=1 colspan=1>http: //mallet.cs. umass. edu/</td></tr><tr><td rowspan=1 colspan=1>UIMA</td><td rowspan=1 colspan=1>Apache 继承 IBM UIMA</td><td rowspan=1 colspan=1>C+ +/Java</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>Apache Licence</td><td rowspan=1 colspan=1>http: //uima.apache.org/</td></tr><tr><td rowspan=1 colspan=1>LingPipe</td><td rowspan=1 colspan=1>Alias</td><td rowspan=1 colspan=1>Java</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>CPL/ Apache Licence</td><td rowspan=1 colspan=1>http://alias-i.com/lingpipe/</td></tr><tr><td rowspan=1 colspan=1>LIBSVM</td><td rowspan=1 colspan=1>台湾大学林智仁团队</td><td rowspan=1 colspan=1>Java、Matlab、C #、Ruby、Python、R、Perl、Common LISP、Labview</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>不详</td><td rowspan=1 colspan=1>http://ww.csie.ntu.edu.tw/~cjlin/libsvm/</td></tr><tr><td rowspan=1 colspan=1>OpenNLP</td><td rowspan=1 colspan=1>Apache</td><td rowspan=1 colspan=1>Java</td><td rowspan=1 colspan=1>跨平台</td><td rowspan=1 colspan=1>Apache Licence/GPL</td><td rowspan=1 colspan=1>http://incubator.apache.org/opennlp/</td></tr><tr><td rowspan=1 colspan=1>ROST CM</td><td rowspan=1 colspan=1>武汉大学ROST团队</td><td rowspan=1 colspan=1>C++/C#</td><td rowspan=1 colspan=1>Windows</td><td rowspan=1 colspan=1>不详</td><td rowspan=1 colspan=1>http://hi.baidu.com/rostcm/blog/item/6dea9f0d7a13068fd0581bf6. html</td></tr></table>",
    "context7": "目前文本挖掘还处于探索发展的阶段，其中商业文本挖掘工具的发展要快于开源文本挖掘工具。不过,任何事物都有其两面性,大部分商业软件由于其高质量和稀缺性而非常昂贵,不适合小企业和科研机构。优秀的开源文本挖掘工具则能在最大程度上满足相关需求,并且还能够支持加载使用者自己扩充的算法，或者直接嵌入到使用者自己的程序当中去。"
  },
  "2典型的开源文本挖掘工具比较": {
    "context1": "笔者选取了四款具有代表性的开源文本挖掘工具,在数据格式、功能模块和用户体验三个方面进行详细分析。其中Weka以算法全面得到了许多数据挖掘工作人员的青睐,LingPipe[是专内针对自然语言处理开发的工具包,LIBSVM是SVM模式识别与回归的工具包,ROSTCM在各大高校应用面非常广,对中文的支持最好。具体比较情况如下:"
  },
  "2.1数据格式": {
    "context1": "开源工具通常做不到像商业工具那样对各种格式的数据都提供良好的支持，而会有一定的格式限制,甚至要求自身专有的数据格式。在选择工具时，应该首先考虑数据是否符合或者经转换后能够符合工具的要求。同时,如果对工具分析的结果还要进行后续处理,也应该事先考虑到所使用的工具的输出格式是否常见或者能否转换为常见的格式，以支持后期的工作。四款开源文本挖掘工具的格式要求以及输出格式如表3所示：",
    "context2": "表3文本挖掘典型开源工具数据格式比较",
    "context3": "<table><tr><td rowspan=1 colspan=1>工具属性</td><td rowspan=1 colspan=1>Weka</td><td rowspan=1 colspan=1>LingPipe</td><td rowspan=1 colspan=1>LIBSVM</td><td rowspan=1 colspan=1>ROST CM</td></tr><tr><td rowspan=1 colspan=1>输入格式</td><td rowspan=1 colspan=1>ARFF、CSV、XRFF、C4.5(.data和.name)</td><td rowspan=1 colspan=1>XML、HTML、Text</td><td rowspan=1 colspan=1>特定格式</td><td rowspan=1 colspan=1>Text</td></tr><tr><td rowspan=1 colspan=1>输出格式</td><td rowspan=1 colspan=1>ARFF、CSV、通过JDBC存入数据库</td><td rowspan=1 colspan=1>XML</td><td rowspan=1 colspan=1>model</td><td rowspan=1 colspan=1>Text</td></tr></table>",
    "context4": "可见，四款开源工具都有自己固定的格式要求,需要针对采集到的数据做格式化处理。虽然Weka支持常见的CSV格式,但是在进行后期分析时ARFF格式的文档效果更好，一般会使用其自带工具将CSV转换为ARFF。Weka不支持txt格式的文档,需要使用者用另外的工具或者自己编写代码实现格式转换。LIBSVM使用数据格式为：<label $>$ <index1 $>$ ： $<$ valuel $>$ <index2 >: $<$ value2>…,相关帮助文档里提供了格式转换函数write4libsvm（）。Lingpipe 和 Rost CM都支持 Text文档。",
    "context5": "LIBSVM的数据输出格式需要专用的工具才能打开查看,难以集成到其他应用。其他三个开源工具的数据输出格式更易于扩展使用。"
  },
  "2.2功能模块": {
    "context1": "功能模块是工具开发时的重中之重，但功能最全的并非就是最好的,因为全面经常会导致浅显，而不够深入、不够专业的分析结果是使用人员所不愿见到的。应该根据实际情况,针对性地选择最合适的工具来完成分析工作,这样可达到事半功倍的效果。因此,工具的功能模块是否符合自己的要求，通常直接左右着使用者的挑选意愿。笔者对四款开源的文本挖掘工具从文本预处理操作步骤、文本分类和回归、文本聚类和关联规则的各种常见算法以及能否访问数据库、模型评估和二次开发接口等方面进行了较为详细的比较。",
    "context2": "文本预处理是文本挖掘过程中至关重要的一步，它直接影响到分类、聚类、关联规则等后期工作的效果。其中文本分词、去停用词、词频分析、文本特征提取是较为常规的操作，也是文本预处理最核心的内容。",
    "context3": "文本分类是在经过预处理的数据上，选择分类器进行训练、评价和反馈结果的过程。本文中,笔者仅针对分类器进行比较。常见的分类算法有TF-IDF分类、Naive Bayes分类、 $\\mathrm { K n n }$ 分类、决策树分类、神经网络分类和支持向量分类机（SVM）[9-20。分类器不存在优劣，每一组数据都有其适合的分类器,所以在训练分类模型时，需要尝试不同的分类器和不同的参数，以实现模型优化。",
    "context4": "文本聚类包括基于划分的聚类、基于层次的聚类、基于密度的聚类、基于网格和基于模型的聚类。基于划分的聚类主要包括K-means、X-means、K-medoid 和ISODATA,其中X-means 是K-means算法的改进。基于层次的聚类主要包括 Birch Clusterer、Cure Clusterer、Single Link Clusterer、Complete Link Clusterer 和 AverageLink Clusterer。基于密度的聚类主要包括DBScan和Optics。基于网格的聚类主要包括 Sting Clusterer和",
    "context5": "Clique Clusterer,Cobweb 属于基于模型的聚类[1 -22]表3所列出的聚类算法并没有完全包含上述算法，因为文本聚类作为一个尚未完全成熟的研究领域，每款开源工具实现方式各异，所以笔者只针对四款开源工具聚类算法的并集进行分析讨论。",
    "context6": "回归分析用于确定两种或两种以上变数间相互依赖的定量关系，运用十分广泛。一般会将回归分析纳入文本分类的范畴，但是本文为了更清晰地比较每款工具不同回归算法,所以单独拿出来分析比较。",
    "context7": "除了上述的功能以外,工具的适用范围与可扩展性、是否支持访问数据库、二次开发接口，以及分类、聚类训练模型的评估等因素也是在挑选工具时所必须考虑的。具体的比较结果3-24如表4所示:",
    "context8": "表4文本挖掘典型开源工具功能比较",
    "context9": "<table><tr><td rowspan=1 colspan=2>工具属性</td><td rowspan=1 colspan=1>Weka</td><td rowspan=1 colspan=1>Lingpipe</td><td rowspan=1 colspan=2>LIBSVM</td><td rowspan=1 colspan=2>ROST CM</td></tr><tr><td rowspan=15 colspan=1></td><td rowspan=1 colspan=1>噪音消除</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>分词</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>拼写检查</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>词性标注</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>去停用词</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>命名实体识别</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>词频分析</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>情感分析</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>社会网络和语义网络分析</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>相似性分析</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>支持自定义词库</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>语言辨别</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>特征表示</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>特征提取</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>奇异值分解(SVD)</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=6 colspan=1>分美</td><td rowspan=1 colspan=1>TF-DF分类器</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Naive Bayes</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Knn</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>决策树</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>神经网络</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>支持向量分类机</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=8 colspan=1>聚类</td><td rowspan=1 colspan=1>Single Link Clusterer</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Complete Link Clusterer</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Average Link Clusterer</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>K-means</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>X-means</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>DBScan</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Optics</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Cobweb</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=4 colspan=1>长</td><td rowspan=1 colspan=1>Apriori</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Tertius</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>FPGrowth</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>FilteredAssociator</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=4 colspan=1>回归</td><td rowspan=1 colspan=1>Logistic Regression</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Linear Regression</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Pace Regression</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>SVR(SVM)</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=2>字符语言建模</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=2>访问数据库</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=2>模型评估</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=2></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=2>二次开发接口</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=2>√</td><td rowspan=1 colspan=1></td></tr></table>",
    "context10": "2.2.1 文本预处理Rost CM和LingPipe的文本预处理功能都比较完善，但是前者的中文支持更好。Weka不支持中文的分词和消噪，需要自己修改程序实现。目前文本特征表示模型有向量空间模型、布尔模型、概率检索模型、语言模型等，其中向量空间模型处于主流地位。Weka的过滤器能将ARFF格式转换为向量空间模型。LIBSVM的前期处理功能相对较弱,只针对数据进行特征表示和特征提取以实现降维。",
    "context11": "2.2.2文本分类四款开源工具中，Weka的分类算法最为完善，ROSTCM的强项在于前期的中文预处理,而后面算法都十分简陋。LIBSVM提供了c-SVC和$\\mathrm { v } \\mathrm { \\ - s V C }$ 两种基于SVM的分类算法。Weka的SMO分类器实现了SVM分类,同时它也能够调用LIBSVM，但是Weka只是提供了LIBSVM的Wrapper调用机制,必须安装LIBSVM后将附带的jar路径添加到Weka的后动路径中。在Weka的平台下调用LIBSVM,可以非常方便地和其他算法进行同一配置下的比较。",
    "context12": "2.2.3文本聚类同文本分类一样,Weka 囊括了大部分聚类方式,但是其中一些算法并不适用于自然语言处理。相反，由于LingPipe是专门针对自然语言处理开发的工具，它的算法虽较少，分析结果却相对优秀。LIBSVM和ROSTCM都不带有文本聚类功能。",
    "context13": "2.2.4关联规则由于关联规则在文本挖掘领域的发展还不够成熟，参与比较的四款工具只有Weka带有关联规则的算法实现;Weka本身主要是用于结构化数值型数据挖掘分析的工具，所以它的关联规则功能对文本,特别是中文文本的支持也是欠佳的。",
    "context14": "2.2.5回归Weka和LingPipe都把回归分析放在分类器的.jar包中，Weka分别实现了线性回归、逻辑回归和逐步回归，LingPipe只有逻辑回归算法。LIBSVM提供了 $\\pmb { \\varepsilon } { \\mathrm { - } } \\mathbf { S } \\mathbf { V } \\mathbf { R }$ 和 $\\mathbf { v } { \\ - } \\mathbf { S } \\mathbf { V } \\mathbf { R }$ 两种基于SVM的回归算法。",
    "context15": "2.2.6其他LingPipe支持字符语言建模、医学文献下载/解析/索引、数据库文本挖掘。Weak和LingPipe都支持数据库访问，提升了工具的适用范围。四款开源工具中,只有ROSTCM不提供二次开发接口,其余三者均能在相应的开发环境下按需修改。Weka在算法实现上较为优秀，也支持新算法的添加。"
  },
  "2.3用户体验": {
    "context1": "用户体验在评估的过程中也占据了重要的位置，本文的用户体验比较指标主要有图形化操作界面、命令行操作、辅助文档是否齐全和支持多层次分析人员等。具体结果如表5所示：",
    "context2": "表5文本挖掘典型开源工具用户体验比较",
    "context3": "<table><tr><td rowspan=1 colspan=1>工具属性</td><td rowspan=1 colspan=1>Weka</td><td rowspan=1 colspan=1>LingPipe</td><td rowspan=1 colspan=1>LIBSVM</td><td rowspan=1 colspan=1>ROST CM</td></tr><tr><td rowspan=1 colspan=1>图形化界面</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>命令行操作</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>辅助文档齐全</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1>√</td></tr><tr><td rowspan=1 colspan=1>支持多层次分析人员</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>可集成于其他应用</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>结论易于理解</td><td rowspan=1 colspan=1>√</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>√</td></tr></table>",
    "context4": "可以看出,Weka的效果较好,ROSTCM虽然支持图形化界面的操作,但是后期算法较为简陋,所以不支持高层次分析人员，只适合用来做前期的文本处理工具。LIBSVM主要依靠命令行和嵌入其他程序操作,没有图形化界面，使用难度较大，适合专业人士使用。LingPipe的使用主要靠引用工具包，自己编译程序来实现各种挖掘功能。前三款开源工具都可以按照自己的需要打包加载到自己的程序里面，比如可以将LIBSVM加载到Weka程序里面。"
  },
  "3基于文本分类的工具测评": {
    "context1": "为了更深入地了解文本挖掘工具的运作情况和它们在实现相同算法时的差异，笔者结合实际情况，选取了Weka、LingPipe进行实验测评。同时考虑到文本挖掘几个主要的功能模块中分类算法和聚类算法的实现最为成熟，但是文本聚类的分析对机器的性能要求极高，故本文在测试过程中选取了较为经典且两款工具都含有的Naive Bayes分类器。"
  },
  "3.1实验设计": {
    "context1": "由于实验的分类语料和测试语料都是中文，而ROSTCM的中文预处理能力较强,但文本分词结果欠佳,后期文本分类算法也比较简单,同时Weka和Ling-Pipe的中文预处理能力较弱，后期分类算法比较优秀，所以实验采用取长补短的策略,即使用IKAnalyze先对语料库做分词处理,再用ROSTCM做文本预处理工作,然后针对Weka和LingPipe的NaiveBayes分类算法进行比较。具体实验步骤安排如下: $\\textcircled{1}$ 网上下载公开的文本测试语料库,实验选取了复旦大学李荣陆提供的中文语料库； $\\textcircled{2}$ 用IKAnalyze对获取到的语料进行分词处理; $\\textcircled{3}$ 对分好词的语料用ROSTCM实现文本预处理,主要包括去停用词、进行词频统计和文本特征提取; $\\textcircled{4}$ 处理好的文本一式两份，一份用于LingPipe分类实验，一份经过转换程序转换为Weka要求的ARFF格式进行分类实验7-28。"
  },
  "3.2实验结果分析": {
    "context1": "由于两款工具对测试结果的评价指标不尽相同，笔者选取了两者的交集，主要对文本分类结果的总体评价、每个类别的详细精度以及对分类结果的混合矩阵(Confusion Matrix)三方面来分析实验结果。",
    "context2": "两款工具文本分类的总体概况如表6所示：",
    "context3": "表6Weka和LingPipe文本分类结果的总体比较",
    "context4": "<table><tr><td rowspan=1 colspan=1>评价指标</td><td rowspan=1 colspan=1>Weka</td><td rowspan=1 colspan=1>LingPipe</td></tr><tr><td rowspan=1 colspan=1>正确率</td><td rowspan=1 colspan=1>79.580 6%</td><td rowspan=1 colspan=1>99.889 6%</td></tr><tr><td rowspan=1 colspan=1>错误率</td><td rowspan=1 colspan=1>20.419 4%</td><td rowspan=1 colspan=1>0.110 4%</td></tr><tr><td rowspan=1 colspan=1>卡巴统计</td><td rowspan=1 colspan=1>0.775 9</td><td rowspan=1 colspan=1>0.998 811 343 182 203 9</td></tr><tr><td rowspan=1 colspan=1>精确度</td><td rowspan=1 colspan=1>0.802</td><td rowspan=1 colspan=1>0.998 896 247 240 618 1</td></tr><tr><td rowspan=1 colspan=1>召回率</td><td rowspan=1 colspan=1>0.796</td><td rowspan=1 colspan=1>0.998 896 247 240 618 1</td></tr><tr><td rowspan=1 colspan=1>文本总数</td><td rowspan=1 colspan=2>906</td></tr></table>",
    "context5": "可以明显看出LingPipe的正确分类率高出Weka$20 \\%$ ,接近 $100 \\%$ ,同时LingPipe 的召回率（recall）和准确率(precision)都非常令人满意。此外,可以通过其分析结果评估项中的数据计算得出置信度为$9 5 \\%$ 。",
    "context6": "再从两款工具的详细分类精度来进行比较,其中LingPipe的TPRate和FPRate两项数据工具本身并未直接给出，但是为了方便比较分析,笔者经计算将其罗列出来。具体数据如表7和表8所示：",
    "context7": "表7Weka文本分类的详细精度",
    "context8": "<table><tr><td rowspan=1 colspan=1>Class</td><td rowspan=1 colspan=1>正确率</td><td rowspan=1 colspan=1>错误率</td><td rowspan=1 colspan=1>精确率</td><td rowspan=1 colspan=1>召回率</td><td rowspan=1 colspan=1>F-Measure</td></tr><tr><td rowspan=1 colspan=1>C1-Art</td><td rowspan=1 colspan=1>0.707</td><td rowspan=1 colspan=1>0.027</td><td rowspan=1 colspan=1>0.761</td><td rowspan=1 colspan=1>0.707</td><td rowspan=1 colspan=1>0.733</td></tr><tr><td rowspan=1 colspan=1>C2-Literature</td><td rowspan=1 colspan=1>0.606</td><td rowspan=1 colspan=1>0.021</td><td rowspan=1 colspan=1>0.526</td><td rowspan=1 colspan=1>0.606</td><td rowspan=1 colspan=1>0.563</td></tr><tr><td rowspan=1 colspan=1>C3-Education</td><td rowspan=1 colspan=1>0.661</td><td rowspan=1 colspan=1>0.022</td><td rowspan=1 colspan=1>0.672</td><td rowspan=1 colspan=1>0.661</td><td rowspan=1 colspan=1>0.667</td></tr><tr><td rowspan=1 colspan=1>C4-Philosophy</td><td rowspan=1 colspan=1>0.591</td><td rowspan=1 colspan=1>0.01</td><td rowspan=1 colspan=1>0.743</td><td rowspan=1 colspan=1>0.591</td><td rowspan=1 colspan=1>0.658</td></tr><tr><td rowspan=1 colspan=1>C5-History</td><td rowspan=1 colspan=1>0.737</td><td rowspan=1 colspan=1>0.033</td><td rowspan=1 colspan=1>0.73</td><td rowspan=1 colspan=1>0.737</td><td rowspan=1 colspan=1>0.734</td></tr><tr><td rowspan=1 colspan=1>C6-Space</td><td rowspan=1 colspan=1>0.899</td><td rowspan=1 colspan=1>0.016</td><td rowspan=1 colspan=1>0.873</td><td rowspan=1 colspan=1>0.899</td><td rowspan=1 colspan=1>0.886</td></tr><tr><td rowspan=1 colspan=1>C7-Energy</td><td rowspan=1 colspan=1>0.688</td><td rowspan=1 colspan=1>0.006</td><td rowspan=1 colspan=1>0.815</td><td rowspan=1 colspan=1>0.688</td><td rowspan=1 colspan=1>0.746</td></tr><tr><td rowspan=1 colspan=1>C8-Electronics</td><td rowspan=1 colspan=1>0.556</td><td rowspan=1 colspan=1>0.001</td><td rowspan=1 colspan=1>0.938</td><td rowspan=1 colspan=1>0.556</td><td rowspan=1 colspan=1>0.698</td></tr><tr><td rowspan=1 colspan=1>C9-Communication</td><td rowspan=1 colspan=1>0.76</td><td rowspan=1 colspan=1>0.008</td><td rowspan=1 colspan=1>0.731</td><td rowspan=1 colspan=1>0.76</td><td rowspan=1 colspan=1>0.745</td></tr><tr><td rowspan=1 colspan=1>C10-Computer</td><td rowspan=1 colspan=1>0.899</td><td rowspan=1 colspan=1>0.006</td><td rowspan=1 colspan=1>0.947</td><td rowspan=1 colspan=1>0.899</td><td rowspan=1 colspan=1>0.922</td></tr><tr><td rowspan=1 colspan=1>C11-Mine</td><td rowspan=1 colspan=1>0.545</td><td rowspan=1 colspan=1>0.011</td><td rowspan=1 colspan=1>0.643</td><td rowspan=1 colspan=1>0.545</td><td rowspan=1 colspan=1>0.59</td></tr><tr><td rowspan=1 colspan=1>C12-Transport</td><td rowspan=1 colspan=1>0.879</td><td rowspan=1 colspan=1>0.038</td><td rowspan=1 colspan=1>0.614</td><td rowspan=1 colspan=1>0.879</td><td rowspan=1 colspan=1>0.723</td></tr><tr><td rowspan=1 colspan=1>C13-Enviornment</td><td rowspan=1 colspan=1>0.949</td><td rowspan=1 colspan=1>0.01</td><td rowspan=1 colspan=1>0.922</td><td rowspan=1 colspan=1>0.949</td><td rowspan=1 colspan=1>0.935</td></tr><tr><td rowspan=1 colspan=1>C14-Agriculture</td><td rowspan=1 colspan=1>0.96</td><td rowspan=1 colspan=1>0.011</td><td rowspan=1 colspan=1>0.914</td><td rowspan=1 colspan=1>0.96</td><td rowspan=1 colspan=1>0.937</td></tr><tr><td rowspan=1 colspan=1>Weighted Avg</td><td rowspan=1 colspan=1>0.796</td><td rowspan=1 colspan=1>0.017</td><td rowspan=1 colspan=1>0.802</td><td rowspan=1 colspan=1>0.796</td><td rowspan=1 colspan=1>0.795</td></tr></table>",
    "context9": "由表7可以看出,Weka 对 C6-Space、C10-Computer、C13-Enviornment、C14-Agriculture 分类结果较好,笔者比对原数据发现这四类样本数据包含较多的数值型数据和英文,这说明Weka比较擅长处理数值型数据和英文文本,而对中文的处理结果欠佳。表8的数据是非常令人欣喜的，趋近 $100 \\%$ 的准确率，但是在处理 $_ { \\mathrm { C l 0 - C o m - } }$ puter这个类别时出现了一点误差,比对原数据发现此样本数据的中英文混合比例较大,可以得出Lingpipe面对两种语言的混合样本时也许会出现偏差。",
    "context10": "表8LingPipe文本分类的详细精度",
    "context11": "<table><tr><td rowspan=1 colspan=1>Class</td><td rowspan=1 colspan=1>正确率</td><td rowspan=1 colspan=1>错误率</td><td rowspan=1 colspan=1>精确度</td><td rowspan=1 colspan=1>召回率</td><td rowspan=1 colspan=1>F-Measure</td></tr><tr><td rowspan=1 colspan=1>C1-Art</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0.001 2</td><td rowspan=1 colspan=1>0.99</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0.995 0</td></tr><tr><td rowspan=1 colspan=1>C2-Literature</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C3-Education</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C4-Philosophy</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C5-History</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C6-Space</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C7-Energy</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C8-Electronics</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C9-Communication</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C10-Computer</td><td rowspan=1 colspan=1>0.989 9</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0.989 9</td><td rowspan=1 colspan=1>0.994 9</td></tr><tr><td rowspan=1 colspan=1>C11-Mine</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C12-Transport</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C13-Enviornment</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>C14-Agriculture</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr><tr><td rowspan=1 colspan=1>Weighted Avg</td><td rowspan=1 colspan=1>0.999 3</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>1</td></tr></table>",
    "context12": "最后通过混合矩阵来比较两款工具的分类结果。混合矩阵是一个非常直观的展示工具,如果对角线上的数值越大，其余的数值越小,则说明分类结果越好。具体如表9和表10所示：",
    "context13": "表9Weka 混合矩阵",
    "context14": "<table><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>abCDefghijk1mn&lt;--clssifed as</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>7000001701200000a=Cl-Art</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>089010100007001b=C10-Computer</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>001891201000200c=C11-Mine</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>001511011101100d=C12-Transport</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>001094100003000e=C13-Enviomment</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>001019600011000f=C14-Agriculture</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>201200203130100g=C2-Literature</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2011002139300001h=C3-Education</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2000012102630000i=C4-Philosophy</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>1600011413730000j=C5History</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>050040010089000k=C6-Space</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0045000000122001=C7Energy</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000200310001155m=C8-Electronics</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>001300010000119n=C9-Communication</td></tr></table>",
    "context15": "表10 LingPipe 混合矩阵",
    "context16": "<table><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>abcDefghiik1mN&lt;-clssified as</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>990000000000000a=C1-Art</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>03300ooo0oo0ooob=C2-Literature</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>005900000000000c=C3-Education</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000440000000000d=C4-Philosophy</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000099000000000e=C5-History</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000009900。00。0。f=c6-Space</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000000320000000g=C7-Energy</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000000o27000000h=C8-Electronics</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000000oo25o0000i=C9-Communication</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>100000000980000j=C10-Computer</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>000000000033000k=C11-Mine</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0000000000058001=C12-Transport</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>00000000000990m=C13-Enviomment</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>oo000o000o00o100n=C14-Agriculture</td></tr></table>",
    "context17": "可以看出,LingPipe的数据几乎都是集中于对角线上的,所以LingPipe的文本分类结果较Weka优秀。",
    "context18": "通过前面对两款工具分类结果的详细分析，可以看出LingPipe在自然语言处理方面较Weka强,Weka更擅长数值型数据和英文文本的分析。但是在试验过程中,笔者也发现面对相同的数据量，Weka的处理效率明显高于LingPipe,且执行期间LingPipe需占用大量内存。此外,LingPipe给出的分类结果更为详细,甚至细化到对每个测试文本的各种指标评估，可以支持不同的分析需要，非常适合不同的分析人员。"
  },
  "4总结": {
    "context1": "目前国内文本挖掘的研究大部分仍然停留在对算法的改进上,文本挖掘工具的应用相对欠缺,且使用的工具较为集中,主要是Weka和ROSTCM。Weka在自动分类领域,使用频次较高,但是大部分只针对结构化的数据。如图书馆的流通挖掘和读者借阅行为分析等，都是以数据库里规范的数据为分析对象，缺少以非结构化数据为处理对象的应用。ROSTCM情感分析和社会网络分析功能使用者众多，但是分类和聚类等常规的文本挖掘算法却乏善可陈,因此相关的应用寥寥无几。LingPipe和LIBSVM的相关研究几乎都是基于算法改进的,实际应用较少。但是笔者通过比较、实验发现，Weka和ROSTCM的处理结果并不尽如人意。所以文本挖掘还有很长的路要走，更多优秀的开源文本挖掘工具,如LingPipe和LIBSVM等,需得到应有的重视。针对国内文本挖掘工具的现状,笔者提出"
  },
  "几点建议：": {
    "context1": "·文本挖掘工具的英文文本挖掘相对于中文的文本挖掘成熟很多，国外的一些开源工具在面对汉语时显得有些力不从心,这方面国内的ROSTCM做得是比较好的，但是它后期的算法较弱，所以应该试图将国外开源工具先进齐全的算法与国内开源工具对中文的良好支持结合起来。",
    "context2": "·在将现存的数据挖掘技术引入文本挖掘领域的同时也要考虑到文本挖掘技术的特殊性，例如语义关系的处理、非结构化文本对时间和空间的资源需求量较大等。可以针对这些特性开发新的文本挖掘算法，以提高结果的满意度。",
    "context3": "·开源工具对数据输入格式要求不同，需要自己用程序转换，要求使用者有一定的编程基础，所以开源工具应该更进一步支持多种常用数据格式。",
    "context4": "·目前较主流的开源文本挖掘工具用户体验非常不理想,大部分以工具包呈现,没有直观的图形化界面，使用难度较大，需要增强人机交互的便捷性和工具的易用性。",
    "context5": "·使用者可适当提高自身的编程能力，不将研究或应用局限于可视化的挖掘工具，而是尝试使用甚至改进一些优秀的开源挖掘工具包,以适应目前易用的开源文本挖掘工具欠缺的现状。"
  },
  "参考文献:": {
    "context1": "[1]Feldman R，Sanger J. The text mining handbook [M]．Cambridge:Cambridge University Press,2007.   \n[2]钱峰.国内数据挖掘工具研究综述[].情报杂志,2008（10)： 11 -13.   \n[3]王敏,李海存,张玢,等.国外专利文本挖掘可视化工具研究 [.图书情报工作,2009,53(24):29-32.   \n[4]Yang Yunyun,Akers L,Klose T,et al. Text mining and visualization tools- Impressions of emerging capabilities []．World Patent Information,2008,30(4):280-293.   \n[5]谌志群,张国煊.文本挖掘研究进展[]．模式识别与人工智 能,2005(1) :65 -71.   \n[6]van Gemert J.Text mining tools on the Internet $\\mathbb { I }$ . Intelligent Sensory Information Systems,2000,25:1-68.   \n[7]杨建武.文本挖掘工具与应用[01]．[2011-11-20].http:// cn.minidx.com/index.php? option $=$ com_docman&task $=$ doc_ view&gid $= 4 4$   \n[8]周宇葵.国外数据挖掘与知识发现工具的评估研究[].长沙： 中南大学湘雅医学院，2007.   \n[9]张雪英.国外先进数据挖掘工具的比较分析[].计算机工程， 2003(16):1-3. via social networks among homeless populations .The New Review of Information Behaviour Research,2003,4(1):95-108.   \n[3]Mooko N P.A study of the family information needs and information seeking behaviors of rural women in Botswana[D].Pittsburgh:University of Pittsburgh,2002.   \n[4] Hodge I,Dunn J,Monk S,et al.Barriers to participation in residual rural labour markets[]．Work，Employment and Society, 2002,16(3):457 -476.   \n[25]Lindsay C,McCracken M,McQuaid R W. Unemployment duration and employability in remote rural labour markets[．Journal of Rural Studies,2003,19(2)：187 -200.   \n[6]Wathen C N,Harris R M. An examination of the health information seeking experiences of women in rural Ontario,Canada[EB/OL]. [011-08 -06 .http://informationr.net/ir/11-4/paper267.html.   \n[7]Spink A，ColeC.Informationand poverty:Information－seeking channels used by African American low- income households ．Library and Information Science Research,2001,23(1):45 -65."
  },
  "[28]李丰春．论社会网络与农村剩余劳动力转移—对农村剩余劳动力转移途径的经济社会学解读[．安徽农业科学，2008,36(2):11594 -11595.": {
    "context1": "[29]曹子玮．农民工的再建构社会网与网内资源流向[．社会学(作者简介）刘亚,女,1983年生,博士研究生,发表论文6篇",
    "context2": "研究， $2 0 0 3 \\left( \\ 3 \\right) : \\ 9 9 \\mathrm { ~ - 1 1 0 ~ }$   \n[0] 叶敬忠．农民发展创新中的社会网络[].农业经济问题,2004(9):37 -43.  \nβ1]王成斌．农民外出就业：乡土社会网络的困境与制度化路径的作用．学海， $2 0 0 4 ( 6 ) : 7 9 - 8 2$   \n[2] 王莉，杨印生．农村劳动力流动的社会网络效应分析[.农村技术经济， $2 0 0 5 ( 5 ) : 2 2 - 2 7$   \nB3] 王欢,张亮,马敬东,等.贫困农村地区健康风险管理中的整体社会网络分析——以贵州省某村庄为例[．中国卫生经济，$2 0 0 8 , 2 7 \\bigl ( 1 2 \\bigr ) : 3 1 - 3 4 .$   \nB4] 王瑞新，胡少龙.农村经纪人信息交流的社会网络分析——以邓州市为例的研究[.中国西部科技， $2 0 0 9 ( 9 ) : 8 2 \\ : - 8 3$ .  \nB5] 周大鸣.技术与社会网络资本——关于中国农村妇女社会网络资本的研究视角.湖北民族学院学报(哲学社会科学版），$2 0 0 5 , 2 5 ( 6 ) \\colon 2 3 - 2 7 .$   \nB6] 罗家德．社会网分析讲义M．北京：社会科学文献出版社,2005:133.  \nβ7]张文宏，阮丹青，潘允康．天津农村居民的社会网[．社会学研究，1999(2)：109-118.  \nB8]Agrest A，Agrest BF. Statistical analysis of qualitative variation[．Sociological Methodology，1978,9:204-237."
  },
  "(上接第31页)": {
    "context1": "[0]马准中.对三种数据挖掘工具的比较[].实验科学与技术，2005(1) :37 -38.  \n[1]李讽.基于GATE的中文信息抽取系统的开发和实现[D].北京：中国科学院研究生院，2006.  \n[2]孙青.GATE:一个开放的自然语言处理平台 [OL]．[2011－12-01].http://www.docin.com/p-19298621.html.  \n[3]McCallum A K. Bow:A toolkit for statistical language modeling,text retrieval，classification and clustering [OL]．[2O11 -11 -20l .http://www.cs.cmu.edu/\\~mccallum/bow.  \n[4]McCallm A K. MALLET:A machine learning for language toolkit[o1]．[011 -11 -20] .http: $/$ /mallet. cs. umass. edu.  \n[5] Carpenter B.LingPipe for 99.99 $\\%$ recall of gene mentions [o1] .[2011- 12-1o]．http://www.colloquial.com/carp/Publica-tions/biocreative-8-alias-i.pdf.  \n[6] Chang Chih -Chung,Lin Chih - Jen.LIBSVM-A library for sup-port vector machines [O1]．[011-12-13] .http://www.csie.ntu.edu.tw/\\~cjlin/libsvm.  \n[7]Alias-i.LingPipe [OL]．[2011 -12-11] .htp://alias-i.com/lingpipe.  \n[8]王娜.WEKA3-5-5 Explorer用户指南 [OL]．[2011-12-04].http://download.csdn.net/source/616170."
  },
  "[19]姚天昉,彭思崴.汉语主客观文本分类方法的研究[C]//中国": {
    "context1": "中文信息学会.全国信息检索与内容安全学术会议论文集.北京：中国中文信息学会,2007:1-7.  \n[0] 陈晓云.文本挖掘若干关键技术研究[D].上海:复旦大学,2005.  \n[1]钱小军.WEB文本挖掘技术研究及其实现[D].杭州:浙江大学,2002.  \n[2] 徐建锁.知识管理和文本挖掘的若干问题研究[D]．天津：天津大学,2004.  \n[3]ROST 虚拟学习团队.ROSTCM6使用手册[I]．[011-12－18].http://hi.baidu.com/rostcm/blog/item/6dea9fOd7al3068fd0581bf6.html.  \n[4]曹斌.互联网上旅游评论的情感分析及其有用性研究[].哈尔滨：哈尔滨工业大学,2008.  \n[5]Machine Learning Group at University of Waikato.Weka OI]．[011-12-10] .http://www.cs.waikato.ac.nz/ml/weka/index.html.  \n[6]中文自然语言处理开放平台 [EB/OL]．[2011－12－11] .ht-tp://www.nlp.org.cn/docs/doclist.php? cat_id $=$ 16&type $= 1 5$   \n[7]林莉莉.基于JAVA的WEKA数据挖掘平台分析及二次开发[].南京：河海大学,2007.  \n[8] 陈嘉勇.基于WEKA平台的文本聚类研究与实现[．中国管理信息化,2009(21):9-12.  \n[9]袁军鹏,朱东华,李毅,等.文本挖掘技术研究进展[].计算机应用研究,2006(2):1-4."
  }
}